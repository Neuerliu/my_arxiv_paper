{"2023-06-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.03091v1","updated":"2023-06-05T17:59:41Z","published":"2023-06-05T17:59:41Z","title":"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems","summary":"  Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench consists of three interconnected evaluation tasks:\nRepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P\n(Pipeline). Each task respectively measures the system's ability to retrieve\nthe most relevant code snippets from other files as cross-file context, predict\nthe next line of code with cross-file and in-file context, and handle complex\ntasks that require a combination of both retrieval and next-line prediction.\nRepoBench aims to facilitate a more complete comparison of performance and\nencouraging continuous improvement in auto-completion systems. RepoBench is\npublicly available at https://github.com/Leolty/repobench.\n","authors":["Tianyang Liu","Canwen Xu","Julian McAuley"],"pdf_url":"https://arxiv.org/pdf/2306.03091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03090v1","updated":"2023-06-05T17:59:21Z","published":"2023-06-05T17:59:21Z","title":"Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For\n  Scoring and Providing Actionable Insights on Classroom Instruction","summary":"  Coaching, which involves classroom observation and expert feedback, is a\nwidespread and fundamental part of teacher training. However, the majority of\nteachers do not have access to consistent, high quality coaching due to limited\nresources and access to expertise. We explore whether generative AI could\nbecome a cost-effective complement to expert feedback by serving as an\nautomated teacher coach. In doing so, we propose three teacher coaching tasks\nfor generative AI: (A) scoring transcript segments based on classroom\nobservation instruments, (B) identifying highlights and missed opportunities\nfor good instructional strategies, and (C) providing actionable suggestions for\neliciting more student reasoning. We recruit expert math teachers to evaluate\nthe zero-shot performance of ChatGPT on each of these tasks for elementary math\nclassroom transcripts. Our results reveal that ChatGPT generates responses that\nare relevant to improving instruction, but they are often not novel or\ninsightful. For example, 82% of the model's suggestions point to places in the\ntranscript where the teacher is already implementing that suggestion. Our work\nhighlights the challenges of producing insightful, novel and truthful feedback\nfor teachers while paving the way for future research to address these\nobstacles and improve the capacity of generative AI to coach teachers.\n","authors":["Rose E. Wang","Dorottya Demszky"],"pdf_url":"https://arxiv.org/pdf/2306.03090v1.pdf","comment":"In the Proceedings of Innovative Use of NLP for Building Educational\n  Applications 2023; The code and model outputs are open-sourced here:\n  https://github.com/rosewang2008/zero-shot-teacher-feedback"},{"id":"http://arxiv.org/abs/2209.06794v4","updated":"2023-06-05T17:55:12Z","published":"2022-09-14T17:24:07Z","title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model","summary":"  Effective scaling and a flexible task interface enable large language models\nto excel at many tasks. We present PaLI (Pathways Language and Image model), a\nmodel that extends this approach to the joint modeling of language and vision.\nPaLI generates text based on visual and textual inputs, and with this interface\nperforms many vision, language, and multimodal tasks, in many languages. To\ntrain PaLI, we make use of large pre-trained encoder-decoder language models\nand Vision Transformers (ViTs). This allows us to capitalize on their existing\ncapabilities and leverage the substantial cost of training them. We find that\njoint scaling of the vision and language components is important. Since\nexisting Transformers for language are much larger than their vision\ncounterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the\nbenefits from even larger-capacity vision models. To train PaLI, we create a\nlarge multilingual mix of pretraining tasks, based on a new image-text training\nset containing 10B images and texts in over 100 languages. PaLI achieves\nstate-of-the-art in multiple vision and language tasks (such as captioning,\nvisual question-answering, scene-text understanding), while retaining a simple,\nmodular, and scalable design.\n","authors":["Xi Chen","Xiao Wang","Soravit Changpinyo","AJ Piergiovanni","Piotr Padlewski","Daniel Salz","Sebastian Goodman","Adam Grycner","Basil Mustafa","Lucas Beyer","Alexander Kolesnikov","Joan Puigcerver","Nan Ding","Keran Rong","Hassan Akbari","Gaurav Mishra","Linting Xue","Ashish Thapliyal","James Bradbury","Weicheng Kuo","Mojtaba Seyedhosseini","Chao Jia","Burcu Karagol Ayan","Carlos Riquelme","Andreas Steiner","Anelia Angelova","Xiaohua Zhai","Neil Houlsby","Radu Soricut"],"pdf_url":"https://arxiv.org/pdf/2209.06794v4.pdf","comment":"ICLR 2023 (Notable-top-5%)"},{"id":"http://arxiv.org/abs/2306.03081v1","updated":"2023-06-05T17:55:05Z","published":"2023-06-05T17:55:05Z","title":"Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs","summary":"  Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.\n","authors":["Alexander K. Lew","Tan Zhi-Xuan","Gabriel Grand","Vikash K. Mansinghka"],"pdf_url":"https://arxiv.org/pdf/2306.03081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03079v1","updated":"2023-06-05T17:53:41Z","published":"2023-06-05T17:53:41Z","title":"Machine Learning and Statistical Approaches to Measuring Similarity of\n  Political Parties","summary":"  Mapping political party systems to metric policy spaces is one of the major\nmethodological problems in political science. At present, in most political\nscience project this task is performed by domain experts relying on purely\nqualitative assessments, with all the attendant problems of subjectivity and\nlabor intensiveness. We consider how advances in natural language processing,\nincluding large transformer-based language models, can be applied to solve that\nissue. We apply a number of texts similarity measures to party political\nprograms, analyze how they correlate with each other, and -- in the absence of\na satisfactory benchmark -- evaluate them against other measures, including\nthose based on expert surveys, voting records, electoral patterns, and\ncandidate networks. Finally, we consider the prospects of relying on those\nmethods to correct, supplement, and eventually replace expert judgments.\n","authors":["Daria Boratyn","Damian Brzyski","Beata Kosowska-Gąstoł","Jan Rybicki","Wojciech Słomczyński","Dariusz Stolicki"],"pdf_url":"https://arxiv.org/pdf/2306.03079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03078v1","updated":"2023-06-05T17:53:28Z","published":"2023-06-05T17:53:28Z","title":"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression","summary":"  Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.\n","authors":["Tim Dettmers","Ruslan Svirschevski","Vage Egiazarian","Denis Kuznedelev","Elias Frantar","Saleh Ashkboos","Alexander Borzunov","Torsten Hoefler","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2306.03078v1.pdf","comment":"Extended preprint"},{"id":"http://arxiv.org/abs/2302.11042v2","updated":"2023-06-05T17:49:58Z","published":"2023-02-21T22:47:45Z","title":"In-context Example Selection with Influences","summary":"  In-context learning (ICL) is a powerful paradigm emerged from large language\nmodels (LLMs). Despite its promises, ICL performance is known to be highly\nsensitive to input examples. In this work, we use $\\textit{in-context\ninfluences}$ to analyze few-shot ICL performance directly from the in-context\nexamples. Our proposed influence-based example selection method can identify\nboth positive and negative examples, outperforming several baselines when\nevaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\\%$\nperformance gap between using the most negative in-context examples compared to\nthe most positive. In a case study, we apply our influence-based framework to\nquantify the phenomena of recency bias in example ordering for few-shot ICL.\n","authors":["Tai Nguyen","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2302.11042v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03067v1","updated":"2023-06-05T17:43:53Z","published":"2023-06-05T17:43:53Z","title":"Interactive Editing for Text Summarization","summary":"  Summarizing lengthy documents is a common and essential task in our daily\nlives. Although recent advancements in neural summarization models can assist\nin crafting general-purpose summaries, human writers often have specific\nrequirements that call for a more customized approach. To address this need, we\nintroduce REVISE (Refinement and Editing via Iterative Summarization\nEnhancement), an innovative framework designed to facilitate iterative editing\nand refinement of draft summaries by human writers. Within our framework,\nwriters can effortlessly modify unsatisfactory segments at any location or\nlength and provide optional starting phrases -- our system will generate\ncoherent alternatives that seamlessly integrate with the existing summary. At\nits core, REVISE incorporates a modified fill-in-the-middle model with the\nencoder-decoder architecture while developing novel evaluation metrics tailored\nfor the summarization task. In essence, our framework empowers users to create\nhigh-quality, personalized summaries by effectively harnessing both human\nexpertise and AI capabilities, ultimately transforming the summarization\nprocess into a truly collaborative and adaptive experience.\n","authors":["Yujia Xie","Xun Wang","Si-Qing Chen","Wayne Xiong","Pengcheng He"],"pdf_url":"https://arxiv.org/pdf/2306.03067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03061v1","updated":"2023-06-05T17:32:35Z","published":"2023-06-05T17:32:35Z","title":"Structured Voronoi Sampling","summary":"  Recently, there has been a growing interest in the development of\ngradient-based sampling algorithms for text generation, especially in the\ncontext of controlled generation. However, there exists a lack of theoretically\ngrounded and principled approaches for this task. In this paper, we take an\nimportant step toward building a principled approach for sampling from language\nmodels with gradient-based methods. We use discrete distributions given by\nlanguage models to define densities and develop an algorithm based on\nHamiltonian Monte Carlo to sample from them. We name our gradient-based\ntechnique Structured Voronoi Sampling (SVS). In an experimental setup where the\nreference distribution is known, we show that the empirical distribution of SVS\nsamples is closer to the reference distribution compared to alternative\nsampling schemes. Furthermore, in a controlled generation task, SVS is able to\ngenerate fluent and diverse samples while following the control targets\nsignificantly better than other methods.\n","authors":["Afra Amini","Li Du","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2306.03061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03055v1","updated":"2023-06-05T17:27:48Z","published":"2023-06-05T17:27:48Z","title":"Analyzing Syntactic Generalization Capacity of Pre-trained Language\n  Models on Japanese Honorific Conversion","summary":"  Using Japanese honorifics is challenging because it requires not only\nknowledge of the grammatical rules but also contextual information, such as\nsocial relationships. It remains unclear whether pre-trained large language\nmodels (LLMs) can flexibly handle Japanese honorifics like humans. To analyze\nthis, we introduce an honorific conversion task that considers social\nrelationships among people mentioned in a conversation. We construct a Japanese\nhonorifics dataset from problem templates of various sentence structures to\ninvestigate the syntactic generalization capacity of GPT-3, one of the leading\nLLMs, on this task under two settings: fine-tuning and prompt learning. Our\nresults showed that the fine-tuned GPT-3 performed better in a context-aware\nhonorific conversion task than the prompt-based one. The fine-tuned model\ndemonstrated overall syntactic generalizability towards compound honorific\nsentences, except when tested with the data involving direct speech.\n","authors":["Ryo Sekizawa","Hitomi Yanaka"],"pdf_url":"https://arxiv.org/pdf/2306.03055v1.pdf","comment":"To appear in the Proceedings of the 12th Joint Conference on Lexical\n  and Computational Semantics (*SEM2023) with ACL2023"},{"id":"http://arxiv.org/abs/2212.09648v3","updated":"2023-06-05T17:17:53Z","published":"2022-12-19T17:28:22Z","title":"NusaCrowd: Open Source Initiative for Indonesian NLP Resources","summary":"  We present NusaCrowd, a collaborative initiative to collect and unify\nexisting resources for Indonesian languages, including opening access to\npreviously non-public resources. Through this initiative, we have brought\ntogether 137 datasets and 118 standardized data loaders. The quality of the\ndatasets has been assessed manually and automatically, and their value is\ndemonstrated through multiple experiments. NusaCrowd's data collection enables\nthe creation of the first zero-shot benchmarks for natural language\nunderstanding and generation in Indonesian and the local languages of\nIndonesia. Furthermore, NusaCrowd brings the creation of the first multilingual\nautomatic speech recognition benchmark in Indonesian and the local languages of\nIndonesia. Our work strives to advance natural language processing (NLP)\nresearch for languages that are under-represented despite being widely spoken.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Alham Fikri Aji","Genta Indra Winata","Bryan Wilie","Rahmad Mahendra","Christian Wibisono","Ade Romadhony","Karissa Vincentio","Fajri Koto","Jennifer Santoso","David Moeljadi","Cahya Wirawan","Frederikus Hudi","Ivan Halim Parmonangan","Ika Alfina","Muhammad Satrio Wicaksono","Ilham Firdausi Putra","Samsul Rahmadani","Yulianti Oenang","Ali Akbar Septiandri","James Jaya","Kaustubh D. Dhole","Arie Ardiyanti Suryani","Rifki Afina Putri","Dan Su","Keith Stevens","Made Nindyatama Nityasya","Muhammad Farid Adilazuarda","Ryan Ignatius","Ryandito Diandaru","Tiezheng Yu","Vito Ghifari","Wenliang Dai","Yan Xu","Dyah Damapuspita","Cuk Tho","Ichwanul Muslim Karo Karo","Tirana Noor Fatyanosa","Ziwei Ji","Pascale Fung","Graham Neubig","Timothy Baldwin","Sebastian Ruder","Herry Sujaini","Sakriani Sakti","Ayu Purwarianti"],"pdf_url":"https://arxiv.org/pdf/2212.09648v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03030v1","updated":"2023-06-05T16:48:41Z","published":"2023-06-05T16:48:41Z","title":"Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset","summary":"  Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.5% and a weighted F1 score of 0.616. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.\n","authors":["Junling Liu","Peilin Zhou","Yining Hua","Dading Chong","Zhongyu Tian","Andrew Liu","Helin Wang","Chenyu You","Zhenhua Guo","Lei Zhu","Michael Lingzhi Li"],"pdf_url":"https://arxiv.org/pdf/2306.03030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03024v1","updated":"2023-06-05T16:44:27Z","published":"2023-06-05T16:44:27Z","title":"PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge","summary":"  The recently released ChatGPT model demonstrates unprecedented capabilities\nin zero-shot question-answering. In this work, we probe ChatGPT for its\nconversational understanding and introduce a conversational framework\n(protocol) that can be adopted in future studies. The Pok\\'emon universe serves\nas an ideal testing ground for auditing ChatGPT's reasoning capabilities due to\nits closed world assumption. After bringing ChatGPT's background knowledge (on\nthe Pok\\'emon universe) to light, we test its reasoning process when using\nthese concepts in battle scenarios. We then evaluate its ability to acquire new\nknowledge and include it in its reasoning process. Our ultimate goal is to\nassess ChatGPT's ability to generalize, combine features, and to acquire and\nreason over newly introduced knowledge from human feedback. We find that\nChatGPT has prior knowledge of the Pokemon universe, which can reason upon in\nbattle scenarios to a great extent, even when new information is introduced.\nThe model performs better with collaborative feedback and if there is an\ninitial phase of information retrieval, but also hallucinates occasionally and\nis susceptible to adversarial attacks.\n","authors":["Laura Cabello","Jiaang Li","Ilias Chalkidis"],"pdf_url":"https://arxiv.org/pdf/2306.03024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18486v2","updated":"2023-06-05T16:21:40Z","published":"2023-05-29T12:37:21Z","title":"A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark\n  Datasets","summary":"  The development of large language models (LLMs) such as ChatGPT has brought a\nlot of attention recently. However, their evaluation in the benchmark academic\ndatasets remains under-explored due to the difficulty of evaluating the\ngenerative outputs produced by this model against the ground truth. In this\npaper, we aim to present a thorough evaluation of ChatGPT's performance on\ndiverse academic datasets, covering tasks like question-answering, text\nsummarization, code generation, commonsense reasoning, mathematical\nproblem-solving, machine translation, bias detection, and ethical\nconsiderations. Specifically, we evaluate ChatGPT across 140 tasks and analyze\n255K responses it generates in these datasets. This makes our work the largest\nevaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate\nthe strengths and weaknesses of ChatGPT in various tasks and provide insights\nfor future research using LLMs. We also report a new emergent ability to follow\nmulti-query instructions that we mostly found in ChatGPT and other\ninstruction-tuned models. Our extensive evaluation shows that even though\nChatGPT is capable of performing a wide variety of tasks, and may obtain\nimpressive performance in several benchmark datasets, it is still far from\nachieving the ability to reliably solve many challenging tasks. By providing a\nthorough assessment of ChatGPT's performance across diverse NLP tasks, this\npaper sets the stage for a targeted deployment of ChatGPT-like LLMs in\nreal-world applications.\n","authors":["Md Tahmid Rahman Laskar","M Saiful Bari","Mizanur Rahman","Md Amran Hossen Bhuiyan","Shafiq Joty","Jimmy Xiangji Huang"],"pdf_url":"https://arxiv.org/pdf/2305.18486v2.pdf","comment":"Accepted by ACL 2023 Findings. The first three authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2304.13005v2","updated":"2023-06-05T15:55:47Z","published":"2023-04-25T17:24:32Z","title":"Evaluating Inter-Bilingual Semantic Parsing for Indian Languages","summary":"  Despite significant progress in Natural Language Generation for Indian\nlanguages (IndicNLP), there is a lack of datasets around complex structured\ntasks such as semantic parsing. One reason for this imminent gap is the\ncomplexity of the logical form, which makes English to multilingual translation\ndifficult. The process involves alignment of logical forms, intents and slots\nwith translated unstructured utterance. To address this, we propose an\nInter-bilingual Seq2seq Semantic parsing dataset IE-SEMPARSE for 11 distinct\nIndian languages. We highlight the proposed task's practicality, and evaluate\nexisting multilingual seq2seq models across several train-test strategies. Our\nexperiment reveals a high correlation across performance of original\nmultilingual semantic parsing datasets (such as mTOP, multilingual TOP and\nmultiATIS++) and our proposed IE-SEMPARSE suite.\n","authors":["Divyanshu Aggarwal","Vivek Gupta","Anoop Kunchukuttan"],"pdf_url":"https://arxiv.org/pdf/2304.13005v2.pdf","comment":"21 pages, 9 figures, 15 tables"},{"id":"http://arxiv.org/abs/2306.02982v1","updated":"2023-06-05T15:53:15Z","published":"2023-06-05T15:53:15Z","title":"PolyVoice: Language Models for Speech to Speech Translation","summary":"  We propose PolyVoice, a language model-based framework for speech-to-speech\ntranslation (S2ST) system. Our framework consists of two language models: a\ntranslation language model and a speech synthesis language model. We use\ndiscretized speech units, which are generated in a fully unsupervised way, and\nthus our framework can be used for unwritten languages. For the speech\nsynthesis part, we adopt the existing VALL-E X approach and build a unit-based\naudio language model. This grants our framework the ability to preserve the\nvoice characteristics and the speaking style of the original speech. We examine\nour system on Chinese $\\rightarrow$ English and English $\\rightarrow$ Spanish\npairs. Experimental results show that our system can generate speech with high\ntranslation quality and audio quality. Speech samples are available at\nhttps://speechtranslation.github.io/polyvoice.\n","authors":["Qianqian Dong","Zhiying Huang","Chen Xu","Yunlong Zhao","Kexin Wang","Xuxin Cheng","Tom Ko","Qiao Tian","Tang Li","Fengpeng Yue","Ye Bai","Xi Chen","Lu Lu","Zejun Ma","Yuping Wang","Mingxuan Wang","Yuxuan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.02982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02980v1","updated":"2023-06-05T15:51:58Z","published":"2023-06-05T15:51:58Z","title":"KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating\n  Inconsistencies in Natural Language Explanations","summary":"  While recent works have been considerably improving the quality of the\nnatural language explanations (NLEs) generated by a model to justify its\npredictions, there is very limited research in detecting and alleviating\ninconsistencies among generated NLEs. In this work, we leverage external\nknowledge bases to significantly improve on an existing adversarial attack for\ndetecting inconsistent NLEs. We apply our attack to high-performing NLE models\nand show that models with higher NLE quality do not necessarily generate fewer\ninconsistencies. Moreover, we propose an off-the-shelf mitigation method to\nalleviate inconsistencies by grounding the model into external background\nknowledge. Our method decreases the inconsistencies of previous high-performing\nNLE models as detected by our attack.\n","authors":["Myeongjun Jang","Bodhisattwa Prasad Majumder","Julian McAuley","Thomas Lukasiewicz","Oana-Maria Camburu"],"pdf_url":"https://arxiv.org/pdf/2306.02980v1.pdf","comment":"Short paper, ACL 2023"},{"id":"http://arxiv.org/abs/2306.02978v1","updated":"2023-06-05T15:50:57Z","published":"2023-06-05T15:50:57Z","title":"Which Argumentative Aspects of Hate Speech in Social Media can be\n  reliably identified?","summary":"  With the increasing diversity of use cases of large language models, a more\ninformative treatment of texts seems necessary. An argumentative analysis could\nfoster a more reasoned usage of chatbots, text completion mechanisms or other\napplications. However, it is unclear which aspects of argumentation can be\nreliably identified and integrated in language models. In this paper, we\npresent an empirical assessment of the reliability with which different\nargumentative aspects can be automatically identified in hate speech in social\nmedia. We have enriched the Hateval corpus (Basile et al. 2019) with a manual\nannotation of some argumentative components, adapted from Wagemans (2016)'s\nPeriodic Table of Arguments. We show that some components can be identified\nwith reasonable reliability. For those that present a high error ratio, we\nanalyze the patterns of disagreement between expert annotators and errors in\nautomatic procedures, and we propose adaptations of those categories that can\nbe more reliably reproduced.\n","authors":["Damián Furman","Pablo Torres","José A. Rodríguez","Diego Letzen","Vanina Martínez","Laura Alonso Alemany"],"pdf_url":"https://arxiv.org/pdf/2306.02978v1.pdf","comment":"9 Pages plus reference and appendix"},{"id":"http://arxiv.org/abs/2306.02955v1","updated":"2023-06-05T15:23:55Z","published":"2023-06-05T15:23:55Z","title":"A Simple and Flexible Modeling for Mental Disorder Detection by Learning\n  from Clinical Questionnaires","summary":"  Social media is one of the most highly sought resources for analyzing\ncharacteristics of the language by its users. In particular, many researchers\nutilized various linguistic features of mental health problems from social\nmedia. However, existing approaches to detecting mental disorders face critical\nchallenges, such as the scarcity of high-quality data or the trade-off between\naddressing the complexity of models and presenting interpretable results\ngrounded in expert domain knowledge. To address these challenges, we design a\nsimple but flexible model that preserves domain-based interpretability. We\npropose a novel approach that captures the semantic meanings directly from the\ntext and compares them to symptom-related descriptions. Experimental results\ndemonstrate that our model outperforms relevant baselines on various mental\ndisorder detection tasks. Our detailed analysis shows that the proposed model\nis effective at leveraging domain knowledge, transferable to other mental\ndisorders, and providing interpretable detection results.\n","authors":["Hoyun Song","Jisu Shin","Huije Lee","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2306.02955v1.pdf","comment":"ACL 2023, 15 pages, 11 tables, 4 figures"},{"id":"http://arxiv.org/abs/2206.03382v2","updated":"2023-06-05T15:05:24Z","published":"2022-06-07T15:20:20Z","title":"Tutel: Adaptive Mixture-of-Experts at Scale","summary":"  Sparsely-gated mixture-of-experts (MoE) has been widely adopted to scale deep\nlearning models to trillion-plus parameters with fixed computational cost. The\nalgorithmic performance of MoE relies on its token routing mechanism that\nforwards each input token to the right sub-models or experts. While token\nrouting dynamically determines the amount of expert workload at runtime,\nexisting systems suffer inefficient computation due to their static execution,\nnamely static parallelism and pipelining, which does not adapt to the dynamic\nworkload. We present Flex, a highly scalable stack design and implementation\nfor MoE with dynamically adaptive parallelism and pipelining. Flex designs an\nidentical layout for distributing MoE model parameters and input data, which\ncan be leveraged by all possible parallelism or pipelining methods without any\nmathematical inequivalence or tensor migration overhead. This enables adaptive\nparallelism/pipelining optimization at zero cost during runtime. Based on this\nkey design, Flex also implements various MoE acceleration techniques.\nAggregating all techniques, Flex finally delivers huge speedup at any scale --\n4.96x and 5.75x speedup of a single MoE layer over 16 and 2,048 A100 GPUs,\nrespectively, over the previous state-of-the-art. Our evaluation shows that\nFlex efficiently and effectively runs a real-world MoE-based model named\nSwinV2-MoE, built upon Swin Transformer V2, a state-of-the-art computer vision\narchitecture. On efficiency, Flex accelerates SwinV2-MoE, achieving up to 1.55x\nand 2.11x speedup in training and inference over Fairseq, respectively. On\neffectiveness, the SwinV2-MoE model achieves superior accuracy in both\npre-training and down-stream computer vision tasks such as COCO object\ndetection than the counterpart dense model, indicating the readiness of Flex\nfor end-to-end real-world model training and inference.\n","authors":["Changho Hwang","Wei Cui","Yifan Xiong","Ziyue Yang","Ze Liu","Han Hu","Zilong Wang","Rafael Salas","Jithin Jose","Prabhat Ram","Joe Chau","Peng Cheng","Fan Yang","Mao Yang","Yongqiang Xiong"],"pdf_url":"https://arxiv.org/pdf/2206.03382v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02923v1","updated":"2023-06-05T14:36:31Z","published":"2023-06-05T14:36:31Z","title":"MidMed: Towards Mixed-Type Dialogues for Medical Consultation","summary":"  Most medical dialogue systems assume that patients have clear goals (medicine\nquerying, surgical operation querying, etc.) before medical consultation.\nHowever, in many real scenarios, due to the lack of medical knowledge, it is\nusually difficult for patients to determine clear goals with all necessary\nslots. In this paper, we identify this challenge as how to construct medical\nconsultation dialogue systems to help patients clarify their goals. To mitigate\nthis challenge, we propose a novel task and create a human-to-human mixed-type\nmedical consultation dialogue corpus, termed MidMed, covering five dialogue\ntypes: task-oriented dialogue for diagnosis, recommendation, knowledge-grounded\ndialogue, QA, and chitchat. MidMed covers four departments\n(otorhinolaryngology, ophthalmology, skin, and digestive system), with 8,175\ndialogues. Furthermore, we build baselines on MidMed and propose an\ninstruction-guiding medical dialogue generation framework, termed InsMed, to\naddress this task. Experimental results show the effectiveness of InsMed.\n","authors":["Xiaoming Shi","Zeming Liu","Chuan Wang","Haitao Leng","Kui Xue","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.02923v1.pdf","comment":"Accepted by ACL 2023 Main conference. First two authors contributed\n  equally to this work"},{"id":"http://arxiv.org/abs/2210.04183v2","updated":"2023-06-05T14:35:59Z","published":"2022-10-09T06:31:15Z","title":"MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language\n  Representation Learning","summary":"  Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.\n","authors":["Zijia Zhao","Longteng Guo","Xingjian He","Shuai Shao","Zehuan Yuan","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2210.04183v2.pdf","comment":"SIGIR 2023, 10 pages"},{"id":"http://arxiv.org/abs/2306.02920v1","updated":"2023-06-05T14:32:41Z","published":"2023-06-05T14:32:41Z","title":"Second Language Acquisition of Neural Language Models","summary":"  With the success of neural language models (LMs), their language acquisition\nhas gained much attention. This work sheds light on the second language (L2)\nacquisition of LMs, while previous work has typically explored their first\nlanguage (L1) acquisition. Specifically, we trained bilingual LMs with a\nscenario similar to human L2 acquisition and analyzed their cross-lingual\ntransfer from linguistic perspectives. Our exploratory experiments demonstrated\nthat the L1 pretraining accelerated their linguistic generalization in L2, and\nlanguage transfer configurations (e.g., the L1 choice, and presence of parallel\ntexts) substantially affected their generalizations. These clarify their\n(non-)human-like L2 acquisition in particular aspects.\n","authors":["Miyu Oba","Tatsuki Kuribayashi","Hiroki Ouchi","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2306.02920v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02907v1","updated":"2023-06-05T14:12:46Z","published":"2023-06-05T14:12:46Z","title":"SelfEvolve: A Code Evolution Framework via Large Language Models","summary":"  Large language models (LLMs) have already revolutionized code generation,\nafter being pretrained on publicly available code data. However, while various\nmethods have been proposed to augment LLMs with retrieved knowledge and enhance\nthe quality of code generation, the performance of these retrieval-based\nmethods is limited by the strength of the retrievers used. In addition, while\nLLMs show great emergent ability, they still struggle to produce the correct\ncode in one turn. To address these challenges, we propose a novel two-step\npipeline, called \\autoknow, that leverages LLMs as both knowledge providers and\nself-reflective programmers. Unlike retrieval-based methods, \\autoknow~obtains\nthe knowledge from input prompts and generates intermediate code based on the\ngenerated knowledge. After that, \\autoknow~asks LLM to act as an expert\nprogrammer to perform debugging for the generated code. This is achieved by\nreceiving the error message from the interpreter, without requiring special\ntest cases for correctness verification. We evaluate \\autoknow~on three code\ngeneration datasets, including DS-1000 for data science code, HumanEval for\nsoftware engineering code, and TransCoder for C++-to-Python translation. Our\nempirical experiments show that \\autoknow~outperforms strong baselines by a\nsignificant margin on all datasets. We also conduct exhaustive analytical\nexperiments to validate the effectiveness of the two stages of \\autoknow, and\nfind that both are superior to other prompting-based methods. Further\nscalability analysis demonstrates that \\autoknow~can be adapted to other more\nadvanced models, such as GPT-4, and bring consistent efficacy improvement.\n","authors":["Shuyang Jiang","Yuhao Wang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.02907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02902v1","updated":"2023-06-05T14:09:25Z","published":"2023-06-05T14:09:25Z","title":"N-Shot Benchmarking of Whisper on Diverse Arabic Speech Recognition","summary":"  Whisper, the recently developed multilingual weakly supervised model, is\nreported to perform well on multiple speech recognition benchmarks in both\nmonolingual and multilingual settings. However, it is not clear how Whisper\nwould fare under diverse conditions even on languages it was evaluated on such\nas Arabic. In this work, we address this gap by comprehensively evaluating\nWhisper on several varieties of Arabic speech for the ASR task. Our evaluation\ncovers most publicly available Arabic speech data and is performed under n-shot\n(zero-, few-, and full) finetuning. We also investigate the robustness of\nWhisper under completely novel conditions, such as in dialect-accented standard\nArabic and in unseen dialects for which we develop evaluation data. Our\nexperiments show that although Whisper zero-shot outperforms fully finetuned\nXLS-R models on all datasets, its performance deteriorates significantly in the\nzero-shot setting for five unseen dialects (i.e., Algeria, Jordan, Palestine,\nUAE, and Yemen).\n","authors":["Bashar Talafha","Abdul Waheed","Muhammad Abdul-Mageed"],"pdf_url":"https://arxiv.org/pdf/2306.02902v1.pdf","comment":"4 pages, INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.02887v1","updated":"2023-06-05T13:56:36Z","published":"2023-06-05T13:56:36Z","title":"Gen-IR @ SIGIR 2023: The First Workshop on Generative Information\n  Retrieval","summary":"  Generative information retrieval (IR) has experienced substantial growth\nacross multiple research communities (e.g., information retrieval, computer\nvision, natural language processing, and machine learning), and has been highly\nvisible in the popular press. Theoretical, empirical, and actual user-facing\nproducts have been released that retrieve documents (via generation) or\ndirectly generate answers given an input request. We would like to investigate\nwhether end-to-end generative models are just another trend or, as some claim,\na paradigm change for IR. This necessitates new metrics, theoretical grounding,\nevaluation methods, task definitions, models, user interfaces, etc. The goal of\nthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previously\nexplored Generative IR techniques like document retrieval and direct Grounded\nAnswer Generation, while also offering a venue for the discussion and\nexploration of how Generative IR can be applied to new domains like\nrecommendation systems, summarization, etc. The format of the workshop is\ninteractive, including roundtable and keynote sessions and tends to avoid the\none-sided dialogue of a mini-conference.\n","authors":["Gabriel Bénédict","Ruqing Zhang","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2306.02887v1.pdf","comment":"Accepted SIGIR 23 workshop"},{"id":"http://arxiv.org/abs/2306.02873v1","updated":"2023-06-05T13:46:31Z","published":"2023-06-05T13:46:31Z","title":"DecompX: Explaining Transformers Decisions by Propagating Token\n  Decomposition","summary":"  An emerging solution for explaining Transformer-based models is to use\nvector-based analysis on how the representations are formed. However, providing\na faithful vector-based explanation for a multi-layer model could be\nchallenging in three aspects: (1) Incorporating all components into the\nanalysis, (2) Aggregating the layer dynamics to determine the information flow\nand mixture throughout the entire model, and (3) Identifying the connection\nbetween the vector-based analysis and the model's predictions. In this paper,\nwe present DecompX to tackle these challenges. DecompX is based on the\nconstruction of decomposed token representations and their successive\npropagation throughout the model without mixing them in between layers.\nAdditionally, our proposal provides multiple advantages over existing solutions\nfor its inclusion of all encoder components (especially nonlinear feed-forward\nnetworks) and the classification head. The former allows acquiring precise\nvectors while the latter transforms the decomposition into meaningful\nprediction-based values, eliminating the need for norm- or summation-based\nvector aggregation. According to the standard faithfulness evaluations, DecompX\nconsistently outperforms existing gradient-based and vector-based approaches on\nvarious datasets. Our code is available at\nhttps://github.com/mohsenfayyaz/DecompX.\n","authors":["Ali Modarressi","Mohsen Fayyaz","Ehsan Aghazadeh","Yadollah Yaghoobzadeh","Mohammad Taher Pilehvar"],"pdf_url":"https://arxiv.org/pdf/2306.02873v1.pdf","comment":"Accepted to ACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2306.02871v1","updated":"2023-06-05T13:45:45Z","published":"2023-06-05T13:45:45Z","title":"Text-To-KG Alignment: Comparing Current Methods on Classification Tasks","summary":"  In contrast to large text corpora, knowledge graphs (KG) provide dense and\nstructured representations of factual information. This makes them attractive\nfor systems that supplement or ground the knowledge found in pre-trained\nlanguage models with an external knowledge source. This has especially been the\ncase for classification tasks, where recent work has focused on creating\npipeline models that retrieve information from KGs like ConceptNet as\nadditional context. Many of these models consist of multiple components, and\nalthough they differ in the number and nature of these parts, they all have in\ncommon that for some given text query, they attempt to identify and retrieve a\nrelevant subgraph from the KG. Due to the noise and idiosyncrasies often found\nin KGs, it is not known how current methods compare to a scenario where the\naligned subgraph is completely relevant to the query. In this work, we try to\nbridge this knowledge gap by reviewing current approaches to text-to-KG\nalignment and evaluating them on two datasets where manually created graphs are\navailable, providing insights into the effectiveness of current methods.\n","authors":["Sondre Wold","Lilja Øvrelid","Erik Velldal"],"pdf_url":"https://arxiv.org/pdf/2306.02871v1.pdf","comment":"Camera ready version for MATCHING workshop at ACL 2023"},{"id":"http://arxiv.org/abs/2306.02870v1","updated":"2023-06-05T13:43:50Z","published":"2023-06-05T13:43:50Z","title":"On \"Scientific Debt\" in NLP: A Case for More Rigour in Language Model\n  Pre-Training Research","summary":"  This evidence-based position paper critiques current research practices\nwithin the language model pre-training literature. Despite rapid recent\nprogress afforded by increasingly better pre-trained language models (PLMs),\ncurrent PLM research practices often conflate different possible sources of\nmodel improvement, without conducting proper ablation studies and principled\ncomparisons between different models under comparable conditions. These\npractices (i) leave us ill-equipped to understand which pre-training approaches\nshould be used under what circumstances; (ii) impede reproducibility and credit\nassignment; and (iii) render it difficult to understand: \"How exactly does each\nfactor contribute to the progress that we have today?\" We provide a case in\npoint by revisiting the success of BERT over its baselines, ELMo and GPT-1, and\ndemonstrate how -- under comparable conditions where the baselines are tuned to\na similar extent -- these baselines (and even-simpler variants thereof) can, in\nfact, achieve competitive or better performance than BERT. These findings\ndemonstrate how disentangling different factors of model improvements can lead\nto valuable new insights. We conclude with recommendations for how to encourage\nand incentivize this line of work, and accelerate progress towards a better and\nmore systematic understanding of what factors drive the progress of our\nfoundation models today.\n","authors":["Made Nindyatama Nityasya","Haryo Akbarianto Wibowo","Alham Fikri Aji","Genta Indra Winata","Radityo Eko Prasojo","Phil Blunsom","Adhiguna Kuncoro"],"pdf_url":"https://arxiv.org/pdf/2306.02870v1.pdf","comment":"Accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2306.02864v1","updated":"2023-06-05T13:35:01Z","published":"2023-06-05T13:35:01Z","title":"Leveraging Large Language Models for Topic Classification in the Domain\n  of Public Affairs","summary":"  The analysis of public affairs documents is crucial for citizens as it\npromotes transparency, accountability, and informed decision-making. It allows\ncitizens to understand government policies, participate in public discourse,\nand hold representatives accountable. This is crucial, and sometimes a matter\nof life or death, for companies whose operation depend on certain regulations.\nLarge Language Models (LLMs) have the potential to greatly enhance the analysis\nof public affairs documents by effectively processing and understanding the\ncomplex language used in such documents. In this work, we analyze the\nperformance of LLMs in classifying public affairs documents. As a natural\nmulti-label task, the classification of these documents presents important\nchallenges. In this work, we use a regex-powered tool to collect a database of\npublic affairs documents with more than 33K samples and 22.5M tokens. Our\nexperiments assess the performance of 4 different Spanish LLMs to classify up\nto 30 different topics in the data in different configurations. The results\nshows that LLMs can be of great use to process domain-specific documents, such\nas those in the domain of public affairs.\n","authors":["Alejandro Peña","Aythami Morales","Julian Fierrez","Ignacio Serna","Javier Ortega-Garcia","Iñigo Puente","Jorge Cordova","Gonzalo Cordova"],"pdf_url":"https://arxiv.org/pdf/2306.02864v1.pdf","comment":"Accepted in ICDAR 2023 Workshop on Automatic Domain-Adapted and\n  Personalized Document Analysis"},{"id":"http://arxiv.org/abs/2306.02858v1","updated":"2023-06-05T13:17:27Z","published":"2023-06-05T13:17:27Z","title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video\n  Understanding","summary":"  We present Video-LLaMA, a multi-modal framework that empowers Large Language\nModels (LLMs) with the capability of understanding both visual and auditory\ncontent in the video. Video-LLaMA bootstraps cross-modal training from the\nfrozen pre-trained visual \\& audio encoders and the frozen LLMs. Unlike\nprevious vision- LLMs that focus on static image comprehensions such as\nMiniGPT-4~\\citep{zhu2023minigpt} and LLaVA~\\citep{liu2023visualit}, Video-LLaMA\ntackles two challenges in video understanding: (1) capturing the temporal\nchanges in visual scenes, (2) integrating audio-visual signals. For the first\nchallenge, we propose Video Q-former to extend the pre-trained image encoder to\na video encoder and introduce a video-to-text generation task to learn\nvideo-language correspondence. For the second challenge, we leverage\nImageBind~\\citep{girdhar2023imagebind} as the pre-trained audio encoder which\nperforms exceptionally well in aligning different modalities to a common\nembedding space. And then introduce an Audio Q-former to learn auditory query\ntokens. To align the output of both visual \\& audio encoder with LLM's\nembedding space, we train Video-LLaMA on a large-scale vision caption dataset\nand a hign-quantity vision-instruction-tuning dataset. We found Video-LLaMA\nshowcases the ability to perceive and comprehend video content, generating\nmeaningful responses that are grounded in the visual and auditory information\npresent in the videos. This highlights the potential of Video-LLaMA as a\npromising prototype for audio-visual AI assistants. Our code, pre-trained\nmodel, and demo are available at\n\\url{https://github.com/DAMO-NLP-SG/Video-LLaMA}.\n","authors":["Hang Zhang","Xin Li","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2306.02858v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2209.05135v3","updated":"2023-06-05T12:56:14Z","published":"2022-09-12T10:42:26Z","title":"Signs of Language: Embodied Sign Language Fingerspelling Acquisition\n  from Demonstrations for Human-Robot Interaction","summary":"  Learning fine-grained movements is a challenging topic in robotics,\nparticularly in the context of robotic hands. One specific instance of this\nchallenge is the acquisition of fingerspelling sign language in robots. In this\npaper, we propose an approach for learning dexterous motor imitation from video\nexamples without additional information. To achieve this, we first build a URDF\nmodel of a robotic hand with a single actuator for each joint. We then leverage\npre-trained deep vision models to extract the 3D pose of the hand from RGB\nvideos. Next, using state-of-the-art reinforcement learning algorithms for\nmotion imitation (namely, proximal policy optimization and soft actor-critic),\nwe train a policy to reproduce the movement extracted from the demonstrations.\nWe identify the optimal set of hyperparameters for imitation based on a\nreference motion. Finally, we demonstrate the generalizability of our approach\nby testing it on six different tasks, corresponding to fingerspelled letters.\nOur results show that our approach is able to successfully imitate these\nfine-grained movements without additional information, highlighting its\npotential for real-world applications in robotics.\n","authors":["Federico Tavella","Aphrodite Galata","Angelo Cangelosi"],"pdf_url":"https://arxiv.org/pdf/2209.05135v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02842v1","updated":"2023-06-05T12:48:56Z","published":"2023-06-05T12:48:56Z","title":"Improving Conversational Recommendation Systems via Counterfactual Data\n  Simulation","summary":"  Conversational recommender systems (CRSs) aim to provide recommendation\nservices via natural language conversations. Although a number of approaches\nhave been proposed for developing capable CRSs, they typically rely on\nsufficient training data for training. Since it is difficult to annotate\nrecommendation-oriented dialogue datasets, existing CRS approaches often suffer\nfrom the issue of insufficient training due to the scarcity of training data.\nTo address this issue, in this paper, we propose a CounterFactual data\nsimulation approach for CRS, named CFCRS, to alleviate the issue of data\nscarcity in CRSs. Our approach is developed based on the framework of\ncounterfactual data augmentation, which gradually incorporates the rewriting to\nthe user preference from a real dialogue without interfering with the entire\nconversation flow. To develop our approach, we characterize user preference and\norganize the conversation flow by the entities involved in the dialogue, and\ndesign a multi-stage recommendation dialogue simulator based on a conversation\nflow language model. Under the guidance of the learned user preference and\ndialogue schema, the flow language model can produce reasonable, coherent\nconversation flows, which can be further realized into complete dialogues.\nBased on the simulator, we perform the intervention at the representations of\nthe interacted entities of target users, and design an adversarial training\nmethod with a curriculum schedule that can gradually optimize the data\naugmentation strategy. Extensive experiments show that our approach can\nconsistently boost the performance of several competitive CRSs, and outperform\nother data augmentation methods, especially when the training data is limited.\nOur code is publicly available at https://github.com/RUCAIBox/CFCRS.\n","authors":["Xiaolei Wang","Kun Zhou","Xinyu Tang","Wayne Xin Zhao","Fan Pan","Zhao Cao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2306.02842v1.pdf","comment":"Accepted by KDD 2023. Code: https://github.com/RUCAIBox/CFCRS"},{"id":"http://arxiv.org/abs/2306.02840v1","updated":"2023-06-05T12:44:18Z","published":"2023-06-05T12:44:18Z","title":"Learning to Substitute Spans towards Improving Compositional\n  Generalization","summary":"  Despite the rising prevalence of neural sequence models, recent empirical\nevidences suggest their deficiency in compositional generalization. One of the\ncurrent de-facto solutions to this problem is compositional data augmentation,\naiming to incur additional compositional inductive bias. Nonetheless, the\nimprovement offered by existing handcrafted augmentation strategies is limited\nwhen successful systematic generalization of neural sequence models requires\nmulti-grained compositional bias (i.e., not limited to either lexical or\nstructural biases only) or differentiation of training sequences in an\nimbalanced difficulty distribution. To address the two challenges, we first\npropose a novel compositional augmentation strategy dubbed \\textbf{Span}\n\\textbf{Sub}stitution (SpanSub) that enables multi-grained composition of\nsubstantial substructures in the whole training set. Over and above that, we\nintroduce the \\textbf{L}earning \\textbf{to} \\textbf{S}ubstitute \\textbf{S}pan\n(L2S2) framework which empowers the learning of span substitution probabilities\nin SpanSub in an end-to-end manner by maximizing the loss of neural sequence\nmodels, so as to outweigh those challenging compositions with elusive concepts\nand novel surroundings. Our empirical results on three standard compositional\ngeneralization benchmarks, including SCAN, COGS and GeoQuery (with an\nimprovement of at most 66.5\\%, 10.3\\%, 1.2\\%, respectively), demonstrate the\nsuperiority of SpanSub, %the learning framework L2S2 and their combination.\n","authors":["Zhaoyi Li","Ying Wei","Defu Lian"],"pdf_url":"https://arxiv.org/pdf/2306.02840v1.pdf","comment":"accepted by ACL 2023"},{"id":"http://arxiv.org/abs/2306.02827v1","updated":"2023-06-05T12:23:04Z","published":"2023-06-05T12:23:04Z","title":"UNIDECOR: A Unified Deception Corpus for Cross-Corpus Deception\n  Detection","summary":"  Verbal deception has been studied in psychology, forensics, and computational\nlinguistics for a variety of reasons, like understanding behaviour patterns,\nidentifying false testimonies, and detecting deception in online communication.\nVarying motivations across research fields lead to differences in the domain\nchoices to study and in the conceptualization of deception, making it hard to\ncompare models and build robust deception detection systems for a given\nlanguage. With this paper, we improve this situation by surveying available\nEnglish deception datasets which include domains like social media reviews,\ncourt testimonials, opinion statements on specific topics, and deceptive\ndialogues from online strategy games. We consolidate these datasets into a\nsingle unified corpus. Based on this resource, we conduct a correlation\nanalysis of linguistic cues of deception across datasets to understand the\ndifferences and perform cross-corpus modeling experiments which show that a\ncross-domain generalization is challenging to achieve. The unified deception\ncorpus (UNIDECOR) can be obtained from\nhttps://www.ims.uni-stuttgart.de/data/unidecor.\n","authors":["Aswathy Velutharambath","Roman Klinger"],"pdf_url":"https://arxiv.org/pdf/2306.02827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02819v1","updated":"2023-06-05T12:15:12Z","published":"2023-06-05T12:15:12Z","title":"Enhancing Language Representation with Constructional Information for\n  Natural Language Understanding","summary":"  Natural language understanding (NLU) is an essential branch of natural\nlanguage processing, which relies on representations generated by pre-trained\nlanguage models (PLMs). However, PLMs primarily focus on acquiring\nlexico-semantic information, while they may be unable to adequately handle the\nmeaning of constructions. To address this issue, we introduce construction\ngrammar (CxG), which highlights the pairings of form and meaning, to enrich\nlanguage representation. We adopt usage-based construction grammar as the basis\nof our work, which is highly compatible with statistical models such as PLMs.\nThen a HyCxG framework is proposed to enhance language representation through a\nthree-stage solution. First, all constructions are extracted from sentences via\na slot-constraints approach. As constructions can overlap with each other,\nbringing redundancy and imbalance, we formulate the conditional max coverage\nproblem for selecting the discriminative constructions. Finally, we propose a\nrelational hypergraph attention network to acquire representation from\nconstructional information by capturing high-order word interactions among\nconstructions. Extensive experiments demonstrate the superiority of the\nproposed model on a variety of NLU tasks.\n","authors":["Lvxiaowei Xu","Jianwang Wu","Jiawei Peng","Zhilin Gong","Ming Cai","Tianxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.02819v1.pdf","comment":"Long paper, accepted at the ACL 2023"},{"id":"http://arxiv.org/abs/2306.02797v1","updated":"2023-06-05T11:46:45Z","published":"2023-06-05T11:46:45Z","title":"Modeling Human-like Concept Learning with Bayesian Inference over\n  Natural Language","summary":"  We model learning of abstract symbolic concepts by performing Bayesian\ninference over utterances in natural language. For efficient inference, we use\na large language model as a proposal distribution. We fit a prior to human data\nto better model human learners, and evaluate on both generative and logical\nconcepts.\n","authors":["Kevin Ellis"],"pdf_url":"https://arxiv.org/pdf/2306.02797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02796v1","updated":"2023-06-05T11:46:36Z","published":"2023-06-05T11:46:36Z","title":"MCTS: A Multi-Reference Chinese Text Simplification Dataset","summary":"  Text simplification aims to make the text easier to understand by applying\nrewriting transformations. There has been very little research on Chinese text\nsimplification for a long time. The lack of generic evaluation data is an\nessential reason for this phenomenon. In this paper, we introduce MCTS, a\nmulti-reference Chinese text simplification dataset. We describe the annotation\nprocess of the dataset and provide a detailed analysis of it. Furthermore, we\nevaluate the performance of some unsupervised methods and advanced large\nlanguage models. We hope to build a basic understanding of Chinese text\nsimplification through the foundational work and provide references for future\nresearch. We release our data at https://github.com/blcuicall/mcts.\n","authors":["Ruining Chong","Luming Lu","Liner Yang","Jinran Nie","Shuhan Zhou","Yaoxin Li","Erhong Yang"],"pdf_url":"https://arxiv.org/pdf/2306.02796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11716v3","updated":"2023-06-05T11:44:02Z","published":"2023-01-27T14:03:09Z","title":"Pre-training for Speech Translation: CTC Meets Optimal Transport","summary":"  The gap between speech and text modalities is a major challenge in\nspeech-to-text translation (ST). Different methods have been proposed to reduce\nthis gap, but most of them require architectural changes in ST training. In\nthis work, we propose to mitigate this issue at the pre-training stage,\nrequiring no change in the ST model. First, we show that the connectionist\ntemporal classification (CTC) loss can reduce the modality gap by design. We\nprovide a quantitative comparison with the more common cross-entropy loss,\nshowing that pre-training with CTC consistently achieves better final ST\naccuracy. Nevertheless, CTC is only a partial solution and thus, in our second\ncontribution, we propose a novel pre-training method combining CTC and optimal\ntransport to further reduce this gap. Our method pre-trains a Siamese-like\nmodel composed of two encoders, one for acoustic inputs and the other for\ntextual inputs, such that they produce representations that are close to each\nother in the Wasserstein space. Extensive experiments on the standard CoVoST-2\nand MuST-C datasets show that our pre-training method applied to the vanilla\nencoder-decoder Transformer achieves state-of-the-art performance under the\nno-external-data setting, and performs on par with recent strong multi-task\nlearning systems trained with external data. Finally, our method can also be\napplied on top of these multi-task systems, leading to further improvements for\nthese models. Code and pre-trained models are available at\nhttps://github.com/formiel/fairseq.\n","authors":["Phuong-Hang Le","Hongyu Gong","Changhan Wang","Juan Pino","Benjamin Lecouteux","Didier Schwab"],"pdf_url":"https://arxiv.org/pdf/2301.11716v3.pdf","comment":"ICML 2023 (oral presentation). This version fixed URLs, updated\n  affiliations & acknowledgements, and improved formatting"},{"id":"http://arxiv.org/abs/2306.02790v1","updated":"2023-06-05T11:35:40Z","published":"2023-06-05T11:35:40Z","title":"Exploring the Relationship between Alignment and Cross-lingual Transfer\n  in Multilingual Transformers","summary":"  Without any explicit cross-lingual training data, multilingual language\nmodels can achieve cross-lingual transfer. One common way to improve this\ntransfer is to perform realignment steps before fine-tuning, i.e., to train the\nmodel to build similar representations for pairs of words from translated\nsentences. But such realignment methods were found to not always improve\nresults across languages and tasks, which raises the question of whether\naligned representations are truly beneficial for cross-lingual transfer. We\nprovide evidence that alignment is actually significantly correlated with\ncross-lingual transfer across languages, models and random seeds. We show that\nfine-tuning can have a significant impact on alignment, depending mainly on the\ndownstream task and the model. Finally, we show that realignment can, in some\ninstances, improve cross-lingual transfer, and we identify conditions in which\nrealignment methods provide significant improvements. Namely, we find that\nrealignment works better on tasks for which alignment is correlated with\ncross-lingual transfer when generalizing to a distant language and with smaller\nmodels, as well as when using a bilingual dictionary rather than FastAlign to\nextract realignment pairs. For example, for POS-tagging, between English and\nArabic, realignment can bring a +15.8 accuracy improvement on distilmBERT, even\noutperforming XLM-R Large by 1.7. We thus advocate for further research on\nrealignment methods for smaller multilingual models as an alternative to\nscaling.\n","authors":["Félix Gaschi","Patricio Cerda","Parisa Rastin","Yannick Toussaint"],"pdf_url":"https://arxiv.org/pdf/2306.02790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02777v1","updated":"2023-06-05T11:01:58Z","published":"2023-06-05T11:01:58Z","title":"German CheXpert Chest X-ray Radiology Report Labeler","summary":"  This study aimed to develop an algorithm to automatically extract annotations\nfor chest X-ray classification models from German thoracic radiology reports.\nAn automatic label extraction model was designed based on the CheXpert\narchitecture, and a web-based annotation interface was created for iterative\nimprovements. Results showed that automated label extraction can reduce time\nspent on manual labeling and improve overall modeling performance. The model\ntrained on automatically extracted labels performed competitively to manually\nlabeled data and strongly outperformed the model trained on publicly available\ndata.\n","authors":["Alessandro Wollek","Sardi Hyska","Thomas Sedlmeyr","Philip Haitzer","Johannes Rueckel","Bastian O. Sabel","Michael Ingrisch","Tobias Lasser"],"pdf_url":"https://arxiv.org/pdf/2306.02777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02771v1","updated":"2023-06-05T10:55:15Z","published":"2023-06-05T10:55:15Z","title":"Identifying the style by a qualified reader on a short fragment of\n  generated poetry","summary":"  Style is an important concept in today's challenges in natural language\ngenerating. After the success in the field of image style transfer, the task of\ntext style transfer became actual and attractive. Researchers are also\ninterested in the tasks of style reproducing in generation of the poetic text.\nEvaluation of style reproducing in natural poetry generation remains a problem.\nI used 3 character-based LSTM-models to work with style reproducing assessment.\nAll three models were trained on the corpus of texts by famous Russian-speaking\npoets. Samples were shown to the assessors and 4 answer options were offered,\nthe style of which poet this sample reproduces. In addition, the assessors were\nasked how well they were familiar with the work of the poet they had named.\nStudents studying history of literature were the assessors, 94 answers were\nreceived. It has appeared that accuracy of definition of style increases if the\nassessor can quote the poet by heart. Each model showed at least 0.7\nmacro-average accuracy. The experiment showed that it is better to involve a\nprofessional rather than a naive reader in the evaluation of style in the tasks\nof poetry generation, while lstm models are good at reproducing the style of\nRussian poets even on a limited training corpus.\n","authors":["Boris Orekhov"],"pdf_url":"https://arxiv.org/pdf/2306.02771v1.pdf","comment":"6 pages, 2 tables"},{"id":"http://arxiv.org/abs/2306.02767v1","updated":"2023-06-05T10:46:33Z","published":"2023-06-05T10:46:33Z","title":"Cross-Lingual Transfer with Target Language-Ready Task Adapters","summary":"  Adapters have emerged as a modular and parameter-efficient approach to\n(zero-shot) cross-lingual transfer. The established MAD-X framework employs\nseparate language and task adapters which can be arbitrarily combined to\nperform the transfer of any task to any target language. Subsequently, BAD-X,\nan extension of the MAD-X framework, achieves improved transfer at the cost of\nMAD-X's modularity by creating \"bilingual\" adapters specific to the\nsource-target language pair. In this work, we aim to take the best of both\nworlds by (i) fine-tuning task adapters adapted to the target language(s)\n(so-called \"target language-ready\" (TLR) adapters) to maintain high transfer\nperformance, but (ii) without sacrificing the highly modular design of MAD-X.\nThe main idea of \"target language-ready\" adapters is to resolve the\ntraining-vs-inference discrepancy of MAD-X: the task adapter \"sees\" the target\nlanguage adapter for the very first time during inference, and thus might not\nbe fully compatible with it. We address this mismatch by exposing the task\nadapter to the target language adapter during training, and empirically\nvalidate several variants of the idea: in the simplest form, we alternate\nbetween using the source and target language adapters during task adapter\ntraining, which can be generalized to cycling over any set of language\nadapters. We evaluate different TLR-based transfer configurations with varying\ndegrees of generality across a suite of standard cross-lingual benchmarks, and\nfind that the most general (and thus most modular) configuration consistently\noutperforms MAD-X and BAD-X on most tasks and languages.\n","authors":["Marinela Parović","Alan Ansell","Ivan Vulić","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2306.02767v1.pdf","comment":"Accepted to Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2305.04561v2","updated":"2023-06-05T10:28:11Z","published":"2023-05-08T09:12:44Z","title":"Boosting Radiology Report Generation by Infusing Comparison Prior","summary":"  Recent transformer-based models have made significant strides in generating\nradiology reports from chest X-ray images. However, a prominent challenge\nremains: these models often lack prior knowledge, resulting in the generation\nof synthetic reports that mistakenly reference non-existent prior exams. This\ndiscrepancy can be attributed to a knowledge gap between radiologists and the\ngeneration models. While radiologists possess patient-specific prior\ninformation, the models solely receive X-ray images at a specific time point.\nTo tackle this issue, we propose a novel approach that leverages a rule-based\nlabeler to extract comparison prior information from radiology reports. This\nextracted comparison prior is then seamlessly integrated into state-of-the-art\ntransformer-based models, enabling them to produce more realistic and\ncomprehensive reports. Our method is evaluated on English report datasets, such\nas IU X-ray and MIMIC-CXR. The results demonstrate that our approach surpasses\nbaseline models in terms of natural language generation metrics. Notably, our\nmodel generates reports that are free from false references to non-existent\nprior exams, setting it apart from previous models. By addressing this\nlimitation, our approach represents a significant step towards bridging the gap\nbetween radiologists and generation models in the domain of medical report\ngeneration.\n","authors":["Sanghwan Kim","Farhad Nooralahzadeh","Morteza Rohanian","Koji Fujimoto","Mizuho Nishio","Ryo Sakamoto","Fabio Rinaldi","Michael Krauthammer"],"pdf_url":"https://arxiv.org/pdf/2305.04561v2.pdf","comment":"Accepted at ACL 2023, BioNLP Workshop"},{"id":"http://arxiv.org/abs/2306.02754v1","updated":"2023-06-05T10:17:50Z","published":"2023-06-05T10:17:50Z","title":"PULSAR: Pre-training with Extracted Healthcare Terms for Summarising\n  Patients' Problems and Data Augmentation with Black-box Large Language Models","summary":"  Medical progress notes play a crucial role in documenting a patient's\nhospital journey, including his or her condition, treatment plan, and any\nupdates for healthcare providers. Automatic summarisation of a patient's\nproblems in the form of a problem list can aid stakeholders in understanding a\npatient's condition, reducing workload and cognitive bias. BioNLP 2023 Shared\nTask 1A focuses on generating a list of diagnoses and problems from the\nprovider's progress notes during hospitalisation. In this paper, we introduce\nour proposed approach to this task, which integrates two complementary\ncomponents. One component employs large language models (LLMs) for data\naugmentation; the other is an abstractive summarisation LLM with a novel\npre-training objective for generating the patients' problems summarised as a\nlist. Our approach was ranked second among all submissions to the shared task.\nThe performance of our model on the development and test datasets shows that\nour approach is more robust on unknown data, with an improvement of up to 3.1\npoints over the same size of the larger model.\n","authors":["Hao Li","Yuping Wu","Viktor Schlegel","Riza Batista-Navarro","Thanh-Tung Nguyen","Abhinav Ramesh Kashyap","Xiaojun Zeng","Daniel Beck","Stefan Winkler","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2306.02754v1.pdf","comment":"Accepted by ACL 2023's workshop BioNLP 2023"},{"id":"http://arxiv.org/abs/2205.12677v2","updated":"2023-06-05T09:13:05Z","published":"2022-05-25T11:38:12Z","title":"Language Anisotropic Cross-Lingual Model Editing","summary":"  Multilingual pre-trained language models can learn task-specific abilities or\nmemorize facts across multiple languages but inevitably make undesired\npredictions with specific inputs. Under similar observation, model editing aims\nto post-hoc calibrate a model targeted to specific inputs with keeping the\nmodel's raw behavior. However, existing work only studies the monolingual\nscenario, which lacks the cross-lingual transferability to perform editing\nsimultaneously across languages. In this work, we focus on cross-lingual model\nediting. Firstly, we define the cross-lingual model editing task and\ncorresponding metrics, where an edit in one language propagates to the others.\nNext, we propose a framework to naturally adapt monolingual model editing\napproaches to the cross-lingual scenario using parallel corpus. Further, we\npropose language anisotropic editing to improve cross-lingual editing by\namplifying different subsets of parameters for each language. On the newly\ndefined cross-lingual model editing task, we empirically demonstrate the\nfailure of monolingual baselines in propagating the edit to multiple languages\nand the effectiveness of the proposed language anisotropic model editing. Our\ncode is publicly available at https://github.com/franklear/LiME.\n","authors":["Yang Xu","Yutai Hou","Wanxiang Che","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12677v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02719v1","updated":"2023-06-05T09:12:34Z","published":"2023-06-05T09:12:34Z","title":"Multiple output samples for each input in a single-output Gaussian\n  process","summary":"  The standard Gaussian Process (GP) only considers a single output sample per\ninput in the training set. Datasets for subjective tasks, such as spoken\nlanguage assessment, may be annotated with output labels from multiple human\nraters per input. This paper proposes to generalise the GP to allow for these\nmultiple output samples in the training set, and thus make use of available\noutput uncertainty information. This differs from a multi-output GP, as all\noutput samples are from the same task here. The output density function is\nformulated to be the joint likelihood of observing all output samples, and\nlatent variables are not repeated to reduce computation cost. The test set\npredictions are inferred similarly to a standard GP, with a difference being in\nthe optimised hyper-parameters. This is evaluated on speechocean762, showing\nthat it allows the GP to compute a test set output distribution that is more\nsimilar to the collection of reference outputs from the multiple human raters.\n","authors":["Jeremy H. M. Wong","Huayun Zhang","Nancy F. Chen"],"pdf_url":"https://arxiv.org/pdf/2306.02719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01393v2","updated":"2023-06-05T09:04:32Z","published":"2023-06-02T09:39:36Z","title":"Assessing the Importance of Frequency versus Compositionality for\n  Subword-based Tokenization in NMT","summary":"  Subword tokenization is the de facto standard for tokenization in neural\nlanguage models and machine translation systems. Three advantages are\nfrequently cited in favor of subwords: shorter encoding of frequent tokens,\ncompositionality of subwords, and ability to deal with unknown words. As their\nrelative importance is not entirely clear yet, we propose a tokenization\napproach that enables us to separate frequency (the first advantage) from\ncompositionality. The approach uses Huffman coding to tokenize words, by order\nof frequency, using a fixed amount of symbols. Experiments with CS-DE, EN-FR\nand EN-DE NMT show that frequency alone accounts for 90%-95% of the scores\nreached by BPE, hence compositionality has less importance than previously\nthought.\n","authors":["Benoist Wolleb","Romain Silvestri","Giorgos Vernikos","Ljiljana Dolamic","Andrei Popescu-Belis"],"pdf_url":"https://arxiv.org/pdf/2306.01393v2.pdf","comment":"Accepted at EAMT 2023"},{"id":"http://arxiv.org/abs/2206.14578v2","updated":"2023-06-05T09:02:01Z","published":"2022-06-23T08:58:05Z","title":"Evaluating Generative Patent Language Models","summary":"  Generative language models are promising for assisting human writing in\nvarious domains. This manuscript aims to build generative language models in\nthe patent domain and evaluate model performance from a human-centric\nperspective. The perspective is to measure the ratio of keystrokes that can be\nsaved by autocompletion based on generative patent language models. A higher\nratio means a more effective model which can save more keystrokes. This metric\ncan be used to benchmark model performance. The metric is different from\nconventional machine-centric metrics that are token-based instead of\nkeystroke-based. In terms of model size, the largest model built in this\nmanuscript is 6B, which is state-of-the-art in the patent domain. Based on the\nmetric, it is found that the largest model is not necessarily the best for the\nhuman-centric metric. The finding means that keeping increasing model sizes in\nthe patent domain might be unnecessary if the purpose is to assist human\nwriting with autocompletion. Several patent language models are pre-trained\nfrom scratch in this research. The pre-trained models are released for future\nresearchers. Several visualization tools are also provided. The importance of\nbuilding a generative language model in the patent domain is the potential to\nfacilitate creativity and innovations in the future.\n","authors":["Jieh-Sheng Lee"],"pdf_url":"https://arxiv.org/pdf/2206.14578v2.pdf","comment":"12 pages, 7 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2306.02707v1","updated":"2023-06-05T08:58:39Z","published":"2023-06-05T08:58:39Z","title":"Orca: Progressive Learning from Complex Explanation Traces of GPT-4","summary":"  Recent research has focused on enhancing the capability of smaller models\nthrough imitation learning, drawing on the outputs generated by large\nfoundation models (LFMs). A number of issues impact the quality of these\nmodels, ranging from limited imitation signals from shallow LFM outputs; small\nscale homogeneous training data; and most notably a lack of rigorous evaluation\nresulting in overestimating the small model's capability as they tend to learn\nto imitate the style, but not the reasoning process of LFMs. To address these\nchallenges, we develop Orca (We are working with our legal team to publicly\nrelease a diff of the model weights in accordance with LLaMA's release policy\nto be published at https://aka.ms/orca-lm), a 13-billion parameter model that\nlearns to imitate the reasoning process of LFMs. Orca learns from rich signals\nfrom GPT-4 including explanation traces; step-by-step thought processes; and\nother complex instructions, guided by teacher assistance from ChatGPT. To\npromote this progressive learning, we tap into large-scale and diverse\nimitation data with judicious sampling and selection. Orca surpasses\nconventional state-of-the-art instruction-tuned models such as Vicuna-13B by\nmore than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard\n(BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH\nbenchmark and shows competitive performance (4 pts gap with optimized system\nmessage) in professional and academic examinations like the SAT, LSAT, GRE, and\nGMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our\nresearch indicates that learning from step-by-step explanations, whether these\nare generated by humans or more advanced AI models, is a promising direction to\nimprove model capabilities and skills.\n","authors":["Subhabrata Mukherjee","Arindam Mitra","Ganesh Jawahar","Sahaj Agarwal","Hamid Palangi","Ahmed Awadallah"],"pdf_url":"https://arxiv.org/pdf/2306.02707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02693v1","updated":"2023-06-05T08:35:31Z","published":"2023-06-05T08:35:31Z","title":"CELDA: Leveraging Black-box Language Model as Enhanced Classifier\n  without Labels","summary":"  Utilizing language models (LMs) without internal access is becoming an\nattractive paradigm in the field of NLP as many cutting-edge LMs are released\nthrough APIs and boast a massive scale. The de-facto method in this type of\nblack-box scenario is known as prompting, which has shown progressive\nperformance enhancements in situations where data labels are scarce or\nunavailable. Despite their efficacy, they still fall short in comparison to\nfully supervised counterparts and are generally brittle to slight\nmodifications. In this paper, we propose Clustering-enhanced Linear\nDiscriminative Analysis, a novel approach that improves the text classification\naccuracy with a very weak-supervision signal (i.e., name of the labels). Our\nframework draws a precise decision boundary without accessing weights or\ngradients of the LM model or data labels. The core ideas of CELDA are twofold:\n(1) extracting a refined pseudo-labeled dataset from an unlabeled dataset, and\n(2) training a lightweight and robust model on the top of LM, which learns an\naccurate decision boundary from an extracted noisy dataset. Throughout in-depth\ninvestigations on various datasets, we demonstrated that CELDA reaches new\nstate-of-the-art in weakly-supervised text classification and narrows the gap\nwith a fully-supervised model. Additionally, our proposed methodology can be\napplied universally to any LM and has the potential to scale to larger models,\nmaking it a more viable option for utilizing large LMs.\n","authors":["Hyunsoo Cho","Youna Kim","Sang-goo Lee"],"pdf_url":"https://arxiv.org/pdf/2306.02693v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.02682v1","updated":"2023-06-05T08:18:01Z","published":"2023-06-05T08:18:01Z","title":"End-to-End Word-Level Pronunciation Assessment with MASK Pre-training","summary":"  Pronunciation assessment is a major challenge in the computer-aided\npronunciation training system, especially at the word (phoneme)-level. To\nobtain word (phoneme)-level scores, current methods usually rely on aligning\ncomponents to obtain acoustic features of each word (phoneme), which limits the\nperformance of assessment to the accuracy of alignments. Therefore, to address\nthis problem, we propose a simple yet effective method, namely\n\\underline{M}asked pre-training for \\underline{P}ronunciation\n\\underline{A}ssessment (MPA). Specifically, by incorporating a mask-predict\nstrategy, our MPA supports end-to-end training without leveraging any aligning\ncomponents and can solve misalignment issues to a large extent during\nprediction. Furthermore, we design two evaluation strategies to enable our\nmodel to conduct assessments in both unsupervised and supervised settings.\nExperimental results on SpeechOcean762 dataset demonstrate that MPA could\nachieve better performance than previous methods, without any explicit\nalignment. In spite of this, MPA still has some limitations, such as requiring\nmore inference time and reference text. They expect to be addressed in future\nwork.\n","authors":["Yukang Liang","Kaitao Song","Shaoguang Mao","Huiqiang Jiang","Luna Qiu","Yuqing Yang","Dongsheng Li","Linli Xu","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2306.02682v1.pdf","comment":"Accepted by InterSpeech 2023"},{"id":"http://arxiv.org/abs/2212.05251v2","updated":"2023-06-05T08:14:47Z","published":"2022-12-10T09:18:43Z","title":"A Unified Knowledge Graph Augmentation Service for Boosting\n  Domain-specific NLP Tasks","summary":"  By focusing the pre-training process on domain-specific corpora, some\ndomain-specific pre-trained language models (PLMs) have achieved\nstate-of-the-art results. However, it is under-investigated to design a unified\nparadigm to inject domain knowledge in the PLM fine-tuning stage. We propose\nKnowledgeDA, a unified domain language model development service to enhance the\ntask-specific training procedure with domain knowledge graphs. Given\ndomain-specific task texts input, KnowledgeDA can automatically generate a\ndomain-specific language model following three steps: (i) localize domain\nknowledge entities in texts via an embedding-similarity approach; (ii) generate\naugmented samples by retrieving replaceable domain entity pairs from two views\nof both knowledge graph and training data; (iii) select high-quality augmented\nsamples for fine-tuning via confidence-based assessment. We implement a\nprototype of KnowledgeDA to learn language models for two domains, healthcare\nand software development. Experiments on domain-specific text classification\nand QA tasks verify the effectiveness and generalizability of KnowledgeDA.\n","authors":["Ruiqing Ding","Xiao Han","Leye Wang"],"pdf_url":"https://arxiv.org/pdf/2212.05251v2.pdf","comment":"Accepted by ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.02680v1","updated":"2023-06-05T08:12:17Z","published":"2023-06-05T08:12:17Z","title":"BeAts: Bengali Speech Acts Recognition using Multimodal Attention Fusion","summary":"  Spoken languages often utilise intonation, rhythm, intensity, and structure,\nto communicate intention, which can be interpreted differently depending on the\nrhythm of speech of their utterance. These speech acts provide the foundation\nof communication and are unique in expression to the language. Recent\nadvancements in attention-based models, demonstrating their ability to learn\npowerful representations from multilingual datasets, have performed well in\nspeech tasks and are ideal to model specific tasks in low resource languages.\nHere, we develop a novel multimodal approach combining two models, wav2vec2.0\nfor audio and MarianMT for text translation, by using multimodal attention\nfusion to predict speech acts in our prepared Bengali speech corpus. We also\nshow that our model BeAts ($\\underline{\\textbf{Be}}$ngali speech acts\nrecognition using Multimodal $\\underline{\\textbf{At}}$tention\nFu$\\underline{\\textbf{s}}$ion) significantly outperforms both the unimodal\nbaseline using only speech data and a simpler bimodal fusion using both speech\nand text data. Project page: https://soumitri2001.github.io/BeAts\n","authors":["Ahana Deb","Sayan Nag","Ayan Mahapatra","Soumitri Chattopadhyay","Aritra Marik","Pijush Kanti Gayen","Shankha Sanyal","Archi Banerjee","Samir Karmakar"],"pdf_url":"https://arxiv.org/pdf/2306.02680v1.pdf","comment":"Accepted at INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.02679v1","updated":"2023-06-05T08:11:59Z","published":"2023-06-05T08:11:59Z","title":"Joint Pre-training and Local Re-training: Transferable Representation\n  Learning on Multi-source Knowledge Graphs","summary":"  In this paper, we present the ``joint pre-training and local re-training''\nframework for learning and applying multi-source knowledge graph (KG)\nembeddings. We are motivated by the fact that different KGs contain\ncomplementary information to improve KG embeddings and downstream tasks. We\npre-train a large teacher KG embedding model over linked multi-source KGs and\ndistill knowledge to train a student model for a task-specific KG. To enable\nknowledge transfer across different KGs, we use entity alignment to build a\nlinked subgraph for connecting the pre-trained KGs and the target KG. The\nlinked subgraph is re-trained for three-level knowledge distillation from the\nteacher to the student, i.e., feature knowledge distillation, network knowledge\ndistillation, and prediction knowledge distillation, to generate more\nexpressive embeddings. The teacher model can be reused for different target KGs\nand tasks without having to train from scratch. We conduct extensive\nexperiments to demonstrate the effectiveness and efficiency of our framework.\n","authors":["Zequn Sun","Jiacheng Huang","Jinghao Lin","Xiaozhou Xu","Qijin Chen","Wei Hu"],"pdf_url":"https://arxiv.org/pdf/2306.02679v1.pdf","comment":"Accepted in the 29th ACM SIGKDD International Conference on Knowledge\n  Discovery and Data Mining (KDD 2023)"},{"id":"http://arxiv.org/abs/2306.02671v1","updated":"2023-06-05T08:05:05Z","published":"2023-06-05T08:05:05Z","title":"Improving Grammar-based Sequence-to-Sequence Modeling with Decomposition\n  and Constraints","summary":"  Neural QCFG is a grammar-based sequence-tosequence (seq2seq) model with\nstrong inductive biases on hierarchical structures. It excels in\ninterpretability and generalization but suffers from expensive inference. In\nthis paper, we study two low-rank variants of Neural QCFG for faster inference\nwith different trade-offs between efficiency and expressiveness. Furthermore,\nutilizing the symbolic interface provided by the grammar, we introduce two soft\nconstraints over tree hierarchy and source coverage. We experiment with various\ndatasets and find that our models outperform vanilla Neural QCFG in most\nsettings.\n","authors":["Chao Lou","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2306.02671v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.02646v1","updated":"2023-06-05T07:32:21Z","published":"2023-06-05T07:32:21Z","title":"Colexifications for Bootstrapping Cross-lingual Datasets: The Case of\n  Phonology, Concreteness, and Affectiveness","summary":"  Colexification refers to the linguistic phenomenon where a single lexical\nform is used to convey multiple meanings. By studying cross-lingual\ncolexifications, researchers have gained valuable insights into fields such as\npsycholinguistics and cognitive sciences [Jackson et al.,2019]. While several\nmultilingual colexification datasets exist, there is untapped potential in\nusing this information to bootstrap datasets across such semantic features. In\nthis paper, we aim to demonstrate how colexifications can be leveraged to\ncreate such cross-lingual datasets. We showcase curation procedures which\nresult in a dataset covering 142 languages across 21 language families across\nthe world. The dataset includes ratings of concreteness and affectiveness,\nmapped with phonemes and phonological features. We further analyze the dataset\nalong different dimensions to demonstrate potential of the proposed procedures\nin facilitating further interdisciplinary research in psychology, cognitive\nscience, and multilingual natural language processing (NLP). Based on initial\ninvestigations, we observe that i) colexifications that are closer in\nconcreteness/affectiveness are more likely to colexify; ii) certain\ninitial/last phonemes are significantly correlated with\nconcreteness/affectiveness intra language families, such as /k/ as the initial\nphoneme in both Turkic and Tai-Kadai correlated with concreteness, and /p/ in\nDravidian and Sino-Tibetan correlated with Valence; iii) the type-to-token\nratio (TTR) of phonemes are positively correlated with concreteness across\nseveral language families, while the length of phoneme segments are negatively\ncorrelated with concreteness; iv) certain phonological features are negatively\ncorrelated with concreteness across languages. The dataset is made public\nonline for further research.\n","authors":["Yiyi Chen","Johannes Bjerva"],"pdf_url":"https://arxiv.org/pdf/2306.02646v1.pdf","comment":"13 pages, 4 figures, accepted to SIGMORPHON 2023"},{"id":"http://arxiv.org/abs/2305.17626v2","updated":"2023-06-05T06:57:29Z","published":"2023-05-28T04:22:26Z","title":"In-Context Analogical Reasoning with Pre-Trained Language Models","summary":"  Analogical reasoning is a fundamental capacity of human cognition that allows\nus to reason abstractly about novel situations by relating them to past\nexperiences. While it is thought to be essential for robust reasoning in AI\nsystems, conventional approaches require significant training and/or\nhard-coding of domain knowledge to be applied to benchmark tasks. Inspired by\ncognitive science research that has found connections between human language\nand analogy-making, we explore the use of intuitive language-based abstractions\nto support analogy in AI systems. Specifically, we apply large pre-trained\nlanguage models (PLMs) to visual Raven's Progressive Matrices (RPM), a common\nrelational reasoning test. By simply encoding the perceptual features of the\nproblem into language form, we find that PLMs exhibit a striking capacity for\nzero-shot relational reasoning, exceeding human performance and nearing\nsupervised vision-based methods. We explore different encodings that vary the\nlevel of abstraction over task features, finding that higher-level abstractions\nfurther strengthen PLMs' analogical reasoning. Our detailed analysis reveals\ninsights on the role of model complexity, in-context learning, and prior\nknowledge in solving RPM tasks.\n","authors":["Xiaoyang Hu","Shane Storks","Richard L. Lewis","Joyce Chai"],"pdf_url":"https://arxiv.org/pdf/2305.17626v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02623v1","updated":"2023-06-05T06:50:42Z","published":"2023-06-05T06:50:42Z","title":"Do-GOOD: Towards Distribution Shift Evaluation for Pre-Trained Visual\n  Document Understanding Models","summary":"  Numerous pre-training techniques for visual document understanding (VDU) have\nrecently shown substantial improvements in performance across a wide range of\ndocument tasks. However, these pre-trained VDU models cannot guarantee\ncontinued success when the distribution of test data differs from the\ndistribution of training data. In this paper, to investigate how robust\nexisting pre-trained VDU models are to various distribution shifts, we first\ndevelop an out-of-distribution (OOD) benchmark termed Do-GOOD for the\nfine-Grained analysis on Document image-related tasks specifically. The Do-GOOD\nbenchmark defines the underlying mechanisms that result in different\ndistribution shifts and contains 9 OOD datasets covering 3 VDU related tasks,\ne.g., document information extraction, classification and question answering.\nWe then evaluate the robustness and perform a fine-grained analysis of 5 latest\nVDU pre-trained models and 2 typical OOD generalization algorithms on these OOD\ndatasets. Results from the experiments demonstrate that there is a significant\nperformance gap between the in-distribution (ID) and OOD settings for document\nimages, and that fine-grained analysis of distribution shifts can reveal the\nbrittle nature of existing pre-trained VDU models and OOD generalization\nalgorithms. The code and datasets for our Do-GOOD benchmark can be found at\nhttps://github.com/MAEHCM/Do-GOOD.\n","authors":["Jiabang He","Yi Hu","Lei Wang","Xing Xu","Ning Liu","Hui Liu","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2306.02623v1.pdf","comment":"SIGIR 2023. The code and datasets for our Do-GOOD benchmark can be\n  found at https://github.com/MAEHCM/Do-GOOD"},{"id":"http://arxiv.org/abs/2306.02622v1","updated":"2023-06-05T06:50:09Z","published":"2023-06-05T06:50:09Z","title":"What Makes Entities Similar? A Similarity Flooding Perspective for\n  Multi-sourced Knowledge Graph Embeddings","summary":"  Joint representation learning over multi-sourced knowledge graphs (KGs)\nyields transferable and expressive embeddings that improve downstream tasks.\nEntity alignment (EA) is a critical step in this process. Despite recent\nconsiderable research progress in embedding-based EA, how it works remains to\nbe explored. In this paper, we provide a similarity flooding perspective to\nexplain existing translation-based and aggregation-based EA models. We prove\nthat the embedding learning process of these models actually seeks a fixpoint\nof pairwise similarities between entities. We also provide experimental\nevidence to support our theoretical analysis. We propose two simple but\neffective methods inspired by the fixpoint computation in similarity flooding,\nand demonstrate their effectiveness on benchmark datasets. Our work bridges the\ngap between recent embedding-based models and the conventional similarity\nflooding algorithm. It would improve our understanding of and increase our\nfaith in embedding-based EA.\n","authors":["Zequn Sun","Jiacheng Huang","Xiaozhou Xu","Qijin Chen","Weijun Ren","Wei Hu"],"pdf_url":"https://arxiv.org/pdf/2306.02622v1.pdf","comment":"Accepted in the 40th International Conference on Machine Learning\n  (ICML 2023)"},{"id":"http://arxiv.org/abs/2306.02612v1","updated":"2023-06-05T06:01:00Z","published":"2023-06-05T06:01:00Z","title":"Building Resilient SMEs: Harnessing Large Language Models for Cyber\n  Security in Australia","summary":"  The escalating digitalisation of our lives and enterprises has led to a\nparallel growth in the complexity and frequency of cyber-attacks. Small and\nmedium-sized enterprises (SMEs), particularly in Australia, are experiencing\nincreased vulnerability to cyber threats, posing a significant challenge to the\nnation's cyber security landscape. Embracing transformative technologies such\nas Artificial Intelligence (AI), Machine Learning (ML) and Large Language\nModels (LLMs) can potentially strengthen cyber security policies for Australian\nSMEs. However, their practical application, advantages, and limitations remain\nunderexplored, with prior research mainly focusing on large corporations. This\nstudy aims to address this gap by providing a comprehensive understanding of\nthe potential role of LLMs in enhancing cyber security policies for Australian\nSMEs. Employing a mixed-methods study design, this research includes a\nliterature review, qualitative analysis of SME case studies, and a quantitative\nassessment of LLM performance metrics in cyber security applications. The\nfindings highlight the promising potential of LLMs across various performance\ncriteria, including relevance, accuracy, and applicability, though gaps remain\nin areas such as completeness and clarity. The study underlines the importance\nof integrating human expertise with LLM technology and refining model\ndevelopment to address these limitations. By proposing a robust conceptual\nframework guiding the effective adoption of LLMs, this research aims to\ncontribute to a safer and more resilient cyber environment for Australian SMEs,\nenabling sustainable growth and competitiveness in the digital era.\n","authors":["Benjamin Kereopa-Yorke"],"pdf_url":"https://arxiv.org/pdf/2306.02612v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2306.02597v1","updated":"2023-06-05T05:04:28Z","published":"2023-06-05T05:04:28Z","title":"Early Rumor Detection Using Neural Hawkes Process with a New Benchmark\n  Dataset","summary":"  Little attention has been paid on \\underline{EA}rly \\underline{R}umor\n\\underline{D}etection (EARD), and EARD performance was evaluated\ninappropriately on a few datasets where the actual early-stage information is\nlargely missing. To reverse such situation, we construct BEARD, a new\n\\underline{B}enchmark dataset for \\underline{EARD}, based on claims from\nfact-checking websites by trying to gather as many early relevant posts as\npossible. We also propose HEARD, a novel model based on neural\n\\underline{H}awkes process for \\underline{EARD}, which can guide a generic\nrumor detection model to make timely, accurate and stable predictions.\nExperiments show that HEARD achieves effective EARD performance on two commonly\nused general rumor detection datasets and our BEARD dataset.\n","authors":["Fengzhu Zeng","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2306.02597v1.pdf","comment":"Accepted at NAACL 2022"},{"id":"http://arxiv.org/abs/2306.02596v1","updated":"2023-06-05T05:03:11Z","published":"2023-06-05T05:03:11Z","title":"A Novel Interpretable and Generalizable Re-synchronization Model for\n  Cued Speech based on a Multi-Cuer Corpus","summary":"  Cued Speech (CS) is a multi-modal visual coding system combining lip reading\nwith several hand cues at the phonetic level to make the spoken language\nvisible to the hearing impaired. Previous studies solved asynchronous problems\nbetween lip and hand movements by a cuer\\footnote{The people who perform Cued\nSpeech are called the cuer.}-dependent piecewise linear model for English and\nFrench CS. In this work, we innovatively propose three statistical measure on\nthe lip stream to build an interpretable and generalizable model for predicting\nhand preceding time (HPT), which achieves cuer-independent by a proper\nnormalization. Particularly, we build the first Mandarin CS corpus comprising\nannotated videos from five speakers including three normal and two hearing\nimpaired individuals. Consequently, we show that the hand preceding phenomenon\nexists in Mandarin CS production with significant differences between normal\nand hearing impaired people. Extensive experiments demonstrate that our model\noutperforms the baseline and the previous state-of-the-art methods.\n","authors":["Lufei Gao","Shan Huang","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2306.02596v1.pdf","comment":"5 pages, 4 figures, Accepted to INTERSPEECH2023"},{"id":"http://arxiv.org/abs/2306.02592v1","updated":"2023-06-05T04:46:44Z","published":"2023-06-05T04:46:44Z","title":"Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help\n  Multiple Graph Applications","summary":"  Model pre-training on large text corpora has been demonstrated effective for\nvarious downstream applications in the NLP domain. In the graph mining domain,\na similar analogy can be drawn for pre-training graph models on large graphs in\nthe hope of benefiting downstream graph applications, which has also been\nexplored by several recent studies. However, no existing study has ever\ninvestigated the pre-training of text plus graph models on large heterogeneous\ngraphs with abundant textual information (a.k.a. large graph corpora) and then\nfine-tuning the model on different related downstream applications with\ndifferent graph schemas. To address this problem, we propose a framework of\ngraph-aware language model pre-training (GALM) on a large graph corpus, which\nincorporates large language models and graph neural networks, and a variety of\nfine-tuning methods on downstream applications. We conduct extensive\nexperiments on Amazon's real internal datasets and large public datasets.\nComprehensive empirical results and in-depth analysis demonstrate the\neffectiveness of our proposed methods along with lessons learned.\n","authors":["Han Xie","Da Zheng","Jun Ma","Houyu Zhang","Vassilis N. Ioannidis","Xiang Song","Qing Ping","Sheng Wang","Carl Yang","Yi Xu","Belinda Zeng","Trishul Chilimbi"],"pdf_url":"https://arxiv.org/pdf/2306.02592v1.pdf","comment":"To be published in the KDD 2023 proceedings as a full paper"},{"id":"http://arxiv.org/abs/2305.04087v3","updated":"2023-06-05T04:38:07Z","published":"2023-05-06T16:12:19Z","title":"Self-Edit: Fault-Aware Code Editor for Code Generation","summary":"  Large language models (LLMs) have demonstrated an impressive ability to\ngenerate codes on competitive programming tasks. However, with limited sample\nnumbers, LLMs still suffer from poor accuracy. Inspired by the process of human\nprogramming, we propose a generate-and-edit approach named Self-Edit that\nutilizes execution results of the generated code from LLMs to improve the code\nquality on the competitive programming task. We execute the generated code on\nthe example test case provided in the question and wrap execution results into\na supplementary comment. Utilizing this comment as guidance, our fault-aware\ncode editor is employed to correct errors in the generated code. We perform\nextensive evaluations across two competitive programming datasets with nine\ndifferent LLMs. Compared to directly generating from LLMs, our approach can\nimprove the average of pass@1 by 89\\% on APPS-dev, 31\\% on APPS-test, and 48\\%\non HumanEval over nine popular code generation LLMs with parameter sizes\nranging from 110M to 175B. Compared to other post-processing methods, our\nmethod demonstrates superior accuracy and efficiency.\n","authors":["Kechi Zhang","Zhuo Li","Jia Li","Ge Li","Zhi Jin"],"pdf_url":"https://arxiv.org/pdf/2305.04087v3.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.02579v1","updated":"2023-06-05T04:10:04Z","published":"2023-06-05T04:10:04Z","title":"Cross-Lingual Transfer Learning for Phrase Break Prediction with\n  Multilingual Language Model","summary":"  Phrase break prediction is a crucial task for improving the prosody\nnaturalness of a text-to-speech (TTS) system. However, most proposed phrase\nbreak prediction models are monolingual, trained exclusively on a large amount\nof labeled data. In this paper, we address this issue for low-resource\nlanguages with limited labeled data using cross-lingual transfer. We\ninvestigate the effectiveness of zero-shot and few-shot cross-lingual transfer\nfor phrase break prediction using a pre-trained multilingual language model. We\nuse manually collected datasets in four Indo-European languages: one\nhigh-resource language and three with limited resources. Our findings\ndemonstrate that cross-lingual transfer learning can be a particularly\neffective approach, especially in the few-shot setting, for improving\nperformance in low-resource languages. This suggests that cross-lingual\ntransfer can be inexpensive and effective for developing TTS front-end in\nresource-poor languages.\n","authors":["Hoyeon Lee","Hyun-Wook Yoon","Jong-Hwan Kim","Jae-Min Kim"],"pdf_url":"https://arxiv.org/pdf/2306.02579v1.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2212.09849v4","updated":"2023-06-05T04:02:10Z","published":"2022-12-19T20:46:43Z","title":"Dataless Knowledge Fusion by Merging Weights of Language Models","summary":"  Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.\n","authors":["Xisen Jin","Xiang Ren","Daniel Preotiuc-Pietro","Pengxiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2212.09849v4.pdf","comment":"ICLR 2023; Updated captions of Table 1. The code is available at\n  https://github.com/bloomberg/dataless-model-merging"},{"id":"http://arxiv.org/abs/2305.10847v3","updated":"2023-06-05T03:54:52Z","published":"2023-05-18T10:03:25Z","title":"Large Language Models can be Guided to Evade AI-Generated Text Detection","summary":"  Large Language Models (LLMs) have demonstrated exceptional performance in a\nvariety of tasks, including essay writing and question answering. However, it\nis crucial to address the potential misuse of these models, which can lead to\ndetrimental outcomes such as plagiarism and spamming. Recently, several\ndetectors have been proposed, including fine-tuned classifiers and various\nstatistical methods. In this study, we reveal that with the aid of carefully\ncrafted prompts, LLMs can effectively evade these detection systems. We propose\na novel Substitution-based In-Context example Optimization method (SICO) to\nautomatically generate such prompts. On three real-world tasks where LLMs can\nbe misused, SICO successfully enables ChatGPT to evade six existing detectors,\ncausing a significant 0.54 AUC drop on average. Surprisingly, in most cases\nthese detectors perform even worse than random classifiers. These results\nfirmly reveal the vulnerability of existing detectors. Finally, the strong\nperformance of SICO suggests itself as a reliable evaluation protocol for any\nnew detector in this field.\n","authors":["Ning Lu","Shengcai Liu","Rui He","Qi Wang","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2305.10847v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02569v1","updated":"2023-06-05T03:49:13Z","published":"2023-06-05T03:49:13Z","title":"Prompt to be Consistent is Better than Self-Consistent? Few-Shot and\n  Zero-Shot Fact Verification with Pre-trained Language Models","summary":"  Few-shot or zero-shot fact verification only relies on a few or no labeled\ntraining examples. In this paper, we propose a novel method called ProToCo, to\n\\underline{Pro}mpt pre-trained language models (PLMs) \\underline{To} be\n\\underline{Co}nsistent, for improving the factuality assessment capability of\nPLMs in the few-shot and zero-shot settings. Given a claim-evidence pair,\nProToCo generates multiple variants of the claim with different relations and\nframes a simple consistency mechanism as constraints for making compatible\npredictions across these variants. We update PLMs by using parameter-efficient\nfine-tuning (PEFT), leading to more accurate predictions in few-shot and\nzero-shot fact verification tasks. Our experiments on three public verification\ndatasets show that ProToCo significantly outperforms state-of-the-art few-shot\nfact verification baselines. With a small number of unlabeled instances,\nProToCo also outperforms the strong zero-shot learner T0 on zero-shot\nverification. Compared to large PLMs using in-context learning (ICL) method,\nProToCo outperforms OPT-30B and the Self-Consistency-enabled OPT-6.7B model in\nboth few- and zero-shot settings.\n","authors":["Fengzhu Zeng","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2306.02569v1.pdf","comment":"Accepted as ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.02561v1","updated":"2023-06-05T03:32:26Z","published":"2023-06-05T03:32:26Z","title":"LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and\n  Generative Fusion","summary":"  We present LLM-Blender, an ensembling framework designed to attain\nconsistently superior performance by leveraging the diverse strengths of\nmultiple open-source large language models (LLMs). Our framework consists of\ntwo modules: PairRanker and GenFuser, addressing the observation that optimal\nLLMs for different examples can significantly vary. PairRanker employs a\nspecialized pairwise comparison method to distinguish subtle differences\nbetween candidate outputs. It jointly encodes the input text and a pair of\ncandidates, using cross-attention encoders to determine the superior one. Our\nresults demonstrate that PairRanker exhibits the highest correlation with\nChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates,\ngenerating an improved output by capitalizing on their strengths and mitigating\ntheir weaknesses. To facilitate large-scale evaluation, we introduce a\nbenchmark dataset, MixInstruct, which is a mixture of multiple instruction\ndatasets featuring oracle pairwise comparisons. Our LLM-Blender significantly\noutperform individual LLMs and baseline methods across various metrics,\nestablishing a substantial performance gap.\n","authors":["Dongfu Jiang","Xiang Ren","Bill Yuchen Lin"],"pdf_url":"https://arxiv.org/pdf/2306.02561v1.pdf","comment":"ACL 2023 (Main conference). Project website:\n  https://yuchenlin.xyz/LLM-Blender/"},{"id":"http://arxiv.org/abs/2306.02553v1","updated":"2023-06-05T03:00:10Z","published":"2023-06-05T03:00:10Z","title":"Learning to Relate to Previous Turns in Conversational Search","summary":"  Conversational search allows a user to interact with a search system in\nmultiple turns. A query is strongly dependent on the conversation context. An\neffective way to improve retrieval effectiveness is to expand the current query\nwith historical queries. However, not all the previous queries are related to,\nand useful for expanding the current query. In this paper, we propose a new\nmethod to select relevant historical queries that are useful for the current\nquery. To cope with the lack of labeled training data, we use a pseudo-labeling\napproach to annotate useful historical queries based on their impact on the\nretrieval results. The pseudo-labeled data are used to train a selection model.\nWe further propose a multi-task learning framework to jointly train the\nselector and the retriever during fine-tuning, allowing us to mitigate the\npossible inconsistency between the pseudo labels and the changed retriever.\nExtensive experiments on four conversational search datasets demonstrate the\neffectiveness and broad applicability of our method compared with several\nstrong baselines.\n","authors":["Fengran Mo","Jian-Yun Nie","Kaiyu Huang","Kelong Mao","Yutao Zhu","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.02553v1.pdf","comment":"Accepted by SIGKDD 2023 Research Track"},{"id":"http://arxiv.org/abs/2305.04492v5","updated":"2023-06-05T02:56:28Z","published":"2023-05-08T06:36:46Z","title":"MGR: Multi-generator Based Rationalization","summary":"  Rationalization is to employ a generator and a predictor to construct a\nself-explaining NLP model in which the generator selects a subset of\nhuman-intelligible pieces of the input text to the following predictor.\nHowever, rationalization suffers from two key challenges, i.e., spurious\ncorrelation and degeneration, where the predictor overfits the spurious or\nmeaningless pieces solely selected by the not-yet well-trained generator and in\nturn deteriorates the generator. Although many studies have been proposed to\naddress the two challenges, they are usually designed separately and do not\ntake both of them into account. In this paper, we propose a simple yet\neffective method named MGR to simultaneously solve the two problems. The key\nidea of MGR is to employ multiple generators such that the occurrence stability\nof real pieces is improved and more meaningful pieces are delivered to the\npredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%\nas compared to state-of-the-art methods. Codes are available at\nhttps://github.com/jugechengzi/Rationalization-MGR .\n","authors":["Wei Liu","Haozhao Wang","Jun Wang","Ruixuan Li","Xinyang Li","Yuankai Zhang","Yang Qiu"],"pdf_url":"https://arxiv.org/pdf/2305.04492v5.pdf","comment":"Accepted as a main conference paper of ACL 2023. arXiv admin note:\n  text overlap with arXiv:2209.08285"},{"id":"http://arxiv.org/abs/2306.02549v1","updated":"2023-06-05T02:52:54Z","published":"2023-06-05T02:52:54Z","title":"Evaluation of AI Chatbots for Patient-Specific EHR Questions","summary":"  This paper investigates the use of artificial intelligence chatbots for\npatient-specific question answering (QA) from clinical notes using several\nlarge language model (LLM) based systems: ChatGPT (versions 3.5 and 4), Google\nBard, and Claude. We evaluate the accuracy, relevance, comprehensiveness, and\ncoherence of the answers generated by each model using a 5-point Likert scale\non a set of patient-specific questions.\n","authors":["Alaleh Hamidi","Kirk Roberts"],"pdf_url":"https://arxiv.org/pdf/2306.02549v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02534v1","updated":"2023-06-05T01:55:33Z","published":"2023-06-05T01:55:33Z","title":"Incorporating L2 Phonemes Using Articulatory Features for Robust Speech\n  Recognition","summary":"  The limited availability of non-native speech datasets presents a major\nchallenge in automatic speech recognition (ASR) to narrow the performance gap\nbetween native and non-native speakers. To address this, the focus of this\nstudy is on the efficient incorporation of the L2 phonemes, which in this work\nrefer to Korean phonemes, through articulatory feature analysis. This not only\nenables accurate modeling of pronunciation variants but also allows for the\nutilization of both native Korean and English speech datasets. We employ the\nlattice-free maximum mutual information (LF-MMI) objective in an end-to-end\nmanner, to train the acoustic model to align and predict one of multiple\npronunciation candidates. Experimental results show that the proposed method\nimproves ASR accuracy for Korean L2 speech by training solely on L1 speech\ndata. Furthermore, fine-tuning on L2 speech improves recognition accuracy for\nboth L1 and L2 speech without performance trade-offs.\n","authors":["Jisung Wang","Haram Lee","Myungwoo Oh"],"pdf_url":"https://arxiv.org/pdf/2306.02534v1.pdf","comment":"Accepted at INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.02531v1","updated":"2023-06-05T01:36:39Z","published":"2023-06-05T01:36:39Z","title":"PLANNER: Generating Diversified Paragraph via Latent Language Diffusion\n  Model","summary":"  Autoregressive models for text sometimes generate repetitive and low-quality\noutput because errors accumulate during the steps of generation. This issue is\noften attributed to exposure bias - the difference between how a model is\ntrained, and how it is used during inference. Denoising diffusion models\nprovide an alternative approach in which a model can revisit and revise its\noutput. However, they can be computationally expensive and prior efforts on\ntext have led to models that produce less fluent output compared to\nautoregressive models, especially for longer text and paragraphs. In this\npaper, we propose PLANNER, a model that combines latent semantic diffusion with\nautoregressive generation, to generate fluent text while exercising global\ncontrol over paragraphs. The model achieves this by combining an autoregressive\n\"decoding\" module with a \"planning\" module that uses latent diffusion to\ngenerate semantic paragraph embeddings in a coarse-to-fine manner. The proposed\nmethod is evaluated on various conditional generation tasks, and results on\nsemantic generation, text completion and summarization show its effectiveness\nin generating high-quality long-form text in an efficient manner.\n","authors":["Yizhe Zhang","Jiatao Gu","Zhuofeng Wu","Shuangfei Zhai","Josh Susskind","Navdeep Jaitly"],"pdf_url":"https://arxiv.org/pdf/2306.02531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09955v2","updated":"2023-06-05T01:29:40Z","published":"2022-12-20T02:17:30Z","title":"BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of\n  Faithfulness Metrics","summary":"  The proliferation of automatic faithfulness metrics for summarization has\nproduced a need for benchmarks to evaluate them. While existing benchmarks\nmeasure the correlation with human judgements of faithfulness on\nmodel-generated summaries, they are insufficient for diagnosing whether metrics\nare: 1) consistent, i.e., indicate lower faithfulness as errors are introduced\ninto a summary, 2) effective on human-written texts, and 3) sensitive to\ndifferent error types (as summaries can contain multiple errors). To address\nthese needs, we present a benchmark of unfaithful minimal pairs (BUMP), a\ndataset of 889 human-written, minimally different summary pairs, where a single\nerror is introduced to a summary from the CNN/DailyMail dataset to produce an\nunfaithful summary. We find BUMP complements existing benchmarks in a number of\nways: 1) the summaries in BUMP are harder to discriminate and less probable\nunder SOTA summarization models, 2) unlike non-pair-based datasets, BUMP can be\nused to measure the consistency of metrics, and reveals that the most\ndiscriminative metrics tend not to be the most consistent, and 3) unlike\ndatasets containing generated summaries with multiple errors, BUMP enables the\nmeasurement of metrics' performance on individual error types.\n","authors":["Liang Ma","Shuyang Cao","Robert L. Logan IV","Di Lu","Shihao Ran","Ke Zhang","Joel Tetreault","Alejandro Jaimes"],"pdf_url":"https://arxiv.org/pdf/2212.09955v2.pdf","comment":"Accepted as a long main conference paper at ACL 2023"},{"id":"http://arxiv.org/abs/2306.02520v1","updated":"2023-06-05T01:01:12Z","published":"2023-06-05T01:01:12Z","title":"A Study of Situational Reasoning for Traffic Understanding","summary":"  Intelligent Traffic Monitoring (ITMo) technologies hold the potential for\nimproving road safety/security and for enabling smart city infrastructure.\nUnderstanding traffic situations requires a complex fusion of perceptual\ninformation with domain-specific and causal commonsense knowledge. Whereas\nprior work has provided benchmarks and methods for traffic monitoring, it\nremains unclear whether models can effectively align these information sources\nand reason in novel scenarios. To address this assessment gap, we devise three\nnovel text-based tasks for situational reasoning in the traffic domain: i)\nBDD-QA, which evaluates the ability of Language Models (LMs) to perform\nsituational decision-making, ii) TV-QA, which assesses LMs' abilities to reason\nabout complex event causality, and iii) HDT-QA, which evaluates the ability of\nmodels to solve human driving exams. We adopt four knowledge-enhanced methods\nthat have shown generalization capability across language reasoning tasks in\nprior work, based on natural language inference, commonsense knowledge-graph\nself-supervision, multi-QA joint training, and dense retrieval of domain\ninformation. We associate each method with a relevant knowledge source,\nincluding knowledge graphs, relevant benchmarks, and driving manuals. In\nextensive experiments, we benchmark various knowledge-aware methods against the\nthree datasets, under zero-shot evaluation; we provide in-depth analyses of\nmodel performance on data partitions and examine model predictions\ncategorically, to yield useful insights on traffic understanding, given\ndifferent background knowledge and reasoning strategies.\n","authors":["Jiarui Zhang","Filip Ilievski","Kaixin Ma","Aravinda Kollaa","Jonathan Francis","Alessandro Oltramari"],"pdf_url":"https://arxiv.org/pdf/2306.02520v1.pdf","comment":"11 pages, 6 figures, 5 tables, camera ready version of SIGKDD 2023"},{"id":"http://arxiv.org/abs/2305.03517v2","updated":"2023-06-05T00:58:41Z","published":"2023-05-04T00:10:57Z","title":"Few-shot Domain-Adaptive Visually-fused Event Detection from Text","summary":"  Incorporating auxiliary modalities such as images into event detection models\nhas attracted increasing interest over the last few years. The complexity of\nnatural language in describing situations has motivated researchers to leverage\nthe related visual context to improve event detection performance. However,\ncurrent approaches in this area suffer from data scarcity, where a large amount\nof labelled text-image pairs are required for model training. Furthermore,\nlimited access to the visual context at inference time negatively impacts the\nperformance of such models, which makes them practically ineffective in\nreal-world scenarios. In this paper, we present a novel domain-adaptive\nvisually-fused event detection approach that can be trained on a few labelled\nimage-text paired data points. Specifically, we introduce a visual imaginator\nmethod that synthesises images from text in the absence of visual context.\nMoreover, the imaginator can be customised to a specific domain. In doing so,\nour model can leverage the capabilities of pre-trained vision-language models\nand can be trained in a few-shot setting. This also allows for effective\ninference where only single-modality data (i.e. text) is available. The\nexperimental evaluation on the benchmark M2E2 dataset shows that our model\noutperforms existing state-of-the-art models, by up to 11 points.\n","authors":["Farhad Moghimifar","Fatemeh Shiri","Van Nguyen","Reza Haffari","Yuan-Fang Li"],"pdf_url":"https://arxiv.org/pdf/2305.03517v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09282v2","updated":"2023-06-05T00:56:11Z","published":"2022-12-19T07:40:02Z","title":"APOLLO: A Simple Approach for Adaptive Pretraining of Language Models\n  for Logical Reasoning","summary":"  Logical reasoning of text is an important ability that requires understanding\nthe information present in the text, their interconnections, and then reasoning\nthrough them to infer new conclusions. Prior works on improving the logical\nreasoning ability of language models require complex processing of training\ndata (e.g., aligning symbolic knowledge to text), yielding task-specific data\naugmentation solutions that restrict the learning of general logical reasoning\nskills. In this work, we propose APOLLO, an adaptively pretrained language\nmodel that has improved logical reasoning abilities. We select a subset of\nWikipedia, based on a set of logical inference keywords, for continued\npretraining of a language model. We use two self-supervised loss functions: a\nmodified masked language modeling loss where only specific parts-of-speech\nwords, that would likely require more reasoning than basic language\nunderstanding, are masked, and a sentence-level classification loss that\nteaches the model to distinguish between entailment and contradiction types of\nsentences. The proposed training paradigm is both simple and independent of\ntask formats. We demonstrate the effectiveness of APOLLO by comparing it with\nprior baselines on two logical reasoning datasets. APOLLO performs comparably\non ReClor and outperforms baselines on LogiQA. The code base has been made\npublicly available.\n","authors":["Soumya Sanyal","Yichong Xu","Shuohang Wang","Ziyi Yang","Reid Pryzant","Wenhao Yu","Chenguang Zhu","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2212.09282v2.pdf","comment":"Accepted at ACL 2023, code available at\n  https://github.com/INK-USC/APOLLO"},{"id":"http://arxiv.org/abs/2212.10786v2","updated":"2023-06-05T00:43:13Z","published":"2022-12-21T06:00:22Z","title":"Multi-hop Evidence Retrieval for Cross-document Relation Extraction","summary":"  Relation Extraction (RE) has been extended to cross-document scenarios\nbecause many relations are not simply described in a single document. This\ninevitably brings the challenge of efficient open-space evidence retrieval to\nsupport the inference of cross-document relations, along with the challenge of\nmulti-hop reasoning on top of entities and evidence scattered in an open set of\ndocuments. To combat these challenges, we propose MR.COD (Multi-hop evidence\nretrieval for Cross-document relation extraction), which is a multi-hop\nevidence retrieval method based on evidence path mining and ranking. We explore\nmultiple variants of retrievers to show evidence retrieval is essential in\ncross-document RE. We also propose a contextual dense retriever for this\nsetting. Experiments on CodRED show that evidence retrieval with MR.COD\neffectively acquires crossdocument evidence and boosts end-to-end RE\nperformance in both closed and open settings.\n","authors":["Keming Lu","I-Hung Hsu","Wenxuan Zhou","Mingyu Derek Ma","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2212.10786v2.pdf","comment":"ACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.02514v1","updated":"2023-06-05T00:32:57Z","published":"2023-06-05T00:32:57Z","title":"Jambu: A historical linguistic database for South Asian languages","summary":"  We introduce Jambu, a cognate database of South Asian languages which unifies\ndozens of previous sources in a structured and accessible format. The database\nincludes 287k lemmata from 602 lects, grouped together in 23k sets of cognates.\nWe outline the data wrangling necessary to compile the dataset and train neural\nmodels for reflex prediction on the Indo-Aryan subset of the data. We hope that\nJambu is an invaluable resource for all historical linguists and Indologists,\nand look towards further improvement and expansion of the database.\n","authors":["Aryaman Arora","Adam Farris","Samopriya Basu","Suresh Kolichala"],"pdf_url":"https://arxiv.org/pdf/2306.02514v1.pdf","comment":"5 pages main text, 10 pages total. To appear at SIGMORPHON"},{"id":"http://arxiv.org/abs/2204.05428v2","updated":"2023-06-05T00:14:19Z","published":"2022-04-11T22:11:05Z","title":"A Multilingual Perspective Towards the Evaluation of Attribution Methods\n  in Natural Language Inference","summary":"  Most evaluations of attribution methods focus on the English language. In\nthis work, we present a multilingual approach for evaluating attribution\nmethods for the Natural Language Inference (NLI) task in terms of faithfulness\nand plausibility. First, we introduce a novel cross-lingual strategy to measure\nfaithfulness based on word alignments, which eliminates the drawbacks of\nerasure-based evaluations.We then perform a comprehensive evaluation of\nattribution methods, considering different output mechanisms and aggregation\nmethods. Finally, we augment the XNLI dataset with highlight-based\nexplanations, providing a multilingual NLI dataset with highlights, to support\nfuture exNLP studies. Our results show that attribution methods performing best\nfor plausibility and faithfulness are different.\n","authors":["Kerem Zaman","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2204.05428v2.pdf","comment":"21 pages, 7 figures. Code and data at\n  https://keremzaman.com/explaiNLI/; Published in the Proceedings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2306.03316v1","updated":"2023-06-05T23:58:40Z","published":"2023-06-05T23:58:40Z","title":"CoSiNES: Contrastive Siamese Network for Entity Standardization","summary":"  Entity standardization maps noisy mentions from free-form text to standard\nentities in a knowledge base. The unique challenge of this task relative to\nother entity-related tasks is the lack of surrounding context and numerous\nvariations in the surface form of the mentions, especially when it comes to\ngeneralization across domains where labeled data is scarce. Previous research\nmostly focuses on developing models either heavily relying on context, or\ndedicated solely to a specific domain. In contrast, we propose CoSiNES, a\ngeneric and adaptable framework with Contrastive Siamese Network for Entity\nStandardization that effectively adapts a pretrained language model to capture\nthe syntax and semantics of the entities in a new domain.\n  We construct a new dataset in the technology domain, which contains 640\ntechnical stack entities and 6,412 mentions collected from industrial content\nmanagement systems. We demonstrate that CoSiNES yields higher accuracy and\nfaster runtime than baselines derived from leading methods in this domain.\nCoSiNES also achieves competitive performance in four standard datasets from\nthe chemistry, medicine, and biomedical domains, demonstrating its cross-domain\napplicability.\n","authors":["Jiaqing Yuan","Michele Merler","Mihir Choudhury","Raju Pavuluri","Munindar P. Singh","Maja Vukovic"],"pdf_url":"https://arxiv.org/pdf/2306.03316v1.pdf","comment":"Accepted by Matching Workshop at ACL2023"},{"id":"http://arxiv.org/abs/2306.03315v1","updated":"2023-06-05T23:57:52Z","published":"2023-06-05T23:57:52Z","title":"Few Shot Rationale Generation using Self-Training with Dual Teachers","summary":"  Self-rationalizing models that also generate a free-text explanation for\ntheir predicted labels are an important tool to build trustworthy AI\napplications. Since generating explanations for annotated labels is a laborious\nand costly pro cess, recent models rely on large pretrained language models\n(PLMs) as their backbone and few-shot learning. In this work we explore a\nself-training approach leveraging both labeled and unlabeled data to further\nimprove few-shot models, under the assumption that neither human written\nrationales nor annotated task labels are available at scale. We introduce a\nnovel dual-teacher learning framework, which learns two specialized teacher\nmodels for task prediction and rationalization using self-training and distills\ntheir knowledge into a multi-tasking student model that can jointly generate\nthe task label and rationale. Furthermore, we formulate a new loss function,\nMasked Label Regularization (MLR) which promotes explanations to be strongly\nconditioned on predicted labels. Evaluation on three public datasets\ndemonstrate that the proposed methods are effective in modeling task labels and\ngenerating faithful rationales.\n","authors":["Aditya Srikanth Veerubhotla","Lahari Poddar","Jun Yin","György Szarvas","Sharanya Eswaran"],"pdf_url":"https://arxiv.org/pdf/2306.03315v1.pdf","comment":"ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.03313v1","updated":"2023-06-05T23:55:09Z","published":"2023-06-05T23:55:09Z","title":"A Scalable and Adaptive System to Infer the Industry Sectors of\n  Companies: Prompt + Model Tuning of Generative Language Models","summary":"  The Private Equity (PE) firms operate investment funds by acquiring and\nmanaging companies to achieve a high return upon selling. Many PE funds are\nthematic, meaning investment professionals aim to identify trends by covering\nas many industry sectors as possible, and picking promising companies within\nthese sectors. So, inferring sectors for companies is critical to the success\nof thematic PE funds. In this work, we standardize the sector framework and\ndiscuss the typical challenges; we then introduce our sector inference system\naddressing these challenges. Specifically, our system is built on a\nmedium-sized generative language model, finetuned with a prompt + model tuning\nprocedure. The deployed model demonstrates a superior performance than the\ncommon baselines. The system has been serving many PE professionals for over a\nyear, showing great scalability to data volume and adaptability to any change\nin sector framework and/or annotation.\n","authors":["Lele Cao","Vilhelm von Ehrenheim","Astrid Berghult","Cecilia Henje","Richard Anselmo Stahl","Joar Wandborg","Sebastian Stan","Armin Catovic","Erik Ferm","Hannes Ingelhag"],"pdf_url":"https://arxiv.org/pdf/2306.03313v1.pdf","comment":"Accepted by FinNLP (Financial Technology and Natural Language\n  Processing) @ IJCAI2023 as long paper (8 pages and 8 figures)"},{"id":"http://arxiv.org/abs/2301.04761v2","updated":"2023-06-05T23:47:43Z","published":"2023-01-11T23:45:50Z","title":"NarrowBERT: Accelerating Masked Language Model Pretraining and Inference","summary":"  Large-scale language model pretraining is a very successful form of\nself-supervised learning in natural language processing, but it is increasingly\nexpensive to perform as the models and pretraining corpora have become larger\nover time. We propose NarrowBERT, a modified transformer encoder that increases\nthe throughput for masked language model pretraining by more than $2\\times$.\nNarrowBERT sparsifies the transformer model such that the self-attention\nqueries and feedforward layers only operate on the masked tokens of each\nsentence during pretraining, rather than all of the tokens as with the usual\ntransformer encoder. We also show that NarrowBERT increases the throughput at\ninference time by as much as $3.5\\times$ with minimal (or no) performance\ndegradation on sentence encoding tasks like MNLI. Finally, we examine the\nperformance of NarrowBERT on the IMDB and Amazon reviews classification and\nCoNLL NER tasks and show that it is also comparable to standard BERT\nperformance.\n","authors":["Haoxin Li","Phillip Keung","Daniel Cheng","Jungo Kasai","Noah A. Smith"],"pdf_url":"https://arxiv.org/pdf/2301.04761v2.pdf","comment":"To appear in ACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2210.01351v3","updated":"2023-06-05T22:40:20Z","published":"2022-10-04T03:36:53Z","title":"Less is More: Task-aware Layer-wise Distillation for Language Model\n  Compression","summary":"  Layer-wise distillation is a powerful tool to compress large models (i.e.\nteacher models) into small ones (i.e., student models). The student distills\nknowledge from the teacher by mimicking the hidden representations of the\nteacher at every intermediate layer. However, layer-wise distillation is\ndifficult. Since the student has a smaller model capacity than the teacher, it\nis often under-fitted. Furthermore, the hidden representations of the teacher\ncontain redundant information that the student does not necessarily need for\nthe target task's learning. To address these challenges, we propose a novel\nTask-aware layEr-wise Distillation (TED). TED designs task-aware filters to\nalign the hidden representations of the student and the teacher at each layer.\nThe filters select the knowledge that is useful for the target task from the\nhidden representations. As such, TED reduces the knowledge gap between the two\nmodels and helps the student to fit better on the target task. We evaluate TED\nin two scenarios: continual pre-training and fine-tuning. TED demonstrates\nsignificant and consistent improvements over existing distillation methods in\nboth scenarios. Code is available at\nhttps://github.com/cliang1453/task-aware-distillation.\n","authors":["Chen Liang","Simiao Zuo","Qingru Zhang","Pengcheng He","Weizhu Chen","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2210.01351v3.pdf","comment":"Proceedings of ICML 2023"},{"id":"http://arxiv.org/abs/2306.03268v1","updated":"2023-06-05T21:38:30Z","published":"2023-06-05T21:38:30Z","title":"Stack Over-Flowing with Results: The Case for Domain-Specific\n  Pre-Training Over One-Size-Fits-All Models","summary":"  Large pre-trained neural language models have brought immense progress to\nboth NLP and software engineering. Models in OpenAI's GPT series now dwarf\nGoogle's BERT and Meta's RoBERTa, which previously set new benchmarks on a wide\nrange of NLP applications. These models are trained on massive corpora of\nheterogeneous data from web crawls, which enables them to learn general\nlanguage patterns and semantic relationships. However, the largest models are\nboth expensive to train and deploy and are often closed-source, so we lack\naccess to their data and design decisions. We argue that this trend towards\nlarge, general-purpose models should be complemented with single-purpose, more\nmodestly sized pre-trained models. In this work, we take StackOverflow (SO) as\na domain example in which large volumes of rich aligned code and text data is\navailable. We adopt standard practices for pre-training large language models,\nincluding using a very large context size (2,048 tokens), batch size (0.5M\ntokens) and training set (27B tokens), coupled with a powerful toolkit\n(Megatron-LM), to train two models: SOBertBase, with 109M parameters, and\nSOBertLarge with 762M parameters, at a budget of just $187 and $800 each. We\ncompare the performance of our models with both the previous SOTA model trained\non SO data exclusively as well general-purpose BERT models and OpenAI's ChatGPT\non four SO-specific downstream tasks - question quality prediction, closed\nquestion prediction, named entity recognition and obsoletion prediction (a new\ntask we introduce). Not only do our models consistently outperform all\nbaselines, the smaller model is often sufficient for strong results. Both\nmodels are released to the public. These results demonstrate that pre-training\nboth extensively and properly on in-domain data can yield a powerful and\naffordable alternative to leveraging closed-source general-purpose models.\n","authors":["Manisha Mukherjee","Vincent J. Hellendoorn"],"pdf_url":"https://arxiv.org/pdf/2306.03268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03264v1","updated":"2023-06-05T21:33:04Z","published":"2023-06-05T21:33:04Z","title":"shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned\n  LLMs for Radiology Report Impression Generation","summary":"  Instruction-tuned generative Large language models (LLMs) like ChatGPT and\nBloomz possess excellent generalization abilities, but they face limitations in\nunderstanding radiology reports, particularly in the task of generating the\nIMPRESSIONS section from the FINDINGS section. They tend to generate either\nverbose or incomplete IMPRESSIONS, mainly due to insufficient exposure to\nmedical text data during training. We present a system which leverages\nlarge-scale medical text data for domain-adaptive pre-training of\ninstruction-tuned LLMs to enhance its medical knowledge and performance on\nspecific medical tasks. We show that this system performs better in a zero-shot\nsetting than a number of pretrain-and-finetune adaptation methods on the\nIMPRESSIONS generation task, and ranks 1st among participating systems in Task\n1B: Radiology Report Summarization at the BioNLP 2023 workshop.\n","authors":["Sanjeev Kumar Karn","Rikhiya Ghosh","Kusuma P","Oladimeji Farri"],"pdf_url":"https://arxiv.org/pdf/2306.03264v1.pdf","comment":"1st Place in Task 1B: Radiology Report Summarization at BioNLP 2023"},{"id":"http://arxiv.org/abs/2211.10438v5","updated":"2023-06-05T21:21:28Z","published":"2022-11-18T18:59:33Z","title":"SmoothQuant: Accurate and Efficient Post-Training Quantization for Large\n  Language Models","summary":"  Large language models (LLMs) show excellent performance but are compute- and\nmemory-intensive. Quantization can reduce memory and accelerate inference.\nHowever, existing methods cannot maintain accuracy and hardware efficiency at\nthe same time. We propose SmoothQuant, a training-free, accuracy-preserving,\nand general-purpose post-training quantization (PTQ) solution to enable 8-bit\nweight, 8-bit activation (W8A8) quantization for LLMs. Based on the fact that\nweights are easy to quantize while activations are not, SmoothQuant smooths the\nactivation outliers by offline migrating the quantization difficulty from\nactivations to weights with a mathematically equivalent transformation.\nSmoothQuant enables an INT8 quantization of both weights and activations for\nall the matrix multiplications in LLMs, including OPT, BLOOM, GLM, MT-NLG, and\nLLaMA family. We demonstrate up to 1.56x speedup and 2x memory reduction for\nLLMs with negligible loss in accuracy. SmoothQuant enables serving 530B LLM\nwithin a single node. Our work offers a turn-key solution that reduces hardware\ncosts and democratizes LLMs. Code is available at\nhttps://github.com/mit-han-lab/smoothquant.\n","authors":["Guangxuan Xiao","Ji Lin","Mickael Seznec","Hao Wu","Julien Demouth","Song Han"],"pdf_url":"https://arxiv.org/pdf/2211.10438v5.pdf","comment":"ICML 2023. First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2306.03241v1","updated":"2023-06-05T20:51:44Z","published":"2023-06-05T20:51:44Z","title":"Understanding the Effectiveness of Early Weight Averaging for Training\n  Large Language Models","summary":"  Training LLMs is expensive, and recent evidence indicates training all the\nway to convergence is inefficient. In this paper, we investigate the ability of\na simple idea, checkpoint averaging along the trajectory of a training run to\nimprove the quality of models before they have converged. This approach incurs\nno extra cost during training or inference. Specifically, we analyze the\ntraining trajectories of Pythia LLMs with 1 to 12 billion parameters and\ndemonstrate that, particularly during the early to mid stages of training, this\nidea accelerates convergence and improves both test and zero-shot\ngeneralization. Loss spikes are a well recognized problem in LLM training; in\nour analysis we encountered two instances of this in the underlying\ntrajectories, and both instances were mitigated by our averaging.\n  For a 6.9B parameter LLM, for example, our early weight averaging recipe can\nsave upto 4200 hours of GPU time, which corresponds to significant savings in\ncloud compute costs.\n","authors":["Sunny Sanyal","Jean Kaddour","Abhishek Kumar","Sujay Sanghavi"],"pdf_url":"https://arxiv.org/pdf/2306.03241v1.pdf","comment":"17 pages, 12 figures, under review"},{"id":"http://arxiv.org/abs/2209.08284v3","updated":"2023-06-05T20:41:18Z","published":"2022-09-17T08:48:50Z","title":"Structured Knowledge Grounding for Question Answering","summary":"  Can language models (LM) ground question-answering (QA) tasks in the\nknowledge base via inherent relational reasoning ability? While previous models\nthat use only LMs have seen some success on many QA tasks, more recent methods\ninclude knowledge graphs (KG) to complement LMs with their more logic-driven\nimplicit knowledge. However, effectively extracting information from structured\ndata, like KGs, empowers LMs to remain an open question, and current models\nrely on graph techniques to extract knowledge. In this paper, we propose to\nsolely leverage the LMs to combine the language and knowledge for knowledge\nbased question-answering with flexibility, breadth of coverage and structured\nreasoning. Specifically, we devise a knowledge construction method that\nretrieves the relevant context with a dynamic hop, which expresses more\ncomprehensivenes than traditional GNN-based techniques. And we devise a deep\nfusion mechanism to further bridge the information exchanging bottleneck\nbetween the language and the knowledge. Extensive experiments show that our\nmodel consistently demonstrates its state-of-the-art performance over\nCommensenseQA benchmark, showcasing the possibility to leverage LMs solely to\nrobustly ground QA into the knowledge base.\n","authors":["Yujie Lu","Siqi Ouyang","Kairui Zhou"],"pdf_url":"https://arxiv.org/pdf/2209.08284v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03208v1","updated":"2023-06-05T19:30:41Z","published":"2023-06-05T19:30:41Z","title":"NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification\n  Tasks","summary":"  Finetuning large language models inflates the costs of NLU applications and\nremains the bottleneck of development cycles. Recent works in computer vision\nuse data pruning to reduce training time. Pruned data selection with static\nmethods is based on a score calculated for each training example prior to\nfinetuning, which involves important computational overhead. Moreover, the\nscore may not necessarily be representative of sample importance throughout the\nentire training duration. We propose to address these issues with a refined\nversion of dynamic data pruning, a curriculum which periodically scores and\ndiscards unimportant examples during finetuning. Our method leverages an EL2N\nmetric that we extend to the joint intent and slot classification task, and an\ninitial finetuning phase on the full train set. Our results on the GLUE\nbenchmark and four joint NLU datasets show a better time-accuracy trade-off\ncompared to static methods. Our method preserves full accuracy while training\non 50% of the data points and reduces computational times by up to 41%. If we\ntolerate instead a minor drop of accuracy of 1%, we can prune 80% of the\ntraining examples for a reduction in finetuning time reaching 66%.\n","authors":["Jean-Michel Attendu","Jean-Philippe Corbeil"],"pdf_url":"https://arxiv.org/pdf/2306.03208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03203v1","updated":"2023-06-05T19:23:34Z","published":"2023-06-05T19:23:34Z","title":"A Static Evaluation of Code Completion by Large Language Models","summary":"  Large language models trained on code have shown great potential to increase\nproductivity of software developers. Several execution-based benchmarks have\nbeen proposed to evaluate functional correctness of model-generated code on\nsimple programming problems. Nevertheless, it is expensive to perform the same\nevaluation on complex real-world projects considering the execution cost. On\nthe contrary, static analysis tools such as linters, which can detect errors\nwithout running the program, haven't been well explored for evaluating code\ngeneration models. In this work, we propose a static evaluation framework to\nquantify static errors in Python code completions, by leveraging Abstract\nSyntax Trees. Compared with execution-based evaluation, our method is not only\nmore efficient, but also applicable to code in the wild. For experiments, we\ncollect code context from open source repos to generate one million function\nbodies using public models. Our static analysis reveals that Undefined Name and\nUnused Variable are the most common errors among others made by language\nmodels. Through extensive studies, we also show the impact of sampling\ntemperature, model size, and context on static errors in code completions.\n","authors":["Hantian Ding","Varun Kumar","Yuchen Tian","Zijian Wang","Rob Kwiatkowski","Xiaopeng Li","Murali Krishna Ramanathan","Baishakhi Ray","Parminder Bhatia","Sudipta Sengupta","Dan Roth","Bing Xiang"],"pdf_url":"https://arxiv.org/pdf/2306.03203v1.pdf","comment":"Accepted by ACL 2023 industry track"},{"id":"http://arxiv.org/abs/2306.03197v1","updated":"2023-06-05T19:16:37Z","published":"2023-06-05T19:16:37Z","title":"AutoScrum: Automating Project Planning Using Large Language Models","summary":"  Recent advancements in the field of large language models have made it\npossible to use language models for advanced reasoning. In this paper we\nleverage this ability for designing complex project plans based only on knowing\nthe current state and the desired state. Two approaches are demonstrated - a\nscrum based approach and a shortcut plan approach. The scrum based approach\nexecutes an automated process of requirements gathering, user story mapping,\nfeature identification, task decomposition and finally generates questions and\nsearch terms for seeking out domain specific information to assist with task\ncompletion. The shortcut approach looks at most recent snapshot of the current\nand desired state and generates the next most reasonable task to do in order to\nget to the desired state as quickly as possible. In this paper we automate\neverything using a novel concept of \"Language Programs\". These are programs\nwritten in natural language designed to process input data through the language\nmodel. Guidance language is used for all LLM programs. All demo source code for\nthis paper is available at https://github.com/autoscrum/autoscrum\n","authors":["Martin Schroder"],"pdf_url":"https://arxiv.org/pdf/2306.03197v1.pdf","comment":"25 pages, 3 figures, demo: https://github.com/autoscrum/autoscrum"},{"id":"http://arxiv.org/abs/2212.10534v3","updated":"2023-06-05T19:16:25Z","published":"2022-12-20T18:46:08Z","title":"DISCO: Distilling Counterfactuals with Large Language Models","summary":"  Models trained with counterfactually augmented data learn representations of\nthe causal structure of tasks, enabling robust generalization. However,\nhigh-quality counterfactual data is scarce for most tasks and not easily\ngenerated at scale. When crowdsourced, such data is typically limited in scale\nand diversity; when generated using supervised methods, it is computationally\nexpensive to extend to new counterfactual dimensions. In this work, we\nintroduce DISCO (DIStilled COunterfactual Data), a new method for automatically\ngenerating high quality counterfactual data at scale. DISCO engineers prompts\nto generate phrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters these generations to distill high-quality\ncounterfactual data. While task-agnostic, we apply our pipeline to the task of\nnatural language inference (NLI) and find that on challenging evaluations such\nas the NLI stress test, comparatively smaller student models trained with DISCO\ngenerated counterfactuals are more robust (6% absolute) and generalize better\nacross distributions (2%) compared to models trained without data augmentation.\nFurthermore, DISCO augmented models are 10% more consistent between\ncounterfactual pairs on three evaluation sets, demonstrating that DISCO\naugmentation enables models to more reliably learn causal representations. Our\nrepository is available at: https://github.com/eric11eca/disco\n","authors":["Zeming Chen","Qiyue Gao","Antoine Bosselut","Ashish Sabharwal","Kyle Richardson"],"pdf_url":"https://arxiv.org/pdf/2212.10534v3.pdf","comment":"ACL 2023 camera ready, final title change"},{"id":"http://arxiv.org/abs/2306.03189v1","updated":"2023-06-05T19:00:25Z","published":"2023-06-05T19:00:25Z","title":"Easy-to-Read in Germany: A Survey on its Current State and Available\n  Resources","summary":"  Easy-to-Read Language (E2R) is a controlled language variant that makes any\nwritten text more accessible through the use of clear, direct and simple\nlanguage. It is mainly aimed at people with cognitive or intellectual\ndisabilities, among other target users. Plain Language (PL), on the other hand,\nis a variant of a given language, which aims to promote the use of simple\nlanguage to communicate information. German counts with Leichte Sprache (LS),\nits version of E2R, and Einfache Sprache (ES), its version of PL. In recent\nyears, important developments have been conducted in the field of LS. This\npaper offers an updated overview of the existing Natural Language Processing\n(NLP) tools and resources for LS. Besides, it also aims to set out the\nsituation with regard to LS and ES in Germany.\n","authors":["Margot Madina","Itziar Gonzalez-Dios","Melanie Siegel"],"pdf_url":"https://arxiv.org/pdf/2306.03189v1.pdf","comment":"10th Language & Technology Conference: Human Language Technologies as\n  a Challenge for Computer Science and Linguistics, 2023"},{"id":"http://arxiv.org/abs/2306.03168v1","updated":"2023-06-05T18:22:23Z","published":"2023-06-05T18:22:23Z","title":"Composition and Deformance: Measuring Imageability with a Text-to-Image\n  Model","summary":"  Although psycholinguists and psychologists have long studied the tendency of\nlinguistic strings to evoke mental images in hearers or readers, most\ncomputational studies have applied this concept of imageability only to\nisolated words. Using recent developments in text-to-image generation models,\nsuch as DALLE mini, we propose computational methods that use generated images\nto measure the imageability of both single English words and connected text. We\nsample text prompts for image generation from three corpora: human-generated\nimage captions, news article sentences, and poem lines. We subject these\nprompts to different deformances to examine the model's ability to detect\nchanges in imageability caused by compositional change. We find high\ncorrelation between the proposed computational measures of imageability and\nhuman judgments of individual words. We also find the proposed measures more\nconsistently respond to changes in compositionality than baseline approaches.\nWe discuss possible effects of model training and implications for the study of\ncompositionality in text-to-image models.\n","authors":["Si Wu","David A. Smith"],"pdf_url":"https://arxiv.org/pdf/2306.03168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03166v1","updated":"2023-06-05T18:20:27Z","published":"2023-06-05T18:20:27Z","title":"Unsupervised Dense Retrieval with Relevance-Aware Contrastive\n  Pre-Training","summary":"  Dense retrievers have achieved impressive performance, but their demand for\nabundant training data limits their application scenarios. Contrastive\npre-training, which constructs pseudo-positive examples from unlabeled data,\nhas shown great potential to solve this problem. However, the pseudo-positive\nexamples crafted by data augmentations can be irrelevant. To this end, we\npropose relevance-aware contrastive learning. It takes the intermediate-trained\nmodel itself as an imperfect oracle to estimate the relevance of positive pairs\nand adaptively weighs the contrastive loss of different pairs according to the\nestimated relevance. Our method consistently improves the SOTA unsupervised\nContriever model on the BEIR and open-domain QA retrieval benchmarks. Further\nexploration shows that our method can not only beat BM25 after further\npre-training on the target corpus but also serves as a good few-shot learner.\nOur code is publicly available at https://github.com/Yibin-Lei/ReContriever.\n","authors":["Yibin Lei","Liang Ding","Yu Cao","Changtong Zan","Andrew Yates","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.03166v1.pdf","comment":"ACL 2023 Findings (Short), 5 pages main + 1 page references + 1 page\n  appendix"},{"id":"http://arxiv.org/abs/2304.10611v2","updated":"2023-06-05T18:16:29Z","published":"2023-04-20T19:17:49Z","title":"Joint Repetition Suppression and Content Moderation of Large Language\n  Models","summary":"  Natural language generation (NLG) is one of the most impactful fields in NLP,\nand recent years have witnessed its evolution brought about by large language\nmodels (LLMs). As the key instrument for writing assistance applications, they\nare generally prone to replicating or extending offensive content provided in\nthe input. In low-resource data regime, they can also lead to repetitive\noutputs. Usually, offensive content and repetitions are mitigated with post-hoc\nmethods, including n-gram level blocklists, top-k and nucleus sampling. In this\npaper, we apply non-exact repetition suppression using token and sequence level\nunlikelihood loss, and further explore the framework of unlikelihood training\nobjective in order to jointly endow the model with abilities to avoid\ngenerating offensive words and phrases from the beginning. Finally, with\ncomprehensive experiments, we demonstrate that our proposed methods work\nexceptionally in controlling the repetition and content quality of LLM outputs.\n","authors":["Minghui Zhang","Alex Sokolov","Weixin Cai","Si-Qing Chen"],"pdf_url":"https://arxiv.org/pdf/2304.10611v2.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2306.03065v1","updated":"2023-06-05T17:43:46Z","published":"2023-06-05T17:43:46Z","title":"LibAUC: A Deep Learning Library for X-Risk Optimization","summary":"  This paper introduces the award-winning deep learning (DL) library called\nLibAUC for implementing state-of-the-art algorithms towards optimizing a family\nof risk functions named X-risks. X-risks refer to a family of compositional\nfunctions in which the loss function of each data point is defined in a way\nthat contrasts the data point with a large number of others. They have broad\napplications in AI for solving classical and emerging problems, including but\nnot limited to classification for imbalanced data (CID), learning to rank\n(LTR), and contrastive learning of representations (CLR). The motivation of\ndeveloping LibAUC is to address the convergence issues of existing libraries\nfor solving these problems. In particular, existing libraries may not converge\nor require very large mini-batch sizes in order to attain good performance for\nthese problems, due to the usage of the standard mini-batch technique in the\nempirical risk minimization (ERM) framework. Our library is for deep X-risk\noptimization (DXO) that has achieved great success in solving a variety of\ntasks for CID, LTR and CLR. The contributions of this paper include: (1) It\nintroduces a new mini-batch based pipeline for implementing DXO algorithms,\nwhich differs from existing DL pipeline in the design of controlled data\nsamplers and dynamic mini-batch losses; (2) It provides extensive benchmarking\nexperiments for ablation studies and comparison with existing libraries. The\nLibAUC library features scalable performance for millions of items to be\ncontrasted, faster and better convergence than existing libraries for\noptimizing X-risks, seamless PyTorch deployment and versatile APIs for various\nloss optimization. Our library is available to the open source community at\nhttps://github.com/Optimization-AI/LibAUC, to facilitate further academic\nresearch and industrial applications.\n","authors":["Zhuoning Yuan","Dixian Zhu","Zi-Hao Qiu","Gang Li","Xuanhui Wang","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03065v1.pdf","comment":"Accepted by KDD2023"},{"id":"http://arxiv.org/abs/2306.03033v1","updated":"2023-06-05T16:51:01Z","published":"2023-06-05T16:51:01Z","title":"Entropic mean-field min-max problems via Best Response and Fisher-Rao\n  flows","summary":"  We investigate convergence properties of two continuous-time optimization\nmethods, the Mean-Field Best Response and the Fisher-Rao (Mean-Field\nBirth-Death) flows, for solving convex-concave min-max games with entropy\nregularization. We introduce suitable Lyapunov functions to establish\nexponential convergence to the unique mixed Nash equilibrium for both methods,\nalbeit under slightly different conditions. Additionally, we demonstrate the\nconvergence of the fictitious play flow as a by-product of our analysis.\n","authors":["Razvan-Andrei Lascu","Mateusz B. Majka","Łukasz Szpruch"],"pdf_url":"https://arxiv.org/pdf/2306.03033v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2306.03027v1","updated":"2023-06-05T16:46:13Z","published":"2023-06-05T16:46:13Z","title":"Explicit feedback synthesis driven by quasi-interpolation for nonlinear\n  robust model predictive control","summary":"  We present QuIFS (Quasi-Interpolation driven Feedback Synthesis) -- an\noffline feedback synthesis algorithm for explicit nonlinear robust minmax model\npredictive control (MPC) problems with guaranteed quality of approximation. The\nunderlying technique is driven by a particular type of grid-based\nquasi-interpolation scheme. The QuIFS algorithm departs drastically from\nconventional approximation algorithms that are employed in the MPC industry (in\nparticular, it is neither based on multi-parametric programming tools nor does\nit involve kernel methods), and the essence of their point of departure is\nencoded in the following challenge-answer approach: Given an error margin\n$\\varepsilon>0$, compute a feasible feedback policy that is uniformly\n$\\varepsilon$-close to the optimal MPC feedback policy for a given nonlinear\nsystem subjected to hard constraints and bounded uncertainties. Conditions for\nclosed-loop stability and recursive feasibility under the approximate feedback\npolicy are also established. We provide a library of numerical examples to\nillustrate our results.\n","authors":["Siddhartha Ganguly","Debasish Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2306.03027v1.pdf","comment":"26 Pages"},{"id":"http://arxiv.org/abs/2112.04571v4","updated":"2023-06-05T16:32:55Z","published":"2021-12-08T20:22:04Z","title":"Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach","summary":"  A main research goal in various studies is to use an observational data set\nand provide a new set of counterfactual guidelines that can yield causal\nimprovements. Dynamic Treatment Regimes (DTRs) are widely studied to formalize\nthis process. However, available methods in finding optimal DTRs often rely on\nassumptions that are violated in real-world applications (e.g., medical\ndecision-making or public policy), especially when (a) the existence of\nunobserved confounders cannot be ignored, and (b) the unobserved confounders\nare time-varying (e.g., affected by previous actions). When such assumptions\nare violated, one often faces ambiguity regarding the underlying causal model.\nThis ambiguity is inevitable, since the dynamics of unobserved confounders and\ntheir causal impact on the observed part of the data cannot be understood from\nthe observed data. Motivated by a case study of finding superior treatment\nregimes for patients who underwent transplantation in our partner hospital and\nfaced a medical condition known as New Onset Diabetes After Transplantation\n(NODAT), we extend DTRs to a new class termed Ambiguous Dynamic Treatment\nRegimes (ADTRs), in which the causal impact of treatment regimes is evaluated\nbased on a \"cloud\" of causal models. We then connect ADTRs to Ambiguous\nPartially Observable Mark Decision Processes (APOMDPs) and develop\nReinforcement Learning methods, which enable using the observed data to\nefficiently learn an optimal treatment regime. We establish theoretical results\nfor these learning methods, including (weak) consistency and asymptotic\nnormality. We further evaluate the performance of these learning methods both\nin our case study and in simulation experiments.\n","authors":["Soroush Saghafian"],"pdf_url":"https://arxiv.org/pdf/2112.04571v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02987v1","updated":"2023-06-05T16:00:22Z","published":"2023-06-05T16:00:22Z","title":"Frequency Regulation with Storage: On Losses and Profits","summary":"  Low-carbon societies will need to store vast amounts of electricity to\nbalance intermittent generation from wind and solar energy, for example,\nthrough frequency regulation. Here, we derive an analytical solution to the\ndecision-making problem of storage operators who sell frequency regulation\npower to grid operators and trade electricity on day-ahead markets.\nMathematically, we treat future frequency deviation trajectories as functional\nuncertainties in a receding horizon robust optimization problem. We constrain\nthe expected terminal state-of-charge to be equal to some target to allow\nstorage operators to make good decisions not only for the present but also the\nfuture. Thanks to this constraint, the amount of electricity traded on\nday-ahead markets is an implicit function of the regulation power sold to grid\noperators. The implicit function quantifies the amount of power that needs to\nbe purchased to cover the expected energy loss that results from providing\nfrequency regulation. We show how the marginal cost associated with the\nexpected energy loss decreases with roundtrip efficiency and increases with\nfrequency deviation dispersion. We find that the profits from frequency\nregulation over the lifetime of energy-constrained storage devices are roughly\ninversely proportional to the length of time for which regulation power must be\ncommitted.\n","authors":["Dirk Lauinger","François Vuille","Daniel Kuhn"],"pdf_url":"https://arxiv.org/pdf/2306.02987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02959v1","updated":"2023-06-05T15:25:36Z","published":"2023-06-05T15:25:36Z","title":"Curvature and complexity: Better lower bounds for geodesically convex\n  optimization","summary":"  We study the query complexity of geodesically convex (g-convex) optimization\non a manifold. To isolate the effect of that manifold's curvature, we primarily\nfocus on hyperbolic spaces. In a variety of settings (smooth or not; strongly\ng-convex or not; high- or low-dimensional), known upper bounds worsen with\ncurvature. It is natural to ask whether this is warranted, or an artifact.\n  For many such settings, we propose a first set of lower bounds which indeed\nconfirm that (negative) curvature is detrimental to complexity. To do so, we\nbuild on recent lower bounds (Hamilton and Moitra, 2021; Criscitiello and\nBoumal, 2022) for the particular case of smooth, strongly g-convex\noptimization. Using a number of techniques, we also secure lower bounds which\ncapture dependence on condition number and optimality gap, which was not\npreviously the case.\n  We suspect these bounds are not optimal. We conjecture optimal ones, and\nsupport them with a matching lower bound for a class of algorithms which\nincludes subgradient descent, and a lower bound for a related game. Lastly, to\npinpoint the difficulty of proving lower bounds, we study how negative\ncurvature influences (and sometimes obstructs) interpolation with g-convex\nfunctions.\n","authors":["Christopher Criscitiello","Nicolas Boumal"],"pdf_url":"https://arxiv.org/pdf/2306.02959v1.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2206.02774v3","updated":"2023-06-05T14:33:39Z","published":"2022-06-06T17:56:20Z","title":"Polyak-Łojasiewicz inequality on the space of measures and convergence\n  of mean-field birth-death processes","summary":"  The Polyak-Lojasiewicz inequality (PLI) in $\\mathbb{R}^d$ is a natural\ncondition for proving convergence of gradient descent algorithms. In the\npresent paper, we study an analogue of PLI on the space of probability measures\n$\\mathcal{P}(\\mathbb{R}^d)$ and show that it is a natural condition for showing\nexponential convergence of a class of birth-death processes related to certain\nmean-field optimization problems. We verify PLI for a broad class of such\nproblems for energy functions regularised by the KL-divergence.\n","authors":["Linshan Liu","Mateusz B. Majka","Łukasz Szpruch"],"pdf_url":"https://arxiv.org/pdf/2206.02774v3.pdf","comment":"21 pages, revised version, accepted for publication in Applied\n  Mathematics & Optimization. The final manuscript is available at Springer via\n  https://doi.org/10.1007/s00245-022-09962-0"},{"id":"http://arxiv.org/abs/2211.09523v3","updated":"2023-06-05T14:25:14Z","published":"2022-11-17T13:39:55Z","title":"Right-left asymmetry of the eigenvector method: A simulation study","summary":"  The eigenvalue method, suggested by the developer of the extensively used\nAnalytic Hierarchy Process methodology, exhibits right-left asymmetry: the\npriorities derived from the right eigenvector do not necessarily coincide with\nthe priorities derived from the reciprocal left eigenvector. This paper offers\na comprehensive numerical experiment to compare the two eigenvector-based\nweighting procedures and their reasonable alternative of the row geometric mean\nwith respect to four measures. The underlying pairwise comparison matrices are\nconstructed randomly with different dimensions and levels of inconsistency. The\ndisagreement between the two eigenvectors turns out to be not always a\nmonotonic function of these important characteristics of the matrix. The\nranking contradictions can affect alternatives with relatively distant\npriorities. The row geometric mean is found to be almost at the midpoint\nbetween the right and inverse left eigenvectors, making it a straightforward\ncompromise between them.\n","authors":["László Csató"],"pdf_url":"https://arxiv.org/pdf/2211.09523v3.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2301.11342v2","updated":"2023-06-05T14:13:40Z","published":"2023-01-26T19:00:02Z","title":"A Robust Optimisation Perspective on Counterexample-Guided Repair of\n  Neural Networks","summary":"  Counterexample-guided repair aims at creating neural networks with\nmathematical safety guarantees, facilitating the application of neural networks\nin safety-critical domains. However, whether counterexample-guided repair is\nguaranteed to terminate remains an open question. We approach this question by\nshowing that counterexample-guided repair can be viewed as a robust\noptimisation algorithm. While termination guarantees for neural network repair\nitself remain beyond our reach, we prove termination for more restrained\nmachine learning models and disprove termination in a general setting. We\nempirically study the practical implications of our theoretical results,\ndemonstrating the suitability of common verifiers and falsifiers for repair\ndespite a disadvantageous theoretical result. Additionally, we use our\ntheoretical insights to devise a novel algorithm for repairing linear\nregression models based on quadratic programming, surpassing existing\napproaches.\n","authors":["David Boetius","Stefan Leue","Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2301.11342v2.pdf","comment":"Accepted at ICML 2023. 9 pages + 13 pages appendix, 8 figures"},{"id":"http://arxiv.org/abs/2211.12908v2","updated":"2023-06-05T13:33:10Z","published":"2022-11-23T12:21:57Z","title":"Exact solution approaches for the discrete $α$-neighbor $p$-center\n  problem","summary":"  The discrete $\\alpha$-neighbor $p$-center problem (d-$\\alpha$-$p$CP) is an\nemerging variant of the classical $p$-center problem which recently got\nattention in literature. In this problem, we are given a discrete set of points\nand we need to locate $p$ facilities on these points in such a way that the\nmaximum distance between each point where no facility is located and its\n$\\alpha$-closest facility is minimized. The only existing algorithms in\nliterature for solving the d-$\\alpha$-$p$CP are approximation algorithms and\ntwo recently proposed heuristics.\n  In this work, we present two integer programming formulations for the\nd-$\\alpha$-$p$CP, together with lifting of inequalities, valid inequalities,\ninequalities that do not change the optimal objective function value and\nvariable fixing procedures. We provide theoretical results on the strength of\nthe formulations and convergence results for the lower bounds obtained after\napplying the lifting procedures or the variable fixing procedures in an\niterative fashion. Based on our formulations and theoretical results, we\ndevelop branch-and-cut (B&C) algorithms, which are further enhanced with a\nstarting heuristic and a primal heuristic.\n  We evaluate the effectiveness of our B&C algorithms using instances from\nliterature. Our algorithms are able to solve 116 out of 194 instances from\nliterature to proven optimality, with a runtime of under a minute for most of\nthem. By doing so, we also provide improved solution values for 116 instances.\n","authors":["Elisabeth Gaar","Markus Sinnl"],"pdf_url":"https://arxiv.org/pdf/2211.12908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.11989v6","updated":"2023-06-05T13:20:53Z","published":"2022-01-28T08:52:01Z","title":"Existence and Estimation of Critical Batch Size for Training Generative\n  Adversarial Networks with Two Time-Scale Update Rule","summary":"  Previous results have shown that a two time-scale update rule (TTUR) using\ndifferent learning rates, such as different constant rates or different\ndecaying rates, is useful for training generative adversarial networks (GANs)\nin theory and in practice. Moreover, not only the learning rate but also the\nbatch size is important for training GANs with TTURs and they both affect the\nnumber of steps needed for training. This paper studies the relationship\nbetween batch size and the number of steps needed for training GANs with TTURs\nbased on constant learning rates. We theoretically show that, for a TTUR with\nconstant learning rates, the number of steps needed to find stationary points\nof the loss functions of both the discriminator and generator decreases as the\nbatch size increases and that there exists a critical batch size minimizing the\nstochastic first-order oracle (SFO) complexity. Then, we use the Fr'echet\ninception distance (FID) as the performance measure for training and provide\nnumerical results indicating that the number of steps needed to achieve a low\nFID score decreases as the batch size increases and that the SFO complexity\nincreases once the batch size exceeds the measured critical batch size.\nMoreover, we show that measured critical batch sizes are close to the sizes\nestimated from our theoretical results.\n","authors":["Naoki Sato","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2201.11989v6.pdf","comment":"Accepted at the 40th International Conference on Machine Learning\n  (ICML 2023)"},{"id":"http://arxiv.org/abs/2306.02849v1","updated":"2023-06-05T12:58:55Z","published":"2023-06-05T12:58:55Z","title":"Exact Two-Step Benders Decomposition for Two-Stage Stochastic\n  Mixed-Integer Programs","summary":"  Many real-life optimization problems belong to the class of two-stage\nstochastic mixed-integer programming problems with continuous recourse. This\npaper introduces Two-Step Benders Decomposition with Scenario Clustering (TBDS)\nas a general exact solution methodology for solving such stochastic programs to\noptimality. The method combines and generalizes Benders dual decomposition,\npartial Benders decomposition, and Scenario Clustering techniques and does so\nwithin a novel two-step decomposition along the binary and continuous\nfirst-stage decisions. We use TBDS to provide the first exact solutions for the\nso-called Time Window Assignment Traveling Salesperson problem. This is a\ncanonical optimization problem for service-oriented vehicle routing; it\nconsiders jointly assigning time windows to customers and routing a vehicle\namong them while travel times are stochastic. Extensive experiments show that\nTBDS is superior to state-of-the-art approaches in the literature. It solves\ninstances with up to 25 customers to optimality. It provides better lower and\nupper bounds that lead to faster convergence than related methods. For example,\nBenders dual decomposition cannot solve instances of 10 customers to\noptimality. We use TBDS to analyze the structure of the optimal solutions. By\nincreasing routing costs only slightly, customer service can be improved\ntremendously, driven by smartly alternating between high- and low-variance\ntravel arcs to reduce the impact of delay propagation throughout the executed\nvehicle route.\n","authors":["Sifa Celik","Layla Martin","Albert H. Schrotenboer","Tom Van Woensel"],"pdf_url":"https://arxiv.org/pdf/2306.02849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02832v1","updated":"2023-06-05T12:27:34Z","published":"2023-06-05T12:27:34Z","title":"Probabilistic Region-of-Attraction Estimation with Scenario Optimization\n  and Converse Theorems","summary":"  The region of attraction characterizes well-behaved and safe operation of a\nnonlinear system and is hence sought after for verification. In this paper, a\nframework for probabilistic region of attraction estimation is developed that\ncombines scenario optimization and converse theorems. With this approach, the\nprobability of an unstable condition being included in the estimate is\nindependent of the system's complexity, while convergence in probability to the\ntrue region of attraction is proven. Numerical examples demonstrate the\neffectiveness for optimization-based control applications. Combining systems\ntheory and sampling, the complexity of Monte--Carlo-based verification\ntechniques can be reduced. The results can be extended to arbitrary level sets\nof which the defining function can be sampled, such as finite-horizon\nviability. Thus, the proposed approach is applicable and/or adaptable to\nverification of a wide range of safety-related properties for nonlinear systems\nincluding feedback laws based on optimization or learning.\n","authors":["Torbjørn Cunis"],"pdf_url":"https://arxiv.org/pdf/2306.02832v1.pdf","comment":"Submitted to IEEE Transactions of Automatic Control"},{"id":"http://arxiv.org/abs/2306.02817v1","updated":"2023-06-05T12:13:11Z","published":"2023-06-05T12:13:11Z","title":"Integer Programming Games: A Gentle Computational Overview","summary":"  In this tutorial, we present a computational overview on computing Nash\nequilibria in Integer Programming Games ($IPG$s), $i.e.$, how to compute\nsolutions for a class of non-cooperative and nonconvex games where each player\nsolves a mixed-integer optimization problem. $IPG$s are a broad class of games\nextending the modeling power of mixed-integer optimization to multi-agent\nsettings. This class of games includes, for instance, any finite game and any\nmulti-agent extension of traditional combinatorial optimization problems. After\nproviding some background motivation and context of applications, we\nsystematically review and classify the state-of-the-art algorithms to compute\nNash equilibria. We propose an essential taxonomy of the algorithmic\ningredients needed to compute equilibria, and we describe the theoretical and\npractical challenges associated with equilibria computation. Finally, we\nquantitatively and qualitatively compare a sequential Stackelberg game with a\nsimultaneous $IPG$ to highlight the different properties of their solutions.\n","authors":["Margarida Carvalho","Gabriele Dragotto","Andrea Lodi","Sriram Sankaranarayan"],"pdf_url":"https://arxiv.org/pdf/2306.02817v1.pdf","comment":"To appear in INFORMS TutORials in Operations Research 2023"},{"id":"http://arxiv.org/abs/2302.14471v3","updated":"2023-06-05T11:59:36Z","published":"2023-02-28T10:29:42Z","title":"Safe Peeling for L0-Regularized Least-Squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of L0-regularized least-squares problems via a Branch-and-Bound\n(BnB) algorithm. Our procedure enables to tighten the convex relaxation\nconsidered at each node of the BnB decision tree and therefore potentially\nallows for more aggressive pruning. Numerical simulations show that our\nproposed methodology leads to significant gains in terms of number of nodes\nexplored and overall solving time.s show that our proposed methodology leads to\nsignificant gains in terms of number of nodes explored and overall solving\ntime.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.08897v2","updated":"2023-06-05T11:56:09Z","published":"2023-04-18T10:52:16Z","title":"An adaptive safety layer with hard constraints for safe reinforcement\n  learning in multi-energy management systems","summary":"  Safe reinforcement learning (RL) with hard constraint guarantees is a\npromising optimal control direction for multi-energy management systems. It\nonly requires the environment-specific constraint functions itself a priori and\nnot a complete model (i.e. plant, disturbance and noise models, and prediction\nmodels for states not included in the plant model - e.g. demand forecasts,\nweather forecasts, price forecasts). The project-specific upfront and ongoing\nengineering efforts are therefore still reduced, better representations of the\nunderlying system dynamics can still be learned and modelling bias is kept to a\nminimum (no model-based objective function). However, even the constraint\nfunctions alone are not always trivial to accurately provide in advance,\nleading to potentially unsafe behaviour. In this paper, we present two novel\nadvancements: (I) combining the Optlayer and SafeFallback method, named\nOptLayerPolicy, to increase the initial utility while keeping a high sample\nefficiency. (II) introducing self-improving hard constraints, to increase the\naccuracy of the constraint functions as more data becomes available so that\nbetter policies can be learned. Both advancements keep the constraint\nformulation decoupled from the RL formulation, so that new (presumably better)\nRL algorithms can act as drop-in replacements. We have shown that, in a\nsimulated multi-energy system case study, the initial utility is increased to\n92.4% (OptLayerPolicy) compared to 86.1% (OptLayer) and that the policy after\ntraining is increased to 104.9% (GreyOptLayerPolicy) compared to 103.4%\n(OptLayer) - all relative to a vanilla RL benchmark. While introducing\nsurrogate functions into the optimization problem requires special attention,\nwe do conclude that the newly presented GreyOptLayerPolicy method is the most\nadvantageous.\n","authors":["Glenn Ceusters","Muhammad Andy Putratama","Rüdiger Franke","Ann Nowé","Maarten Messagie"],"pdf_url":"https://arxiv.org/pdf/2304.08897v2.pdf","comment":"4703 words. arXiv admin note: text overlap with arXiv:2207.03830"},{"id":"http://arxiv.org/abs/2306.02784v1","updated":"2023-06-05T11:23:14Z","published":"2023-06-05T11:23:14Z","title":"Tight Big-Ms for Optimal Transmission Switching","summary":"  This paper addresses the Optimal Transmission Switching (OTS) problem in\nelectricity networks, which aims to find an optimal power grid topology that\nminimizes system operation costs while satisfying physical and operational\nconstraints. Existing methods typically convert the OTS problem into a\nMixed-Integer Linear Program (MILP) using big-M constants. However, the\ncomputational performance of these approaches relies significantly on the\ntightness of these big-Ms. In this paper, we propose an iterative tightening\nstrategy to strengthen the big-Ms by efficiently solving a series of bounding\nproblems that account for the economics of the OTS objective function through\nan upper-bound on the generating cost. We also discuss how the performance of\nthe proposed tightening strategy is enhanced if reduced line capacities are\nconsidered. Using the 118-bus test system we demonstrate that the proposed\nmethodology outperforms existing approaches, offering tighter bounds and\nsignificantly reducing the computational burden of the OTS problem.\n","authors":["Salvador Pineda","Juan Miguel Morales","Álvaro Porras","Concepción Domínguez"],"pdf_url":"https://arxiv.org/pdf/2306.02784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02904v2","updated":"2023-06-05T10:01:48Z","published":"2023-02-06T16:18:48Z","title":"Rethinking Gauss-Newton for learning over-parameterized models","summary":"  This work studies the global convergence and generalization properties of\nGauss Newton's (GN) when optimizing one-hidden layer networks in the\nover-parameterized regime. We first establish a global convergence result for\nGN in the continuous-time limit exhibiting a faster convergence rate compared\nto GD due to improved conditioning. We then perform an empirical study on a\nsynthetic regression task to investigate the implicit bias of GN's method. We\nfind that, while GN is consistently faster than GD in finding a global optimum,\nthe performance of the learned model on a test dataset is heavily influenced by\nboth the learning rate and the variance of the randomly initialized network's\nweights. Specifically, we find that initializing with a smaller variance\nresults in a better generalization, a behavior also observed for GD. However,\nin contrast to GD where larger learning rates lead to the best generalization,\nwe find that GN achieves an improved generalization when using smaller learning\nrates, albeit at the cost of slower convergence. This study emphasizes the\nsignificance of the learning rate in balancing the optimization speed of GN\nwith the generalization ability of the learned solution.\n","authors":["Michael Arbel","Romain Menegaux","Pierre Wolinski"],"pdf_url":"https://arxiv.org/pdf/2302.02904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02746v1","updated":"2023-06-05T09:58:20Z","published":"2023-06-05T09:58:20Z","title":"On the Split Closure of the Periodic Timetabling Polytope","summary":"  The Periodic Event Scheduling Problem (PESP) is the central mathematical tool\nfor periodic timetable optimization in public transport. PESP can be formulated\nin several ways as a mixed-integer linear program with typically general\ninteger variables. We investigate the split closure of these formulations and\nshow that split inequalities are identical with the recently introduced flip\ninequalities. While split inequalities are a general mixed-integer programming\ntechnique, flip inequalities are defined in purely combinatorial terms, namely\ncycles and arc sets of the digraph underlying the PESP instance. It is known\nthat flip inequalities can be separated in pseudo-polynomial time. We prove\nthat this is best possible unless P $=$ NP, but also observe that the\ncomplexity becomes linear-time if the cycle defining the flip inequality is\nfixed. Moreover, introducing mixed-integer-compatible maps, we compare the\nsplit closures of different formulations, and show that reformulation or\nbinarization by subdivision do not lead to stronger split closures. Finally, we\nestimate computationally how much of the optimality gap of the instances of the\nbenchmark library PESPlib can be closed exclusively by split cuts, and provide\nbetter dual bounds for five instances.\n","authors":["Niels Lindner","Berenike Masing"],"pdf_url":"https://arxiv.org/pdf/2306.02746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02737v1","updated":"2023-06-05T09:33:00Z","published":"2023-06-05T09:33:00Z","title":"Comparative analysis of the existence and uniqueness conditions of\n  parameter estimation in paired comparison models","summary":"  In this paper paired comparison models with stochastic background are\ninvestigated. We focus on the models which allow three options for choice and\nthe parameters are estimated by maximum likelihood method. The existence and\nuniqueness of the estimator is a key issue of the evaluation. In the case of\ntwo options, a necessary and sufficient condition is given by Ford in the\nBradley-Terry model. We generalize this statement for the set of strictly\nlog-concave distribution. Although in the case of three options necessary and\nsufficient condition is not known, there are two different sufficient\nconditions which are formulated in the literature. In this paper we generalize\nthem, moreover we compare these conditions. Their capacities to indicate the\nexistence of the maximum are analyzed by a large number of computer\nsimulations. These simulations support that the new condition indicates the\nexistence of the maximum much more frequently then the previously known ones,\n","authors":["László Gyarmati","Éva Orbán-Mihálykó","Csaba Mihálykó"],"pdf_url":"https://arxiv.org/pdf/2306.02737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02725v1","updated":"2023-06-05T09:20:26Z","published":"2023-06-05T09:20:26Z","title":"On the convergence of the $k$-point bound for topological packing graphs","summary":"  We show that the $k$-point bound of de Laat, Machado, Oliveira, and\nVallentin, a hierarchy of upper bounds for the independence number of a\ntopological packing graph derived from the Lasserre hierarchy, converges to the\nindependence number.\n","authors":["Bram Bekker","Fernando Mário de Oliveira Filho"],"pdf_url":"https://arxiv.org/pdf/2306.02725v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2305.04736v2","updated":"2023-06-05T08:53:05Z","published":"2023-05-08T14:40:18Z","title":"Accelerated Stochastic Optimization Methods under Quasar-convexity","summary":"  Non-convex optimization plays a key role in a growing number of machine\nlearning applications. This motivates the identification of specialized\nstructure that enables sharper theoretical analysis. One such identified\nstructure is quasar-convexity, a non-convex generalization of convexity that\nsubsumes convex functions. Existing algorithms for minimizing quasar-convex\nfunctions in the stochastic setting have either high complexity or slow\nconvergence, which prompts us to derive a new class of stochastic methods for\noptimizing smooth quasar-convex functions. We demonstrate that our algorithms\nhave fast convergence and outperform existing algorithms on several examples,\nincluding the classical problem of learning linear dynamical systems. We also\npresent a unified analysis of our newly proposed algorithms and a previously\nstudied deterministic algorithm.\n","authors":["Qiang Fu","Dongchu Xu","Ashia Wilson"],"pdf_url":"https://arxiv.org/pdf/2305.04736v2.pdf","comment":"Accepted at the main conference of ICML 2023. 30 pages"},{"id":"http://arxiv.org/abs/2306.02689v1","updated":"2023-06-05T08:29:55Z","published":"2023-06-05T08:29:55Z","title":"Solving NP-hard Min-max Routing Problems as Sequential Generation with\n  Equity Context","summary":"  Min-max routing problems aim to minimize the maximum tour length among agents\nas they collaboratively visit all cities, i.e., the completion time. These\nproblems include impactful real-world applications but are known as NP-hard.\nExisting methods are facing challenges, particularly in large-scale problems\nthat require the coordination of numerous agents to cover thousands of cities.\nThis paper proposes a new deep-learning framework to solve large-scale min-max\nrouting problems. We model the simultaneous decision-making of multiple agents\nas a sequential generation process, allowing the utilization of scalable\ndeep-learning models for sequential decision-making. In the sequentially\napproximated problem, we propose a scalable contextual Transformer model,\nEquity-Transformer, which generates sequential actions considering an equitable\nworkload among other agents. The effectiveness of Equity-Transformer is\ndemonstrated through its superior performance in two representative min-max\nrouting tasks: the min-max multiple traveling salesman problem (min-max mTSP)\nand the min-max multiple pick-up and delivery problem (min-max mPDP). Notably,\nour method achieves significant reductions of runtime, approximately 335 times,\nand cost values of about 53% compared to a competitive heuristic (LKH3) in the\ncase of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source\ncode: https://github.com/kaist-silab/equity-transformer\n","authors":["Jiwoo Son","Minsu Kim","Sanghyeok Choi","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02689v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2009.07574v2","updated":"2023-06-05T08:28:25Z","published":"2020-09-16T09:37:59Z","title":"Second-order analysis of an optimal control problem in a phase field\n  tumor growth model with singular potentials and chemotaxis","summary":"  This paper concerns a distributed optimal control problem for a tumor growth\nmodel of Cahn-Hilliard type including chemotaxis with possibly singular\npotentials, where the control and state variables are nonlinearly coupled.\nFirst, we discuss the weak well-posedness of the system under very general\nassumptions for the potentials, which may be singular and nonsmooth. Then, we\nestablish the strong well-posedness of the system in a reduced setting, which\nhowever admits the logarithmic potential: this analysis will lay the foundation\nfor the study of the corresponding optimal control problem. Concerning the\noptimization problem, we address the existence of minimizers and establish both\nfirst-order necessary and second-order sufficient conditions for optimality.\nThe mathematically challenging second-order analysis is completely performed\nhere, after showing that the solution mapping is twice continuously\ndifferentiable between suitable Banach spaces via the implicit function\ntheorem. Then, we completely identify the second-order Fr\\'echet derivative of\nthe control-to-state operator and carry out a thorough and detailed\ninvestigation about the related properties.\n","authors":["Pierluigi Colli","Andrea Signori","Jürgen Sprekels"],"pdf_url":"https://arxiv.org/pdf/2009.07574v2.pdf","comment":"Please note that the formula (6.5), in both the arXiv preprint and in\n  the journal article, contains three sign errors: indeed, the term in the\n  second line of (6.5) involving P'' should carry a `plus' sign, while the two\n  terms in the third line should carry `minus' signs. These sign errors,\n  however, do not have an impact on the validity of the results"},{"id":"http://arxiv.org/abs/2306.02666v1","updated":"2023-06-05T08:01:50Z","published":"2023-06-05T08:01:50Z","title":"Does a sparse ReLU network training problem always admit an optimum?","summary":"  Given a training set, a loss function, and a neural network architecture, it\nis often taken for granted that optimal network parameters exist, and a common\npractice is to apply available optimization algorithms to search for them. In\nthis work, we show that the existence of an optimal solution is not always\nguaranteed, especially in the context of {\\em sparse} ReLU neural networks. In\nparticular, we first show that optimization problems involving deep networks\nwith certain sparsity patterns do not always have optimal parameters, and that\noptimization algorithms may then diverge. Via a new topological relation\nbetween sparse ReLU neural networks and their linear counterparts, we derive --\nusing existing tools from real algebraic geometry -- an algorithm to verify\nthat a given sparsity pattern suffers from this issue. Then, the existence of a\nglobal optimum is proved for every concrete optimization problem involving a\nshallow sparse ReLU neural network of output dimension one. Overall, the\nanalysis is based on the investigation of two topological properties of the\nspace of functions implementable as sparse ReLU neural networks: a best\napproximation property, and a closedness property, both in the uniform norm.\nThis is studied both for (finite) domains corresponding to practical training\non finite training sets, and for more general domains such as the unit cube.\nThis allows us to provide conditions for the guaranteed existence of an optimum\ngiven a sparsity pattern. The results apply not only to several sparsity\npatterns proposed in recent works on network pruning/sparsification, but also\nto classical dense neural networks, including architectures not covered by\nexisting results.\n","authors":["Quoc-Tung Le","Elisa Riccietti","Rémi Gribonval"],"pdf_url":"https://arxiv.org/pdf/2306.02666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02660v1","updated":"2023-06-05T07:48:42Z","published":"2023-06-05T07:48:42Z","title":"Automated Importance Sampling via Optimal Control for Stochastic\n  Reaction Networks: A Markovian Projection-based Approach","summary":"  We propose a novel alternative approach to our previous work (Ben Hammouda et\nal., 2023) to improve the efficiency of Monte Carlo (MC) estimators for rare\nevent probabilities for stochastic reaction networks (SRNs). In the same spirit\nof (Ben Hammouda et al., 2023), an efficient path-dependent measure change is\nderived based on a connection between determining optimal importance sampling\n(IS) parameters within a class of probability measures and a stochastic optimal\ncontrol formulation, corresponding to solving a variance minimization problem.\nIn this work, we propose a novel approach to address the encountered curse of\ndimensionality by mapping the problem to a significantly lower-dimensional\nspace via a Markovian projection (MP) idea. The output of this model reduction\ntechnique is a low-dimensional SRN (potentially even one dimensional) that\npreserves the marginal distribution of the original high-dimensional SRN\nsystem. The dynamics of the projected process are obtained by solving a related\noptimization problem via a discrete $L^2$ regression. By solving the resulting\nprojected Hamilton-Jacobi-Bellman (HJB) equations for the reduced-dimensional\nSRN, we obtain projected IS parameters, which are then mapped back to the\noriginal full-dimensional SRN system, resulting in an efficient IS-MC estimator\nfor rare events probabilities of the full-dimensional SRN. Our analysis and\nnumerical experiments reveal that the proposed MP-HJB-IS approach substantially\nreduces the MC estimator variance, resulting in a lower computational\ncomplexity in the rare event regime than standard MC estimators.\n","authors":["Chiheb Ben Hammouda","Nadhir Ben Rached","Raúl Tempone","Sophia Wiechert"],"pdf_url":"https://arxiv.org/pdf/2306.02660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07611v2","updated":"2023-06-05T07:17:49Z","published":"2022-11-14T18:32:46Z","title":"Robust optimality and duality for composite uncertain multiobjective\n  optimization in Asplund spaces with its applications","summary":"  This article is devoted to investigate a nonsmooth/nonconvex uncertain\nmultiobjective optimization problem with composition fields\n($(\\hyperlink{CUP}{\\mathrm{CUP}})$ for brevity) over arbitrary Asplund spaces.\nEmploying some advanced techniques of variational analysis and generalized\ndifferentiation, we establish necessary optimality conditions for weakly robust\nefficient solutions of $(\\hyperlink{CUP}{\\mathrm{CUP}})$ in terms of the\nlimiting subdifferential. Sufficient conditions for the existence of (weakly)\nrobust efficient solutions to such a problem are also driven under the new\nconcept of pseudo-quasi convexity for composite functions. We formulate a\nMond-Weir-type robust dual problem to the primal problem\n$(\\hyperlink{CUP}{\\mathrm{CUP}})$, and explore weak, strong, and converse\nduality properties. In addition, the obtained results are applied to an\napproximate uncertain multiobjective problem and a composite uncertain\nmultiobjective problem with linear operators.\n","authors":["Maryam Saadati","Morteza Oveisiha"],"pdf_url":"https://arxiv.org/pdf/2211.07611v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2105.14366,\n  arXiv:2205.01145"},{"id":"http://arxiv.org/abs/2306.02601v1","updated":"2023-06-05T05:21:01Z","published":"2023-06-05T05:21:01Z","title":"Aiming towards the minimizers: fast convergence of SGD for\n  overparametrized problems","summary":"  Modern machine learning paradigms, such as deep learning, occur in or close\nto the interpolation regime, wherein the number of model parameters is much\nlarger than the number of data samples. In this work, we propose a regularity\ncondition within the interpolation regime which endows the stochastic gradient\nmethod with the same worst-case iteration complexity as the deterministic\ngradient method, while using only a single sampled gradient (or a minibatch) in\neach iteration. In contrast, all existing guarantees require the stochastic\ngradient method to take small steps, thereby resulting in a much slower linear\nrate of convergence. Finally, we demonstrate that our condition holds when\ntraining sufficiently wide feedforward neural networks with a linear output\nlayer.\n","authors":["Chaoyue Liu","Dmitriy Drusvyatskiy","Mikhail Belkin","Damek Davis","Yi-An Ma"],"pdf_url":"https://arxiv.org/pdf/2306.02601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02570v1","updated":"2023-06-05T03:51:14Z","published":"2023-06-05T03:51:14Z","title":"When Decentralized Optimization Meets Federated Learning","summary":"  Federated learning is a new learning paradigm for extracting knowledge from\ndistributed data. Due to its favorable properties in preserving privacy and\nsaving communication costs, it has been extensively studied and widely applied\nto numerous data analysis applications. However, most existing federated\nlearning approaches concentrate on the centralized setting, which is vulnerable\nto a single-point failure. An alternative strategy for addressing this issue is\nthe decentralized communication topology. In this article, we systematically\ninvestigate the challenges and opportunities when renovating decentralized\noptimization for federated learning. In particular, we discussed them from the\nmodel, data, and communication sides, respectively, which can deepen our\nunderstanding about decentralized federated learning.\n","authors":["Hongchang Gao","My T. Thai","Jie Wu"],"pdf_url":"https://arxiv.org/pdf/2306.02570v1.pdf","comment":"Accepted to IEEE Network"},{"id":"http://arxiv.org/abs/2211.04594v3","updated":"2023-06-05T02:38:28Z","published":"2022-11-08T22:33:24Z","title":"Frugal and Decentralised Resolvent Splittings Defined by Nonexpansive\n  Operators","summary":"  Frugal resolvent splittings are a class of fixed point algorithms for finding\na zero in the sum of the sum of finitely many set-valued monotone operators,\nwhere the fixed point operator uses only vector addition, scalar multiplication\nand the resolvent of each monotone operator once per iteration. In the\nliterature, the convergence analyses of these schemes are performed in an\ninefficient, algorithm-by-algorithm basis. In this work, we address this by\ndeveloping a general framework for frugal resolvent splitting which\nsimultaneously covers and extends several important schemes in the literature.\nThe framework also yields a new resolvent splitting algorithm which is suitable\nfor decentralised implementation on regular networks.\n","authors":["Matthew K. Tam"],"pdf_url":"https://arxiv.org/pdf/2211.04594v3.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2304.13972v2","updated":"2023-06-05T01:41:27Z","published":"2023-04-27T06:27:37Z","title":"Convergence of Adam under Relaxed Assumptions","summary":"  In this paper, we provide a rigorous proof of convergence of the Adaptive\nMoment Estimate (Adam) algorithm for a wide class of optimization objectives.\nDespite the popularity and efficiency of the Adam algorithm in training deep\nneural networks, its theoretical properties are not yet fully understood, and\nexisting convergence proofs require unrealistically strong assumptions, such as\nglobally bounded gradients, to show the convergence to stationary points. In\nthis paper, we show that Adam provably converges to $\\epsilon$-stationary\npoints with $\\mathcal{O}(\\epsilon^{-4})$ gradient complexity under far more\nrealistic conditions. The key to our analysis is a new proof of boundedness of\ngradients along the optimization trajectory of Adam, under a generalized\nsmoothness assumption according to which the local smoothness (i.e., Hessian\nnorm when it exists) is bounded by a sub-quadratic function of the gradient\nnorm. Moreover, we propose a variance-reduced version of Adam with an\naccelerated gradient complexity of $\\mathcal{O}(\\epsilon^{-3})$.\n","authors":["Haochuan Li","Alexander Rakhlin","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2304.13972v2.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2306.02527v1","updated":"2023-06-05T01:23:49Z","published":"2023-06-05T01:23:49Z","title":"Searching for Optimal Per-Coordinate Step-sizes with Multidimensional\n  Backtracking","summary":"  The backtracking line-search is an effective technique to automatically tune\nthe step-size in smooth optimization. It guarantees similar performance to\nusing the theoretically optimal step-size. Many approaches have been developed\nto instead tune per-coordinate step-sizes, also known as diagonal\npreconditioners, but none of the existing methods are provably competitive with\nthe optimal per-coordinate stepsizes. We propose multidimensional backtracking,\nan extension of the backtracking line-search to find good diagonal\npreconditioners for smooth convex problems. Our key insight is that the\ngradient with respect to the step-sizes, also known as hypergradients, yields\nseparating hyperplanes that let us search for good preconditioners using\ncutting-plane methods. As black-box cutting-plane approaches like the ellipsoid\nmethod are computationally prohibitive, we develop an efficient algorithm\ntailored to our setting. Multidimensional backtracking is provably competitive\nwith the best diagonal preconditioner and requires no manual tuning.\n","authors":["Frederik Kunstner","Victor S. Portella","Mark Schmidt","Nick Harvey"],"pdf_url":"https://arxiv.org/pdf/2306.02527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05416v2","updated":"2023-06-05T01:03:21Z","published":"2023-02-10T18:32:40Z","title":"Approximate Dynamic Programming for a Mean-field Game of Traffic Flow:\n  Existence and Uniqueness","summary":"  Highway vehicular traffic is an inherently multi-agent problem. Traffic jams\ncan appear and disappear mysteriously. We develop a method for traffic flow\ncontrol that is applied at the vehicular level via mean-field games. We begin\nthis work with a microscopic model of vehicles subject to control input,\ndisturbances, noise, and a speed limit. We formulate a discounted-cost\ninfinite-horizon robust mean-field game on the vehicles, and obtain the\nassociated dynamic programming (DP) PDE system. We then perform approximate\ndynamic programming (ADP) using these equations to obtain a sub-optimal control\nfor the traffic density adaptively. The sub-optimal controls are subject to an\nODE-PDE system. We show that the ADP ODE-PDE system has a unique weak solution\nin a suitable Hilbert space using semigroup and successive approximation\nmethods. We additionally give a numerical simulation, and interpret the\nresults.\n","authors":["Amoolya Tirumalai","John S. Baras"],"pdf_url":"https://arxiv.org/pdf/2302.05416v2.pdf","comment":"42 pages, 5 figures"},{"id":"http://arxiv.org/abs/2209.03640v3","updated":"2023-06-05T22:33:43Z","published":"2022-09-08T08:37:07Z","title":"Viability and Exponentially Stable Trajectories for Differential\n  Inclusions in Wasserstein Spaces","summary":"  In this article, we prove a general viability theorem for continuity\ninclusions in Wasserstein spaces, and provide an application thereof to the\nexistence of exponentially stable trajectories obtained via the second method\nof Lyapunov.\n","authors":["Benoît Bonnet","Hélène Frankowska"],"pdf_url":"https://arxiv.org/pdf/2209.03640v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.00759v6","updated":"2023-06-05T21:31:11Z","published":"2020-04-02T00:39:07Z","title":"Safe Learning MPC with Limited Model Knowledge and Data","summary":"  This paper presents an end-to-end framework for safe learning-based control\n(LbC) using nonlinear stochastic MPC and distributionally robust optimization\n(DRO). This work is motivated by several open challenges in LbC literature. In\nparticular, many control-theoretic LbC methods require subject matter expertise\nin order to translate their own safety guarantees, often manifested as\npreexisting data of safe trajectories or structural model knowledge. In this\npaper, we focus on LbC where the controller is applied directly to a system of\nwhich it has no or extremely limited direct experience, towards safety during\ntabula-rasa or ``blank slate'' model-based learning and control. This explores\nthe boundary of the status-quo in control theory relating to requirements for\nsubject matter expertise. We show under basic and limited assumptions on the\nunderlying problem, we can translate probabilistic guarantees on feasibility to\nnonlinear systems using existing results in stochastic MPC and DRO literature.\nWe also present a coupled and intuitive formulation for persistence of\nexcitation (PoE), and illustrate the connection between PoE and applicability\nof the proposed method. Our case studies of vehicle obstacle avoidance and safe\nextreme fast charging of lithium-ion batteries reveal powerful empirical\nresults supporting the underlying DRO theory. Our method is widely applicable\nwithin the LbC domain to applications including for example airborne wind\nenergy systems, vehicle obstacle avoidance, energy storage systems management,\nand video compression.\n","authors":["Aaron Kandel","Scott J. Moura"],"pdf_url":"https://arxiv.org/pdf/2004.00759v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03261v1","updated":"2023-06-05T21:26:00Z","published":"2023-06-05T21:26:00Z","title":"On Lagrange multipliers of the KKT system in Hilbert spaces","summary":"  In this paper we develop a new decomposition framework to deal with Lagrange\nmultipliers of the Karush-Kuhn-Tucker (KKT) system of constrained optimization\nproblems and variational inequalities in Hilbert spaces. It is different from\nexisting frameworks based on separation theorems. We introduce the essential\nLagrange multiplier and establish the basic theory of this new multiplier. The\nessential Lagrange multiplier poses essentially different existence results in\nfinite and infinite-dimensional spaces. It can also be used to give an\nessential characterization of the convergence of multipliers generated by the\nclassical augmented Lagrangian method. Our analysis reveals that the essential\nLagrange multiplier is at the core of both theories and applications of\nLagrange multipliers.\n","authors":["Zhiyu Tan"],"pdf_url":"https://arxiv.org/pdf/2306.03261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03243v1","updated":"2023-06-05T20:54:57Z","published":"2023-06-05T20:54:57Z","title":"Equilibration of Coordinating Imitation and Best-Response Dynamics","summary":"  Decision-making individuals are often considered to be either imitators who\ncopy the action of their most successful neighbors or best-responders who\nmaximize their benefit against the current actions of their neighbors. In the\ncontext of coordination games, where neighboring individuals earn more if they\ntake the same action, by means of potential functions, it was shown that\npopulations of all imitators and populations of all best-responders equilibrate\nin finite time when they become active to update their decisions sequentially.\nHowever, for mixed populations of the two, the equilibration was shown only for\nspecific activation sequences. It is therefore, unknown, whether a potential\nfunction also exists for mixed populations or if there actually exists a\ncounter example where an activation sequence prevents equilibration. We show\nthat in a linear graph, the number of ``sections'' (a sequence of consecutive\nindividuals taking the same action) serves as a potential function, leading to\nequilibration, and that this result can be extended to sparse trees. The\nexistence of a potential function for other types of networks remains an open\nproblem.\n","authors":["Nazanin Hasheminejad","Pouria Ramazi"],"pdf_url":"https://arxiv.org/pdf/2306.03243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03202v1","updated":"2023-06-05T19:22:02Z","published":"2023-06-05T19:22:02Z","title":"Nonlinear Distributionally Robust Optimization","summary":"  This article focuses on a class of distributionally robust optimization (DRO)\nproblems where, unlike the growing body of the literature, the objective\nfunction is potentially non-linear in the distribution. Existing methods to\noptimize nonlinear functions in probability space use the Frechet derivatives,\nwhich present both theoretical and computational challenges. Motivated by this,\nwe propose an alternative notion for the derivative and corresponding\nsmoothness based on Gateaux (G)-derivative for generic risk measures. These\nconcepts are explained via three running risk measure examples of variance,\nentropic risk, and risk on finite support sets. We then propose a G-derivative\nbased Frank-Wolfe~(FW) algorithm for generic non-linear optimization problems\nin probability spaces and establish its convergence under the proposed notion\nof smoothness in a completely norm-independent manner. We use the set-up of the\nFW algorithm to devise a methodology to compute a saddle point of the\nnon-linear DRO problem. Finally, for the minimum variance portfolio selection\nproblem we analyze the regularity conditions and compute the FW-oracle in\nvarious settings, and validate the theoretical results numerically.\n","authors":["Mohammed Rayyan Sheriff","Peyman Mohajerin Esfahani"],"pdf_url":"https://arxiv.org/pdf/2306.03202v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.03088v1","updated":"2023-06-05T17:58:49Z","published":"2023-06-05T17:58:49Z","title":"DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear\n  Functional Brain Network Dynamics","summary":"  Functional brain dynamics is supported by parallel and overlapping functional\nnetwork modes that are associated with specific neural circuits. Decomposing\nthese network modes from fMRI data and finding their temporal characteristics\nis challenging due to their time-varying nature and the non-linearity of the\nfunctional dynamics. Dynamic Mode Decomposition (DMD) algorithms have been\nquite popular for solving this decomposition problem in recent years. In this\nwork, we apply GraphDMD -- an extension of the DMD for network data -- to\nextract the dynamic network modes and their temporal characteristics from the\nfMRI time series in an interpretable manner. GraphDMD, however, regards the\nunderlying system as a linear dynamical system that is sub-optimal for\nextracting the network modes from non-linear functional data. In this work, we\ndevelop a generalized version of the GraphDMD algorithm -- DeepGraphDMD --\napplicable to arbitrary non-linear graph dynamical systems. DeepGraphDMD is an\nautoencoder-based deep learning model that learns Koopman eigenfunctions for\ngraph data and embeds the non-linear graph dynamics into a latent linear space.\nWe show the effectiveness of our method in both simulated data and the HCP\nresting-state fMRI data. In the HCP data, DeepGraphDMD provides novel insights\ninto cognitive brain functions by discovering two major network modes related\nto fluid and crystallized intelligence.\n","authors":["Md Asadullah Turja","Martin Styner","Guorong Wu"],"pdf_url":"https://arxiv.org/pdf/2306.03088v1.pdf","comment":"to be published in MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.00937v2","updated":"2023-06-05T17:58:30Z","published":"2023-06-01T17:39:41Z","title":"STEVE-1: A Generative Model for Text-to-Behavior in Minecraft","summary":"  Constructing AI models that respond to text instructions is challenging,\nespecially for sequential decision-making tasks. This work introduces an\ninstruction-tuned Video Pretraining (VPT) model for Minecraft called STEVE-1,\ndemonstrating that the unCLIP approach, utilized in DALL-E 2, is also effective\nfor creating instruction-following sequential decision-making agents. STEVE-1\nis trained in two steps: adapting the pretrained VPT model to follow commands\nin MineCLIP's latent space, then training a prior to predict latent codes from\ntext. This allows us to finetune VPT through self-supervised behavioral cloning\nand hindsight relabeling, bypassing the need for costly human text annotations.\nBy leveraging pretrained models like VPT and MineCLIP and employing best\npractices from text-conditioned image generation, STEVE-1 costs just $60 to\ntrain and can follow a wide range of short-horizon open-ended text and visual\ninstructions in Minecraft. STEVE-1 sets a new bar for open-ended instruction\nfollowing in Minecraft with low-level controls (mouse and keyboard) and raw\npixel inputs, far outperforming previous baselines. We provide experimental\nevidence highlighting key factors for downstream performance, including\npretraining, classifier-free guidance, and data scaling. All resources,\nincluding our model weights, training scripts, and evaluation tools are made\navailable for further research.\n","authors":["Shalev Lifshitz","Keiran Paster","Harris Chan","Jimmy Ba","Sheila McIlraith"],"pdf_url":"https://arxiv.org/pdf/2306.00937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06599v2","updated":"2023-06-05T17:58:24Z","published":"2023-02-13T18:55:31Z","title":"FilFL: Client Filtering for Optimized Client Participation in Federated\n  Learning","summary":"  Federated learning is an emerging machine learning paradigm that enables\nclients to train collaboratively without exchanging local data. The clients\nparticipating in the training process have a crucial impact on the convergence\nrate, learning efficiency, and model generalization. In this work, we propose\nFilFL, a new approach to optimizing client participation and training by\nintroducing client filtering. FilFL periodically filters the available clients\nto identify a subset that maximizes a combinatorial objective function using an\nefficient greedy filtering algorithm. From this filtered-in subset, clients are\nthen selected for the training process. We provide a thorough analysis of FilFL\nconvergence in a heterogeneous setting and evaluate its performance across\ndiverse vision and language tasks and realistic federated scenarios with\ntime-varying client availability. Our empirical results demonstrate several\nbenefits of our approach, including improved learning efficiency, faster\nconvergence, and up to 10 percentage points higher test accuracy compared to\nscenarios where client filtering is not utilized.\n","authors":["Fares Fourati","Salma Kharrat","Vaneet Aggarwal","Mohamed-Slim Alouini","Marco Canini"],"pdf_url":"https://arxiv.org/pdf/2302.06599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03078v1","updated":"2023-06-05T17:53:28Z","published":"2023-06-05T17:53:28Z","title":"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression","summary":"  Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.\n","authors":["Tim Dettmers","Ruslan Svirschevski","Vage Egiazarian","Denis Kuznedelev","Elias Frantar","Saleh Ashkboos","Alexander Borzunov","Torsten Hoefler","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2306.03078v1.pdf","comment":"Extended preprint"},{"id":"http://arxiv.org/abs/2306.03076v1","updated":"2023-06-05T17:52:44Z","published":"2023-06-05T17:52:44Z","title":"Sensitivity-Aware Finetuning for Accuracy Recovery on Deep Learning\n  Hardware","summary":"  Existing methods to recover model accuracy on analog-digital hardware in the\npresence of quantization and analog noise include noise-injection training.\nHowever, it can be slow in practice, incurring high computational costs, even\nwhen starting from pretrained models. We introduce the Sensitivity-Aware\nFinetuning (SAFT) approach that identifies noise sensitive layers in a model,\nand uses the information to freeze specific layers for noise-injection\ntraining. Our results show that SAFT achieves comparable accuracy to\nnoise-injection training and is 2x to 8x faster.\n","authors":["Lakshmi Nair","Darius Bunandar"],"pdf_url":"https://arxiv.org/pdf/2306.03076v1.pdf","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.03074v1","updated":"2023-06-05T17:50:29Z","published":"2023-06-05T17:50:29Z","title":"A General Perspective on Objectives of Reinforcement Learning","summary":"  In this lecture, we present a general perspective on reinforcement learning\n(RL) objectives, where we show three versions of objectives. The first version\nis the standard definition of objective in RL literature. Then we extend the\nstandard definition to the $\\lambda$-return version, which unifies the standard\ndefinition of objective. Finally, we propose a general objective that unifies\nthe previous two versions. The last version provides a high level to understand\nof RL's objective, where it shows a fundamental formulation that connects some\nwidely used RL techniques (e.g., TD$(\\lambda)$ and GAE), and this objective can\nbe potentially applied to extensive RL algorithms.\n","authors":["Long Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11042v2","updated":"2023-06-05T17:49:58Z","published":"2023-02-21T22:47:45Z","title":"In-context Example Selection with Influences","summary":"  In-context learning (ICL) is a powerful paradigm emerged from large language\nmodels (LLMs). Despite its promises, ICL performance is known to be highly\nsensitive to input examples. In this work, we use $\\textit{in-context\ninfluences}$ to analyze few-shot ICL performance directly from the in-context\nexamples. Our proposed influence-based example selection method can identify\nboth positive and negative examples, outperforming several baselines when\nevaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\\%$\nperformance gap between using the most negative in-context examples compared to\nthe most positive. In a case study, we apply our influence-based framework to\nquantify the phenomena of recency bias in example ordering for few-shot ICL.\n","authors":["Tai Nguyen","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2302.11042v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03072v1","updated":"2023-06-05T17:49:43Z","published":"2023-06-05T17:49:43Z","title":"Explore to Generalize in Zero-Shot RL","summary":"  We study zero-shot generalization in reinforcement learning - optimizing a\npolicy on a set of training tasks such that it will perform well on a similar\nbut unseen test task. To mitigate overfitting, previous work explored different\nnotions of invariance to the task. However, on problems such as the ProcGen\nMaze, an adequate solution that is invariant to the task visualization does not\nexist, and therefore invariance-based approaches fail. Our insight is that\nlearning a policy that $\\textit{explores}$ the domain effectively is harder to\nmemorize than a policy that maximizes reward for a specific task, and therefore\nwe expect such learned behavior to generalize well; we indeed demonstrate this\nempirically on several domains that are difficult for invariance-based\napproaches. Our $\\textit{Explore to Generalize}$ algorithm (ExpGen) builds on\nthis insight: We train an additional ensemble of agents that optimize reward.\nAt test time, either the ensemble agrees on an action, and we generalize well,\nor we take exploratory actions, which are guaranteed to generalize and drive us\nto a novel part of the state space, where the ensemble may potentially agree\nagain. We show that our approach is the state-of-the-art on several tasks in\nthe ProcGen challenge that have so far eluded effective generalization. For\nexample, we demonstrate a success rate of $82\\%$ on the Maze task and $74\\%$ on\nHeist with $200$ training levels.\n","authors":["Ev Zisselman","Itai Lavie","Daniel Soudry","Aviv Tamar"],"pdf_url":"https://arxiv.org/pdf/2306.03072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.10965v5","updated":"2023-06-05T17:49:40Z","published":"2022-04-23T00:40:02Z","title":"CLIP-Dissect: Automatic Description of Neuron Representations in Deep\n  Vision Networks","summary":"  In this paper, we propose CLIP-Dissect, a new technique to automatically\ndescribe the function of individual hidden neurons inside vision networks.\nCLIP-Dissect leverages recent advances in multimodal vision/language models to\nlabel internal neurons with open-ended concepts without the need for any\nlabeled data or human examples. We show that CLIP-Dissect provides more\naccurate descriptions than existing methods for last layer neurons where the\nground-truth is available as well as qualitatively good descriptions for hidden\nlayer neurons. In addition, our method is very flexible: it is model agnostic,\ncan easily handle new concepts and can be extended to take advantage of better\nmultimodal models in the future. Finally CLIP-Dissect is computationally\nefficient and can label all neurons from five layers of ResNet-50 in just 4\nminutes, which is more than 10 times faster than existing methods. Our code is\navailable at https://github.com/Trustworthy-ML-Lab/CLIP-dissect. Finally,\ncrowdsourced user study results are available at Appendix B to further support\nthe effectiveness of our method.\n","authors":["Tuomas Oikarinen","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2204.10965v5.pdf","comment":"Published in ICLR 2023 Conference (Spotlight). New v5(5 June 2023) -\n  Added crowdsourced user study in Appendix B, not included in ICLR publication"},{"id":"http://arxiv.org/abs/2306.03066v1","updated":"2023-06-05T17:43:50Z","published":"2023-06-05T17:43:50Z","title":"Of Mice and Mates: Automated Classification and Modelling of Mouse\n  Behaviour in Groups using a Single Model across Cages","summary":"  Behavioural experiments often happen in specialised arenas, but this may\nconfound the analysis. To address this issue, we provide tools to study mice in\nthe homecage environment, equipping biologists with the possibility to capture\nthe temporal aspect of the individual's behaviour and model the interaction and\ninterdependence between cage-mates with minimal human intervention. We develop\nthe Activity Labelling Module (ALM) to automatically classify mouse behaviour\nfrom video, and a novel Group Behaviour Model (GBM) for summarising their joint\nbehaviour across cages, using a permutation matrix to match the mouse\nidentities in each cage to the model. We also release two datasets, ABODe for\ntraining behaviour classifiers and IMADGE for modelling behaviour.\n","authors":["Michael P. J. Camilleri","Rasneer S. Bains","Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2306.03066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03065v1","updated":"2023-06-05T17:43:46Z","published":"2023-06-05T17:43:46Z","title":"LibAUC: A Deep Learning Library for X-Risk Optimization","summary":"  This paper introduces the award-winning deep learning (DL) library called\nLibAUC for implementing state-of-the-art algorithms towards optimizing a family\nof risk functions named X-risks. X-risks refer to a family of compositional\nfunctions in which the loss function of each data point is defined in a way\nthat contrasts the data point with a large number of others. They have broad\napplications in AI for solving classical and emerging problems, including but\nnot limited to classification for imbalanced data (CID), learning to rank\n(LTR), and contrastive learning of representations (CLR). The motivation of\ndeveloping LibAUC is to address the convergence issues of existing libraries\nfor solving these problems. In particular, existing libraries may not converge\nor require very large mini-batch sizes in order to attain good performance for\nthese problems, due to the usage of the standard mini-batch technique in the\nempirical risk minimization (ERM) framework. Our library is for deep X-risk\noptimization (DXO) that has achieved great success in solving a variety of\ntasks for CID, LTR and CLR. The contributions of this paper include: (1) It\nintroduces a new mini-batch based pipeline for implementing DXO algorithms,\nwhich differs from existing DL pipeline in the design of controlled data\nsamplers and dynamic mini-batch losses; (2) It provides extensive benchmarking\nexperiments for ablation studies and comparison with existing libraries. The\nLibAUC library features scalable performance for millions of items to be\ncontrasted, faster and better convergence than existing libraries for\noptimizing X-risks, seamless PyTorch deployment and versatile APIs for various\nloss optimization. Our library is available to the open source community at\nhttps://github.com/Optimization-AI/LibAUC, to facilitate further academic\nresearch and industrial applications.\n","authors":["Zhuoning Yuan","Dixian Zhu","Zi-Hao Qiu","Gang Li","Xuanhui Wang","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03065v1.pdf","comment":"Accepted by KDD2023"},{"id":"http://arxiv.org/abs/2210.06274v2","updated":"2023-06-05T17:35:53Z","published":"2022-10-12T14:58:32Z","title":"Centralized Training with Hybrid Execution in Multi-Agent Reinforcement\n  Learning","summary":"  We introduce hybrid execution in multi-agent reinforcement learning (MARL), a\nnew paradigm in which agents aim to successfully complete cooperative tasks\nwith arbitrary communication levels at execution time by taking advantage of\ninformation-sharing among the agents. Under hybrid execution, the communication\nlevel can range from a setting in which no communication is allowed between\nagents (fully decentralized), to a setting featuring full communication (fully\ncentralized), but the agents do not know beforehand which communication level\nthey will encounter at execution time. To formalize our setting, we define a\nnew class of multi-agent partially observable Markov decision processes\n(POMDPs) that we name hybrid-POMDPs, which explicitly model a communication\nprocess between the agents. We contribute MARO, an approach that makes use of\nan auto-regressive predictive model, trained in a centralized manner, to\nestimate missing agents' observations at execution time. We evaluate MARO on\nstandard scenarios and extensions of previous benchmarks tailored to emphasize\nthe negative impact of partial observability in MARL. Experimental results show\nthat our method consistently outperforms relevant baselines, allowing agents to\nact with faulty communication while successfully exploiting shared information.\n","authors":["Pedro P. Santos","Diogo S. Carvalho","Miguel Vasco","Alberto Sardinha","Pedro A. Santos","Ana Paiva","Francisco S. Melo"],"pdf_url":"https://arxiv.org/pdf/2210.06274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06129v2","updated":"2023-06-05T17:33:43Z","published":"2023-04-12T19:27:09Z","title":"Label-Free Concept Bottleneck Models","summary":"  Concept bottleneck models (CBM) are a popular way of creating more\ninterpretable neural networks by having hidden layer neurons correspond to\nhuman-understandable concepts. However, existing CBMs and their variants have\ntwo crucial limitations: first, they need to collect labeled data for each of\nthe predefined concepts, which is time consuming and labor intensive; second,\nthe accuracy of a CBM is often significantly lower than that of a standard\nneural network, especially on more complex datasets. This poor performance\ncreates a barrier for adopting CBMs in practical real world applications.\nMotivated by these challenges, we propose Label-free CBM which is a novel\nframework to transform any neural network into an interpretable CBM without\nlabeled concept data, while retaining a high accuracy. Our Label-free CBM has\nmany advantages, it is: scalable - we present the first CBM scaled to ImageNet,\nefficient - creating a CBM takes only a few hours even for very large datasets,\nand automated - training it for a new dataset requires minimal human effort.\nOur code is available at https://github.com/Trustworthy-ML-Lab/Label-free-CBM.\nFinally, in Appendix B we conduct a large scale user evaluation of the\ninterpretability of our method.\n","authors":["Tuomas Oikarinen","Subhro Das","Lam M. Nguyen","Tsui-Wei Weng"],"pdf_url":"https://arxiv.org/pdf/2304.06129v2.pdf","comment":"Published at ICLR 2023. New v2(5 June 2023): added crowdsourced human\n  study in Appendix B"},{"id":"http://arxiv.org/abs/2306.03054v1","updated":"2023-06-05T17:25:45Z","published":"2023-06-05T17:25:45Z","title":"Discriminative Adversarial Privacy: Balancing Accuracy and Membership\n  Privacy in Neural Networks","summary":"  The remarkable proliferation of deep learning across various industries has\nunderscored the importance of data privacy and security in AI pipelines. As the\nevolution of sophisticated Membership Inference Attacks (MIAs) threatens the\nsecrecy of individual-specific information used for training deep learning\nmodels, Differential Privacy (DP) raises as one of the most utilized techniques\nto protect models against malicious attacks. However, despite its proven\ntheoretical properties, DP can significantly hamper model performance and\nincrease training time, turning its use impractical in real-world scenarios.\nTackling this issue, we present Discriminative Adversarial Privacy (DAP), a\nnovel learning technique designed to address the limitations of DP by achieving\na balance between model performance, speed, and privacy. DAP relies on\nadversarial training based on a novel loss function able to minimise the\nprediction error while maximising the MIA's error. In addition, we introduce a\nnovel metric named Accuracy Over Privacy (AOP) to capture the\nperformance-privacy trade-off. Finally, to validate our claims, we compare DAP\nwith diverse DP scenarios, providing an analysis of the results from\nperformance, time, and privacy preservation perspectives.\n","authors":["Eugenio Lomurno","Alberto Archetti","Francesca Ausonio","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2306.03054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03052v1","updated":"2023-06-05T17:23:26Z","published":"2023-06-05T17:23:26Z","title":"Forecasting Crude Oil Prices Using Reservoir Computing Models","summary":"  Accurate crude oil price prediction is crucial for financial decision-making.\nWe propose a novel reservoir computing model for forecasting crude oil prices.\nIt outperforms popular deep learning methods in most scenarios, as demonstrated\nthrough rigorous evaluation using daily closing price data from major stock\nmarket indices. Our model's competitive advantage is further validated by\ncomparing it with recent deep-learning approaches. This study introduces\ninnovative reservoir computing models for predicting crude oil prices, with\npractical implications for financial practitioners. By leveraging advanced\ntechniques, market participants can enhance decision-making and gain valuable\ninsights into crude oil market dynamics.\n","authors":["Kaushal Kumar"],"pdf_url":"https://arxiv.org/pdf/2306.03052v1.pdf","comment":"14 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.03042v1","updated":"2023-06-05T17:06:23Z","published":"2023-06-05T17:06:23Z","title":"SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with\n  Missing Values for Environmental Monitoring","summary":"  Environmental monitoring is crucial to our understanding of climate change,\nbiodiversity loss and pollution. The availability of large-scale\nspatio-temporal data from sources such as sensors and satellites allows us to\ndevelop sophisticated models for forecasting and understanding key drivers.\nHowever, the data collected from sensors often contain missing values due to\nfaulty equipment or maintenance issues. The missing values rarely occur\nsimultaneously leading to data that are multivariate misaligned sparse time\nseries. We propose two models that are capable of performing multivariate\nspatio-temporal forecasting while handling missing data naturally without the\nneed for imputation. The first model is a transformer-based model, which we\nname SERT (Spatio-temporal Encoder Representations from Transformers). The\nsecond is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial\nNeural Network) which is capable of providing interpretable results. We conduct\nextensive experiments on two different datasets for multivariate\nspatio-temporal forecasting and show that our models have competitive or\nsuperior performance to those at the state-of-the-art.\n","authors":["Amin Shoari Nejad","Rocío Alaiz-Rodríguez","Gerard D. McCarthy","Brian Kelleher","Anthony Grey","Andrew Parnell"],"pdf_url":"https://arxiv.org/pdf/2306.03042v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2305.17535v2","updated":"2023-06-05T17:05:51Z","published":"2023-05-27T17:35:01Z","title":"PFNs4BO: In-Context Learning for Bayesian Optimization","summary":"  In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible\nsurrogate for Bayesian Optimization (BO). PFNs are neural processes that are\ntrained to approximate the posterior predictive distribution (PPD) through\nin-context learning on any prior distribution that can be efficiently sampled\nfrom. We describe how this flexibility can be exploited for surrogate modeling\nin BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and\na Bayesian Neural Network (BNN). In addition, we show how to incorporate\nfurther information into the prior, such as allowing hints about the position\nof optima (user priors), ignoring irrelevant dimensions, and performing\nnon-myopic BO by learning the acquisition function. The flexibility underlying\nthese extensions opens up vast possibilities for using PFNs for BO. We\ndemonstrate the usefulness of PFNs for BO in a large-scale evaluation on\nartificial GP samples and three different hyperparameter optimization testbeds:\nHPO-B, Bayesmark, and PD1. We publish code alongside trained models at\nhttps://github.com/automl/PFNs4BO.\n","authors":["Samuel Müller","Matthias Feurer","Noah Hollmann","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2305.17535v2.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.03040v1","updated":"2023-06-05T17:03:10Z","published":"2023-06-05T17:03:10Z","title":"Learning Similarity among Users for Personalized Session-Based\n  Recommendation from hierarchical structure of User-Session-Item","summary":"  The task of the session-based recommendation is to predict the next\ninteraction of the user based on the anonymized user's behavior pattern. And\npersonalized version of this system is a promising research field due to its\navailability to deal with user information. However, there's a problem that the\nuser's preferences and historical sessions were not considered in the typical\nsession-based recommendation since it concentrates only on user-item\ninteraction. In addition, the existing personalized session-based\nrecommendation model has a limited capability in that it only considers the\npreference of the current user without considering those of similar users. It\nmeans there can be the loss of information included within the hierarchical\ndata structure of the user-session-item. To tackle with this problem, we\npropose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).\nTo model global historical sessions of users, we propose UserGraph that has two\ntypes of nodes - ItemNode and UserNode. We then connect the nodes with three\ntypes of edges. The first type of edges connects ItemNode as chronological\norder, and the second connects ItemNode to UserNode, and the last connects\nUserNode to ItemNode. With these user embeddings, we propose additional\ncontrastive loss, that makes users with similar intention be close to each\nother in the vector space. we apply graph neural network on these UserGraph and\nupdate nodes. Experimental results on two real-world datasets demonstrate that\nour method outperforms some state-of-the-art approaches.\n","authors":["Jisoo Cha","Haemin Jeong","Wooju Kim"],"pdf_url":"https://arxiv.org/pdf/2306.03040v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.03025v1","updated":"2023-06-05T16:45:39Z","published":"2023-06-05T16:45:39Z","title":"AI Techniques for Cone Beam Computed Tomography in Dentistry: Trends and\n  Practices","summary":"  Cone-beam computed tomography (CBCT) is a popular imaging modality in\ndentistry for diagnosing and planning treatment for a variety of oral diseases\nwith the ability to produce detailed, three-dimensional images of the teeth,\njawbones, and surrounding structures. CBCT imaging has emerged as an essential\ndiagnostic tool in dentistry. CBCT imaging has seen significant improvements in\nterms of its diagnostic value, as well as its accuracy and efficiency, with the\nmost recent development of artificial intelligence (AI) techniques. This paper\nreviews recent AI trends and practices in dental CBCT imaging. AI has been used\nfor lesion detection, malocclusion classification, measurement of buccal bone\nthickness, and classification and segmentation of teeth, alveolar bones,\nmandibles, landmarks, contours, and pharyngeal airways using CBCT images.\nMainly machine learning algorithms, deep learning algorithms, and\nsuper-resolution techniques are used for these tasks. This review focuses on\nthe potential of AI techniques to transform CBCT imaging in dentistry, which\nwould improve both diagnosis and treatment planning. Finally, we discuss the\nchallenges and limitations of artificial intelligence in dentistry and CBCT\nimaging.\n","authors":["Saba Sarwar","Suraiya Jabin"],"pdf_url":"https://arxiv.org/pdf/2306.03025v1.pdf","comment":"Recent Advances in Electrical, Electronics & Digital Healthcare\n  Technologies REEDCON 2023"},{"id":"http://arxiv.org/abs/2302.04831v3","updated":"2023-06-05T16:44:38Z","published":"2023-02-09T18:37:04Z","title":"Cooperative Open-ended Learning Framework for Zero-shot Coordination","summary":"  Zero-shot coordination in cooperative artificial intelligence (AI) remains a\nsignificant challenge, which means effectively coordinating with a wide range\nof unseen partners. Previous algorithms have attempted to address this\nchallenge by optimizing fixed objectives within a population to improve\nstrategy or behaviour diversity. However, these approaches can result in a loss\nof learning and an inability to cooperate with certain strategies within the\npopulation, known as cooperative incompatibility. To address this issue, we\npropose the Cooperative Open-ended LEarning (COLE) framework, which constructs\nopen-ended objectives in cooperative games with two players from the\nperspective of graph theory to assess and identify the cooperative ability of\neach strategy. We further specify the framework and propose a practical\nalgorithm that leverages knowledge from game theory and graph theory.\nFurthermore, an analysis of the learning process of the algorithm shows that it\ncan efficiently overcome cooperative incompatibility. The experimental results\nin the Overcooked game environment demonstrate that our method outperforms\ncurrent state-of-the-art methods when coordinating with different-level\npartners. Our demo is available at https://sites.google.com/view/cole-2023.\n","authors":["Yang Li","Shao Zhang","Jichen Sun","Yali Du","Ying Wen","Xinbing Wang","Wei Pan"],"pdf_url":"https://arxiv.org/pdf/2302.04831v3.pdf","comment":"15 pages with 9 pages main body"},{"id":"http://arxiv.org/abs/2303.16132v2","updated":"2023-06-05T16:42:44Z","published":"2023-03-28T16:56:47Z","title":"Transformer and Snowball Graph Convolution Learning for Brain functional\n  network Classification","summary":"  Advanced deep learning methods, especially graph neural networks (GNNs), are\nincreasingly expected to learn from brain functional network data and identify\nthe functional connections between brain disorder and health. In this paper, we\nproposed a novel Transformer and snowball encoding networks (TSEN) for brain\nfunctional network classification, which introduced Transformer architecture\nwith graph snowball connection into GNNs for learning whole-graph\nrepresentation. TSEN combined graph snowball connection with graph Transformer\nby snowball encoding layers, which enhanced the power to capture multi-scale\ninformation and global patterns of brain functional networks. TSEN also\nintroduced snowball graph convolution as position embedding in Transformer\nstructure, which was a simple yet effective method for capturing local patterns\nnaturally. We evaluated the proposed model by two large-scale brain functional\nnetwork datasets, and the results demonstrated that TSEN outperformed the\nstate-of-the-art GNN models and the graph-transformer based GNN models.\n","authors":["Jinlong Hu","Yangmin Huang","Shoubin Dong"],"pdf_url":"https://arxiv.org/pdf/2303.16132v2.pdf","comment":"Prepared for submitting to HBP"},{"id":"http://arxiv.org/abs/2306.03022v1","updated":"2023-06-05T16:38:48Z","published":"2023-06-05T16:38:48Z","title":"Interpretable Alzheimer's Disease Classification Via a Contrastive\n  Diffusion Autoencoder","summary":"  In visual object classification, humans often justify their choices by\ncomparing objects to prototypical examples within that class. We may therefore\nincrease the interpretability of deep learning models by imbuing them with a\nsimilar style of reasoning. In this work, we apply this principle by\nclassifying Alzheimer's Disease based on the similarity of images to training\nexamples within the latent space. We use a contrastive loss combined with a\ndiffusion autoencoder backbone, to produce a semantically meaningful latent\nspace, such that neighbouring latents have similar image-level features. We\nachieve a classification accuracy comparable to black box approaches on a\ndataset of 2D MRI images, whilst producing human interpretable model\nexplanations. Therefore, this work stands as a contribution to the pertinent\ndevelopment of accurate and interpretable deep learning within medical imaging.\n","authors":["Ayodeji Ijishakin","Ahmed Abdulaal","Adamos Hadjivasiliou","Sophie Martin","James Cole"],"pdf_url":"https://arxiv.org/pdf/2306.03022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03021v1","updated":"2023-06-05T16:38:11Z","published":"2023-06-05T16:38:11Z","title":"Automating Style Analysis and Visualization With Explainable AI -- Case\n  Studies on Brand Recognition","summary":"  Incorporating style-related objectives into shape design has been centrally\nimportant to maximize product appeal. However, stylistic features such as\naesthetics and semantic attributes are hard to codify even for experts. As\nsuch, algorithmic style capture and reuse have not fully benefited from\nautomated data-driven methodologies due to the challenging nature of design\ndescribability. This paper proposes an AI-driven method to fully automate the\ndiscovery of brand-related features. Our approach introduces BIGNet, a two-tier\nBrand Identification Graph Neural Network (GNN) to classify and analyze scalar\nvector graphics (SVG). First, to tackle the scarcity of vectorized product\nimages, this research proposes two data acquisition workflows: parametric\nmodeling from small curve-based datasets, and vectorization from large\npixel-based datasets. Secondly, this study constructs a novel hierarchical GNN\narchitecture to learn from both SVG's curve-level and chunk-level parameters.\nIn the first case study, BIGNet not only classifies phone brands but also\ncaptures brand-related features across multiple scales, such as the location of\nthe lens, the height-width ratio, and the screen-frame gap, as confirmed by AI\nevaluation. In the second study, this paper showcases the generalizability of\nBIGNet learning from a vectorized car image dataset and validates the\nconsistency and robustness of its predictions given four scenarios. The results\nmatch the difference commonly observed in luxury vs. economy brands in the\nautomobile market. Finally, this paper also visualizes the activation maps\ngenerated from a convolutional neural network and shows BIGNet's advantage of\nbeing a more human-friendly, explainable, and explicit style-capturing agent.\nCode and dataset can be found on Github:\n  1. Phone case study: github.com/parksandrecfan/bignet-phone 2. Car case\nstudy: github.com/parksandrecfan/bignet-car\n","authors":["Yu-hsuan Chen","Levent Burak Kara","Jonathan Cagan"],"pdf_url":"https://arxiv.org/pdf/2306.03021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03018v1","updated":"2023-06-05T16:35:01Z","published":"2023-06-05T16:35:01Z","title":"Quantification of Uncertainties in Deep Learning-based Environment\n  Perception","summary":"  In this work, we introduce a novel Deep Learning-based method to perceive the\nenvironment of a vehicle based on radar scans while accounting for\nuncertainties in its predictions. The environment of the host vehicle is\nsegmented into equally sized grid cells which are classified individually.\nComplementary to the segmentation output, our Deep Learning-based algorithm is\ncapable of differentiating uncertainties in its predictions as being related to\nan inadequate model (epistemic uncertainty) or noisy data (aleatoric\nuncertainty). To this end, weights are described as probability distributions\naccounting for uncertainties in the model parameters. Distributions are learned\nin a supervised fashion using gradient descent. We prove that uncertainties in\nthe model output correlate with the precision of its predictions. Compared to\nprevious concepts, we show superior performance of our approach to reliably\nperceive the environment of a vehicle.\n","authors":["Marco Braun","Moritz Luszek","Jan Siegemund","Kevin Kollek","Anton Kummert"],"pdf_url":"https://arxiv.org/pdf/2306.03018v1.pdf","comment":"2021 IEEE International Conference on Omni-Layer Intelligent Systems\n  (COINS), Barcelona, Spain, 2021"},{"id":"http://arxiv.org/abs/2112.04571v4","updated":"2023-06-05T16:32:55Z","published":"2021-12-08T20:22:04Z","title":"Ambiguous Dynamic Treatment Regimes: A Reinforcement Learning Approach","summary":"  A main research goal in various studies is to use an observational data set\nand provide a new set of counterfactual guidelines that can yield causal\nimprovements. Dynamic Treatment Regimes (DTRs) are widely studied to formalize\nthis process. However, available methods in finding optimal DTRs often rely on\nassumptions that are violated in real-world applications (e.g., medical\ndecision-making or public policy), especially when (a) the existence of\nunobserved confounders cannot be ignored, and (b) the unobserved confounders\nare time-varying (e.g., affected by previous actions). When such assumptions\nare violated, one often faces ambiguity regarding the underlying causal model.\nThis ambiguity is inevitable, since the dynamics of unobserved confounders and\ntheir causal impact on the observed part of the data cannot be understood from\nthe observed data. Motivated by a case study of finding superior treatment\nregimes for patients who underwent transplantation in our partner hospital and\nfaced a medical condition known as New Onset Diabetes After Transplantation\n(NODAT), we extend DTRs to a new class termed Ambiguous Dynamic Treatment\nRegimes (ADTRs), in which the causal impact of treatment regimes is evaluated\nbased on a \"cloud\" of causal models. We then connect ADTRs to Ambiguous\nPartially Observable Mark Decision Processes (APOMDPs) and develop\nReinforcement Learning methods, which enable using the observed data to\nefficiently learn an optimal treatment regime. We establish theoretical results\nfor these learning methods, including (weak) consistency and asymptotic\nnormality. We further evaluate the performance of these learning methods both\nin our case study and in simulation experiments.\n","authors":["Soroush Saghafian"],"pdf_url":"https://arxiv.org/pdf/2112.04571v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03014v1","updated":"2023-06-05T16:30:17Z","published":"2023-06-05T16:30:17Z","title":"On the Behavior of Intrusive and Non-intrusive Speech Enhancement\n  Metrics in Predictive and Generative Settings","summary":"  Since its inception, the field of deep speech enhancement has been dominated\nby predictive (discriminative) approaches, such as spectral mapping or masking.\nRecently, however, novel generative approaches have been applied to speech\nenhancement, attaining good denoising performance with high subjective quality\nscores. At the same time, advances in deep learning also allowed for the\ncreation of neural network-based metrics, which have desirable traits such as\nbeing able to work without a reference (non-intrusively). Since generatively\nenhanced speech tends to exhibit radically different residual distortions, its\nevaluation using instrumental speech metrics may behave differently compared to\npredictively enhanced speech. In this paper, we evaluate the performance of the\nsame speech enhancement backbone trained under predictive and generative\nparadigms on a variety of metrics and show that intrusive and non-intrusive\nmeasures correlate differently for each paradigm. This analysis motivates the\nsearch for metrics that can together paint a complete and unbiased picture of\nspeech enhancement performance, irrespective of the model's training process.\n","authors":["Danilo de Oliveira","Julius Richter","Jean-Marie Lemercier","Tal Peer","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2306.03014v1.pdf","comment":"Submitted to ITG Conference on Speech Communication"},{"id":"http://arxiv.org/abs/2306.03013v1","updated":"2023-06-05T16:29:54Z","published":"2023-06-05T16:29:54Z","title":"Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated\n  Learning","summary":"  Malicious server (MS) attacks have enabled the scaling of data stealing in\nfederated learning to large batch sizes and secure aggregation, settings\npreviously considered private. However, many concerns regarding client-side\ndetectability of MS attacks were raised, questioning their practicality once\nthey are publicly known. In this work, for the first time, we thoroughly study\nthe problem of client-side detectability.We demonstrate that most prior MS\nattacks, which fundamentally rely on one of two key principles, are detectable\nby principled client-side checks. Further, we formulate desiderata for\npractical MS attacks and propose SEER, a novel attack framework that satisfies\nall desiderata, while stealing user data from gradients of realistic networks,\neven for large batch sizes (up to 512 in our experiments) and under secure\naggregation. The key insight of SEER is the use of a secret decoder, which is\njointly trained with the shared model. Our work represents a promising first\nstep towards more principled treatment of MS attacks, paving the way for\nrealistic data stealing that can compromise user privacy in real-world\ndeployments.\n","authors":["Kostadin Garov","Dimitar I. Dimitrov","Nikola Jovanović","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2306.03013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03010v1","updated":"2023-06-05T16:25:33Z","published":"2023-06-05T16:25:33Z","title":"Interval Load Forecasting for Individual Households in the Presence of\n  Electric Vehicle Charging","summary":"  The transition to Electric Vehicles (EV) in place of traditional internal\ncombustion engines is increasing societal demand for electricity. The ability\nto integrate the additional demand from EV charging into forecasting\nelectricity demand is critical for maintaining the reliability of electricity\ngeneration and distribution. Load forecasting studies typically exclude\nhouseholds with home EV charging, focusing on offices, schools, and public\ncharging stations. Moreover, they provide point forecasts which do not offer\ninformation about prediction uncertainty. Consequently, this paper proposes the\nLong Short-Term Memory Bayesian Neural Networks (LSTM-BNNs) for household load\nforecasting in presence of EV charging. The approach takes advantage of the\nLSTM model to capture the time dependencies and uses the dropout layer with\nBayesian inference to generate prediction intervals. Results show that the\nproposed LSTM-BNNs achieve accuracy similar to point forecasts with the\nadvantage of prediction intervals. Moreover, the impact of lockdowns related to\nthe COVID-19 pandemic on the load forecasting model is examined, and the\nanalysis shows that there is no major change in the model performance as, for\nthe considered households, the randomness of the EV charging outweighs the\nchange due to pandemic.\n","authors":["Raiden Skala","Mohamed Ahmed T. A. Elgalhud","Katarina Grolinger","Syed Mir"],"pdf_url":"https://arxiv.org/pdf/2306.03010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03787v3","updated":"2023-06-05T16:21:56Z","published":"2022-06-08T10:06:24Z","title":"Action Noise in Off-Policy Deep Reinforcement Learning: Impact on\n  Exploration and Performance","summary":"  Many Deep Reinforcement Learning (D-RL) algorithms rely on simple forms of\nexploration such as the additive action noise often used in continuous control\ndomains. Typically, the scaling factor of this action noise is chosen as a\nhyper-parameter and is kept constant during training. In this paper, we focus\non action noise in off-policy deep reinforcement learning for continuous\ncontrol. We analyze how the learned policy is impacted by the noise type, noise\nscale, and impact scaling factor reduction schedule. We consider the two most\nprominent types of action noise, Gaussian and Ornstein-Uhlenbeck noise, and\nperform a vast experimental campaign by systematically varying the noise type\nand scale parameter, and by measuring variables of interest like the expected\nreturn of the policy and the state-space coverage during exploration. For the\nlatter, we propose a novel state-space coverage measure\n$\\operatorname{X}_{\\mathcal{U}\\text{rel}}$ that is more robust to estimation\nartifacts caused by points close to the state-space boundary than\npreviously-proposed measures. Larger noise scales generally increase\nstate-space coverage. However, we found that increasing the space coverage\nusing a larger noise scale is often not beneficial. On the contrary, reducing\nthe noise scale over the training process reduces the variance and generally\nimproves the learning performance. We conclude that the best noise type and\nscale are environment dependent, and based on our observations derive heuristic\nrules for guiding the choice of the action noise as a starting point for\nfurther optimization.\n","authors":["Jakob Hollenstein","Sayantan Auddy","Matteo Saveriano","Erwan Renaudo","Justus Piater"],"pdf_url":"https://arxiv.org/pdf/2206.03787v3.pdf","comment":"Published in Transactions on Machine Learning Research (11/2022)\n  https://openreview.net/forum?id=NljBlZ6hmG"},{"id":"http://arxiv.org/abs/2305.18486v2","updated":"2023-06-05T16:21:40Z","published":"2023-05-29T12:37:21Z","title":"A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark\n  Datasets","summary":"  The development of large language models (LLMs) such as ChatGPT has brought a\nlot of attention recently. However, their evaluation in the benchmark academic\ndatasets remains under-explored due to the difficulty of evaluating the\ngenerative outputs produced by this model against the ground truth. In this\npaper, we aim to present a thorough evaluation of ChatGPT's performance on\ndiverse academic datasets, covering tasks like question-answering, text\nsummarization, code generation, commonsense reasoning, mathematical\nproblem-solving, machine translation, bias detection, and ethical\nconsiderations. Specifically, we evaluate ChatGPT across 140 tasks and analyze\n255K responses it generates in these datasets. This makes our work the largest\nevaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate\nthe strengths and weaknesses of ChatGPT in various tasks and provide insights\nfor future research using LLMs. We also report a new emergent ability to follow\nmulti-query instructions that we mostly found in ChatGPT and other\ninstruction-tuned models. Our extensive evaluation shows that even though\nChatGPT is capable of performing a wide variety of tasks, and may obtain\nimpressive performance in several benchmark datasets, it is still far from\nachieving the ability to reliably solve many challenging tasks. By providing a\nthorough assessment of ChatGPT's performance across diverse NLP tasks, this\npaper sets the stage for a targeted deployment of ChatGPT-like LLMs in\nreal-world applications.\n","authors":["Md Tahmid Rahman Laskar","M Saiful Bari","Mizanur Rahman","Md Amran Hossen Bhuiyan","Shafiq Joty","Jimmy Xiangji Huang"],"pdf_url":"https://arxiv.org/pdf/2305.18486v2.pdf","comment":"Accepted by ACL 2023 Findings. The first three authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2306.03009v1","updated":"2023-06-05T16:19:48Z","published":"2023-06-05T16:19:48Z","title":"Using Sequences of Life-events to Predict Human Lives","summary":"  Over the past decade, machine learning has revolutionized computers' ability\nto analyze text through flexible computational models. Due to their structural\nsimilarity to written language, transformer-based architectures have also shown\npromise as tools to make sense of a range of multi-variate sequences from\nprotein-structures, music, electronic health records to weather-forecasts. We\ncan also represent human lives in a way that shares this structural similarity\nto language. From one perspective, lives are simply sequences of events: People\nare born, visit the pediatrician, start school, move to a new location, get\nmarried, and so on. Here, we exploit this similarity to adapt innovations from\nnatural language processing to examine the evolution and predictability of\nhuman lives based on detailed event sequences. We do this by drawing on\narguably the most comprehensive registry data in existence, available for an\nentire nation of more than six million individuals across decades. Our data\ninclude information about life-events related to health, education, occupation,\nincome, address, and working hours, recorded with day-to-day resolution. We\ncreate embeddings of life-events in a single vector space showing that this\nembedding space is robust and highly structured. Our models allow us to predict\ndiverse outcomes ranging from early mortality to personality nuances,\noutperforming state-of-the-art models by a wide margin. Using methods for\ninterpreting deep learning models, we probe the algorithm to understand the\nfactors that enable our predictions. Our framework allows researchers to\nidentify new potential mechanisms that impact life outcomes and associated\npossibilities for personalized interventions.\n","authors":["Germans Savcisens","Tina Eliassi-Rad","Lars Kai Hansen","Laust Mortensen","Lau Lilleholt","Anna Rogers","Ingo Zettler","Sune Lehmann"],"pdf_url":"https://arxiv.org/pdf/2306.03009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03007v1","updated":"2023-06-05T16:19:07Z","published":"2023-06-05T16:19:07Z","title":"Nonparametric Iterative Machine Teaching","summary":"  In this paper, we consider the problem of Iterative Machine Teaching (IMT),\nwhere the teacher provides examples to the learner iteratively such that the\nlearner can achieve fast convergence to a target model. However, existing IMT\nalgorithms are solely based on parameterized families of target models. They\nmainly focus on convergence in the parameter space, resulting in difficulty\nwhen the target models are defined to be functions without dependency on\nparameters. To address such a limitation, we study a more general task --\nNonparametric Iterative Machine Teaching (NIMT), which aims to teach\nnonparametric target models to learners in an iterative fashion. Unlike\nparametric IMT that merely operates in the parameter space, we cast NIMT as a\nfunctional optimization problem in the function space. To solve it, we propose\nboth random and greedy functional teaching algorithms. We obtain the iterative\nteaching dimension (ITD) of the random teaching algorithm under proper\nassumptions, which serves as a uniform upper bound of ITD in NIMT. Further, the\ngreedy teaching algorithm has a significantly lower ITD, which reaches a\ntighter upper bound of ITD in NIMT. Finally, we verify the correctness of our\ntheoretical findings with extensive experiments in nonparametric scenarios.\n","authors":["Chen Zhang","Xiaofeng Cao","Weiyang Liu","Ivor Tsang","James Kwok"],"pdf_url":"https://arxiv.org/pdf/2306.03007v1.pdf","comment":"ICML 2023 (20 pages, 10 figures)"},{"id":"http://arxiv.org/abs/2306.03002v1","updated":"2023-06-05T16:11:19Z","published":"2023-06-05T16:11:19Z","title":"Unveiling the Two-Faced Truth: Disentangling Morphed Identities for Face\n  Morphing Detection","summary":"  Morphing attacks keep threatening biometric systems, especially face\nrecognition systems. Over time they have become simpler to perform and more\nrealistic, as such, the usage of deep learning systems to detect these attacks\nhas grown. At the same time, there is a constant concern regarding the lack of\ninterpretability of deep learning models. Balancing performance and\ninterpretability has been a difficult task for scientists. However, by\nleveraging domain information and proving some constraints, we have been able\nto develop IDistill, an interpretable method with state-of-the-art performance\nthat provides information on both the identity separation on morph samples and\ntheir contribution to the final prediction. The domain information is learnt by\nan autoencoder and distilled to a classifier system in order to teach it to\nseparate identity information. When compared to other methods in the literature\nit outperforms them in three out of five databases and is competitive in the\nremaining.\n","authors":["Eduarda Caldeira","Pedro C. Neto","Tiago Gonçalves","Naser Damer","Ana F. Sequeira","Jaime S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2306.03002v1.pdf","comment":"Accepted at EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2306.02996v1","updated":"2023-06-05T16:06:39Z","published":"2023-06-05T16:06:39Z","title":"Over-the-Air Federated Learning in Satellite systems","summary":"  Federated learning in satellites offers several advantages. Firstly, it\nensures data privacy and security, as sensitive data remains on the satellites\nand is not transmitted to a central location. This is particularly important\nwhen dealing with sensitive or classified information. Secondly, federated\nlearning allows satellites to collectively learn from a diverse set of data\nsources, benefiting from the distributed knowledge across the satellite\nnetwork. Lastly, the use of federated learning reduces the communication\nbandwidth requirements between satellites and the central server, as only model\nupdates are exchanged instead of raw data. By leveraging federated learning,\nsatellites can collaborate and continuously improve their machine learning\nmodels while preserving data privacy and minimizing communication overhead.\nThis enables the development of more intelligent and efficient satellite\nsystems for various applications, such as Earth observation, weather\nforecasting, and space exploration.\n","authors":["Edward Akito Carlos","Raphael Pinard","Mitra Hassani"],"pdf_url":"https://arxiv.org/pdf/2306.02996v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02990v1","updated":"2023-06-05T16:01:33Z","published":"2023-06-05T16:01:33Z","title":"Integrated Sensing, Computation, and Communication for UAV-assisted\n  Federated Edge Learning","summary":"  Federated edge learning (FEEL) enables privacy-preserving model training\nthrough periodic communication between edge devices and the server. Unmanned\nAerial Vehicle (UAV)-mounted edge devices are particularly advantageous for\nFEEL due to their flexibility and mobility in efficient data collection. In\nUAV-assisted FEEL, sensing, computation, and communication are coupled and\ncompete for limited onboard resources, and UAV deployment also affects sensing\nand communication performance. Therefore, the joint design of UAV deployment\nand resource allocation is crucial to achieving the optimal training\nperformance. In this paper, we address the problem of joint UAV deployment\ndesign and resource allocation for FEEL via a concrete case study of human\nmotion recognition based on wireless sensing. We first analyze the impact of\nUAV deployment on the sensing quality and identify a threshold value for the\nsensing elevation angle that guarantees a satisfactory quality of data samples.\nDue to the non-ideal sensing channels, we consider the probabilistic sensing\nmodel, where the successful sensing probability of each UAV is determined by\nits position. Then, we derive the upper bound of the FEEL training loss as a\nfunction of the sensing probability. Theoretical results suggest that the\nconvergence rate can be improved if UAVs have a uniform successful sensing\nprobability. Based on this analysis, we formulate a training time minimization\nproblem by jointly optimizing UAV deployment, integrated sensing, computation,\nand communication (ISCC) resources under a desirable optimality gap constraint.\nTo solve this challenging mixed-integer non-convex problem, we apply the\nalternating optimization technique, and propose the bandwidth, batch size, and\nposition optimization (BBPO) scheme to optimize these three decision variables\nalternately.\n","authors":["Yao Tang","Guangxu Zhu","Wei Xu","Man Hon Cheung","Tat-Ming Lok","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2306.02990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02986v1","updated":"2023-06-05T15:56:30Z","published":"2023-06-05T15:56:30Z","title":"Brain tumor segmentation using synthetic MR images -- A comparison of\n  GANs and diffusion models","summary":"  Large annotated datasets are required for training deep learning models, but\nin medical imaging data sharing is often complicated due to ethics,\nanonymization and data protection legislation (e.g. the general data protection\nregulation (GDPR)). Generative AI models, such as generative adversarial\nnetworks (GANs) and diffusion models, can today produce very realistic\nsynthetic images, and can potentially facilitate data sharing as GDPR should\nnot apply for medical images which do not belong to a specific person. However,\nin order to share synthetic images it must first be demonstrated that they can\nbe used for training different networks with acceptable performance. Here, we\ntherefore comprehensively evaluate four GANs (progressive GAN, StyleGAN 1-3)\nand a diffusion model for the task of brain tumor segmentation. Our results\nshow that segmentation networks trained on synthetic images reach Dice scores\nthat are 80\\% - 90\\% of Dice scores when training with real images, but that\nmemorization of the training images can be a problem for diffusion models if\nthe original dataset is too small. Furthermore, we demonstrate that common\nmetrics for evaluating synthetic images, Fr\\'echet inception distance (FID) and\ninception score (IS), do not correlate well with the obtained performance when\nusing the synthetic images for training segmentation networks.\n","authors":["Muhammad Usman Akbar","Måns Larsson","Anders Eklund"],"pdf_url":"https://arxiv.org/pdf/2306.02986v1.pdf","comment":"20 Pages"},{"id":"http://arxiv.org/abs/2306.02984v1","updated":"2023-06-05T15:53:56Z","published":"2023-06-05T15:53:56Z","title":"A Deep Learning Approach Utilizing Covariance Matrix Analysis for the\n  ISBI Edited MRS Reconstruction Challenge","summary":"  This work proposes a method to accelerate the acquisition of high-quality\nedited magnetic resonance spectroscopy (MRS) scans using machine learning\nmodels taking the sample covariance matrix as input. The method is invariant to\nthe number of transients and robust to noisy input data for both synthetic as\nwell as in-vivo scenarios.\n","authors":["Julian P. Merkofer","Dennis M. J. van de Sande","Sina Amirrajab","Gerhard S. Drenthen","Mitko Veta","Jacobus F. A. Jansen","Marcel Breeuwer","Ruud J. G. van Sloun"],"pdf_url":"https://arxiv.org/pdf/2306.02984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11552v2","updated":"2023-06-05T15:40:57Z","published":"2023-02-22T18:48:46Z","title":"Reduce, Reuse, Recycle: Compositional Generation with Energy-Based\n  Diffusion Models and MCMC","summary":"  Since their introduction, diffusion models have quickly become the prevailing\napproach to generative modeling in many domains. They can be interpreted as\nlearning the gradients of a time-varying sequence of log-probability density\nfunctions. This interpretation has motivated classifier-based and\nclassifier-free guidance as methods for post-hoc control of diffusion models.\nIn this work, we build upon these ideas using the score-based interpretation of\ndiffusion models, and explore alternative ways to condition, modify, and reuse\ndiffusion models for tasks involving compositional generation and guidance. In\nparticular, we investigate why certain types of composition fail using current\ntechniques and present a number of solutions. We conclude that the sampler (not\nthe model) is responsible for this failure and propose new samplers, inspired\nby MCMC, which enable successful compositional generation. Further, we propose\nan energy-based parameterization of diffusion models which enables the use of\nnew compositional operators and more sophisticated, Metropolis-corrected\nsamplers. Intriguingly we find these samplers lead to notable improvements in\ncompositional generation across a wide set of problems such as\nclassifier-guided ImageNet modeling and compositional text-to-image generation.\n","authors":["Yilun Du","Conor Durkan","Robin Strudel","Joshua B. Tenenbaum","Sander Dieleman","Rob Fergus","Jascha Sohl-Dickstein","Arnaud Doucet","Will Grathwohl"],"pdf_url":"https://arxiv.org/pdf/2302.11552v2.pdf","comment":"ICML 2023, Project Webpage:\n  https://energy-based-model.github.io/reduce-reuse-recycle/"},{"id":"http://arxiv.org/abs/2206.04740v3","updated":"2023-06-05T15:38:01Z","published":"2022-06-09T19:19:58Z","title":"XAudit : A Theoretical Look at Auditing with Explanations","summary":"  Responsible use of machine learning requires models to be audited for\nundesirable properties. While a body of work has proposed using explanations\nfor auditing, how to do so and why has remained relatively ill-understood. This\nwork formalizes the role of explanations in auditing and investigates if and\nhow model explanations can help audits. Specifically, we propose\nexplanation-based algorithms for auditing linear classifiers and decision trees\nfor feature sensitivity. Our results illustrate that Counterfactual\nexplanations are extremely helpful for auditing. While Anchors and decision\npaths may not be as beneficial in the worst-case, in the average-case they do\naid a lot.\n","authors":["Chhavi Yadav","Michal Moshkovitz","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2206.04740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02972v1","updated":"2023-06-05T15:35:19Z","published":"2023-06-05T15:35:19Z","title":"Simultaneous or Sequential Training? How Speech Representations\n  Cooperate in a Multi-Task Self-Supervised Learning System","summary":"  Speech representation learning with self-supervised algorithms has resulted\nin notable performance boosts in many downstream tasks. Recent work combined\nself-supervised learning (SSL) and visually grounded speech (VGS) processing\nmechanisms for representation learning. The joint training with SSL and VGS\nmechanisms provides the opportunity to utilize both unlabeled speech and\nspeech-related visual information based on data availability. This has shown to\nenhance the quality of learned representations, especially at encoding\nsemantic- and lexical-level knowledge. In this work, we further study the joint\noptimization of wav2vec 2.0-based SSL and transformer-based VGS as a multi-task\nlearning system. We explore a set of training scenarios to understand how\nspeech representations are shared or transferred between the two tasks, and\nwhat is the optimal training strategy for cross-modal semantic retrieval and\nphoneme discrimination performance. As a result, we find that sequential\ntraining with wav2vec 2.0 first and VGS next provides higher performance on\naudio-visual retrieval compared to simultaneous optimization of both learning\nmechanisms. However, the parallel SSL-VGS training reduces the effects of\ncatastrophic forgetting when switching between optimization criteria. Moreover,\nthe results suggest that phonemic representations learned through the VGS\nmechanism may generalize better across datasets compared to those learned with\nSSL.\n","authors":["Khazar Khorrami","María Andrea Cruz Blandón","Tuomas Virtanen","Okko Räsänen"],"pdf_url":"https://arxiv.org/pdf/2306.02972v1.pdf","comment":"5 pages, accepted by EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2306.02971v1","updated":"2023-06-05T15:35:00Z","published":"2023-06-05T15:35:00Z","title":"Online Learning with Feedback Graphs: The True Shape of Regret","summary":"  Sequential learning with feedback graphs is a natural extension of the\nmulti-armed bandit problem where the problem is equipped with an underlying\ngraph structure that provides additional information - playing an action\nreveals the losses of all the neighbors of the action. This problem was\nintroduced by \\citet{mannor2011} and received considerable attention in recent\nyears. It is generally stated in the literature that the minimax regret rate\nfor this problem is of order $\\sqrt{\\alpha T}$, where $\\alpha$ is the\nindependence number of the graph, and $T$ is the time horizon. However, this is\nproven only when the number of rounds $T$ is larger than $\\alpha^3$, which\nposes a significant restriction for the usability of this result in large\ngraphs. In this paper, we define a new quantity $R^*$, called the \\emph{problem\ncomplexity}, and prove that the minimax regret is proportional to $R^*$ for any\ngraph and time horizon $T$. Introducing an intricate exploration strategy, we\ndefine the \\mainAlgorithm algorithm that achieves the minimax optimal regret\nbound and becomes the first provably optimal algorithm for this setting, even\nif $T$ is smaller than $\\alpha^3$.\n","authors":["Tomáš Kocák","Alexandra Carpentier"],"pdf_url":"https://arxiv.org/pdf/2306.02971v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.07925v5","updated":"2023-06-05T15:32:48Z","published":"2023-03-14T14:10:37Z","title":"Robust incremental learning pipelines for temporal tabular datasets with\n  distribution shifts","summary":"  In this paper, we present a robust incremental learning model for regression\ntasks on temporal tabular datasets. Using commonly available tabular and\ntime-series prediction models as building blocks, a machine-learning model is\nbuilt incrementally to adapt to distributional shifts in data. Using the\nconcept of self-similarity, the model uses only two basic building blocks of\nmachine learning models, gradient boosting decision trees and neural networks\nto build models for any required complexity. The model is efficient as no\nspecialised neural architectures are used and each model building block can be\nindependently trained in parallel. The model is demonstrated to have robust\nperformances under adverse situations such as regime changes, fat-tailed\ndistributions and low signal-to-noise ratios. Model robustness are studied\nunder different hyper-parameters and complexities.\n","authors":["Thomas Wong","Mauricio Barahona"],"pdf_url":"https://arxiv.org/pdf/2303.07925v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01212v3","updated":"2023-06-05T15:32:06Z","published":"2022-10-03T20:07:51Z","title":"\\textit{spred}: Solving $L_1$ Penalty with SGD","summary":"  We propose to minimize a generic differentiable objective with $L_1$\nconstraint using a simple reparametrization and straightforward stochastic\ngradient descent. Our proposal is the direct generalization of previous ideas\nthat the $L_1$ penalty may be equivalent to a differentiable reparametrization\nwith weight decay. We prove that the proposed method, \\textit{spred}, is an\nexact differentiable solver of $L_1$ and that the reparametrization trick is\ncompletely ``benign\" for a generic nonconvex function. Practically, we\ndemonstrate the usefulness of the method in (1) training sparse neural networks\nto perform gene selection tasks, which involves finding relevant features in a\nvery high dimensional space, and (2) neural network compression task, to which\nprevious attempts at applying the $L_1$-penalty have been unsuccessful.\nConceptually, our result bridges the gap between the sparsity in deep learning\nand conventional statistical learning.\n","authors":["Liu Ziyin","Zihao Wang"],"pdf_url":"https://arxiv.org/pdf/2210.01212v3.pdf","comment":"ICML 2023, 16 pages, 10 figures, and 2 tables"},{"id":"http://arxiv.org/abs/2306.02968v1","updated":"2023-06-05T15:31:18Z","published":"2023-06-05T15:31:18Z","title":"Time Interpret: a Unified Model Interpretability Library for Time Series","summary":"  We introduce $\\texttt{time_interpret}$, a library designed as an extension of\nCaptum, with a specific focus on temporal data. As such, this library\nimplements several feature attribution methods that can be used to explain\npredictions made by any Pytorch model. $\\texttt{time_interpret}$ also provides\nseveral synthetic and real world time series datasets, various PyTorch models,\nas well as a set of methods to evaluate feature attributions. Moreover, while\nbeing primarily developed to explain predictions based on temporal data, some\nof its components have a different application, including for instance methods\nexplaining predictions made by language models. In this paper, we give a\ngeneral introduction of this library. We also present several previously\nunpublished feature attribution methods, which have been developed along with\n$\\texttt{time_interpret}$.\n","authors":["Joseph Enguehard"],"pdf_url":"https://arxiv.org/pdf/2306.02968v1.pdf","comment":"7 pages, 1 figure. Code available at\n  https://github.com/josephenguehard/time_interpret"},{"id":"http://arxiv.org/abs/2302.09048v2","updated":"2023-06-05T15:26:26Z","published":"2023-02-17T18:27:14Z","title":"MiDi: Mixed Graph and 3D Denoising Diffusion for Molecule Generation","summary":"  This work introduces MiDi, a novel diffusion model for jointly generating\nmolecular graphs and their corresponding 3D arrangement of atoms. Unlike\nexisting methods that rely on predefined rules to determine molecular bonds\nbased on the 3D conformation, MiDi offers an end-to-end differentiable approach\nthat streamlines the molecule generation process. Our experimental results\ndemonstrate the effectiveness of this approach. On the challenging GEOM-DRUGS\ndataset, MiDi generates 92% of stable molecules, against 6% for the previous\nEDM model that uses interatomic distances for bond prediction, and 40% using\nEDM followed by an algorithm that directly optimize bond orders for validity.\nOur code is available at github.com/cvignac/MiDi.\n","authors":["Clement Vignac","Nagham Osman","Laura Toni","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2302.09048v2.pdf","comment":"22 pages. Under review"},{"id":"http://arxiv.org/abs/2306.02960v1","updated":"2023-06-05T15:26:02Z","published":"2023-06-05T15:26:02Z","title":"Best of Both Worlds: Hybrid SNN-ANN Architecture for Event-based Optical\n  Flow Estimation","summary":"  Event-based cameras offer a low-power alternative to frame-based cameras for\ncapturing high-speed motion and high dynamic range scenes. They provide\nasynchronous streams of sparse events. Spiking Neural Networks (SNNs) with\ntheir asynchronous event-driven compute, show great potential for extracting\nthe spatio-temporal features from these event streams. In contrast, the\nstandard Analog Neural Networks (ANNs1) fail to process event data effectively.\nHowever, training SNNs is difficult due to additional trainable parameters\n(thresholds and leaks), vanishing spikes at deeper layers, non-differentiable\nbinary activation function etc. Moreover, an additional data structure\n\"membrane potential\" responsible for keeping track of temporal information,\nmust be fetched and updated at every timestep in SNNs. To overcome these, we\npropose a novel SNN-ANN hybrid architecture that combines the strengths of\nboth. Specifically, we leverage the asynchronous compute capabilities of SNN\nlayers to effectively extract the input temporal information. While the ANN\nlayers offer trouble-free training and implementation on standard machine\nlearning hardware such as GPUs. We provide extensive experimental analysis for\nassigning each layer to be spiking or analog in nature, leading to a network\nconfiguration optimized for performance and ease of training. We evaluate our\nhybrid architectures for optical flow estimation using event-data on DSEC-flow\nand Mutli-Vehicle Stereo Event-Camera (MVSEC) datasets. The results indicate\nthat our configured hybrid architectures outperform the state-of-the-art\nANN-only, SNN-only and past hybrid architectures both in terms of accuracy and\nefficiency. Specifically, our hybrid architecture exhibit a 31% and 24.8% lower\naverage endpoint error (AEE) at 2.1x and 3.1x lower energy, compared to an\nSNN-only architecture on DSEC and MVSEC datasets, respectively.\n","authors":["Shubham Negi","Deepika Sharma","Adarsh Kumar Kosta","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2306.02960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02957v1","updated":"2023-06-05T15:24:39Z","published":"2023-06-05T15:24:39Z","title":"Complex Preferences for Different Convergent Priors in Discrete Graph\n  Diffusion","summary":"  Diffusion models have achieved state-of-the-art performance in generating\nmany different kinds of data, including images, text, and videos. Despite their\nsuccess, there has been limited research on how the underlying diffusion\nprocess and the final convergent prior can affect generative performance; this\nresearch has also been limited to continuous data types and a score-based\ndiffusion framework. To fill this gap, we explore how different discrete\ndiffusion kernels (which converge to different prior distributions) affect the\nperformance of diffusion models for graphs. To this end, we developed a novel\nformulation of a family of discrete diffusion kernels which are easily\nadjustable to converge to different Bernoulli priors, and we study the effect\nof these different kernels on generative performance. We show that the quality\nof generated graphs is sensitive to the prior used, and that the optimal choice\ncannot be explained by obvious statistics or metrics, which challenges the\nintuitions which previous works have suggested.\n","authors":["Alex M. Tseng","Nathaniel Diamant","Tommaso Biancalani","Gabriele Scalia"],"pdf_url":"https://arxiv.org/pdf/2306.02957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02955v1","updated":"2023-06-05T15:23:55Z","published":"2023-06-05T15:23:55Z","title":"A Simple and Flexible Modeling for Mental Disorder Detection by Learning\n  from Clinical Questionnaires","summary":"  Social media is one of the most highly sought resources for analyzing\ncharacteristics of the language by its users. In particular, many researchers\nutilized various linguistic features of mental health problems from social\nmedia. However, existing approaches to detecting mental disorders face critical\nchallenges, such as the scarcity of high-quality data or the trade-off between\naddressing the complexity of models and presenting interpretable results\ngrounded in expert domain knowledge. To address these challenges, we design a\nsimple but flexible model that preserves domain-based interpretability. We\npropose a novel approach that captures the semantic meanings directly from the\ntext and compares them to symptom-related descriptions. Experimental results\ndemonstrate that our model outperforms relevant baselines on various mental\ndisorder detection tasks. Our detailed analysis shows that the proposed model\nis effective at leveraging domain knowledge, transferable to other mental\ndisorders, and providing interpretable detection results.\n","authors":["Hoyun Song","Jisu Shin","Huije Lee","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2306.02955v1.pdf","comment":"ACL 2023, 15 pages, 11 tables, 4 figures"},{"id":"http://arxiv.org/abs/2304.04033v4","updated":"2023-06-05T15:23:05Z","published":"2023-04-08T15:04:26Z","title":"Exploring the Connection between Robust and Generative Models","summary":"  We offer a study that connects robust discriminative classifiers trained with\nadversarial training (AT) with generative modeling in the form of Energy-based\nModels (EBM). We do so by decomposing the loss of a discriminative classifier\nand showing that the discriminative model is also aware of the input data\ndensity. Though a common assumption is that adversarial points leave the\nmanifold of the input data, our study finds out that, surprisingly, untargeted\nadversarial points in the input space are very likely under the generative\nmodel hidden inside the discriminative classifier -- have low energy in the\nEBM. We present two evidence: untargeted attacks are even more likely than the\nnatural data and their likelihood increases as the attack strength increases.\nThis allows us to easily detect them and craft a novel attack called\nHigh-Energy PGD that fools the classifier yet has energy similar to the data\nset. The code is available at github.com/senad96/Robust-Generative\n","authors":["Senad Beadini","Iacopo Masi"],"pdf_url":"https://arxiv.org/pdf/2304.04033v4.pdf","comment":"Italian Conference on AI - AI per Cybersecurity, 6 pages, 6 figures"},{"id":"http://arxiv.org/abs/2208.05844v2","updated":"2023-06-05T15:22:59Z","published":"2022-08-11T14:27:49Z","title":"Adaptive Identification of Populations with Treatment Benefit in\n  Clinical Trials: Machine Learning Challenges and Solutions","summary":"  We study the problem of adaptively identifying patient subpopulations that\nbenefit from a given treatment during a confirmatory clinical trial. This type\nof adaptive clinical trial has been thoroughly studied in biostatistics, but\nhas been allowed only limited adaptivity so far. Here, we aim to relax\nclassical restrictions on such designs and investigate how to incorporate ideas\nfrom the recent machine learning literature on adaptive and online\nexperimentation to make trials more flexible and efficient. We find that the\nunique characteristics of the subpopulation selection problem -- most\nimportantly that (i) one is usually interested in finding subpopulations with\nany treatment benefit (and not necessarily the single subgroup with largest\neffect) given a limited budget and that (ii) effectiveness only has to be\ndemonstrated across the subpopulation on average -- give rise to interesting\nchallenges and new desiderata when designing algorithmic solutions. Building on\nthese findings, we propose AdaGGI and AdaGCPI, two meta-algorithms for\nsubpopulation construction. We empirically investigate their performance across\na range of simulation scenarios and derive insights into their (dis)advantages\nacross different settings.\n","authors":["Alicia Curth","Alihan Hüyük","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2208.05844v2.pdf","comment":"To appear in the Proceedings of the 40th International Conference on\n  Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023"},{"id":"http://arxiv.org/abs/2306.02948v1","updated":"2023-06-05T15:14:34Z","published":"2023-06-05T15:14:34Z","title":"Random Distribution Shift in Refugee Placement: Strategies for Building\n  Robust Models","summary":"  Algorithmic assignment of refugees and asylum seekers to locations within\nhost countries has gained attention in recent years, with implementations in\nthe US and Switzerland. These approaches use data on past arrivals to generate\nmachine learning models that can be used (along with assignment algorithms) to\nmatch families to locations, with the goal of maximizing a policy-relevant\nintegration outcome such as employment status after a certain duration.\nExisting implementations and research train models to predict the policy\noutcome directly, and use these predictions in the assignment procedure.\nHowever, the merits of this approach, particularly in non-stationary settings,\nhas not been previously explored. This study proposes and compares three\ndifferent modeling strategies: the standard approach described above, an\napproach that uses newer data and proxy outcomes, and a hybrid approach. We\nshow that the hybrid approach is robust to both distribution shift and weak\nproxy relationships -- the failure points of the other two methods,\nrespectively. We compare these approaches empirically using data on asylum\nseekers in the Netherlands. Surprisingly, we find that both the proxy and\nhybrid approaches out-perform the standard approach in practice. These insights\nsupport the development of a real-world recommendation tool currently used by\nNGOs and government agencies.\n","authors":["Kirk Bansak","Elisabeth Paulson","Dominik Rothenhäusler"],"pdf_url":"https://arxiv.org/pdf/2306.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02947v1","updated":"2023-06-05T15:11:59Z","published":"2023-06-05T15:11:59Z","title":"Continual Learning with Pretrained Backbones by Tuning in the Input\n  Space","summary":"  The intrinsic difficulty in adapting deep learning models to non-stationary\nenvironments limits the applicability of neural networks to real-world tasks.\nThis issue is critical in practical supervised learning settings, such as the\nones in which a pre-trained model computes projections toward a latent space\nwhere different task predictors are sequentially learned over time. As a matter\nof fact, incrementally fine-tuning the whole model to better adapt to new tasks\nusually results in catastrophic forgetting, with decreasing performance over\nthe past experiences and losing valuable knowledge from the pre-training stage.\nIn this paper, we propose a novel strategy to make the fine-tuning procedure\nmore effective, by avoiding to update the pre-trained part of the network and\nlearning not only the usual classification head, but also a set of\nnewly-introduced learnable parameters that are responsible for transforming the\ninput data. This process allows the network to effectively leverage the\npre-training knowledge and find a good trade-off between plasticity and\nstability with modest computational efforts, thus especially suitable for\non-the-edge settings. Our experiments on four image classification problems in\na continual learning setting confirm the quality of the proposed approach when\ncompared to several fine-tuning procedures and to popular continual learning\nmethods.\n","authors":["Simone Marullo","Matteo Tiezzi","Marco Gori","Stefano Melacci","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2306.02947v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11702v2","updated":"2023-06-05T15:11:43Z","published":"2023-03-21T09:42:27Z","title":"Linking generative semi-supervised learning and generative open-set\n  recognition","summary":"  This study investigates the relationship between semi-supervised learning\n(SSL) and open-set recognition (OSR) in the context of generative adversarial\nnetworks (GANs). Although no previous study has formally linked SSL and OSR,\ntheir respective methods share striking similarities. Specifically, SSL-GANs\nand OSR-GANs require their generators to produce samples in the complementary\nspace. Subsequently, by regularising networks with generated samples, both SSL\nand OSR classifiers generalize the open space. To demonstrate the connection\nbetween SSL and OSR, we theoretically and experimentally compare\nstate-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our\nresults indicate that the SSL optimised margin-GANs, which have a stronger\nfoundation in literature, set the new standard for the combined SSL-OSR task\nand achieves new state-of-other art results in certain general OSR experiments.\nHowever, the OSR optimised adversarial reciprocal point (ARP)-GANs still\nslightly out-performed margin-GANs at other OSR experiments. This result\nindicates unique insights for the combined optimisation task of SSL-OSR.\n","authors":["Emile Reyn Engelbrecht","Johan du Preez"],"pdf_url":"https://arxiv.org/pdf/2303.11702v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1910.13601v4","updated":"2023-06-05T15:05:13Z","published":"2019-10-30T00:40:25Z","title":"Deep Weakly-supervised Anomaly Detection","summary":"  Recent semi-supervised anomaly detection methods that are trained using small\nlabeled anomaly examples and large unlabeled data (mostly normal data) have\nshown largely improved performance over unsupervised methods. However, these\nmethods often focus on fitting abnormalities illustrated by the given anomaly\nexamples only (i.e.,, seen anomalies), and consequently they fail to generalize\nto those that are not, i.e., new types/classes of anomaly unseen during\ntraining. To detect both seen and unseen anomalies, we introduce a novel deep\nweakly-supervised approach, namely Pairwise Relation prediction Network\n(PReNet), that learns pairwise relation features and anomaly scores by\npredicting the relation of any two randomly sampled training instances, in\nwhich the pairwise relation can be anomaly-anomaly, anomaly-unlabeled, or\nunlabeled-unlabeled. Since unlabeled instances are mostly normal, the relation\nprediction enforces a joint learning of anomaly-anomaly, anomaly-normal, and\nnormal-normal pairwise discriminative patterns, respectively. PReNet can then\ndetect any seen/unseen abnormalities that fit the learned pairwise abnormal\npatterns, or deviate from the normal patterns. Further, this pairwise approach\nalso seamlessly and significantly augments the training anomaly data. Empirical\nresults on 12 real-world datasets show that PReNet significantly outperforms\nnine competing methods in detecting seen and unseen anomalies. We also\ntheoretically and empirically justify the robustness of our model w.r.t.\nanomaly contamination in the unlabeled data. The code is available at\nhttps://github.com/mala-lab/PReNet.\n","authors":["Guansong Pang","Chunhua Shen","Huidong Jin","Anton van den Hengel"],"pdf_url":"https://arxiv.org/pdf/1910.13601v4.pdf","comment":"Accepted to KDD 2023"},{"id":"http://arxiv.org/abs/2306.02939v1","updated":"2023-06-05T15:03:01Z","published":"2023-06-05T15:03:01Z","title":"Improved Stability and Generalization Analysis of the Decentralized SGD\n  Algorithm","summary":"  This paper presents a new generalization error analysis for the Decentralized\nStochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability.\nThe obtained results largely improve upon state-of-the-art results, and even\ninvalidate their claims that the communication graph has a detrimental effect\non generalization. For instance, we show that in convex settings, D-SGD has the\nsame generalization bounds as the classical SGD algorithm, no matter the choice\nof graph. We exhibit that this counter-intuitive result comes from considering\nthe average of local parameters, which hides a final global averaging step\nincompatible with the decentralized scenario. In light of this observation, we\nadvocate to analyze the supremum over local parameters and show that in this\ncase, the graph does have an impact on the generalization. Unlike prior\nresults, our analysis yields non-vacuous bounds even for non-connected graphs.\n","authors":["Batiste Le Bars","Aurélien Bellet","Marc Tommasi"],"pdf_url":"https://arxiv.org/pdf/2306.02939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10782v2","updated":"2023-06-05T15:01:43Z","published":"2022-10-19T07:47:19Z","title":"Topology Optimization via Machine Learning and Deep Learning: A Review","summary":"  Topology optimization (TO) is a method of deriving an optimal design that\nsatisfies a given load and boundary conditions within a design domain. This\nmethod enables effective design without initial design, but has been limited in\nuse due to high computational costs. At the same time, machine learning (ML)\nmethodology including deep learning has made great progress in the 21st\ncentury, and accordingly, many studies have been conducted to enable effective\nand rapid optimization by applying ML to TO. Therefore, this study reviews and\nanalyzes previous research on ML-based TO (MLTO). Two different perspectives of\nMLTO are used to review studies: (1) TO and (2) ML perspectives. The TO\nperspective addresses \"why\" to use ML for TO, while the ML perspective\naddresses \"how\" to apply ML to TO. In addition, the limitations of current MLTO\nresearch and future research directions are examined.\n","authors":["Seungyeon Shin","Dongju Shin","Namwoo Kang"],"pdf_url":"https://arxiv.org/pdf/2210.10782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.02272v2","updated":"2023-06-05T14:59:18Z","published":"2022-04-05T15:09:33Z","title":"Deep surrogate accelerated delayed-acceptance HMC for Bayesian inference\n  of spatio-temporal heat fluxes in rotating disc systems","summary":"  We introduce a deep learning accelerated methodology to solve PDE-based\nBayesian inverse problems with guaranteed accuracy. This is motivated by the\nill-posed problem of inferring a spatio-temporal heat-flux parameter known as\nthe Biot number given temperature data, however the methodology is\ngeneralisable to other settings. To accelerate Bayesian inference, we develop a\nnovel training scheme that uses data to adaptively train a neural-network\nsurrogate simulating the parametric forward model. By simultaneously\nidentifying an approximate posterior distribution over the Biot number, and\nweighting a physics-informed training loss according to this, our approach\napproximates forward and inverse solution together without any need for\nexternal solves. Using a random Chebyshev series, we outline how to approximate\na Gaussian process prior, and using the surrogate we apply Hamiltonian Monte\nCarlo (HMC) to sample from the posterior distribution. We derive convergence of\nthe surrogate posterior to the true posterior distribution in the Hellinger\nmetric as our adaptive loss approaches zero. Additionally, we describe how this\nsurrogate-accelerated HMC approach can be combined with traditional PDE solvers\nin a delayed-acceptance scheme to a-priori control the posterior accuracy. This\novercomes a major limitation of deep learning-based surrogate approaches, which\ndo not achieve guaranteed accuracy a-priori due to their non-convex training.\nBiot number calculations are involved in turbo-machinery design, which is\nsafety critical and highly regulated, therefore it is important that our\nresults have such mathematical guarantees. Our approach achieves fast mixing in\nhigh dimensions whilst retaining the convergence guarantees of a traditional\nPDE solver, and without the burden of evaluating this solver for proposals that\nare likely to be rejected. Numerical results are given using real and simulated\ndata.\n","authors":["Teo Deveney","Eike Mueller","Tony Shardlow"],"pdf_url":"https://arxiv.org/pdf/2204.02272v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05801v3","updated":"2023-06-05T14:52:42Z","published":"2022-10-11T22:00:43Z","title":"Linkless Link Prediction via Relational Distillation","summary":"  Graph Neural Networks (GNNs) have shown exceptional performance in the task\nof link prediction. Despite their effectiveness, the high latency brought by\nnon-trivial neighborhood data dependency limits GNNs in practical deployments.\nConversely, the known efficient MLPs are much less effective than GNNs due to\nthe lack of relational knowledge. In this work, to combine the advantages of\nGNNs and MLPs, we start with exploring direct knowledge distillation (KD)\nmethods for link prediction, i.e., predicted logit-based matching and node\nrepresentation-based matching. Upon observing direct KD analogs do not perform\nwell for link prediction, we propose a relational KD framework, Linkless Link\nPrediction (LLP), to distill knowledge for link prediction with MLPs. Unlike\nsimple KD methods that match independent link logits or node representations,\nLLP distills relational knowledge that is centered around each (anchor) node to\nthe student MLP. Specifically, we propose rank-based matching and\ndistribution-based matching strategies that complement each other. Extensive\nexperiments demonstrate that LLP boosts the link prediction performance of MLPs\nwith significant margins, and even outperforms the teacher GNNs on 7 out of 8\nbenchmarks. LLP also achieves a 70.68x speedup in link prediction inference\ncompared to GNNs on the large-scale OGB dataset.\n","authors":["Zhichun Guo","William Shiao","Shichang Zhang","Yozen Liu","Nitesh V. Chawla","Neil Shah","Tong Zhao"],"pdf_url":"https://arxiv.org/pdf/2210.05801v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02931v1","updated":"2023-06-05T14:51:05Z","published":"2023-06-05T14:51:05Z","title":"Causal Discovery using Bayesian Model Selection","summary":"  With only observational data on two variables, and without other assumptions,\nit is not possible to infer which one causes the other. Much of the causal\nliterature has focused on guaranteeing identifiability of causal direction in\nstatistical models for datasets where strong assumptions hold, such as additive\nnoise or restrictions on parameter count. These methods are then subsequently\ntested on realistic datasets, most of which violate their assumptions. Building\non previous attempts, we show how to use causal assumptions within the Bayesian\nframework. This allows us to specify models with realistic assumptions, while\nalso encoding independent causal mechanisms, leading to an asymmetry between\nthe causal directions. Identifying causal direction then becomes a Bayesian\nmodel selection problem. We analyse why Bayesian model selection works for\nknown identifiable cases and flexible model classes, while also providing\ncorrectness guarantees about its behaviour. To demonstrate our approach, we\nconstruct a Bayesian non-parametric model that can flexibly model the joint. We\nthen outperform previous methods on a wide range of benchmark datasets with\nvarying data generating assumptions showing the usefulness of our method.\n","authors":["Anish Dhir","Mark van der Wilk"],"pdf_url":"https://arxiv.org/pdf/2306.02931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04183v2","updated":"2023-06-05T14:35:59Z","published":"2022-10-09T06:31:15Z","title":"MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language\n  Representation Learning","summary":"  Multimodal representation learning has shown promising improvements on\nvarious vision-language tasks. Most existing methods excel at building\nglobal-level alignment between vision and language while lacking effective\nfine-grained image-text interaction. In this paper, we propose a jointly masked\nmultimodal modeling method to learn fine-grained multimodal representations.\nOur method performs joint masking on image-text input and integrates both\nimplicit and explicit targets for the masked signals to recover. The implicit\ntarget provides a unified and debiased objective for vision and language, where\nthe model predicts latent multimodal representations of the unmasked input. The\nexplicit target further enriches the multimodal representations by recovering\nhigh-level and semantically meaningful information: momentum visual features of\nimage patches and concepts of word tokens. Through such a masked modeling\nprocess, our model not only learns fine-grained multimodal interaction, but\nalso avoids the semantic gap between high-level representations and low- or\nmid-level prediction targets (e.g. image pixels), thus producing semantically\nrich multimodal representations that perform well on both zero-shot and\nfine-tuned settings. Our pre-trained model (named MAMO) achieves\nstate-of-the-art performance on various downstream vision-language tasks,\nincluding image-text retrieval, visual question answering, visual reasoning,\nand weakly-supervised visual grounding.\n","authors":["Zijia Zhao","Longteng Guo","Xingjian He","Shuai Shao","Zehuan Yuan","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2210.04183v2.pdf","comment":"SIGIR 2023, 10 pages"},{"id":"http://arxiv.org/abs/2306.01375v2","updated":"2023-06-05T14:25:53Z","published":"2023-06-02T08:56:56Z","title":"Robust and Generalisable Segmentation of Subtle Epilepsy-causing\n  Lesions: a Graph Convolutional Approach","summary":"  Focal cortical dysplasia (FCD) is a leading cause of drug-resistant focal\nepilepsy, which can be cured by surgery. These lesions are extremely subtle and\noften missed even by expert neuroradiologists. \"Ground truth\" manual lesion\nmasks are therefore expensive, limited and have large inter-rater variability.\nExisting FCD detection methods are limited by high numbers of false positive\npredictions, primarily due to vertex- or patch-based approaches that lack\nwhole-brain context. Here, we propose to approach the problem as semantic\nsegmentation using graph convolutional networks (GCN), which allows our model\nto learn spatial relationships between brain regions. To address the specific\nchallenges of FCD identification, our proposed model includes an auxiliary loss\nto predict distance from the lesion to reduce false positives and a weak\nsupervision classification loss to facilitate learning from uncertain lesion\nmasks. On a multi-centre dataset of 1015 participants with surface-based\nfeatures and manual lesion masks from structural MRI data, the proposed GCN\nachieved an AUC of 0.74, a significant improvement against a previously used\nvertex-wise multi-layer perceptron (MLP) classifier (AUC 0.64). With\nsensitivity thresholded at 67%, the GCN had a specificity of 71% in comparison\nto 49% when using the MLP. This improvement in specificity is vital for\nclinical integration of lesion-detection tools into the radiological workflow,\nthrough increasing clinical confidence in the use of AI radiological adjuncts\nand reducing the number of areas requiring expert review.\n","authors":["Hannah Spitzer","Mathilde Ripart","Abdulah Fawaz","Logan Z. J. Williams","MELD project","Emma Robinson","Juan Eugenio Iglesias","Sophie Adler","Konrad Wagstyl"],"pdf_url":"https://arxiv.org/pdf/2306.01375v2.pdf","comment":"accepted at MICCAI 2023"},{"id":"http://arxiv.org/abs/2306.02913v1","updated":"2023-06-05T14:19:52Z","published":"2023-06-05T14:19:52Z","title":"Decentralized SGD and Average-direction SAM are Asymptotically\n  Equivalent","summary":"  Decentralized stochastic gradient descent (D-SGD) allows collaborative\nlearning on massive devices simultaneously without the control of a central\nserver. However, existing theories claim that decentralization invariably\nundermines generalization. In this paper, we challenge the conventional belief\nand present a completely new perspective for understanding decentralized\nlearning. We prove that D-SGD implicitly minimizes the loss function of an\naverage-direction Sharpness-aware minimization (SAM) algorithm under general\nnon-convex non-$\\beta$-smooth settings. This surprising asymptotic equivalence\nreveals an intrinsic regularization-optimization trade-off and three advantages\nof decentralization: (1) there exists a free uncertainty evaluation mechanism\nin D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient\nsmoothing effect; and (3) the sharpness regularization effect of D-SGD does not\ndecrease as total batch size increases, which justifies the potential\ngeneralization benefit of D-SGD over centralized SGD (C-SGD) in large-batch\nscenarios.\n","authors":["Tongtian Zhu","Fengxiang He","Kaixuan Chen","Mingli Song","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.02913v1.pdf","comment":"Accepted for publication in the 40th International Conference on\n  Machine Learning (ICML 2023)"},{"id":"http://arxiv.org/abs/2301.11342v2","updated":"2023-06-05T14:13:40Z","published":"2023-01-26T19:00:02Z","title":"A Robust Optimisation Perspective on Counterexample-Guided Repair of\n  Neural Networks","summary":"  Counterexample-guided repair aims at creating neural networks with\nmathematical safety guarantees, facilitating the application of neural networks\nin safety-critical domains. However, whether counterexample-guided repair is\nguaranteed to terminate remains an open question. We approach this question by\nshowing that counterexample-guided repair can be viewed as a robust\noptimisation algorithm. While termination guarantees for neural network repair\nitself remain beyond our reach, we prove termination for more restrained\nmachine learning models and disprove termination in a general setting. We\nempirically study the practical implications of our theoretical results,\ndemonstrating the suitability of common verifiers and falsifiers for repair\ndespite a disadvantageous theoretical result. Additionally, we use our\ntheoretical insights to devise a novel algorithm for repairing linear\nregression models based on quadratic programming, surpassing existing\napproaches.\n","authors":["David Boetius","Stefan Leue","Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2301.11342v2.pdf","comment":"Accepted at ICML 2023. 9 pages + 13 pages appendix, 8 figures"},{"id":"http://arxiv.org/abs/2108.01005v4","updated":"2023-06-05T14:10:00Z","published":"2021-08-02T16:07:21Z","title":"Sequoia: A Software Framework to Unify Continual Learning Research","summary":"  The field of Continual Learning (CL) seeks to develop algorithms that\naccumulate knowledge and skills over time through interaction with\nnon-stationary environments. In practice, a plethora of evaluation procedures\n(settings) and algorithmic solutions (methods) exist, each with their own\npotentially disjoint set of assumptions. This variety makes measuring progress\nin CL difficult. We propose a taxonomy of settings, where each setting is\ndescribed as a set of assumptions. A tree-shaped hierarchy emerges from this\nview, where more general settings become the parents of those with more\nrestrictive assumptions. This makes it possible to use inheritance to share and\nreuse research, as developing a method for a given setting also makes it\ndirectly applicable onto any of its children. We instantiate this idea as a\npublicly available software framework called Sequoia, which features a wide\nvariety of settings from both the Continual Supervised Learning (CSL) and\nContinual Reinforcement Learning (CRL) domains. Sequoia also includes a growing\nsuite of methods which are easy to extend and customize, in addition to more\nspecialized methods from external libraries. We hope that this new paradigm and\nits first implementation can help unify and accelerate research in CL. You can\nhelp us grow the tree by visiting www.github.com/lebrice/Sequoia.\n","authors":["Fabrice Normandin","Florian Golemo","Oleksiy Ostapenko","Pau Rodriguez","Matthew D Riemer","Julio Hurtado","Khimya Khetarpal","Ryan Lindeborg","Lucas Cecchi","Timothée Lesort","Laurent Charlin","Irina Rish","Massimo Caccia"],"pdf_url":"https://arxiv.org/pdf/2108.01005v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02899v1","updated":"2023-06-05T14:06:35Z","published":"2023-06-05T14:06:35Z","title":"Learning nonparametric latent causal graphs with unknown interventions","summary":"  We establish conditions under which latent causal graphs are\nnonparametrically identifiable and can be reconstructed from unknown\ninterventions in the latent space. Our primary focus is the identification of\nthe latent structure in a measurement model, i.e. causal graphical models where\ndependence between observed variables is insignificant compared to dependence\nbetween latent representations, without making parametric assumptions such as\nlinearity or Gaussianity. Moreover, we do not assume the number of hidden\nvariables is known, and we show that at most one unknown intervention per\nhidden variable is needed. This extends a recent line of work on learning\ncausal representations from observations and interventions. The proofs are\nconstructive and introduce two new graphical concepts -- imaginary subsets and\nisolated edges -- that may be useful in their own right. As a matter of\nindependent interest, the proofs also involve a novel characterization of the\nlimits of edge orientations within the equivalence class of DAGs induced by\nunknown interventions. Experiments confirm that the latent graph can be\nrecovered from data using our theoretical results. These are the first results\nto characterize the conditions under which causal representations are\nidentifiable without making any parametric assumptions in a general setting\nwith unknown interventions and without faithfulness.\n","authors":["Yibo Jiang","Bryon Aragam"],"pdf_url":"https://arxiv.org/pdf/2306.02899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02896v1","updated":"2023-06-05T14:05:04Z","published":"2023-06-05T14:05:04Z","title":"Representational Strengths and Limitations of Transformers","summary":"  Attention layers, as commonly used in transformers, form the backbone of\nmodern deep learning, yet there is no mathematical description of their\nbenefits and deficiencies as compared with other architectures. In this work we\nestablish both positive and negative results on the representation power of\nattention layers, with a focus on intrinsic complexity parameters such as\nwidth, depth, and embedding dimension. On the positive side, we present a\nsparse averaging task, where recurrent networks and feedforward networks all\nhave complexity scaling polynomially in the input size, whereas transformers\nscale merely logarithmically in the input size; furthermore, we use the same\nconstruction to show the necessity and role of a large embedding dimension in a\ntransformer. On the negative side, we present a triple detection task, where\nattention layers in turn have complexity scaling linearly in the input size; as\nthis scenario seems rare in practice, we also present natural variants that can\nbe efficiently solved by attention layers. The proof techniques emphasize the\nvalue of communication complexity in the analysis of transformers and related\nmodels, and the role of sparse averaging as a prototypical attention task,\nwhich even finds use in the analysis of triple detection.\n","authors":["Clayton Sanford","Daniel Hsu","Matus Telgarsky"],"pdf_url":"https://arxiv.org/pdf/2306.02896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02895v1","updated":"2023-06-05T14:04:53Z","published":"2023-06-05T14:04:53Z","title":"Evading Black-box Classifiers Without Breaking Eggs","summary":"  Decision-based evasion attacks repeatedly query a black-box classifier to\ngenerate adversarial examples. Prior work measures the cost of such attacks by\nthe total number of queries made to the classifier. We argue this metric is\nflawed. Most security-critical machine learning systems aim to weed out \"bad\"\ndata (e.g., malware, harmful content, etc). Queries to such systems carry a\nfundamentally asymmetric cost: queries detected as \"bad\" come at a higher cost\nbecause they trigger additional security filters, e.g., usage throttling or\naccount suspension. Yet, we find that existing decision-based attacks issue a\nlarge number of \"bad\" queries, which likely renders them ineffective against\nsecurity-critical systems. We then design new attacks that reduce the number of\nbad queries by $1.5$-$7.3\\times$, but often at a significant increase in total\n(non-bad) queries. We thus pose it as an open problem to build black-box\nattacks that are more effective under realistic cost metrics.\n","authors":["Edoardo Debenedetti","Nicholas Carlini","Florian Tramèr"],"pdf_url":"https://arxiv.org/pdf/2306.02895v1.pdf","comment":"Code at https://github.com/ethz-privsec/realistic-adv-examples"},{"id":"http://arxiv.org/abs/2206.15269v2","updated":"2023-06-05T13:59:05Z","published":"2022-06-30T13:20:48Z","title":"Deep Reinforcement Learning with Swin Transformers","summary":"  Transformers are neural network models that utilize multiple layers of\nself-attention heads and have exhibited enormous potential in natural language\nprocessing tasks. Meanwhile, there have been efforts to adapt transformers to\nvisual tasks of machine learning, including Vision Transformers and Swin\nTransformers. Although some researchers use Vision Transformers for\nreinforcement learning tasks, their experiments remain at a small scale due to\nthe high computational cost. Experiments conducted at a large scale, on the\nother hand, have to rely on techniques to cut the costs of Vision Transformers,\nwhich also yield inferior results.\n  To address this challenge, this article presents the first online\nreinforcement learning scheme that is based on Swin Transformers: Swin DQN.\nSwin Transformers are promising as a backbone in neural networks by splitting\ngroups of image pixels into small patches and applying local self-attention\noperations inside the (shifted) windows of fixed sizes. They have demonstrated\nstate-of-the-art performances in benchmarks. In contrast to existing research,\nour novel approach is reducing the computational costs, as well as\nsignificantly improving the performance. We demonstrate the superior\nperformance with experiments on 49 games in the Arcade Learning Environment.\nThe results show that our approach, using Swin Transformers with Double DQN,\nachieves significantly higher maximal evaluation scores than the baseline\nmethod in 45 of all the 49 games ~92%, and higher mean evaluation scores than\nthe baseline method in 40 of all the 49 games ~82%.\n","authors":["Li Meng","Morten Goodwin","Anis Yazidi","Paal Engelstad"],"pdf_url":"https://arxiv.org/pdf/2206.15269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00491v2","updated":"2023-06-05T13:58:47Z","published":"2023-02-01T15:02:58Z","title":"Learning Prototype Classifiers for Long-Tailed Recognition","summary":"  The problem of long-tailed recognition (LTR) has received attention in recent\nyears due to the fundamental power-law distribution of objects in the\nreal-world. Most recent works in LTR use softmax classifiers that have a\ntendency to correlate classifier norm with the amount of training data for a\ngiven class. On the other hand, Prototype classifiers do not suffer from this\nshortcoming and can deliver promising results simply using Nearest-Class-Mean\n(NCM), a special case where prototypes are empirical centroids. However, the\npotential of Prototype classifiers as an alternative to softmax in LTR is\nrelatively underexplored. In this work, we propose Prototype classifiers, which\njointly learn prototypes that minimize average cross-entropy loss based on\nprobability scores from distances to prototypes. We theoretically analyze the\nproperties of Euclidean distance based prototype classifiers that leads to\nstable gradient-based optimization which is robust to outliers. We further\nenhance Prototype classifiers by learning channel-dependent temperature\nparameters to enable independent distance scales along each channel. Our\nanalysis shows that prototypes learned by Prototype classifiers are better\nseparated than empirical centroids. Results on four long-tailed recognition\nbenchmarks show that Prototype classifier outperforms or is comparable to the\nstate-of-the-art methods.\n","authors":["Saurabh Sharma","Yongqin Xian","Ning Yu","Ambuj Singh"],"pdf_url":"https://arxiv.org/pdf/2302.00491v2.pdf","comment":"Accepted at IJCAI-23"},{"id":"http://arxiv.org/abs/2204.01815v5","updated":"2023-06-05T13:56:32Z","published":"2022-04-04T19:42:46Z","title":"Tensor Completion with Provable Consistency and Fairness Guarantees for\n  Recommender Systems","summary":"  We introduce a new consistency-based approach for defining and solving\nnonnegative/positive matrix and tensor completion problems. The novelty of the\nframework is that instead of artificially making the problem well-posed in the\nform of an application-arbitrary optimization problem, e.g., minimizing a bulk\nstructural measure such as rank or norm, we show that a single\nproperty/constraint: preserving unit-scale consistency, guarantees the\nexistence of both a solution and, under relatively weak support assumptions,\nuniqueness. The framework and solution algorithms also generalize directly to\ntensors of arbitrary dimensions while maintaining computational complexity that\nis linear in problem size for fixed dimension d. In the context of recommender\nsystem (RS) applications, we prove that two reasonable properties that should\nbe expected to hold for any solution to the RS problem are sufficient to permit\nuniqueness guarantees to be established within our framework. Key theoretical\ncontributions include a general unit-consistent tensor-completion framework\nwith proofs of its properties, e.g., consensus-order and fairness, and\nalgorithms with optimal runtime and space complexities, e.g., O(1)\nterm-completion with preprocessing complexity that is linear in the number of\nknown terms of the matrix/tensor. From a practical perspective, the seamless\nability of the framework to generalize to exploit high-dimensional structural\nrelationships among key state variables, e.g., user and product attributes,\noffers a means for extracting significantly more information than is possible\nfor alternative methods that cannot generalize beyond direct user-product\nrelationships. Finally, we propose our consensus ordering property as an\nadmissibility criterion for any proposed RS method.\n","authors":["Tung Nguyen","Jeffrey Uhlmann"],"pdf_url":"https://arxiv.org/pdf/2204.01815v5.pdf","comment":"Final revision after acceptance by journal"},{"id":"http://arxiv.org/abs/2302.03020v2","updated":"2023-06-05T13:55:19Z","published":"2023-02-06T18:57:14Z","title":"RLSbench: Domain Adaptation Under Relaxed Label Shift","summary":"  Despite the emergence of principled methods for domain adaptation under label\nshift, their sensitivity to shifts in class conditional distributions is\nprecariously under explored. Meanwhile, popular deep domain adaptation\nheuristics tend to falter when faced with label proportions shifts. While\nseveral papers modify these heuristics in attempts to handle label proportions\nshifts, inconsistencies in evaluation standards, datasets, and baselines make\nit difficult to gauge the current best practices. In this paper, we introduce\nRLSbench, a large-scale benchmark for relaxed label shift, consisting of $>$500\ndistribution shift pairs spanning vision, tabular, and language modalities,\nwith varying label proportions. Unlike existing benchmarks, which primarily\nfocus on shifts in class-conditional $p(x|y)$, our benchmark also focuses on\nlabel marginal shifts. First, we assess 13 popular domain adaptation methods,\ndemonstrating more widespread failures under label proportion shifts than were\npreviously known. Next, we develop an effective two-step meta-algorithm that is\ncompatible with most domain adaptation heuristics: (i) pseudo-balance the data\nat each epoch; and (ii) adjust the final classifier with target label\ndistribution estimate. The meta-algorithm improves existing domain adaptation\nheuristics under large label proportion shifts, often by 2--10\\% accuracy\npoints, while conferring minimal effect ($<$0.5\\%) when label proportions do\nnot shift. We hope that these findings and the availability of RLSbench will\nencourage researchers to rigorously evaluate proposed methods in relaxed label\nshift settings. Code is publicly available at\nhttps://github.com/acmi-lab/RLSbench.\n","authors":["Saurabh Garg","Nick Erickson","James Sharpnack","Alex Smola","Sivaraman Balakrishnan","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2302.03020v2.pdf","comment":"Accepted at ICML 2023. Paper website:\n  https://sites.google.com/view/rlsbench/"},{"id":"http://arxiv.org/abs/2306.02886v1","updated":"2023-06-05T13:53:57Z","published":"2023-06-05T13:53:57Z","title":"Image Reconstruction for Accelerated MR Scan with Faster Fourier\n  Convolutional Neural Networks","summary":"  Partial scan is a common approach to accelerate Magnetic Resonance Imaging\n(MRI) data acquisition in both 2D and 3D settings. However, accurately\nreconstructing images from partial scan data (i.e., incomplete k-space\nmatrices) remains challenging due to lack of an effectively global receptive\nfield in both spatial and k-space domains. To address this problem, we propose\nthe following: (1) a novel convolutional operator called Faster Fourier\nConvolution (FasterFC) to replace the two consecutive convolution operations\ntypically used in convolutional neural networks (e.g., U-Net, ResNet). Based on\nthe spectral convolution theorem in Fourier theory, FasterFC employs\nalternating kernels of size 1 in 3D case) in different domains to extend the\ndual-domain receptive field to the global and achieves faster calculation speed\nthan traditional Fast Fourier Convolution (FFC). (2) A 2D accelerated MRI\nmethod, FasterFC-End-to-End-VarNet, which uses FasterFC to improve the\nsensitivity maps and reconstruction quality. (3) A multi-stage 3D accelerated\nMRI method called FasterFC-based Single-to-group Network (FAS-Net) that\nutilizes a single-to-group algorithm to guide k-space domain reconstruction,\nfollowed by FasterFC-based cascaded convolutional neural networks to expand the\neffective receptive field in the dual-domain. Experimental results on the\nfastMRI and Stanford MRI Data datasets demonstrate that FasterFC improves the\nquality of both 2D and 3D reconstruction. Moreover, FAS-Net, as a 3D\nhigh-resolution multi-coil (eight) accelerated MRI method, achieves superior\nreconstruction performance in both qualitative and quantitative results\ncompared with state-of-the-art 2D and 3D methods.\n","authors":["Xiaohan Liu","Yanwei Pang","Xuebin Sun","Yiming Liu","Yonghong Hou","Zhenchang Wang","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2306.02886v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15266v2","updated":"2023-06-05T13:52:24Z","published":"2022-09-30T06:50:08Z","title":"Data Poisoning Attacks Against Multimodal Encoders","summary":"  Recently, the newly emerged multimodal models, which leverage both visual and\nlinguistic modalities to train powerful encoders, have gained increasing\nattention. However, learning from a large-scale unlabeled dataset also exposes\nthe model to the risk of potential poisoning attacks, whereby the adversary\naims to perturb the model's training data to trigger malicious behaviors in it.\nIn contrast to previous work, only poisoning visual modality, in this work, we\ntake the first step to studying poisoning attacks against multimodal models in\nboth visual and linguistic modalities. Specially, we focus on answering two\nquestions: (1) Is the linguistic modality also vulnerable to poisoning attacks?\nand (2) Which modality is most vulnerable? To answer the two questions, we\npropose three types of poisoning attacks against multimodal models. Extensive\nevaluations on different datasets and model architectures show that all three\nattacks can achieve significant attack performance while maintaining model\nutility in both visual and linguistic modalities. Furthermore, we observe that\nthe poisoning effect differs between different modalities. To mitigate the\nattacks, we propose both pre-training and post-training defenses. We\nempirically show that both defenses can significantly reduce the attack\nperformance while preserving the model's utility.\n","authors":["Ziqing Yang","Xinlei He","Zheng Li","Michael Backes","Mathias Humbert","Pascal Berrang","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.15266v2.pdf","comment":"To Appear in the 40th International Conference on Machine Learning,\n  July 2023"},{"id":"http://arxiv.org/abs/2306.02879v1","updated":"2023-06-05T13:50:56Z","published":"2023-06-05T13:50:56Z","title":"Neuron Activation Coverage: Rethinking Out-of-distribution Detection and\n  Generalization","summary":"  The out-of-distribution (OOD) problem generally arises when neural networks\nencounter data that significantly deviates from the training data distribution,\n\\ie, in-distribution (InD). In this paper, we study the OOD problem from a\nneuron activation view. We first formulate neuron activation states by\nconsidering both the neuron output and its influence on model decisions. Then,\nwe propose the concept of \\textit{neuron activation coverage} (NAC), which\ncharacterizes the neuron behaviors under InD and OOD data. Leveraging our NAC,\nwe show that 1) InD and OOD inputs can be naturally separated based on the\nneuron behavior, which significantly eases the OOD detection problem and\nachieves a record-breaking performance of 0.03% FPR95 on ResNet-50,\noutperforming the previous best method by 20.67%; 2) a positive correlation\nbetween NAC and model generalization ability consistently holds across\narchitectures and datasets, which enables a NAC-based criterion for evaluating\nmodel robustness. By comparison with the traditional validation criterion, we\nshow that NAC-based criterion not only can select more robust models, but also\nhas a stronger correlation with OOD test performance.\n","authors":["Yibing Liu","Chris Xing Tian","Haoliang Li","Lei Ma","Shiqi Wang"],"pdf_url":"https://arxiv.org/pdf/2306.02879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01121v2","updated":"2023-06-05T13:45:21Z","published":"2023-06-01T20:18:39Z","title":"Differentially Private Episodic Reinforcement Learning with Heavy-tailed\n  Rewards","summary":"  In this paper, we study the problem of (finite horizon tabular) Markov\ndecision processes (MDPs) with heavy-tailed rewards under the constraint of\ndifferential privacy (DP). Compared with the previous studies for private\nreinforcement learning that typically assume rewards are sampled from some\nbounded or sub-Gaussian distributions to ensure DP, we consider the setting\nwhere reward distributions have only finite $(1+v)$-th moments with some $v \\in\n(0,1]$. By resorting to robust mean estimators for rewards, we first propose\ntwo frameworks for heavy-tailed MDPs, i.e., one is for value iteration and\nanother is for policy optimization. Under each framework, we consider both\njoint differential privacy (JDP) and local differential privacy (LDP) models.\nBased on our frameworks, we provide regret upper bounds for both JDP and LDP\ncases and show that the moment of distribution and privacy budget both have\nsignificant impacts on regrets. Finally, we establish a lower bound of regret\nminimization for heavy-tailed MDPs in JDP model by reducing it to the\ninstance-independent lower bound of heavy-tailed multi-armed bandits in DP\nmodel. We also show the lower bound for the problem in LDP by adopting some\nprivate minimax methods. Our results reveal that there are fundamental\ndifferences between the problem of private RL with sub-Gaussian and that with\nheavy-tailed rewards.\n","authors":["Yulian Wu","Xingyu Zhou","Sayak Ray Chowdhury","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01121v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2303.06034v2","updated":"2023-06-05T13:44:02Z","published":"2023-03-10T16:27:37Z","title":"Tactile-Filter: Interactive Tactile Perception for Part Mating","summary":"  Humans rely on touch and tactile sensing for a lot of dexterous manipulation\ntasks. Our tactile sensing provides us with a lot of information regarding\ncontact formations as well as geometric information about objects during any\ninteraction. With this motivation, vision-based tactile sensors are being\nwidely used for various robotic perception and control tasks. In this paper, we\npresent a method for interactive perception using vision-based tactile sensors\nfor a part mating task, where a robot can use tactile sensors and a feedback\nmechanism using a particle filter to incrementally improve its estimate of\nobjects (pegs and holes) that fit together. To do this, we first train a deep\nneural network that makes use of tactile images to predict the probabilistic\ncorrespondence between arbitrarily shaped objects that fit together. The\ntrained model is used to design a particle filter which is used twofold. First,\ngiven one partial (or non-unique) observation of the hole, it incrementally\nimproves the estimate of the correct peg by sampling more tactile observations.\nSecond, it selects the next action for the robot to sample the next touch (and\nthus image) which results in maximum uncertainty reduction to minimize the\nnumber of interactions during the perception task. We evaluate our method on\nseveral part-mating tasks with novel objects using a robot equipped with a\nvision-based tactile sensor. We also show the efficiency of the proposed action\nselection method against a naive method. See supplementary video at\nhttps://www.youtube.com/watch?v=jMVBg_e3gLw .\n","authors":["Kei Ota","Devesh K. Jha","Hsiao-Yu Tung","Joshua B. Tenenbaum"],"pdf_url":"https://arxiv.org/pdf/2303.06034v2.pdf","comment":"Accepted at RSS2023"},{"id":"http://arxiv.org/abs/2306.02869v1","updated":"2023-06-05T13:43:34Z","published":"2023-06-05T13:43:34Z","title":"Data-Driven Regret Balancing for Online Model Selection in Bandits","summary":"  We consider model selection for sequential decision making in stochastic\nenvironments with bandit feedback, where a meta-learner has at its disposal a\npool of base learners, and decides on the fly which action to take based on the\npolicies recommended by each base learner. Model selection is performed by\nregret balancing but, unlike the recent literature on this subject, we do not\nassume any prior knowledge about the base learners like candidate regret\nguarantees; instead, we uncover these quantities in a data-driven manner. The\nmeta-learner is therefore able to leverage the realized regret incurred by each\nbase learner for the learning environment at hand (as opposed to the expected\nregret), and single out the best such regret. We design two model selection\nalgorithms operating with this more ambitious notion of regret and, besides\nproving model selection guarantees via regret balancing, we experimentally\ndemonstrate the compelling practical benefits of dealing with actual regrets\ninstead of candidate regret bounds.\n","authors":["Aldo Pacchiano","Christoph Dann","Claudio Gentile"],"pdf_url":"https://arxiv.org/pdf/2306.02869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02866v1","updated":"2023-06-05T13:40:54Z","published":"2023-06-05T13:40:54Z","title":"Learning Probabilistic Symmetrization for Architecture Agnostic\n  Equivariance","summary":"  We present a novel framework to overcome the limitations of equivariant\narchitectures in learning functions with group symmetries. In contrary to\nequivariant architectures, we use an arbitrary base model (such as an MLP or a\ntransformer) and symmetrize it to be equivariant to the given group by\nemploying a small equivariant network that parameterizes the probabilistic\ndistribution underlying the symmetrization. The distribution is end-to-end\ntrained with the base model which can maximize performance while reducing\nsample complexity of symmetrization. We show that this approach ensures not\nonly equivariance to given group but also universal approximation capability in\nexpectation. We implement our method on a simple patch-based transformer that\ncan be initialized from pretrained vision transformers, and test it for a wide\nrange of symmetry groups including permutation and Euclidean groups and their\ncombinations. Empirical tests show competitive results against tailored\nequivariant architectures, suggesting the potential for learning equivariant\nfunctions for diverse groups using a non-equivariant universal base\narchitecture. We further show evidence of enhanced learning in symmetric\nmodalities, like graphs, when pretrained from non-symmetric modalities, like\nvision. Our implementation will be open-sourced at\nhttps://github.com/jw9730/lps.\n","authors":["Jinwoo Kim","Tien Dat Nguyen","Ayhan Suleymanzade","Hyeokjun An","Seunghoon Hong"],"pdf_url":"https://arxiv.org/pdf/2306.02866v1.pdf","comment":"25 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.02865v1","updated":"2023-06-05T13:38:14Z","published":"2023-06-05T13:38:14Z","title":"Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy\n  Actor-Critic","summary":"  Learning high-quality Q-value functions plays a key role in the success of\nmany modern off-policy deep reinforcement learning (RL) algorithms. Previous\nworks focus on addressing the value overestimation issue, an outcome of\nadopting function approximators and off-policy learning. Deviating from the\ncommon viewpoint, we observe that Q-values are indeed underestimated in the\nlatter stage of the RL training process, primarily related to the use of\ninferior actions from the current policy in Bellman updates as compared to the\nmore optimal action samples in the replay buffer. We hypothesize that this\nlong-neglected phenomenon potentially hinders policy learning and reduces\nsample efficiency. Our insight to address this issue is to incorporate\nsufficient exploitation of past successes while maintaining exploration\noptimism. We propose the Blended Exploitation and Exploration (BEE) operator, a\nsimple yet effective approach that updates Q-value using both historical\nbest-performing actions and the current policy. The instantiations of our\nmethod in both model-free and model-based settings outperform state-of-the-art\nmethods in various continuous control tasks and achieve strong performance in\nfailure-prone scenarios and real-world robot tasks.\n","authors":["Tianying Ji","Yu Luo","Fuchun Sun","Xianyuan Zhan","Jianwei Zhang","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2306.02865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.00755v3","updated":"2023-06-05T13:32:48Z","published":"2022-08-01T11:33:12Z","title":"Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step\n  Q-learning: A Novel Correction Approach","summary":"  Compared to on-policy counterparts, off-policy model-free deep reinforcement\nlearning can improve data efficiency by repeatedly using the previously\ngathered data. However, off-policy learning becomes challenging when the\ndiscrepancy between the underlying distributions of the agent's policy and\ncollected data increases. Although the well-studied importance sampling and\noff-policy policy gradient techniques were proposed to compensate for this\ndiscrepancy, they usually require a collection of long trajectories and induce\nadditional problems such as vanishing/exploding gradients or discarding many\nuseful experiences, which eventually increases the computational complexity.\nMoreover, their generalization to either continuous action domains or policies\napproximated by deterministic deep neural networks is strictly limited. To\novercome these limitations, we introduce a novel policy similarity measure to\nmitigate the effects of such discrepancy in continuous control. Our method\noffers an adequate single-step off-policy correction that is applicable to\ndeterministic policy networks. Theoretical and empirical studies demonstrate\nthat it can achieve a \"safe\" off-policy learning and substantially improve the\nstate-of-the-art by attaining higher returns in fewer steps than the competing\nmethods through an effective schedule of the learning rate in Q-learning and\npolicy optimization.\n","authors":["Baturay Saglam","Dogan C. Cicek","Furkan B. Mutlu","Suleyman S. Kozat"],"pdf_url":"https://arxiv.org/pdf/2208.00755v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15079v2","updated":"2023-06-05T13:32:19Z","published":"2022-11-28T05:53:09Z","title":"Lightweight and Flexible Deep Equilibrium Learning for CSI Feedback in\n  FDD Massive MIMO","summary":"  In frequency-division duplexing (FDD) massive multiple-input multiple-output\n(MIMO) systems, downlink channel state information (CSI) needs to be sent back\nto the base station (BS) by the users, which causes prohibitive feedback\noverhead. In this paper, we propose a lightweight and flexible deep\nlearning-based CSI feedback approach by capitalizing on deep equilibrium\nmodels. Different from existing deep learning-based methods that stack multiple\nexplicit layers, we propose an implicit equilibrium block to mimic the behavior\nof an infinite-depth neural network. In particular, the implicit equilibrium\nblock is defined by a fixed-point iteration and the trainable parameters in\ndifferent iterations are shared, which results in a lightweight model.\nFurthermore, the number of forward iterations can be adjusted according to\nusers' computation capability, enabling a flexible accuracy-efficiency\ntrade-off. Simulation results will show that the proposed design obtains a\ncomparable performance as the benchmarks but with much-reduced complexity and\npermits an accuracy-efficiency trade-off at runtime.\n","authors":["Yifan Ma","Wentao Yu","Xianghao Yu","Jun Zhang","Shenghui Song","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2211.15079v2.pdf","comment":"submitted to IEEE for possible publication"},{"id":"http://arxiv.org/abs/2306.02859v1","updated":"2023-06-05T13:24:03Z","published":"2023-06-05T13:24:03Z","title":"Local Boosting for Weakly-Supervised Learning","summary":"  Boosting is a commonly used technique to enhance the performance of a set of\nbase models by combining them into a strong ensemble model. Though widely\nadopted, boosting is typically used in supervised learning where the data is\nlabeled accurately. However, in weakly supervised learning, where most of the\ndata is labeled through weak and noisy sources, it remains nontrivial to design\neffective boosting approaches. In this work, we show that the standard\nimplementation of the convex combination of base learners can hardly work due\nto the presence of noisy labels. Instead, we propose $\\textit{LocalBoost}$, a\nnovel framework for weakly-supervised boosting. LocalBoost iteratively boosts\nthe ensemble model from two dimensions, i.e., intra-source and inter-source.\nThe intra-source boosting introduces locality to the base learners and enables\neach base learner to focus on a particular feature regime by training new base\nlearners on granularity-varying error regions. For the inter-source boosting,\nwe leverage a conditional function to indicate the weak source where the sample\nis more likely to appear. To account for the weak labels, we further design an\nestimate-then-modify approach to compute the model weights. Experiments on\nseven datasets show that our method significantly outperforms vanilla boosting\nmethods and other weakly-supervised methods.\n","authors":["Rongzhi Zhang","Yue Yu","Jiaming Shen","Xiquan Cui","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.02859v1.pdf","comment":"Accepted by KDD 2023 Research Track"},{"id":"http://arxiv.org/abs/2211.12507v3","updated":"2023-06-05T13:22:12Z","published":"2022-11-22T03:23:40Z","title":"OpenFE: Automated Feature Generation with Expert-level Performance","summary":"  The goal of automated feature generation is to liberate machine learning\nexperts from the laborious task of manual feature generation, which is crucial\nfor improving the learning performance of tabular data. The major challenge in\nautomated feature generation is to efficiently and accurately identify\neffective features from a vast pool of candidate features. In this paper, we\npresent OpenFE, an automated feature generation tool that provides competitive\nresults against machine learning experts. OpenFE achieves high efficiency and\naccuracy with two components: 1) a novel feature boosting method for accurately\nevaluating the incremental performance of candidate features and 2) a two-stage\npruning algorithm that performs feature pruning in a coarse-to-fine manner.\nExtensive experiments on ten benchmark datasets show that OpenFE outperforms\nexisting baseline methods by a large margin. We further evaluate OpenFE in two\nKaggle competitions with thousands of data science teams participating. In the\ntwo competitions, features generated by OpenFE with a simple baseline model can\nbeat 99.3% and 99.6% data science teams respectively. In addition to the\nempirical results, we provide a theoretical perspective to show that feature\ngeneration can be beneficial in a simple yet representative setting. The code\nis available at https://github.com/ZhangTP1996/OpenFE.\n","authors":["Tianping Zhang","Zheyu Zhang","Zhiyuan Fan","Haoyan Luo","Fengyuan Liu","Qian Liu","Wei Cao","Jian Li"],"pdf_url":"https://arxiv.org/pdf/2211.12507v3.pdf","comment":"22 pages, 3 figures, accepted by ICML2023"},{"id":"http://arxiv.org/abs/2305.16044v3","updated":"2023-06-05T13:22:08Z","published":"2023-05-25T13:21:26Z","title":"Exploiting Noise as a Resource for Computation and Learning in Spiking\n  Neural Networks","summary":"  Networks of spiking neurons underpin the extraordinary information-processing\ncapabilities of the brain and have emerged as pillar models in neuromorphic\nintelligence. Despite extensive research on spiking neural networks (SNNs),\nmost are established on deterministic models. Integrating noise into SNNs leads\nto biophysically more realistic neural dynamics and may benefit model\nperformance. This work presents the noisy spiking neural network (NSNN) and the\nnoise-driven learning rule (NDL) by introducing a spiking neuron model\nincorporating noisy neuronal dynamics. Our approach shows how noise may act as\na resource for computation and learning and theoretically provides a framework\nfor general SNNs. Moreover, NDL provides an insightful biological rationale for\nsurrogate gradients. By incorporating various SNN architectures and algorithms,\nwe show that our approach exhibits competitive performance and improved\nrobustness against challenging perturbations than deterministic SNNs.\nAdditionally, we demonstrate the utility of the NSNN model for neural coding\nstudies. Overall, NSNN offers a powerful, flexible, and easy-to-use tool for\nmachine learning practitioners and computational neuroscience researchers.\n","authors":["Gehua Ma","Rui Yan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2305.16044v3.pdf","comment":"Updated the code link; fixed the bug in the BBL file generated with\n  bibliography management program"},{"id":"http://arxiv.org/abs/2201.11989v6","updated":"2023-06-05T13:20:53Z","published":"2022-01-28T08:52:01Z","title":"Existence and Estimation of Critical Batch Size for Training Generative\n  Adversarial Networks with Two Time-Scale Update Rule","summary":"  Previous results have shown that a two time-scale update rule (TTUR) using\ndifferent learning rates, such as different constant rates or different\ndecaying rates, is useful for training generative adversarial networks (GANs)\nin theory and in practice. Moreover, not only the learning rate but also the\nbatch size is important for training GANs with TTURs and they both affect the\nnumber of steps needed for training. This paper studies the relationship\nbetween batch size and the number of steps needed for training GANs with TTURs\nbased on constant learning rates. We theoretically show that, for a TTUR with\nconstant learning rates, the number of steps needed to find stationary points\nof the loss functions of both the discriminator and generator decreases as the\nbatch size increases and that there exists a critical batch size minimizing the\nstochastic first-order oracle (SFO) complexity. Then, we use the Fr'echet\ninception distance (FID) as the performance measure for training and provide\nnumerical results indicating that the number of steps needed to achieve a low\nFID score decreases as the batch size increases and that the SFO complexity\nincreases once the batch size exceeds the measured critical batch size.\nMoreover, we show that measured critical batch sizes are close to the sizes\nestimated from our theoretical results.\n","authors":["Naoki Sato","Hideaki Iiduka"],"pdf_url":"https://arxiv.org/pdf/2201.11989v6.pdf","comment":"Accepted at the 40th International Conference on Machine Learning\n  (ICML 2023)"},{"id":"http://arxiv.org/abs/2203.00922v2","updated":"2023-06-05T13:15:00Z","published":"2022-03-02T08:09:57Z","title":"Canonical foliations of neural networks: application to robustness","summary":"  Deep learning models are known to be vulnerable to adversarial attacks.\nAdversarial learning is therefore becoming a crucial task. We propose a new\nvision on neural network robustness using Riemannian geometry and foliation\ntheory. The idea is illustrated by creating a new adversarial attack that takes\ninto account the curvature of the data space. This new adversarial attack\ncalled the two-step spectral attack is a piece-wise linear approximation of a\ngeodesic in the data space. The data space is treated as a (degenerate)\nRiemannian manifold equipped with the pullback of the Fisher Information Metric\n(FIM) of the neural network. In most cases, this metric is only semi-definite\nand its kernel becomes a central object to study. A canonical foliation is\nderived from this kernel. The curvature of transverse leaves gives the\nappropriate correction to get a two-step approximation of the geodesic and\nhence a new efficient adversarial attack. The method is first illustrated on a\n2D toy example in order to visualize the neural network foliation and the\ncorresponding attacks. Next, experiments on the MNIST dataset with the proposed\ntechnique and a state of the art attack presented in Zhao et al. (2019) are\nreported. The result show that the proposed attack is more efficient at all\nlevels of available budget for the attack (norm of the attack), confirming that\nthe curvature of the transverse neural network FIM foliation plays an important\nrole in the robustness of neural networks.\n","authors":["Eliot Tron","Nicolas Couellan","Stéphane Puechmorel"],"pdf_url":"https://arxiv.org/pdf/2203.00922v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04837v3","updated":"2023-06-05T13:12:04Z","published":"2023-05-08T16:34:04Z","title":"Scalable Optimal Margin Distribution Machine","summary":"  Optimal margin Distribution Machine (ODM) is a newly proposed statistical\nlearning framework rooting in the novel margin theory, which demonstrates\nbetter generalization performance than the traditional large margin based\ncounterparts. Nonetheless, it suffers from the ubiquitous scalability problem\nregarding both computation time and memory as other kernel methods. This paper\nproposes a scalable ODM, which can achieve nearly ten times speedup compared to\nthe original ODM training method. For nonlinear kernels, we propose a novel\ndistribution-aware partition method to make the local ODM trained on each\npartition be close and converge fast to the global one. When linear kernel is\napplied, we extend a communication efficient SVRG method to accelerate the\ntraining further. Extensive empirical studies validate that our proposed method\nis highly computational efficient and almost never worsen the generalization.\n","authors":["Yilin Wang","Nan Cao","Teng Zhang","Xuanhua Shi","Hai Jin"],"pdf_url":"https://arxiv.org/pdf/2305.04837v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02928v3","updated":"2023-06-05T13:10:22Z","published":"2022-03-06T10:14:09Z","title":"Evaluation of Interpretability Methods and Perturbation Artifacts in\n  Deep Neural Networks","summary":"  Despite excellent performance of deep neural networks (DNNs) in image\nclassification, detection, and prediction, characterizing how DNNs make a given\ndecision remains an open problem, resulting in a number of interpretability\nmethods. Post-hoc interpretability methods primarily aim to quantify the\nimportance of input features with respect to the class probabilities. However,\ndue to the lack of ground truth and the existence of interpretability methods\nwith diverse operating characteristics, evaluating these methods is a crucial\nchallenge. A popular approach to evaluate interpretability methods is to\nperturb input features deemed important for a given prediction and observe the\ndecrease in accuracy. However, perturbation itself may introduce artifacts. We\npropose a method for estimating the impact of such artifacts on the fidelity\nestimation by utilizing model accuracy curves from perturbing input features\naccording to the Most Import First (MIF) and Least Import First (LIF) orders.\nUsing the ResNet-50 trained on the ImageNet, we demonstrate the proposed\nfidelity estimation of four popular post-hoc interpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2203.02928v3.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2305.15877v2","updated":"2023-06-05T13:05:59Z","published":"2023-05-25T09:18:45Z","title":"Exponential Smoothing for Off-Policy Learning","summary":"  Off-policy learning (OPL) aims at finding improved policies from logged\nbandit data, often by minimizing the inverse propensity scoring (IPS) estimator\nof the risk. In this work, we investigate a smooth regularization for IPS, for\nwhich we derive a two-sided PAC-Bayes generalization bound. The bound is\ntractable, scalable, interpretable and provides learning certificates. In\nparticular, it is also valid for standard IPS without making the assumption\nthat the importance weights are bounded. We demonstrate the relevance of our\napproach and its favorable performance through a set of learning tasks. Since\nour bound holds for standard IPS, we are able to provide insight into when\nregularizing IPS is useful. Namely, we identify cases where regularization\nmight not be needed. This goes against the belief that, in practice, clipped\nIPS often enjoys favorable performance than standard IPS in OPL.\n","authors":["Imad Aouali","Victor-Emmanuel Brunel","David Rohde","Anna Korba"],"pdf_url":"https://arxiv.org/pdf/2305.15877v2.pdf","comment":"ICML 2023 (Oral and Poster)"},{"id":"http://arxiv.org/abs/2306.02848v1","updated":"2023-06-05T12:58:13Z","published":"2023-06-05T12:58:13Z","title":"HireVAE: An Online and Adaptive Factor Model Based on Hierarchical and\n  Regime-Switch VAE","summary":"  Factor model is a fundamental investment tool in quantitative investment,\nwhich can be empowered by deep learning to become more flexible and efficient\nin practical complicated investing situations. However, it is still an open\nquestion to build a factor model that can conduct stock prediction in an online\nand adaptive setting, where the model can adapt itself to match the current\nmarket regime identified based on only point-in-time market information. To\ntackle this problem, we propose the first deep learning based online and\nadaptive factor model, HireVAE, at the core of which is a hierarchical latent\nspace that embeds the underlying relationship between the market situation and\nstock-wise latent factors, so that HireVAE can effectively estimate useful\nlatent factors given only historical market information and subsequently\npredict accurate stock returns. Across four commonly used real stock market\nbenchmarks, the proposed HireVAE demonstrate superior performance in terms of\nactive returns over previous methods, verifying the potential of such online\nand adaptive factor model.\n","authors":["Zikai Wei","Anyi Rao","Bo Dai","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2306.02848v1.pdf","comment":"Accepted to IJCAI 2023"},{"id":"http://arxiv.org/abs/2209.05135v3","updated":"2023-06-05T12:56:14Z","published":"2022-09-12T10:42:26Z","title":"Signs of Language: Embodied Sign Language Fingerspelling Acquisition\n  from Demonstrations for Human-Robot Interaction","summary":"  Learning fine-grained movements is a challenging topic in robotics,\nparticularly in the context of robotic hands. One specific instance of this\nchallenge is the acquisition of fingerspelling sign language in robots. In this\npaper, we propose an approach for learning dexterous motor imitation from video\nexamples without additional information. To achieve this, we first build a URDF\nmodel of a robotic hand with a single actuator for each joint. We then leverage\npre-trained deep vision models to extract the 3D pose of the hand from RGB\nvideos. Next, using state-of-the-art reinforcement learning algorithms for\nmotion imitation (namely, proximal policy optimization and soft actor-critic),\nwe train a policy to reproduce the movement extracted from the demonstrations.\nWe identify the optimal set of hyperparameters for imitation based on a\nreference motion. Finally, we demonstrate the generalizability of our approach\nby testing it on six different tasks, corresponding to fingerspelled letters.\nOur results show that our approach is able to successfully imitate these\nfine-grained movements without additional information, highlighting its\npotential for real-world applications in robotics.\n","authors":["Federico Tavella","Aphrodite Galata","Angelo Cangelosi"],"pdf_url":"https://arxiv.org/pdf/2209.05135v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.15821v2","updated":"2023-06-05T12:50:32Z","published":"2023-03-28T08:46:03Z","title":"Scaling Multi-Objective Security Games Provably via Space Discretization\n  Based Evolutionary Search","summary":"  In the field of security, multi-objective security games (MOSGs) allow\ndefenders to simultaneously protect targets from multiple heterogeneous\nattackers. MOSGs aim to simultaneously maximize all the heterogeneous payoffs,\ne.g., life, money, and crime rate, without merging heterogeneous attackers. In\nreal-world scenarios, the number of heterogeneous attackers and targets to be\nprotected may exceed the capability of most existing state-of-the-art methods,\ni.e., MOSGs are limited by the issue of scalability. To this end, this paper\nproposes a general framework called SDES based on many-objective evolutionary\nsearch to scale up MOSGs to large-scale targets and heterogeneous attackers.\nSDES consists of four consecutive key components, i.e., discretization,\noptimization, evaluation, and refinement. Specifically, SDES first discretizes\nthe originally high-dimensional continuous solution space to the\nlow-dimensional discrete one by the maximal indifference property in game\ntheory. This property helps evolutionary algorithms (EAs) bypass the\nhigh-dimensional step function and ensure a well-convergent Pareto front. Then,\na many-objective EA is used for optimization in the low-dimensional discrete\nsolution space to obtain a well-spaced Pareto front. To evaluate solutions,\nSDES restores solutions back to the original space via greedily optimizing a\nnovel divergence measurement. Finally, the refinement in SDES boosts the\noptimization performance with acceptable cost. Theoretically, we prove the\noptimization consistency and convergence of SDES. Experiment results show that\nSDES is the first linear-time MOSG algorithm for both large-scale attackers and\ntargets. SDES is able to solve up to 20 attackers and 100 targets MOSG\nproblems, while the state-of-the-art (SOTA) methods can only solve up to 8\nattackers and 25 targets ones. Ablation study verifies the necessity of all\ncomponents in SDES.\n","authors":["Yu-Peng Wu","Hong Qian","Rong-Jun Qin","Yi Chen","Aimin Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.15821v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02840v1","updated":"2023-06-05T12:44:18Z","published":"2023-06-05T12:44:18Z","title":"Learning to Substitute Spans towards Improving Compositional\n  Generalization","summary":"  Despite the rising prevalence of neural sequence models, recent empirical\nevidences suggest their deficiency in compositional generalization. One of the\ncurrent de-facto solutions to this problem is compositional data augmentation,\naiming to incur additional compositional inductive bias. Nonetheless, the\nimprovement offered by existing handcrafted augmentation strategies is limited\nwhen successful systematic generalization of neural sequence models requires\nmulti-grained compositional bias (i.e., not limited to either lexical or\nstructural biases only) or differentiation of training sequences in an\nimbalanced difficulty distribution. To address the two challenges, we first\npropose a novel compositional augmentation strategy dubbed \\textbf{Span}\n\\textbf{Sub}stitution (SpanSub) that enables multi-grained composition of\nsubstantial substructures in the whole training set. Over and above that, we\nintroduce the \\textbf{L}earning \\textbf{to} \\textbf{S}ubstitute \\textbf{S}pan\n(L2S2) framework which empowers the learning of span substitution probabilities\nin SpanSub in an end-to-end manner by maximizing the loss of neural sequence\nmodels, so as to outweigh those challenging compositions with elusive concepts\nand novel surroundings. Our empirical results on three standard compositional\ngeneralization benchmarks, including SCAN, COGS and GeoQuery (with an\nimprovement of at most 66.5\\%, 10.3\\%, 1.2\\%, respectively), demonstrate the\nsuperiority of SpanSub, %the learning framework L2S2 and their combination.\n","authors":["Zhaoyi Li","Ying Wei","Defu Lian"],"pdf_url":"https://arxiv.org/pdf/2306.02840v1.pdf","comment":"accepted by ACL 2023"},{"id":"http://arxiv.org/abs/2306.02834v1","updated":"2023-06-05T12:29:34Z","published":"2023-06-05T12:29:34Z","title":"Computational Complexity of Detecting Proximity to Losslessly\n  Compressible Neural Network Parameters","summary":"  To better understand complexity in neural networks, we theoretically\ninvestigate the idealised phenomenon of lossless network compressibility,\nwhereby an identical function can be implemented with a smaller network. We\ngive an efficient formal algorithm for optimal lossless compression in the\nsetting of single-hidden-layer hyperbolic tangent networks. To measure lossless\ncompressibility, we define the rank of a parameter as the minimum number of\nhidden units required to implement the same function. Losslessly compressible\nparameters are atypical, but their existence has implications for nearby\nparameters. We define the proximate rank of a parameter as the rank of the most\ncompressible parameter within a small $L^\\infty$ neighbourhood. Unfortunately,\ndetecting nearby losslessly compressible parameters is not so easy: we show\nthat bounding the proximate rank is an NP-complete problem, using a reduction\nfrom Boolean satisfiability via a geometric problem involving covering points\nin the plane with small squares. These results underscore the computational\ncomplexity of measuring neural network complexity, laying a foundation for\nfuture theoretical and empirical work in this direction.\n","authors":["Matthew Farrugia-Roberts"],"pdf_url":"https://arxiv.org/pdf/2306.02834v1.pdf","comment":"9 pages paper, 31 pages total, 9 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.02833v1","updated":"2023-06-05T12:29:13Z","published":"2023-06-05T12:29:13Z","title":"The $L^\\infty$ Learnability of Reproducing Kernel Hilbert Spaces","summary":"  In this work, we analyze the learnability of reproducing kernel Hilbert\nspaces (RKHS) under the $L^\\infty$ norm, which is critical for understanding\nthe performance of kernel methods and random feature models in safety- and\nsecurity-critical applications. Specifically, we relate the $L^\\infty$\nlearnability of a RKHS to the spectrum decay of the associate kernel and both\nlower bounds and upper bounds of the sample complexity are established. In\nparticular, for dot-product kernels on the sphere, we identify conditions when\nthe $L^\\infty$ learning can be achieved with polynomial samples. Let $d$ denote\nthe input dimension and assume the kernel spectrum roughly decays as\n$\\lambda_k\\sim k^{-1-\\beta}$ with $\\beta>0$. We prove that if $\\beta$ is\nindependent of the input dimension $d$, then functions in the RKHS can be\nlearned efficiently under the $L^\\infty$ norm, i.e., the sample complexity\ndepends polynomially on $d$. In contrast, if $\\beta=1/\\mathrm{poly}(d)$, then\nthe $L^\\infty$ learning requires exponentially many samples.\n","authors":["Hongrui Chen","Jihao Long","Lei Wu"],"pdf_url":"https://arxiv.org/pdf/2306.02833v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2306.02831v1","updated":"2023-06-05T12:27:22Z","published":"2023-06-05T12:27:22Z","title":"MM-DAG: Multi-task DAG Learning for Multi-modal Data -- with Application\n  for Traffic Congestion Analysis","summary":"  This paper proposes to learn Multi-task, Multi-modal Direct Acyclic Graphs\n(MM-DAGs), which are commonly observed in complex systems, e.g., traffic,\nmanufacturing, and weather systems, whose variables are multi-modal with\nscalars, vectors, and functions. This paper takes the traffic congestion\nanalysis as a concrete case, where a traffic intersection is usually regarded\nas a DAG. In a road network of multiple intersections, different intersections\ncan only have some overlapping and distinct variables observed. For example, a\nsignalized intersection has traffic light-related variables, whereas\nunsignalized ones do not. This encourages the multi-task design: with each DAG\nas a task, the MM-DAG tries to learn the multiple DAGs jointly so that their\nconsensus and consistency are maximized. To this end, we innovatively propose a\nmulti-modal regression for linear causal relationship description of different\nvariables. Then we develop a novel Causality Difference (CD) measure and its\ndifferentiable approximator. Compared with existing SOTA measures, CD can\npenalize the causal structural difference among DAGs with distinct nodes and\ncan better consider the uncertainty of causal orders. We rigidly prove our\ndesign's topological interpretation and consistency properties. We conduct\nthorough simulations and one case study to show the effectiveness of our\nMM-DAG. The code is available under https://github.com/Lantian72/MM-DAG\n","authors":["Tian Lan","Ziyue Li","Zhishuai Li","Lei Bai","Man Li","Fugee Tsung","Wolfgang Ketter","Rui Zhao","Chen Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.02831v1.pdf","comment":"Accepted in SIGKDD 2023"},{"id":"http://arxiv.org/abs/2306.02826v1","updated":"2023-06-05T12:22:46Z","published":"2023-06-05T12:22:46Z","title":"Near-Optimal Quantum Coreset Construction Algorithms for Clustering","summary":"  $k$-Clustering in $\\mathbb{R}^d$ (e.g., $k$-median and $k$-means) is a\nfundamental machine learning problem. While near-linear time approximation\nalgorithms were known in the classical setting for a dataset with cardinality\n$n$, it remains open to find sublinear-time quantum algorithms. We give quantum\nalgorithms that find coresets for $k$-clustering in $\\mathbb{R}^d$ with\n$\\tilde{O}(\\sqrt{nk}d^{3/2})$ query complexity. Our coreset reduces the input\nsize from $n$ to $\\mathrm{poly}(k\\epsilon^{-1}d)$, so that existing\n$\\alpha$-approximation algorithms for clustering can run on top of it and yield\n$(1 + \\epsilon)\\alpha$-approximation. This eventually yields a quadratic\nspeedup for various $k$-clustering approximation algorithms. We complement our\nalgorithm with a nearly matching lower bound, that any quantum algorithm must\nmake $\\Omega(\\sqrt{nk})$ queries in order to achieve even $O(1)$-approximation\nfor $k$-clustering.\n","authors":["Yecheng Xue","Xiaoyu Chen","Tongyang Li","Shaofeng H. -C. Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.02826v1.pdf","comment":"Comments: 32 pages, 0 figures, 1 table. To appear in the Fortieth\n  International Conference on Machine Learning (ICML 2023)"},{"id":"http://arxiv.org/abs/2211.01842v2","updated":"2023-06-05T12:22:19Z","published":"2022-11-03T14:23:00Z","title":"Construction of Hierarchical Neural Architecture Search Spaces based on\n  Context-free Grammars","summary":"  The discovery of neural architectures from simple building blocks is a\nlong-standing goal of Neural Architecture Search (NAS). Hierarchical search\nspaces are a promising step towards this goal but lack a unifying search space\ndesign framework and typically only search over some limited aspect of\narchitectures. In this work, we introduce a unifying search space design\nframework based on context-free grammars that can naturally and compactly\ngenerate expressive hierarchical search spaces that are 100s of orders of\nmagnitude larger than common spaces from the literature. By enhancing and using\ntheir properties, we effectively enable search over the complete architecture\nand can foster regularity. Further, we propose an efficient hierarchical kernel\ndesign for a Bayesian Optimization search strategy to efficiently search over\nsuch huge spaces. We demonstrate the versatility of our search space design\nframework and show that our search strategy can be superior to existing NAS\napproaches. Code is available at\nhttps://github.com/automl/hierarchical_nas_construction.\n","authors":["Simon Schrodi","Danny Stoll","Binxin Ru","Rhea Sukthanker","Thomas Brox","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2211.01842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02824v1","updated":"2023-06-05T12:21:42Z","published":"2023-06-05T12:21:42Z","title":"COMET: Learning Cardinality Constrained Mixture of Experts with Trees\n  and Local Search","summary":"  The sparse Mixture-of-Experts (Sparse-MoE) framework efficiently scales up\nmodel capacity in various domains, such as natural language processing and\nvision. Sparse-MoEs select a subset of the \"experts\" (thus, only a portion of\nthe overall network) for each input sample using a sparse, trainable gate.\nExisting sparse gates are prone to convergence and performance issues when\ntraining with first-order optimization methods. In this paper, we introduce two\nimprovements to current MoE approaches. First, we propose a new sparse gate:\nCOMET, which relies on a novel tree-based mechanism. COMET is differentiable,\ncan exploit sparsity to speed up computation, and outperforms state-of-the-art\ngates. Second, due to the challenging combinatorial nature of sparse expert\nselection, first-order methods are typically prone to low-quality solutions. To\ndeal with this challenge, we propose a novel, permutation-based local search\nmethod that can complement first-order methods in training any sparse gate,\ne.g., Hash routing, Top-k, DSelect-k, and COMET. We show that local search can\nhelp networks escape bad initializations or solutions. We performed large-scale\nexperiments on various domains, including recommender systems, vision, and\nnatural language processing. On standard vision and recommender systems\nbenchmarks, COMET+ (COMET with local search) achieves up to 13% improvement in\nROC AUC over popular gates, e.g., Hash routing and Top-k, and up to 9% over\nprior differentiable gates e.g., DSelect-k. When Top-k and Hash gates are\ncombined with local search, we see up to $100\\times$ reduction in the budget\nneeded for hyperparameter tuning. Moreover, for language modeling, our approach\nimproves over the state-of-the-art MoEBERT model for distilling BERT on 5/7\nGLUE benchmarks as well as SQuAD dataset.\n","authors":["Shibal Ibrahim","Wenyu Chen","Hussein Hazimeh","Natalia Ponomareva","Zhe Zhao","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2306.02824v1.pdf","comment":"Accepted in KDD 2023"},{"id":"http://arxiv.org/abs/2306.02822v1","updated":"2023-06-05T12:20:40Z","published":"2023-06-05T12:20:40Z","title":"Discovering Dynamic Causal Space for DAG Structure Learning","summary":"  Discovering causal structure from purely observational data (i.e., causal\ndiscovery), aiming to identify causal relationships among variables, is a\nfundamental task in machine learning. The recent invention of differentiable\nscore-based DAG learners is a crucial enabler, which reframes the combinatorial\noptimization problem into a differentiable optimization with a DAG constraint\nover directed graph space. Despite their great success, these cutting-edge DAG\nlearners incorporate DAG-ness independent score functions to evaluate the\ndirected graph candidates, lacking in considering graph structure. As a result,\nmeasuring the data fitness alone regardless of DAG-ness inevitably leads to\ndiscovering suboptimal DAGs and model vulnerabilities. Towards this end, we\npropose a dynamic causal space for DAG structure learning, coined CASPER, that\nintegrates the graph structure into the score function as a new measure in the\ncausal space to faithfully reflect the causal distance between estimated and\nground truth DAG. CASPER revises the learning process as well as enhances the\nDAG structure learning via adaptive attention to DAG-ness. Grounded by\nempirical visualization, CASPER, as a space, satisfies a series of desired\nproperties, such as structure awareness and noise robustness. Extensive\nexperiments on both synthetic and real-world datasets clearly validate the\nsuperiority of our CASPER over the state-of-the-art causal discovery methods in\nterms of accuracy and robustness.\n","authors":["Fangfu Liu","Wenchang Ma","An Zhang","Xiang Wang","Yueqi Duan","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2306.02822v1.pdf","comment":"Accepted by KDD 2023"},{"id":"http://arxiv.org/abs/2306.02816v1","updated":"2023-06-05T12:12:59Z","published":"2023-06-05T12:12:59Z","title":"MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale\n  Training of Physics-informed Neural Networks","summary":"  Physics-informed Neural Networks (PINNs) have recently achieved remarkable\nprogress in solving Partial Differential Equations (PDEs) in various fields by\nminimizing a weighted sum of PDE loss and boundary loss. However, there are\nseveral critical challenges in the training of PINNs, including the lack of\ntheoretical frameworks and the imbalance between PDE loss and boundary loss. In\nthis paper, we present an analysis of second-order non-homogeneous PDEs, which\nare classified into three categories and applicable to various common problems.\nWe also characterize the connections between the training loss and actual\nerror, guaranteeing convergence under mild conditions. The theoretical analysis\ninspires us to further propose MultiAdam, a scale-invariant optimizer that\nleverages gradient momentum to parameter-wisely balance the loss terms.\nExtensive experiment results on multiple problems from different physical\ndomains demonstrate that our MultiAdam solver can improve the predictive\naccuracy by 1-2 orders of magnitude compared with strong baselines.\n","authors":["Jiachen Yao","Chang Su","Zhongkai Hao","Songming Liu","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.02816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02815v1","updated":"2023-06-05T12:12:23Z","published":"2023-06-05T12:12:23Z","title":"Transformer-Based UNet with Multi-Headed Cross-Attention Skip\n  Connections to Eliminate Artifacts in Scanned Documents","summary":"  The extraction of text in high quality is essential for text-based document\nanalysis tasks like Document Classification or Named Entity Recognition.\nUnfortunately, this is not always ensured, as poor scan quality and the\nresulting artifacts lead to errors in the Optical Character Recognition (OCR)\nprocess. Current approaches using Convolutional Neural Networks show promising\nresults for background removal tasks but fail correcting artifacts like\npixelation or compression errors. For general images, Transformer backbones are\ngetting integrated more frequently in well-known neural network structures for\ndenoising tasks. In this work, a modified UNet structure using a Swin\nTransformer backbone is presented to remove typical artifacts in scanned\ndocuments. Multi-headed cross-attention skip connections are used to more\nselectively learn features in respective levels of abstraction. The performance\nof this approach is examined regarding compression errors, pixelation and\nrandom noise. An improvement in text extraction quality with a reduced error\nrate of up to 53.9% on the synthetic data is archived. The pretrained\nbase-model can be easily adapted to new artifacts. The cross-attention skip\nconnections allow to integrate textual information extracted from the encoder\nor in form of commands to more selectively control the models outcome. The\nlatter is shown by means of an example application.\n","authors":["David Kreuzer","Michael Munz"],"pdf_url":"https://arxiv.org/pdf/2306.02815v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09034v3","updated":"2023-06-05T12:02:49Z","published":"2022-12-18T08:17:32Z","title":"Graph Neural Networks are Inherently Good Generalizers: Insights by\n  Bridging GNNs and MLPs","summary":"  Graph neural networks (GNNs), as the de-facto model class for representation\nlearning on graphs, are built upon the multi-layer perceptrons (MLP)\narchitecture with additional message passing layers to allow features to flow\nacross nodes. While conventional wisdom commonly attributes the success of GNNs\nto their advanced expressivity, we conjecture that this is not the main cause\nof GNNs' superiority in node-level prediction tasks. This paper pinpoints the\nmajor source of GNNs' performance gain to their intrinsic generalization\ncapability, by introducing an intermediate model class dubbed as\nP(ropagational)MLP, which is identical to standard MLP in training, but then\nadopts GNN's architecture in testing. Intriguingly, we observe that PMLPs\nconsistently perform on par with (or even exceed) their GNN counterparts, while\nbeing much more efficient in training. This finding sheds new insights into\nunderstanding the learning behavior of GNNs, and can be used as an analytic\ntool for dissecting various GNN-related research problems. As an initial step\nto analyze the inherent generalizability of GNNs, we show the essential\ndifference between MLP and PMLP at infinite-width limit lies in the NTK feature\nmap in the post-training stage. Moreover, by examining their extrapolation\nbehavior, we find that though many GNNs and their PMLP counterparts cannot\nextrapolate non-linear functions for extremely out-of-distribution samples,\nthey have greater potential to generalize to testing samples near the training\ndata range as natural advantages of GNN architectures.\n","authors":["Chenxiao Yang","Qitian Wu","Jiahua Wang","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2212.09034v3.pdf","comment":"Accepted to ICLR 2023. Codes in https://github.com/chr26195/PMLP"},{"id":"http://arxiv.org/abs/2306.02808v1","updated":"2023-06-05T12:00:12Z","published":"2023-06-05T12:00:12Z","title":"Deep Active Learning with Structured Neural Depth Search","summary":"  Previous work optimizes traditional active learning (AL) processes with\nincremental neural network architecture search (Active-iNAS) based on data\ncomplexity change, which improves the accuracy and learning efficiency.\nHowever, Active-iNAS trains several models and selects the model with the best\ngeneralization performance for querying the subsequent samples after each\nactive learning cycle. The independent training processes lead to an\ninsufferable computational budget, which is significantly inefficient and\nlimits search flexibility and final performance. To address this issue, we\npropose a novel active strategy with the method called structured variational\ninference (SVI) or structured neural depth search (SNDS) whereby we could use\nthe gradient descent method in neural network depth search during AL processes.\nAt the same time, we theoretically demonstrate that the current VI-based\nmethods based on the mean-field assumption could lead to poor performance. We\napply our strategy using three querying techniques and three datasets and show\nthat our strategy outperforms current methods.\n","authors":["Xiaoyun Zhang","Xieyi Ping","Jianwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.02808v1.pdf","comment":"10 pages, 8 figures, prepare for TNNLS"},{"id":"http://arxiv.org/abs/2302.14471v3","updated":"2023-06-05T11:59:36Z","published":"2023-02-28T10:29:42Z","title":"Safe Peeling for L0-Regularized Least-Squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of L0-regularized least-squares problems via a Branch-and-Bound\n(BnB) algorithm. Our procedure enables to tighten the convex relaxation\nconsidered at each node of the BnB decision tree and therefore potentially\nallows for more aggressive pruning. Numerical simulations show that our\nproposed methodology leads to significant gains in terms of number of nodes\nexplored and overall solving time.s show that our proposed methodology leads to\nsignificant gains in terms of number of nodes explored and overall solving\ntime.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02807v1","updated":"2023-06-05T11:58:25Z","published":"2023-06-05T11:58:25Z","title":"On Tail Decay Rate Estimation of Loss Function Distributions","summary":"  The study of loss function distributions is critical to characterize a\nmodel's behaviour on a given machine learning problem. For example, while the\nquality of a model is commonly determined by the average loss assessed on a\ntesting set, this quantity does not reflect the existence of the true mean of\nthe loss distribution. Indeed, the finiteness of the statistical moments of the\nloss distribution is related to the thickness of its tails, which are generally\nunknown. Since typical cross-validation schemes determine a family of testing\nloss distributions conditioned on the training samples, the total loss\ndistribution must be recovered by marginalizing over the space of training\nsets. As we show in this work, the finiteness of the sampling procedure\nnegatively affects the reliability and efficiency of classical tail estimation\nmethods from the Extreme Value Theory, such as the Peaks-Over-Threshold\napproach. In this work we tackle this issue by developing a novel general\ntheory for estimating the tails of marginal distributions, when there exists a\nlarge variability between locations of the individual conditional distributions\nunderlying the marginal. To this end, we demonstrate that under some regularity\nconditions, the shape parameter of the marginal distribution is the maximum\ntail shape parameter of the family of conditional distributions. We term this\nestimation approach as Cross Tail Estimation (CTE). We test cross-tail\nestimation in a series of experiments on simulated and real data, showing the\nimproved robustness and quality of tail estimation as compared to classical\napproaches, and providing evidence for the relationship between overfitting and\nloss distribution tail thickness.\n","authors":["Etrit Haxholli","Marco Lorenzi"],"pdf_url":"https://arxiv.org/pdf/2306.02807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03041v2","updated":"2023-06-05T11:58:22Z","published":"2023-01-08T13:30:39Z","title":"Learning the Relation between Similarity Loss and Clustering Loss in\n  Self-Supervised Learning","summary":"  Self-supervised learning enables networks to learn discriminative features\nfrom massive data itself. Most state-of-the-art methods maximize the similarity\nbetween two augmentations of one image based on contrastive learning. By\nutilizing the consistency of two augmentations, the burden of manual\nannotations can be freed. Contrastive learning exploits instance-level\ninformation to learn robust features. However, the learned information is\nprobably confined to different views of the same instance. In this paper, we\nattempt to leverage the similarity between two distinct images to boost\nrepresentation in self-supervised learning. In contrast to instance-level\ninformation, the similarity between two distinct images may provide more useful\ninformation. Besides, we analyze the relation between similarity loss and\nfeature-level cross-entropy loss. These two losses are essential for most deep\nlearning methods. However, the relation between these two losses is not clear.\nSimilarity loss helps obtain instance-level representation, while feature-level\ncross-entropy loss helps mine the similarity between two distinct images. We\nprovide theoretical analyses and experiments to show that a suitable\ncombination of these two losses can get state-of-the-art results. Code is\navailable at https://github.com/guijiejie/ICCL.\n","authors":["Jidong Ge","Yuxiang Liu","Jie Gui","Lanting Fang","Ming Lin","James Tin-Yau Kwok","LiGuo Huang","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2301.03041v2.pdf","comment":"This paper is accepted by IEEE Transactions on Image Processing"},{"id":"http://arxiv.org/abs/2306.02806v1","updated":"2023-06-05T11:58:07Z","published":"2023-06-05T11:58:07Z","title":"A Data-driven Region Generation Framework for Spatiotemporal\n  Transportation Service Management","summary":"  MAUP (modifiable areal unit problem) is a fundamental problem for spatial\ndata management and analysis. As an instantiation of MAUP in online\ntransportation platforms, region generation (i.e., specifying the areal unit\nfor service operations) is the first and vital step for supporting\nspatiotemporal transportation services such as ride-sharing and freight\ntransport. Most existing region generation methods are manually specified\n(e.g., fixed-size grids), suffering from poor spatial semantic meaning and\ninflexibility to meet service operation requirements. In this paper, we propose\nRegionGen, a data-driven region generation framework that can specify regions\nwith key characteristics (e.g., good spatial semantic meaning and\npredictability) by modeling region generation as a multi-objective optimization\nproblem. First, to obtain good spatial semantic meaning, RegionGen segments the\nwhole city into atomic spatial elements based on road networks and obstacles\n(e.g., rivers). Then, it clusters the atomic spatial elements into regions by\nmaximizing various operation characteristics, which is formulated as a\nmulti-objective optimization problem. For this optimization problem, we propose\na multi-objective co-optimization algorithm. Extensive experiments verify that\nRegionGen can generate more suitable regions than traditional methods for\nspatiotemporal service management.\n","authors":["Liyue Chen","Jiangyi Fang","Zhe Yu","Yongxin Tong","Shaosheng Cao","Leye Wang"],"pdf_url":"https://arxiv.org/pdf/2306.02806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15469v2","updated":"2023-06-05T11:56:17Z","published":"2022-10-27T14:21:01Z","title":"Learning Failure-Inducing Models for Testing Software-Defined Networks","summary":"  Software-defined networks (SDN) enable flexible and effective communication\nsystems that are managed by centralized software controllers. However, such a\ncontroller can undermine the underlying communication network of an SDN-based\nsystem and thus must be carefully tested. When an SDN-based system fails, in\norder to address such a failure, engineers need to precisely understand the\nconditions under which it occurs. In this article, we introduce a machine\nlearning-guided fuzzing method, named FuzzSDN, aiming at both (1) generating\neffective test data leading to failures in SDN-based systems and (2) learning\naccurate failure-inducing models that characterize conditions under which such\nsystem fails. To our knowledge, FuzzSDN is the first attempt to simultaneously\naddress these two objectives for SDNs. We evaluate FuzzSDN by applying it to\nsystems controlled by two open-source SDN controllers. Further, we compare\nFuzzSDN with two state-of-the-art methods for fuzzing SDNs and two baselines\nfor learning failure-inducing models. Our results show that (1) compared to the\nstate-of-the-art methods, FuzzSDN generates at least 12 times more failures,\nwithin the same time budget, with a controller that is fairly robust to fuzzing\nand (2) our failure-inducing models have, on average, a precision of 98% and a\nrecall of 86%, significantly outperforming the baselines.\n","authors":["Raphaël Ollando","Seung Yeob Shin","Lionel C. Briand"],"pdf_url":"https://arxiv.org/pdf/2210.15469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.08897v2","updated":"2023-06-05T11:56:09Z","published":"2023-04-18T10:52:16Z","title":"An adaptive safety layer with hard constraints for safe reinforcement\n  learning in multi-energy management systems","summary":"  Safe reinforcement learning (RL) with hard constraint guarantees is a\npromising optimal control direction for multi-energy management systems. It\nonly requires the environment-specific constraint functions itself a priori and\nnot a complete model (i.e. plant, disturbance and noise models, and prediction\nmodels for states not included in the plant model - e.g. demand forecasts,\nweather forecasts, price forecasts). The project-specific upfront and ongoing\nengineering efforts are therefore still reduced, better representations of the\nunderlying system dynamics can still be learned and modelling bias is kept to a\nminimum (no model-based objective function). However, even the constraint\nfunctions alone are not always trivial to accurately provide in advance,\nleading to potentially unsafe behaviour. In this paper, we present two novel\nadvancements: (I) combining the Optlayer and SafeFallback method, named\nOptLayerPolicy, to increase the initial utility while keeping a high sample\nefficiency. (II) introducing self-improving hard constraints, to increase the\naccuracy of the constraint functions as more data becomes available so that\nbetter policies can be learned. Both advancements keep the constraint\nformulation decoupled from the RL formulation, so that new (presumably better)\nRL algorithms can act as drop-in replacements. We have shown that, in a\nsimulated multi-energy system case study, the initial utility is increased to\n92.4% (OptLayerPolicy) compared to 86.1% (OptLayer) and that the policy after\ntraining is increased to 104.9% (GreyOptLayerPolicy) compared to 103.4%\n(OptLayer) - all relative to a vanilla RL benchmark. While introducing\nsurrogate functions into the optimization problem requires special attention,\nwe do conclude that the newly presented GreyOptLayerPolicy method is the most\nadvantageous.\n","authors":["Glenn Ceusters","Muhammad Andy Putratama","Rüdiger Franke","Ann Nowé","Maarten Messagie"],"pdf_url":"https://arxiv.org/pdf/2304.08897v2.pdf","comment":"4703 words. arXiv admin note: text overlap with arXiv:2207.03830"},{"id":"http://arxiv.org/abs/2306.02800v1","updated":"2023-06-05T11:55:57Z","published":"2023-06-05T11:55:57Z","title":"Using Multiple Dermoscopic Photographs of One Lesion Improves Melanoma\n  Classification via Deep Learning: A Prognostic Diagnostic Accuracy Study","summary":"  Background: Convolutional neural network (CNN)-based melanoma classifiers\nface several challenges that limit their usefulness in clinical practice.\nObjective: To investigate the impact of multiple real-world dermoscopic views\nof a single lesion of interest on a CNN-based melanoma classifier.\n  Methods: This study evaluated 656 suspected melanoma lesions. Classifier\nperformance was measured using area under the receiver operating characteristic\ncurve (AUROC), expected calibration error (ECE) and maximum confidence change\n(MCC) for (I) a single-view scenario, (II) a multiview scenario using multiple\nartificially modified images per lesion and (III) a multiview scenario with\nmultiple real-world images per lesion.\n  Results: The multiview approach with real-world images significantly\nincreased the AUROC from 0.905 (95% CI, 0.879-0.929) in the single-view\napproach to 0.930 (95% CI, 0.909-0.951). ECE and MCC also improved\nsignificantly from 0.131 (95% CI, 0.105-0.159) to 0.072 (95% CI: 0.052-0.093)\nand from 0.149 (95% CI, 0.125-0.171) to 0.115 (95% CI: 0.099-0.131),\nrespectively. Comparing multiview real-world to artificially modified images\nshowed comparable diagnostic accuracy and uncertainty estimation, but\nsignificantly worse robustness for the latter.\n  Conclusion: Using multiple real-world images is an inexpensive method to\npositively impact the performance of a CNN-based melanoma classifier.\n","authors":["Achim Hekler","Roman C. Maron","Sarah Haggenmüller","Max Schmitt","Christoph Wies","Jochen S. Utikal","Friedegund Meier","Sarah Hobelsberger","Frank F. Gellrich","Mildred Sergon","Axel Hauschild","Lars E. French","Lucie Heinzerling","Justin G. Schlager","Kamran Ghoreschi","Max Schlaak","Franz J. Hilke","Gabriela Poch","Sören Korsing","Carola Berking","Markus V. Heppt","Michael Erdmann","Sebastian Haferkamp","Konstantin Drexler","Dirk Schadendorf","Wiebke Sondermann","Matthias Goebeler","Bastian Schilling","Jakob N. Kather","Eva Krieghoff-Henning","Titus J. Brinker"],"pdf_url":"https://arxiv.org/pdf/2306.02800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02798v1","updated":"2023-06-05T11:51:04Z","published":"2023-06-05T11:51:04Z","title":"Enhancing naive classifier for positive unlabeled data based on logistic\n  regression approach","summary":"  We argue that for analysis of Positive Unlabeled (PU) data under Selected\nCompletely At Random (SCAR) assumption it is fruitful to view the problem as\nfitting of misspecified model to the data. Namely, we show that the results on\nmisspecified fit imply that in the case when posterior probability of the\nresponse is modelled by logistic regression, fitting the logistic regression to\nthe observable PU data which {\\it does not} follow this model, still yields the\nvector of estimated parameters approximately colinear with the true vector of\nparameters. This observation together with choosing the intercept of the\nclassifier based on optimisation of analogue of F1 measure yields a classifier\nwhich performs on par or better than its competitors on several real data sets\nconsidered.\n","authors":["Mateusz Płatek","Jan Mielniczuk"],"pdf_url":"https://arxiv.org/pdf/2306.02798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.06395v2","updated":"2023-06-05T11:50:38Z","published":"2023-05-10T18:08:55Z","title":"ACTC: Active Threshold Calibration for Cold-Start Knowledge Graph\n  Completion","summary":"  Self-supervised knowledge-graph completion (KGC) relies on estimating a\nscoring model over (entity, relation, entity)-tuples, for example, by embedding\nan initial knowledge graph. Prediction quality can be improved by calibrating\nthe scoring model, typically by adjusting the prediction thresholds using\nmanually annotated examples. In this paper, we attempt for the first time\ncold-start calibration for KGC, where no annotated examples exist initially for\ncalibration, and only a limited number of tuples can be selected for\nannotation. Our new method ACTC finds good per-relation thresholds efficiently\nbased on a limited set of annotated tuples. Additionally to a few annotated\ntuples, ACTC also leverages unlabeled tuples by estimating their correctness\nwith Logistic Regression or Gaussian Process classifiers. We also experiment\nwith different methods for selecting candidate tuples for annotation:\ndensity-based and random selection. Experiments with five scoring models and an\noracle annotator show an improvement of 7% points when using ACTC in the\nchallenging setting with an annotation budget of only 10 tuples, and an average\nimprovement of 4% points over different budgets.\n","authors":["Anastasiia Sedova","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2305.06395v2.pdf","comment":"Accepted to ACL'23"},{"id":"http://arxiv.org/abs/2306.02797v1","updated":"2023-06-05T11:46:45Z","published":"2023-06-05T11:46:45Z","title":"Modeling Human-like Concept Learning with Bayesian Inference over\n  Natural Language","summary":"  We model learning of abstract symbolic concepts by performing Bayesian\ninference over utterances in natural language. For efficient inference, we use\na large language model as a proposal distribution. We fit a prior to human data\nto better model human learners, and evaluate on both generative and logical\nconcepts.\n","authors":["Kevin Ellis"],"pdf_url":"https://arxiv.org/pdf/2306.02797v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11716v3","updated":"2023-06-05T11:44:02Z","published":"2023-01-27T14:03:09Z","title":"Pre-training for Speech Translation: CTC Meets Optimal Transport","summary":"  The gap between speech and text modalities is a major challenge in\nspeech-to-text translation (ST). Different methods have been proposed to reduce\nthis gap, but most of them require architectural changes in ST training. In\nthis work, we propose to mitigate this issue at the pre-training stage,\nrequiring no change in the ST model. First, we show that the connectionist\ntemporal classification (CTC) loss can reduce the modality gap by design. We\nprovide a quantitative comparison with the more common cross-entropy loss,\nshowing that pre-training with CTC consistently achieves better final ST\naccuracy. Nevertheless, CTC is only a partial solution and thus, in our second\ncontribution, we propose a novel pre-training method combining CTC and optimal\ntransport to further reduce this gap. Our method pre-trains a Siamese-like\nmodel composed of two encoders, one for acoustic inputs and the other for\ntextual inputs, such that they produce representations that are close to each\nother in the Wasserstein space. Extensive experiments on the standard CoVoST-2\nand MuST-C datasets show that our pre-training method applied to the vanilla\nencoder-decoder Transformer achieves state-of-the-art performance under the\nno-external-data setting, and performs on par with recent strong multi-task\nlearning systems trained with external data. Finally, our method can also be\napplied on top of these multi-task systems, leading to further improvements for\nthese models. Code and pre-trained models are available at\nhttps://github.com/formiel/fairseq.\n","authors":["Phuong-Hang Le","Hongyu Gong","Changhan Wang","Juan Pino","Benjamin Lecouteux","Didier Schwab"],"pdf_url":"https://arxiv.org/pdf/2301.11716v3.pdf","comment":"ICML 2023 (oral presentation). This version fixed URLs, updated\n  affiliations & acknowledgements, and improved formatting"},{"id":"http://arxiv.org/abs/2306.02786v1","updated":"2023-06-05T11:26:46Z","published":"2023-06-05T11:26:46Z","title":"Navigating Explanatory Multiverse Through Counterfactual Path Geometry","summary":"  Counterfactual explanations are the de facto standard when tasked with\ninterpreting decisions of (opaque) predictive models. Their generation is often\nsubject to algorithmic and domain-specific constraints -- such as density-based\nfeasibility for the former and attribute (im)mutability or directionality of\nchange for the latter -- that aim to maximise their real-life utility. In\naddition to desiderata with respect to the counterfactual instance itself, the\nexistence of a viable path connecting it with the factual data point, known as\nalgorithmic recourse, has become an important technical consideration. While\nboth of these requirements ensure that the steps of the journey as well as its\ndestination are admissible, current literature neglects the multiplicity of\nsuch counterfactual paths. To address this shortcoming we introduce the novel\nconcept of explanatory multiverse that encompasses all the possible\ncounterfactual journeys and shows how to navigate, reason about and compare the\ngeometry of these paths -- their affinity, branching, divergence and possible\nfuture convergence -- with two methods: vector spaces and graphs. Implementing\nthis (interactive) explanatory process grants explainees more agency by\nallowing them to select counterfactuals based on the properties of the journey\nleading to them in addition to their absolute differences.\n","authors":["Kacper Sokol","Edward Small","Yueqing Xuan"],"pdf_url":"https://arxiv.org/pdf/2306.02786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16304v2","updated":"2023-06-05T11:14:41Z","published":"2023-05-25T17:56:24Z","title":"Candidate Set Re-ranking for Composed Image Retrieval with Dual\n  Multi-modal Encoder","summary":"  Composed image retrieval aims to find an image that best matches a given\nmulti-modal user query consisting of a reference image and text pair. Existing\nmethods commonly pre-compute image embeddings over the entire corpus and\ncompare these to a reference image embedding modified by the query text at test\ntime. Such a pipeline is very efficient at test time since fast vector\ndistances can be used to evaluate candidates, but modifying the reference image\nembedding guided only by a short textual description can be difficult,\nespecially independent of potential candidates. An alternative approach is to\nallow interactions between the query and every possible candidate, i.e.,\nreference-text-candidate triplets, and pick the best from the entire set.\nThough this approach is more discriminative, for large-scale datasets the\ncomputational cost is prohibitive since pre-computation of candidate embeddings\nis no longer possible. We propose to combine the merits of both schemes using a\ntwo-stage model. Our first stage adopts the conventional vector distancing\nmetric and performs a fast pruning among candidates. Meanwhile, our second\nstage employs a dual-encoder architecture, which effectively attends to the\ninput triplet of reference-text-candidate and re-ranks the candidates. Both\nstages utilize a vision-and-language pre-trained network, which has proven\nbeneficial for various downstream tasks. Our method consistently outperforms\nstate-of-the-art approaches on standard benchmarks for the task.\n","authors":["Zheyuan Liu","Weixuan Sun","Damien Teney","Stephen Gould"],"pdf_url":"https://arxiv.org/pdf/2305.16304v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2210.14536v2","updated":"2023-06-05T11:14:23Z","published":"2022-10-26T07:54:47Z","title":"Position tracking of a varying number of sound sources with sliding\n  permutation invariant training","summary":"  Recent data- and learning-based sound source localization (SSL) methods have\nshown strong performance in challenging acoustic scenarios. However, little\nwork has been done on adapting such methods to track consistently multiple\nsources appearing and disappearing, as would occur in reality. In this paper,\nwe present a new training strategy for deep learning SSL models with a\nstraightforward implementation based on the mean squared error of the optimal\nassociation between estimated and reference positions in the preceding time\nframes. It optimizes the desired properties of a tracking system: handling a\ntime-varying number of sources and ordering localization estimates according to\ntheir trajectories, minimizing identity switches (IDSs). Evaluation on\nsimulated data of multiple reverberant moving sources and on two model\narchitectures proves its effectiveness on reducing identity switches without\ncompromising frame-wise localization accuracy.\n","authors":["David Diaz-Guerra","Archontis Politis","Tuomas Virtanen"],"pdf_url":"https://arxiv.org/pdf/2210.14536v2.pdf","comment":"Accepted for publication at the 31st European Signal Processing\n  Conference (EUSIPCO 2023)"},{"id":"http://arxiv.org/abs/2306.02781v1","updated":"2023-06-05T11:14:18Z","published":"2023-06-05T11:14:18Z","title":"A survey of Generative AI Applications","summary":"  Generative AI has experienced remarkable growth in recent years, leading to a\nwide array of applications across diverse domains. In this paper, we present a\ncomprehensive survey of more than 350 generative AI applications, providing a\nstructured taxonomy and concise descriptions of various unimodal and even\nmultimodal generative AIs. The survey is organized into sections, covering a\nwide range of unimodal generative AI applications such as text, images, video,\ngaming and brain information. Our survey aims to serve as a valuable resource\nfor researchers and practitioners to navigate the rapidly expanding landscape\nof generative AI, facilitating a better understanding of the current\nstate-of-the-art and fostering further innovation in the field.\n","authors":["Roberto Gozalo-Brizuela","Eduardo C. Garrido-Merchán"],"pdf_url":"https://arxiv.org/pdf/2306.02781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18875v2","updated":"2023-06-05T11:11:42Z","published":"2023-05-30T09:17:09Z","title":"Centralised rehearsal of decentralised cooperation: Multi-agent\n  reinforcement learning for the scalable coordination of residential energy\n  flexibility","summary":"  This paper investigates how deep multi-agent reinforcement learning can\nenable the scalable and privacy-preserving coordination of residential energy\nflexibility. The coordination of distributed resources such as electric\nvehicles and heating will be critical to the successful integration of large\nshares of renewable energy in our electricity grid and, thus, to help mitigate\nclimate change. The pre-learning of individual reinforcement learning policies\ncan enable distributed control with no sharing of personal data required during\nexecution. However, previous approaches for multi-agent reinforcement\nlearning-based distributed energy resources coordination impose an ever greater\ntraining computational burden as the size of the system increases. We therefore\nadopt a deep multi-agent actor-critic method which uses a \\emph{centralised but\nfactored critic} to rehearse coordination ahead of execution. Results show that\ncoordination is achieved at scale, with minimal information and communication\ninfrastructure requirements, no interference with daily activities, and privacy\nprotection. Significant savings are obtained for energy users, the distribution\nnetwork and greenhouse gas emissions. Moreover, training times are nearly 40\ntimes shorter than with a previous state-of-the-art reinforcement learning\napproach without the factored critic for 30 homes.\n","authors":["Flora Charbonnier","Bei Peng","Thomas Morstyn","Malcolm McCulloch"],"pdf_url":"https://arxiv.org/pdf/2305.18875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02775v1","updated":"2023-06-05T11:00:11Z","published":"2023-06-05T11:00:11Z","title":"Input gradient diversity for neural network ensembles","summary":"  Deep Ensembles (DEs) demonstrate improved accuracy, calibration and\nrobustness to perturbations over single neural networks partly due to their\nfunctional diversity. Particle-based variational inference (ParVI) methods\nenhance diversity by formalizing a repulsion term based on a network similarity\nkernel. However, weight-space repulsion is inefficient due to\nover-parameterization, while direct function-space repulsion has been found to\nproduce little improvement over DEs. To sidestep these difficulties, we propose\nFirst-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based\non ParVI, which performs repulsion in the space of first-order input gradients.\nAs input gradients uniquely characterize a function up to translation and are\nmuch smaller in dimension than the weights, this method guarantees that\nensemble members are functionally different. Intuitively, diversifying the\ninput gradients encourages each network to learn different features, which is\nexpected to improve the robustness of an ensemble. Experiments on image\nclassification datasets show that FoRDE significantly outperforms the\ngold-standard DEs and other ensemble methods in accuracy and calibration under\ncovariate shift due to input perturbations.\n","authors":["Trung Trinh","Markus Heinonen","Luigi Acerbi","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2306.02775v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2306.02771v1","updated":"2023-06-05T10:55:15Z","published":"2023-06-05T10:55:15Z","title":"Identifying the style by a qualified reader on a short fragment of\n  generated poetry","summary":"  Style is an important concept in today's challenges in natural language\ngenerating. After the success in the field of image style transfer, the task of\ntext style transfer became actual and attractive. Researchers are also\ninterested in the tasks of style reproducing in generation of the poetic text.\nEvaluation of style reproducing in natural poetry generation remains a problem.\nI used 3 character-based LSTM-models to work with style reproducing assessment.\nAll three models were trained on the corpus of texts by famous Russian-speaking\npoets. Samples were shown to the assessors and 4 answer options were offered,\nthe style of which poet this sample reproduces. In addition, the assessors were\nasked how well they were familiar with the work of the poet they had named.\nStudents studying history of literature were the assessors, 94 answers were\nreceived. It has appeared that accuracy of definition of style increases if the\nassessor can quote the poet by heart. Each model showed at least 0.7\nmacro-average accuracy. The experiment showed that it is better to involve a\nprofessional rather than a naive reader in the evaluation of style in the tasks\nof poetry generation, while lstm models are good at reproducing the style of\nRussian poets even on a limited training corpus.\n","authors":["Boris Orekhov"],"pdf_url":"https://arxiv.org/pdf/2306.02771v1.pdf","comment":"6 pages, 2 tables"},{"id":"http://arxiv.org/abs/2306.02766v1","updated":"2023-06-05T10:45:39Z","published":"2023-06-05T10:45:39Z","title":"Networked Communication for Decentralised Agents in Mean-Field Games","summary":"  We introduce networked communication to the mean-field game framework. In\nparticular, we look at oracle-free settings where $N$ decentralised agents\nlearn along a single, non-episodic evolution path of the empirical system, such\nas we may encounter for a large range of many-agent cooperation problems in the\nreal-world. We provide theoretical evidence that by spreading improved policies\nthrough the network in a decentralised fashion, our sample guarantees are\nupper-bounded by those of the purely independent-learning case. Moreover, we\nshow empirically that our networked method can give faster convergence in\npractice, while removing the reliance on a centralised controller. We also\ndemonstrate that our decentralised communication architecture brings\nsignificant benefits over both the centralised and independent alternatives in\nterms of robustness and flexibility to unexpected learning failures and changes\nin population size. For comparison purposes with our new architecture, we\nmodify recent algorithms for the centralised and independent cases to make\ntheir practical convergence feasible: while contributing the first empirical\ndemonstrations of these algorithms in our setting of $N$ agents learning along\na single system evolution with only local state observability, we additionally\ndisplay the empirical benefits of our new, networked approach.\n","authors":["Patrick Benjamin","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/2306.02766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13875v2","updated":"2023-06-05T10:39:41Z","published":"2023-02-27T15:25:21Z","title":"Evaluating Robustness and Uncertainty of Graph Models Under Structural\n  Distributional Shifts","summary":"  In reliable decision-making systems based on machine learning, models have to\nbe robust to distributional shifts or provide the uncertainty of their\npredictions. In node-level problems of graph learning, distributional shifts\ncan be especially complex since the samples are interdependent. To evaluate the\nperformance of graph models, it is important to test them on diverse and\nmeaningful distributional shifts. However, most graph benchmarks considering\ndistributional shifts for node-level problems focus mainly on node features,\nwhile structural properties are also essential for graph problems. In this\nwork, we propose a general approach for inducing diverse distributional shifts\nbased on graph structure. We use this approach to create data splits according\nto several structural node properties: popularity, locality, and density. In\nour experiments, we thoroughly evaluate the proposed distributional shifts and\nshow that they can be quite challenging for existing graph models. We also\nreveal that simple models often outperform more sophisticated methods on these\nchallenging shifts. Finally, our experiments provide evidence that there is a\ntrade-off between the quality of learned representations for the base\nclassification task under structural distributional shift and the ability to\nseparate the nodes from different distributions using these representations.\n","authors":["Gleb Bazhenov","Denis Kuznedelev","Andrey Malinin","Artem Babenko","Liudmila Prokhorenkova"],"pdf_url":"https://arxiv.org/pdf/2302.13875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19663v2","updated":"2023-06-05T10:35:57Z","published":"2023-05-31T09:01:20Z","title":"Vandermonde Neural Operators","summary":"  Fourier Neural Operators (FNOs) have emerged as very popular machine learning\narchitectures for learning operators, particularly those arising in PDEs.\nHowever, as FNOs rely on the fast Fourier transform for computational\nefficiency, the architecture can be limited to input data on equispaced\nCartesian grids. Here, we generalize FNOs to handle input data on\nnon-equispaced point distributions. Our proposed model, termed as Vandermonde\nNeural Operator (VNO), utilizes Vandermonde-structured matrices to efficiently\ncompute forward and inverse Fourier transforms, even on arbitrarily distributed\npoints. We present numerical experiments to demonstrate that VNOs can be\nsignificantly faster than FNOs, while retaining comparable accuracy, and\nimprove upon accuracy of comparable non-equispaced methods such as the Geo-FNO.\n","authors":["Levi Lingsch","Mike Michelis","Sirani M. Perera","Robert K. Katzschmann","Siddartha Mishra"],"pdf_url":"https://arxiv.org/pdf/2305.19663v2.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.02747v1","updated":"2023-06-05T10:05:43Z","published":"2023-06-05T10:05:43Z","title":"Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin\n  Representation","summary":"  In real-world scenarios, the application of reinforcement learning is\nsignificantly challenged by complex non-stationarity. Most existing methods\nattempt to model the changes of the environment explicitly, often requiring\nimpractical prior knowledge. In this paper, we propose a new perspective,\npositing that non-stationarity can propagate and accumulate through complex\ncausal relationships during state transitions, thereby compounding its\nsophistication and affecting policy learning. We believe that this challenge\ncan be more effectively addressed by tracing the causal origin of\nnon-stationarity. To this end, we introduce the Causal-Origin REPresentation\n(COREP) algorithm. COREP primarily employs a guided updating mechanism to learn\na stable graph representation for states termed as causal-origin\nrepresentation. By leveraging this representation, the learned policy exhibits\nimpressive resilience to non-stationarity. We supplement our approach with a\ntheoretical analysis grounded in the causal interpretation for non-stationary\nreinforcement learning, advocating for the validity of the causal-origin\nrepresentation. Experimental results further demonstrate the superior\nperformance of COREP over existing methods in tackling non-stationarity.\n","authors":["Wanpeng Zhang","Yilin Li","Boyu Yang","Zongqing Lu"],"pdf_url":"https://arxiv.org/pdf/2306.02747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02904v2","updated":"2023-06-05T10:01:48Z","published":"2023-02-06T16:18:48Z","title":"Rethinking Gauss-Newton for learning over-parameterized models","summary":"  This work studies the global convergence and generalization properties of\nGauss Newton's (GN) when optimizing one-hidden layer networks in the\nover-parameterized regime. We first establish a global convergence result for\nGN in the continuous-time limit exhibiting a faster convergence rate compared\nto GD due to improved conditioning. We then perform an empirical study on a\nsynthetic regression task to investigate the implicit bias of GN's method. We\nfind that, while GN is consistently faster than GD in finding a global optimum,\nthe performance of the learned model on a test dataset is heavily influenced by\nboth the learning rate and the variance of the randomly initialized network's\nweights. Specifically, we find that initializing with a smaller variance\nresults in a better generalization, a behavior also observed for GD. However,\nin contrast to GD where larger learning rates lead to the best generalization,\nwe find that GN achieves an improved generalization when using smaller learning\nrates, albeit at the cost of slower convergence. This study emphasizes the\nsignificance of the learning rate in balancing the optimization speed of GN\nwith the generalization ability of the learned solution.\n","authors":["Michael Arbel","Romain Menegaux","Pierre Wolinski"],"pdf_url":"https://arxiv.org/pdf/2302.02904v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10964v2","updated":"2023-06-05T09:52:19Z","published":"2023-05-18T13:30:29Z","title":"Learning Activation Functions for Sparse Neural Networks","summary":"  Sparse Neural Networks (SNNs) can potentially demonstrate similar performance\nto their dense counterparts while saving significant energy and memory at\ninference. However, the accuracy drop incurred by SNNs, especially at high\npruning ratios, can be an issue in critical deployment conditions. While recent\nworks mitigate this issue through sophisticated pruning techniques, we shift\nour focus to an overlooked factor: hyperparameters and activation functions.\nOur analyses have shown that the accuracy drop can additionally be attributed\nto (i) Using ReLU as the default choice for activation functions unanimously,\nand (ii) Fine-tuning SNNs with the same hyperparameters as dense counterparts.\nThus, we focus on learning a novel way to tune activation functions for sparse\nnetworks and combining these with a separate hyperparameter optimization (HPO)\nregime for sparse networks. By conducting experiments on popular DNN models\n(LeNet-5, VGG-16, ResNet-18, and EfficientNet-B0) trained on MNIST, CIFAR-10,\nand ImageNet-16 datasets, we show that the novel combination of these two\napproaches, dubbed Sparse Activation Function Search, short: SAFS, results in\nup to 15.53%, 8.88%, and 6.33% absolute improvement in the accuracy for\nLeNet-5, VGG-16, and ResNet-18 over the default training protocols, especially\nat high pruning ratios. Our code can be found at https://github.com/automl/SAFS\n","authors":["Mohammad Loni","Aditya Mohan","Mehdi Asadi","Marius Lindauer"],"pdf_url":"https://arxiv.org/pdf/2305.10964v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02744v1","updated":"2023-06-05T09:52:05Z","published":"2023-06-05T09:52:05Z","title":"Towards Better Explanations for Object Detection","summary":"  Recent advances in Artificial Intelligence (AI) technology have promoted\ntheir use in almost every field. The growing complexity of deep neural networks\n(DNNs) makes it increasingly difficult and important to explain the inner\nworkings and decisions of the network. However, most current techniques for\nexplaining DNNs focus mainly on interpreting classification tasks. This paper\nproposes a method to explain the decision for any object detection model called\nD-CLOSE. To closely track the model's behavior, we used multiple levels of\nsegmentation on the image and a process to combine them. We performed tests on\nthe MS-COCO dataset with the YOLOX model, which shows that our method\noutperforms D-RISE and can give a better quality and less noise explanation.\n","authors":["Van Binh Truong","Truong Thanh Hung Nguyen","Vo Thanh Khang Nguyen","Quoc Khanh Nguyen","Quoc Hung Cao"],"pdf_url":"https://arxiv.org/pdf/2306.02744v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2211.05551v3","updated":"2023-06-05T09:48:33Z","published":"2022-11-02T13:51:00Z","title":"Causal Counterfactuals for Improving the Robustness of Reinforcement\n  Learning","summary":"  Reinforcement learning (RL) is used in various robotic applications. RL\nenables agents to learn tasks autonomously by interacting with the environment.\nThe more critical the tasks are, the higher the demand for the robustness of\nthe RL systems. Causal RL combines RL and causal inference to make RL more\nrobust. Causal RL agents use a causal representation to capture the invariant\ncausal mechanisms that can be transferred from one task to another. Currently,\nthere is limited research in Causal RL, and existing solutions are usually not\ncomplete or feasible for real-world applications. In this work, we propose\nCausalCF, the first complete Causal RL solution incorporating ideas from Causal\nCuriosity and CoPhy. Causal Curiosity provides an approach for using\ninterventions, and CoPhy is modified to enable the RL agent to perform\ncounterfactuals. Causal Curiosity has been applied to robotic grasping and\nmanipulation tasks in CausalWorld. CausalWorld provides a realistic simulation\nenvironment based on the TriFinger robot. We apply CausalCF to complex robotic\ntasks and show that it improves the RL agent's robustness using CausalWorld.\n","authors":["Tom He","Jasmina Gajcin","Ivana Dusparic"],"pdf_url":"https://arxiv.org/pdf/2211.05551v3.pdf","comment":"Accepted to ARMS-2023 (ARMS-2023: AAMAS 2023 Workshop on Autonomous\n  Robots and Multirobot Systems)"},{"id":"http://arxiv.org/abs/2306.02738v1","updated":"2023-06-05T09:33:39Z","published":"2023-06-05T09:33:39Z","title":"A Large-Scale Study of Probabilistic Calibration in Neural Network\n  Regression","summary":"  Accurate probabilistic predictions are essential for optimal decision making.\nWhile neural network miscalibration has been studied primarily in\nclassification, we investigate this in the less-explored domain of regression.\nWe conduct the largest empirical study to date to assess the probabilistic\ncalibration of neural networks. We also analyze the performance of\nrecalibration, conformal, and regularization methods to enhance probabilistic\ncalibration. Additionally, we introduce novel differentiable recalibration and\nregularization methods, uncovering new insights into their effectiveness. Our\nfindings reveal that regularization methods offer a favorable tradeoff between\ncalibration and sharpness. Post-hoc methods exhibit superior probabilistic\ncalibration, which we attribute to the finite-sample coverage guarantee of\nconformal prediction. Furthermore, we demonstrate that quantile recalibration\ncan be considered as a specific case of conformal prediction. Our study is\nfully reproducible and implemented in a common code base for fair comparisons.\n","authors":["Victor Dheur","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2306.02738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2108.12988v3","updated":"2023-06-05T09:30:00Z","published":"2021-08-30T04:30:53Z","title":"Learning Meta Representations for Agents in Multi-Agent Reinforcement\n  Learning","summary":"  In multi-agent reinforcement learning, the behaviors that agents learn in a\nsingle Markov Game (MG) are typically confined to the given agent number. Every\nsingle MG induced by varying the population may possess distinct optimal joint\nstrategies and game-specific knowledge, which are modeled independently in\nmodern multi-agent reinforcement learning algorithms. In this work, our focus\nis on creating agents that can generalize across population-varying MGs.\nInstead of learning a unimodal policy, each agent learns a policy set\ncomprising effective strategies across a variety of games. To achieve this, we\npropose Meta Representations for Agents (MRA) that explicitly models the\ngame-common and game-specific strategic knowledge. By representing the policy\nsets with multi-modal latent policies, the game-common strategic knowledge and\ndiverse strategic modes are discovered through an iterative optimization\nprocedure. We prove that by approximately maximizing the resulting constrained\nmutual information objective, the policies can reach Nash Equilibrium in every\nevaluation MG when the latent space is sufficiently large. When deploying MRA\nin practical settings with limited latent space sizes, fast adaptation can be\nachieved by leveraging the first-order gradient information. Extensive\nexperiments demonstrate the effectiveness of MRA in improving training\nperformance and generalization ability in challenging evaluation games.\n","authors":["Shenao Zhang","Li Shen","Lei Han","Li Shen"],"pdf_url":"https://arxiv.org/pdf/2108.12988v3.pdf","comment":"Published at CoLLAs"},{"id":"http://arxiv.org/abs/2306.02733v1","updated":"2023-06-05T09:29:46Z","published":"2023-06-05T09:29:46Z","title":"Realising Synthetic Active Inference Agents, Part II: Variational\n  Message Updates","summary":"  The Free Energy Principle (FEP) describes (biological) agents as minimising a\nvariational Free Energy (FE) with respect to a generative model of their\nenvironment. Active Inference (AIF) is a corollary of the FEP that describes\nhow agents explore and exploit their environment by minimising an expected FE\nobjective. In two related papers, we describe a scalable, epistemic approach to\nsynthetic AIF agents, by message passing on free-form Forney-style Factor\nGraphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG)\nnotation that visually represents (generalised) FE objectives for AIF. The\ncurrent paper (part II) derives message passing algorithms that minimise\n(generalised) FE objectives on a CFFG by variational calculus. A comparison\nbetween simulated Bethe and generalised FE agents illustrates how synthetic AIF\ninduces epistemic behaviour on a T-maze navigation task. With a full message\npassing account of synthetic AIF agents, it becomes possible to derive and\nreuse message updates across models and move closer to industrial applications\nof synthetic AIF.\n","authors":["Thijs van de Laar","Magnus Koudahl","Bert de Vries"],"pdf_url":"https://arxiv.org/pdf/2306.02733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02732v1","updated":"2023-06-05T09:28:03Z","published":"2023-06-05T09:28:03Z","title":"Conformal Prediction with Missing Values","summary":"  Conformal prediction is a theoretically grounded framework for constructing\npredictive intervals. We study conformal prediction with missing values in the\ncovariates -- a setting that brings new challenges to uncertainty\nquantification. We first show that the marginal coverage guarantee of conformal\nprediction holds on imputed data for any missingness distribution and almost\nall imputation functions. However, we emphasize that the average coverage\nvaries depending on the pattern of missing values: conformal methods tend to\nconstruct prediction intervals that under-cover the response conditionally to\nsome missing patterns. This motivates our novel generalized conformalized\nquantile regression framework, missing data augmentation, which yields\nprediction intervals that are valid conditionally to the patterns of missing\nvalues, despite their exponential number. We then show that a universally\nconsistent quantile regression algorithm trained on the imputed data is Bayes\noptimal for the pinball risk, thus achieving valid coverage conditionally to\nany given data point. Moreover, we examine the case of a linear model, which\ndemonstrates the importance of our proposal in overcoming the\nheteroskedasticity induced by missing values. Using synthetic and data from\ncritical care, we corroborate our theory and report improved performance of our\nmethods.\n","authors":["Margaux Zaffran","Aymeric Dieuleveut","Julie Josse","Yaniv Romano"],"pdf_url":"https://arxiv.org/pdf/2306.02732v1.pdf","comment":"Code for our experiments can be found at\n  https://github.com/mzaffran/ConformalPredictionMissingValues . To be\n  published in the proceedings of the 40th International Conference on Machine\n  Learning, Honolulu, Hawaii, USA"},{"id":"http://arxiv.org/abs/2306.02731v1","updated":"2023-06-05T09:27:28Z","published":"2023-06-05T09:27:28Z","title":"Enhanced Distribution Modelling via Augmented Architectures For Neural\n  ODE Flows","summary":"  While the neural ODE formulation of normalizing flows such as in FFJORD\nenables us to calculate the determinants of free form Jacobians in O(D) time,\nthe flexibility of the transformation underlying neural ODEs has been shown to\nbe suboptimal. In this paper, we present AFFJORD, a neural ODE-based\nnormalizing flow which enhances the representation power of FFJORD by defining\nthe neural ODE through special augmented transformation dynamics which preserve\nthe topology of the space. Furthermore, we derive the Jacobian determinant of\nthe general augmented form by generalizing the chain rule in the continuous\nsense into the Cable Rule, which expresses the forward sensitivity of ODEs with\nrespect to their initial conditions. The cable rule gives an explicit\nexpression for the Jacobian of a neural ODE transformation, and provides an\nelegant proof of the instantaneous change of variable. Our experimental results\non density estimation in synthetic and high dimensional data, such as MNIST,\nCIFAR-10 and CelebA 32x32, show that AFFJORD outperforms the baseline FFJORD\nthrough the improved flexibility of the underlying vector field.\n","authors":["Etrit Haxholli","Marco Lorenzi"],"pdf_url":"https://arxiv.org/pdf/2306.02731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02729v1","updated":"2023-06-05T09:26:38Z","published":"2023-06-05T09:26:38Z","title":"Gibbs Sampling the Posterior of Neural Networks","summary":"  In this paper, we study sampling from a posterior derived from a neural\nnetwork. We propose a new probabilistic model consisting of adding noise at\nevery pre- and post-activation in the network, arguing that the resulting\nposterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler\nattains similar performances as the state-of-the-art Monte Carlo Markov chain\nmethods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted\nLangevin algorithm, both on real and synthetic data. By framing our analysis in\nthe teacher-student setting, we introduce a thermalization criterion that\nallows us to detect when an algorithm, when run on data with synthetic labels,\nfails to sample from the posterior. The criterion is based on the fact that in\nthe teacher-student setting we can initialize an algorithm directly at\nequilibrium.\n","authors":["Giovanni Piccioli","Emanuele Troiani","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2306.02729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04318v3","updated":"2023-06-05T09:15:49Z","published":"2022-10-09T18:58:24Z","title":"Prediction intervals for neural network models using weighted asymmetric\n  loss functions","summary":"  We propose a simple and efficient approach to generate prediction intervals\n(PIs) for approximated and forecasted trends. Our method leverages a weighted\nasymmetric loss function to estimate the lower and upper bounds of the PIs,\nwith the weights determined by the interval width. We provide a concise\nmathematical proof of the method, show how it can be extended to derive PIs for\nparametrised functions and argue why the method works for predicting PIs of\ndependent variables. The presented tests of the method on a real-world\nforecasting task using a neural network-based model show that it can produce\nreliable PIs in complex machine learning scenarios.\n","authors":["Milo Grillo","Yunpeng Han","Agnieszka Werpachowska"],"pdf_url":"https://arxiv.org/pdf/2210.04318v3.pdf","comment":"14 pages, 3 figures, not submitted anywhere yet"},{"id":"http://arxiv.org/abs/2306.02719v1","updated":"2023-06-05T09:12:34Z","published":"2023-06-05T09:12:34Z","title":"Multiple output samples for each input in a single-output Gaussian\n  process","summary":"  The standard Gaussian Process (GP) only considers a single output sample per\ninput in the training set. Datasets for subjective tasks, such as spoken\nlanguage assessment, may be annotated with output labels from multiple human\nraters per input. This paper proposes to generalise the GP to allow for these\nmultiple output samples in the training set, and thus make use of available\noutput uncertainty information. This differs from a multi-output GP, as all\noutput samples are from the same task here. The output density function is\nformulated to be the joint likelihood of observing all output samples, and\nlatent variables are not repeated to reduce computation cost. The test set\npredictions are inferred similarly to a standard GP, with a difference being in\nthe optimised hyper-parameters. This is evaluated on speechocean762, showing\nthat it allows the GP to compute a test set output distribution that is more\nsimilar to the collection of reference outputs from the multiple human raters.\n","authors":["Jeremy H. M. Wong","Huayun Zhang","Nancy F. Chen"],"pdf_url":"https://arxiv.org/pdf/2306.02719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02715v1","updated":"2023-06-05T09:08:24Z","published":"2023-06-05T09:08:24Z","title":"Federated Intrusion Detection System based on Deep Belief Networks","summary":"  The vast increase of IoT technologies and the ever-evolving attack vectors\nand threat actors have increased cyber-security risks dramatically. Novel\nattacks can compromise IoT devices to gain access to sensitive data or control\nthem to deploy further malicious activities. The detection of novel attacks\noften relies upon AI solutions. A common approach to implementing AI-based IDS\nin distributed IoT systems is in a centralised manner. However, this approach\nmay violate data privacy and secrecy. In addition, centralised data collection\nprohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT\necosystems need to move towards a decentralised direction. FL has attracted\nsignificant interest in recent years due to its ability to perform\ncollaborative learning while preserving data confidentiality and locality.\nNevertheless, most FL-based IDS for IoT systems are designed under unrealistic\ndata distribution conditions. To that end, we design an experiment\nrepresentative of the real world and evaluate the performance of two FL IDS\nimplementations, one based on DNNs and another on our previous work on DBNs.\nFor our experiments, we rely on TON-IoT, a realistic IoT network traffic\ndataset, associating each IP address with a single FL client. Additionally, we\nexplore pre-training and investigate various aggregation methods to mitigate\nthe impact of data heterogeneity. Lastly, we benchmark our approach against a\ncentralised solution. The comparison shows that the heterogeneous nature of the\ndata has a considerable negative impact on the model performance when trained\nin a distributed manner. However, in the case of a pre-trained initial global\nFL model, we demonstrate a performance improvement of over 20% (F1-score) when\ncompared against a randomly initiated global model.\n","authors":["Othmane Belarbi","Theodoros Spyridopoulos","Eirini Anthi","Ioannis Mavromatis","Pietro Carnelli","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2306.02715v1.pdf","comment":"14 pages, 5 figues, 3 tables"},{"id":"http://arxiv.org/abs/2305.00650v2","updated":"2023-06-05T09:06:38Z","published":"2023-05-01T04:19:27Z","title":"Discover and Cure: Concept-aware Mitigation of Spurious Correlation","summary":"  Deep neural networks often rely on spurious correlations to make predictions,\nwhich hinders generalization beyond training environments. For instance, models\nthat associate cats with bed backgrounds can fail to predict the existence of\ncats in other environments without beds. Mitigating spurious correlations is\ncrucial in building trustworthy models. However, the existing works lack\ntransparency to offer insights into the mitigation process. In this work, we\npropose an interpretable framework, Discover and Cure (DISC), to tackle the\nissue. With human-interpretable concepts, DISC iteratively 1) discovers\nunstable concepts across different environments as spurious attributes, then 2)\nintervenes on the training data using the discovered concepts to reduce\nspurious correlation. Across systematic experiments, DISC provides superior\ngeneralization ability and interpretability than the existing approaches.\nSpecifically, it outperforms the state-of-the-art methods on an object\nrecognition task and a skin-lesion classification task by 7.5% and 9.6%,\nrespectively. Additionally, we offer theoretical analysis and guarantees to\nunderstand the benefits of models trained by DISC. Code and data are available\nat https://github.com/Wuyxin/DISC.\n","authors":["Shirley Wu","Mert Yuksekgonul","Linjun Zhang","James Zou"],"pdf_url":"https://arxiv.org/pdf/2305.00650v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2206.14578v2","updated":"2023-06-05T09:02:01Z","published":"2022-06-23T08:58:05Z","title":"Evaluating Generative Patent Language Models","summary":"  Generative language models are promising for assisting human writing in\nvarious domains. This manuscript aims to build generative language models in\nthe patent domain and evaluate model performance from a human-centric\nperspective. The perspective is to measure the ratio of keystrokes that can be\nsaved by autocompletion based on generative patent language models. A higher\nratio means a more effective model which can save more keystrokes. This metric\ncan be used to benchmark model performance. The metric is different from\nconventional machine-centric metrics that are token-based instead of\nkeystroke-based. In terms of model size, the largest model built in this\nmanuscript is 6B, which is state-of-the-art in the patent domain. Based on the\nmetric, it is found that the largest model is not necessarily the best for the\nhuman-centric metric. The finding means that keeping increasing model sizes in\nthe patent domain might be unnecessary if the purpose is to assist human\nwriting with autocompletion. Several patent language models are pre-trained\nfrom scratch in this research. The pre-trained models are released for future\nresearchers. Several visualization tools are also provided. The importance of\nbuilding a generative language model in the patent domain is the potential to\nfacilitate creativity and innovations in the future.\n","authors":["Jieh-Sheng Lee"],"pdf_url":"https://arxiv.org/pdf/2206.14578v2.pdf","comment":"12 pages, 7 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2306.02709v1","updated":"2023-06-05T09:01:38Z","published":"2023-06-05T09:01:38Z","title":"Comparative Study on Semi-supervised Learning Applied for Anomaly\n  Detection in Hydraulic Condition Monitoring System","summary":"  Condition-based maintenance is becoming increasingly important in hydraulic\nsystems. However, anomaly detection for these systems remains challenging,\nespecially since that anomalous data is scarce and labeling such data is\ntedious and even dangerous. Therefore, it is advisable to make use of\nunsupervised or semi-supervised methods, especially for semi-supervised\nlearning which utilizes unsupervised learning as a feature extraction mechanism\nto aid the supervised part when only a small number of labels are available.\nThis study systematically compares semi-supervised learning methods applied for\nanomaly detection in hydraulic condition monitoring systems. Firstly, thorough\ndata analysis and feature learning were carried out to understand the\nopen-sourced hydraulic condition monitoring dataset. Then, various methods were\nimplemented and evaluated including traditional stand-alone semi-supervised\nlearning models (e.g., one-class SVM, Robust Covariance), ensemble models\n(e.g., Isolation Forest), and deep neural network based models (e.g.,\nautoencoder, Hierarchical Extreme Learning Machine (HELM)). Typically, this\nstudy customized and implemented an extreme learning machine based\nsemi-supervised HELM model and verified its superiority over other\nsemi-supervised methods. Extensive experiments show that the customized HELM\nmodel obtained state-of-the-art performance with the highest accuracy (99.5%),\nthe lowest false positive rate (0.015), and the best F1-score (0.985) beating\nother semi-supervised methods.\n","authors":["Yongqi Dong","Kejia Chen","Zhiyuan Ma"],"pdf_url":"https://arxiv.org/pdf/2306.02709v1.pdf","comment":"7 pages, 8 figures, accepted by 2023 IEEE International Conference on\n  Systems, Man, and Cybernetics (SMC 2023) https://ieeesmc2023.org/"},{"id":"http://arxiv.org/abs/2306.02707v1","updated":"2023-06-05T08:58:39Z","published":"2023-06-05T08:58:39Z","title":"Orca: Progressive Learning from Complex Explanation Traces of GPT-4","summary":"  Recent research has focused on enhancing the capability of smaller models\nthrough imitation learning, drawing on the outputs generated by large\nfoundation models (LFMs). A number of issues impact the quality of these\nmodels, ranging from limited imitation signals from shallow LFM outputs; small\nscale homogeneous training data; and most notably a lack of rigorous evaluation\nresulting in overestimating the small model's capability as they tend to learn\nto imitate the style, but not the reasoning process of LFMs. To address these\nchallenges, we develop Orca (We are working with our legal team to publicly\nrelease a diff of the model weights in accordance with LLaMA's release policy\nto be published at https://aka.ms/orca-lm), a 13-billion parameter model that\nlearns to imitate the reasoning process of LFMs. Orca learns from rich signals\nfrom GPT-4 including explanation traces; step-by-step thought processes; and\nother complex instructions, guided by teacher assistance from ChatGPT. To\npromote this progressive learning, we tap into large-scale and diverse\nimitation data with judicious sampling and selection. Orca surpasses\nconventional state-of-the-art instruction-tuned models such as Vicuna-13B by\nmore than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard\n(BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH\nbenchmark and shows competitive performance (4 pts gap with optimized system\nmessage) in professional and academic examinations like the SAT, LSAT, GRE, and\nGMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our\nresearch indicates that learning from step-by-step explanations, whether these\nare generated by humans or more advanced AI models, is a promising direction to\nimprove model capabilities and skills.\n","authors":["Subhabrata Mukherjee","Arindam Mitra","Ganesh Jawahar","Sahaj Agarwal","Hamid Palangi","Ahmed Awadallah"],"pdf_url":"https://arxiv.org/pdf/2306.02707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12159v2","updated":"2023-06-05T08:56:05Z","published":"2023-01-28T11:10:50Z","title":"ClusterFuG: Clustering Fully connected Graphs by Multicut","summary":"  We propose a graph clustering formulation based on multicut (a.k.a. weighted\ncorrelation clustering) on the complete graph. Our formulation does not need\nspecification of the graph topology as in the original sparse formulation of\nmulticut, making our approach simpler and potentially better performing. In\ncontrast to unweighted correlation clustering we allow for a more expressive\nweighted cost structure. In dense multicut, the clustering objective is given\nin a factorized form as inner products of node feature vectors. This allows for\nan efficient formulation and inference in contrast to multicut/weighted\ncorrelation clustering, which has at least quadratic representation and\ncomputation complexity when working on the complete graph. We show how to\nrewrite classical greedy algorithms for multicut in our dense setting and how\nto modify them for greater efficiency and solution quality. In particular, our\nalgorithms scale to graphs with tens of thousands of nodes. Empirical evidence\non instance segmentation on Cityscapes and clustering of ImageNet datasets\nshows the merits of our approach.\n","authors":["Ahmed Abbas","Paul Swoboda"],"pdf_url":"https://arxiv.org/pdf/2301.12159v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.02701v1","updated":"2023-06-05T08:45:44Z","published":"2023-06-05T08:45:44Z","title":"Unlocking the Potential of Federated Learning for Deeper Models","summary":"  Federated learning (FL) is a new paradigm for distributed machine learning\nthat allows a global model to be trained across multiple clients without\ncompromising their privacy. Although FL has demonstrated remarkable success in\nvarious scenarios, recent studies mainly utilize shallow and small neural\nnetworks. In our research, we discover a significant performance decline when\napplying the existing FL framework to deeper neural networks, even when client\ndata are independently and identically distributed (i.i.d.). Our further\ninvestigation shows that the decline is due to the continuous accumulation of\ndissimilarities among client models during the layer-by-layer back-propagation\nprocess, which we refer to as \"divergence accumulation.\" As deeper models\ninvolve a longer chain of divergence accumulation, they tend to manifest\ngreater divergence, subsequently leading to performance decline. Both\ntheoretical derivations and empirical evidence are proposed to support the\nexistence of divergence accumulation and its amplified effects in deeper\nmodels. To address this issue, we propose several technical guidelines based on\nreducing divergence, such as using wider models and reducing the receptive\nfield. These approaches can greatly improve the accuracy of FL on deeper\nmodels. For example, the application of these guidelines can boost the\nResNet101 model's performance by as much as 43\\% on the Tiny-ImageNet dataset.\n","authors":["Haolin Wang","Xuefeng Liu","Jianwei Niu","Shaojie Tang","Jiaxing Shen"],"pdf_url":"https://arxiv.org/pdf/2306.02701v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.01677v2","updated":"2023-06-05T08:35:02Z","published":"2023-02-03T11:58:14Z","title":"Revisiting Personalized Federated Learning: Robustness Against Backdoor\n  Attacks","summary":"  In this work, besides improving prediction accuracy, we study whether\npersonalization could bring robustness benefits to backdoor attacks. We conduct\nthe first study of backdoor attacks in the pFL framework, testing 4 widely used\nbackdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and\nCIFAR-10, a total of 600 experiments. The study shows that pFL methods with\npartial model-sharing can significantly boost robustness against backdoor\nattacks. In contrast, pFL methods with full model-sharing do not show\nrobustness. To analyze the reasons for varying robustness performances, we\nprovide comprehensive ablation studies on different pFL methods. Based on our\nfindings, we further propose a lightweight defense method, Simple-Tuning, which\nempirically improves defense performance against backdoor attacks. We believe\nthat our work could provide both guidance for pFL application in terms of its\nrobustness and offer valuable insights to design more robust FL methods in the\nfuture. We open-source our code to establish the first benchmark for black-box\nbackdoor attacks in pFL:\nhttps://github.com/alibaba/FederatedScope/tree/backdoor-bench.\n","authors":["Zeyu Qin","Liuyi Yao","Daoyuan Chen","Yaliang Li","Bolin Ding","Minhao Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.01677v2.pdf","comment":"KDD 2023"},{"id":"http://arxiv.org/abs/2305.18477v2","updated":"2023-06-05T08:33:25Z","published":"2023-05-29T11:05:20Z","title":"Beyond the Meta: Leveraging Game Design Parameters for Patch-Agnostic\n  Esport Analytics","summary":"  Esport games comprise a sizeable fraction of the global games market, and is\nthe fastest growing segment in games. This has given rise to the domain of\nesports analytics, which uses telemetry data from games to inform players,\ncoaches, broadcasters and other stakeholders. Compared to traditional sports,\nesport titles change rapidly, in terms of mechanics as well as rules. Due to\nthese frequent changes to the parameters of the game, esport analytics models\ncan have a short life-spam, a problem which is largely ignored within the\nliterature. This paper extracts information from game design (i.e. patch notes)\nand utilises clustering techniques to propose a new form of character\nrepresentation. As a case study, a neural network model is trained to predict\nthe number of kills in a Dota 2 match utilising this novel character\nrepresentation technique. The performance of this model is then evaluated\nagainst two distinct baselines, including conventional techniques. Not only did\nthe model significantly outperform the baselines in terms of accuracy (85%\nAUC), but the model also maintains the accuracy in two newer iterations of the\ngame that introduced one new character and a brand new character type. These\nchanges introduced to the design of the game would typically break conventional\ntechniques that are commonly used within the literature. Therefore, the\nproposed methodology for representing characters can increase the life-spam of\nmachine learning models as well as contribute to a higher performance when\ncompared to traditional techniques typically employed within the literature.\n","authors":["Alan Pedrassoli Chitayat","Florian Block","James Walker","Anders Drachen"],"pdf_url":"https://arxiv.org/pdf/2305.18477v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02689v1","updated":"2023-06-05T08:29:55Z","published":"2023-06-05T08:29:55Z","title":"Solving NP-hard Min-max Routing Problems as Sequential Generation with\n  Equity Context","summary":"  Min-max routing problems aim to minimize the maximum tour length among agents\nas they collaboratively visit all cities, i.e., the completion time. These\nproblems include impactful real-world applications but are known as NP-hard.\nExisting methods are facing challenges, particularly in large-scale problems\nthat require the coordination of numerous agents to cover thousands of cities.\nThis paper proposes a new deep-learning framework to solve large-scale min-max\nrouting problems. We model the simultaneous decision-making of multiple agents\nas a sequential generation process, allowing the utilization of scalable\ndeep-learning models for sequential decision-making. In the sequentially\napproximated problem, we propose a scalable contextual Transformer model,\nEquity-Transformer, which generates sequential actions considering an equitable\nworkload among other agents. The effectiveness of Equity-Transformer is\ndemonstrated through its superior performance in two representative min-max\nrouting tasks: the min-max multiple traveling salesman problem (min-max mTSP)\nand the min-max multiple pick-up and delivery problem (min-max mPDP). Notably,\nour method achieves significant reductions of runtime, approximately 335 times,\nand cost values of about 53% compared to a competitive heuristic (LKH3) in the\ncase of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source\ncode: https://github.com/kaist-silab/equity-transformer\n","authors":["Jiwoo Son","Minsu Kim","Sanghyeok Choi","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02689v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.02688v1","updated":"2023-06-05T08:28:42Z","published":"2023-06-05T08:28:42Z","title":"Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided\n  Exploration for Mitigating Scale Shift on Combinatorial Optimization","summary":"  This paper proposes Meta-SAGE, a novel approach for improving the scalability\nof deep reinforcement learning models for combinatorial optimization (CO)\ntasks. Our method adapts pre-trained models to larger-scale problems in test\ntime by suggesting two components: a scale meta-learner (SML) and scheduled\nadaptation with guided exploration (SAGE). First, SML transforms the context\nembedding for subsequent adaptation of SAGE based on scale information. Then,\nSAGE adjusts the model parameters dedicated to the context embedding for a\nspecific instance. SAGE introduces locality bias, which encourages selecting\nnearby locations to determine the next location. The locality bias gradually\ndecays as the model is adapted to the target instance. Results show that\nMeta-SAGE outperforms previous adaptation methods and significantly improves\nscalability in representative CO tasks. Our source code is available at\nhttps://github.com/kaist-silab/meta-sage\n","authors":["Jiwoo Son","Minsu Kim","Hyeonah Kim","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02688v1.pdf","comment":"18 pages, 9 figures, International Conference on Machine Learning\n  (ICML) 2023"},{"id":"http://arxiv.org/abs/2306.02685v1","updated":"2023-06-05T08:22:18Z","published":"2023-06-05T08:22:18Z","title":"Predicting malaria dynamics in Burundi using deep Learning Models","summary":"  Malaria continues to be a major public health problem on the African\ncontinent, particularly in Sub-Saharan Africa. Nonetheless, efforts are\nongoing, and significant progress has been made. In Burundi, malaria is among\nthe main public health concerns. In the literature, there are limited\nprediction models for Burundi. We know that such tools are much needed for\ninterventions design. In our study, we built machine-learning based models to\nestimates malaria cases in Burundi. The forecast was carried out at province\nlevel, allowing us to estimate malaria cases on a national scale as well. Long\nshort term memory (LSTM) model, a type of deep learning model has been used to\nachieve best results using climate-change related factors such as temperature,\nrainfal, and relative humidity, together with malaria historical data and human\npopulation. The results showed that at country level different tuning of\nparameters can be used in order to determine the minimum and maximum expected\nmalaria\n","authors":["Daxelle Sakubu","Kelly Joelle Gatore Sinigirira","David Niyukuri"],"pdf_url":"https://arxiv.org/pdf/2306.02685v1.pdf","comment":null}]},"2023-06-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2104.15114v2","updated":"2023-06-04T22:43:14Z","published":"2021-04-30T16:55:28Z","title":"Paraphrastic Representations at Scale","summary":"  We present a system that allows users to train their own state-of-the-art\nparaphrastic sentence representations in a variety of languages. We also\nrelease trained models for English, Arabic, German, French, Spanish, Russian,\nTurkish, and Chinese. We train these models on large amounts of data, achieving\nsignificantly improved performance from the original papers proposing the\nmethods on a suite of monolingual semantic similarity, cross-lingual semantic\nsimilarity, and bitext mining tasks. Moreover, the resulting models surpass all\nprior work on unsupervised semantic textual similarity, significantly\noutperforming even BERT-based models like Sentence-BERT (Reimers and Gurevych,\n2019). Additionally, our models are orders of magnitude faster than prior work\nand can be used on CPU with little difference in inference speed (even improved\nspeed over GPU when using more CPU cores), making these models an attractive\nchoice for users without access to GPUs or for use on embedded devices.\nFinally, we add significantly increased functionality to the code bases for\ntraining paraphrastic sentence models, easing their use for both inference and\nfor training them for any desired language with parallel data. We also include\ncode to automatically download and preprocess training data.\n","authors":["John Wieting","Kevin Gimpel","Graham Neubig","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2104.15114v2.pdf","comment":"Published as a demo paper at EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.10726v2","updated":"2023-06-04T22:42:10Z","published":"2022-12-21T02:41:40Z","title":"Beyond Contrastive Learning: A Variational Generative Model for\n  Multilingual Retrieval","summary":"  Contrastive learning has been successfully used for retrieval of semantically\naligned sentences, but it often requires large batch sizes or careful\nengineering to work well. In this paper, we instead propose a generative model\nfor learning multilingual text embeddings which can be used to retrieve or\nscore sentence pairs. Our model operates on parallel data in $N$ languages and,\nthrough an approximation we introduce, efficiently encourages source separation\nin this multilingual setting, separating semantic information that is shared\nbetween translations from stylistic or language-specific variation. We show\ncareful large-scale comparisons between contrastive and generation-based\napproaches for learning multilingual text embeddings, a comparison that has not\nbeen done to the best of our knowledge despite the popularity of these\napproaches. We evaluate this method on a suite of tasks including semantic\nsimilarity, bitext mining, and cross-lingual question retrieval -- the last of\nwhich we introduce in this paper. Overall, our Variational Multilingual\nSource-Separation Transformer (VMSST) model outperforms both a strong\ncontrastive and generative baseline on these tasks.\n","authors":["John Wieting","Jonathan H. Clark","William W. Cohen","Graham Neubig","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2212.10726v2.pdf","comment":"Published as a long paper at ACL 2023"},{"id":"http://arxiv.org/abs/2202.02842v3","updated":"2023-06-04T21:59:47Z","published":"2022-02-06T20:07:35Z","title":"Evaluating natural language processing models with generalization\n  metrics that do not need access to any training or testing data","summary":"  Selecting suitable architecture parameters and training hyperparameters is\nessential for enhancing machine learning (ML) model performance. Several recent\nempirical studies conduct large-scale correlational analysis on neural networks\n(NNs) to search for effective \\emph{generalization metrics} that can guide this\ntype of model selection. Effective metrics are typically expected to correlate\nstrongly with test performance. In this paper, we expand on prior analyses by\nexamining generalization-metric-based model selection with the following\nobjectives: (i) focusing on natural language processing (NLP) tasks, as prior\nwork primarily concentrates on computer vision (CV) tasks; (ii) considering\nmetrics that directly predict \\emph{test error} instead of the\n\\emph{generalization gap}; (iii) exploring metrics that do not need access to\ndata to compute. From these objectives, we are able to provide the first model\nselection results on large pretrained Transformers from Huggingface using\ngeneralization metrics. Our analyses consider (I) hundreds of Transformers\ntrained in different settings, in which we systematically vary the amount of\ndata, the model size and the optimization hyperparameters, (II) a total of 51\npretrained Transformers from eight families of Huggingface NLP models,\nincluding GPT2, BERT, etc., and (III) a total of 28 existing and novel\ngeneralization metrics. Despite their niche status, we find that metrics\nderived from the heavy-tail (HT) perspective are particularly useful in NLP\ntasks, exhibiting stronger correlations than other, more popular metrics. To\nfurther examine these metrics, we extend prior formulations relying on power\nlaw (PL) spectral distributions to exponential (EXP) and\nexponentially-truncated power law (E-TPL) families.\n","authors":["Yaoqing Yang","Ryan Theisen","Liam Hodgkinson","Joseph E. Gonzalez","Kannan Ramchandran","Charles H. Martin","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2202.02842v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02492v1","updated":"2023-06-04T21:53:04Z","published":"2023-06-04T21:53:04Z","title":"RadLing: Towards Efficient Radiology Report Understanding","summary":"  Most natural language tasks in the radiology domain use language models\npre-trained on biomedical corpus. There are few pretrained language models\ntrained specifically for radiology, and fewer still that have been trained in a\nlow data setting and gone on to produce comparable results in fine-tuning\ntasks. We present RadLing, a continuously pretrained language model using\nElectra-small (Clark et al., 2020) architecture, trained using over 500K\nradiology reports, that can compete with state-of-the-art results for fine\ntuning tasks in radiology domain. Our main contribution in this paper is\nknowledge-aware masking which is a taxonomic knowledge-assisted pretraining\ntask that dynamically masks tokens to inject knowledge during pretraining. In\naddition, we also introduce an knowledge base-aided vocabulary extension to\nadapt the general tokenization vocabulary to radiology domain.\n","authors":["Rikhiya Ghosh","Sanjeev Kumar Karn","Manuela Daniela Danu","Larisa Micu","Ramya Vunikili","Oladimeji Farri"],"pdf_url":"https://arxiv.org/pdf/2306.02492v1.pdf","comment":"Association for Computational Linguistics (ACL), 2023"},{"id":"http://arxiv.org/abs/2205.10282v2","updated":"2023-06-04T21:20:01Z","published":"2022-05-20T16:26:39Z","title":"Heterformer: Transformer-based Deep Node Representation Learning on\n  Heterogeneous Text-Rich Networks","summary":"  Representation learning on networks aims to derive a meaningful vector\nrepresentation for each node, thereby facilitating downstream tasks such as\nlink prediction, node classification, and node clustering. In heterogeneous\ntext-rich networks, this task is more challenging due to (1) presence or\nabsence of text: Some nodes are associated with rich textual information, while\nothers are not; (2) diversity of types: Nodes and edges of multiple types form\na heterogeneous network structure. As pretrained language models (PLMs) have\ndemonstrated their effectiveness in obtaining widely generalizable text\nrepresentations, a substantial amount of effort has been made to incorporate\nPLMs into representation learning on text-rich networks. However, few of them\ncan jointly consider heterogeneous structure (network) information as well as\nrich textual semantic information of each node effectively. In this paper, we\npropose Heterformer, a Heterogeneous Network-Empowered Transformer that\nperforms contextualized text encoding and heterogeneous structure encoding in a\nunified model. Specifically, we inject heterogeneous structure information into\neach Transformer layer when encoding node texts. Meanwhile, Heterformer is\ncapable of characterizing node/edge type heterogeneity and encoding nodes with\nor without texts. We conduct comprehensive experiments on three tasks (i.e.,\nlink prediction, node classification, and node clustering) on three large-scale\ndatasets from different domains, where Heterformer outperforms competitive\nbaselines significantly and consistently.\n","authors":["Bowen Jin","Yu Zhang","Qi Zhu","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2205.10282v2.pdf","comment":"KDD 2023. (Code: https://github.com/PeterGriffinJin/Heterformer)"},{"id":"http://arxiv.org/abs/2212.08061v2","updated":"2023-06-04T21:09:55Z","published":"2022-12-15T18:59:32Z","title":"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in\n  Zero-Shot Reasoning","summary":"  Generating a Chain of Thought (CoT) has been shown to consistently improve\nlarge language model (LLM) performance on a wide range of NLP tasks. However,\nprior work has mainly focused on logical reasoning tasks (e.g. arithmetic,\ncommonsense QA); it remains unclear whether improvements hold for more diverse\ntypes of reasoning, especially in socially situated contexts. Concretely, we\nperform a controlled evaluation of zero-shot CoT across two socially sensitive\ndomains: harmful questions and stereotype benchmarks. We find that zero-shot\nCoT reasoning in sensitive domains significantly increases a model's likelihood\nto produce harmful or undesirable output, with trends holding across different\nprompt formats and model variants. Furthermore, we show that harmful CoTs\nincrease with model size, but decrease with improved instruction following. Our\nwork suggests that zero-shot CoT should be used with caution on socially\nimportant tasks, especially when marginalized groups or sensitive topics are\ninvolved.\n","authors":["Omar Shaikh","Hongxin Zhang","William Held","Michael Bernstein","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2212.08061v2.pdf","comment":"ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2305.08195v2","updated":"2023-06-04T21:05:26Z","published":"2023-05-14T16:20:09Z","title":"Learning to Simulate Natural Language Feedback for Interactive Semantic\n  Parsing","summary":"  Interactive semantic parsing based on natural language (NL) feedback, where\nusers provide feedback to correct the parser mistakes, has emerged as a more\npractical scenario than the traditional one-shot semantic parsing. However,\nprior work has heavily relied on human-annotated feedback data to train the\ninteractive semantic parser, which is prohibitively expensive and not scalable.\nIn this work, we propose a new task of simulating NL feedback for interactive\nsemantic parsing. We accompany the task with a novel feedback evaluator. The\nevaluator is specifically designed to assess the quality of the simulated\nfeedback, based on which we decide the best feedback simulator from our\nproposed variants. On a text-to-SQL dataset, we show that our feedback\nsimulator can generate high-quality NL feedback to boost the error correction\nability of a specific parser. In low-data settings, our feedback simulator can\nhelp achieve comparable error correction performance as trained using the\ncostly, full set of human annotations.\n","authors":["Hao Yan","Saurabh Srivastava","Yintao Tai","Sida I. Wang","Wen-tau Yih","Ziyu Yao"],"pdf_url":"https://arxiv.org/pdf/2305.08195v2.pdf","comment":"Accepted to ACL 2023. 18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.02475v1","updated":"2023-06-04T20:47:07Z","published":"2023-06-04T20:47:07Z","title":"Modeling Cross-Cultural Pragmatic Inference with Codenames Duet","summary":"  Pragmatic reference enables efficient interpersonal communication. Prior work\nuses simple reference games to test models of pragmatic reasoning, often with\nunidentified speakers and listeners. In practice, however, speakers'\nsociocultural background shapes their pragmatic assumptions. For example,\nreaders of this paper assume NLP refers to \"Natural Language Processing,\" and\nnot \"Neuro-linguistic Programming.\" This work introduces the Cultural Codes\ndataset, which operationalizes sociocultural pragmatic inference in a simple\nword reference game.\n  Cultural Codes is based on the multi-turn collaborative two-player game,\nCodenames Duet. Our dataset consists of 794 games with 7,703 turns, distributed\nacross 153 unique players. Alongside gameplay, we collect information about\nplayers' personalities, values, and demographics. Utilizing theories of\ncommunication and pragmatics, we predict each player's actions via joint\nmodeling of their sociocultural priors and the game context. Our experiments\nshow that accounting for background characteristics significantly improves\nmodel performance for tasks related to both clue giving and guessing,\nindicating that sociocultural priors play a vital role in gameplay decisions.\n","authors":["Omar Shaikh","Caleb Ziems","William Held","Aryan J. Pariani","Fred Morstatter","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2306.02475v1.pdf","comment":"ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2210.06068v2","updated":"2023-06-04T20:42:19Z","published":"2022-10-12T10:19:44Z","title":"Investigating Massive Multilingual Pre-Trained Machine Translation\n  Models for Clinical Domain via Transfer Learning","summary":"  Massively multilingual pre-trained language models (MMPLMs) are developed in\nrecent years demonstrating superpowers and the pre-knowledge they acquire for\ndownstream tasks. This work investigates whether MMPLMs can be applied to\nclinical domain machine translation (MT) towards entirely unseen languages via\ntransfer learning. We carry out an experimental investigation using Meta-AI's\nMMPLMs ``wmt21-dense-24-wide-en-X and X-en (WMT21fb)'' which were pre-trained\non 7 language pairs and 14 translation directions including English to Czech,\nGerman, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite\ndirection. We fine-tune these MMPLMs towards English-\\textit{Spanish} language\npair which \\textit{did not exist at all} in their original pre-trained corpora\nboth implicitly and explicitly. We prepare carefully aligned \\textit{clinical}\ndomain data for this fine-tuning, which is different from their original mixed\ndomain knowledge. Our experimental result shows that the fine-tuning is very\nsuccessful using just 250k well-aligned in-domain EN-ES segments for three\nsub-task translation testings: clinical cases, clinical terms, and ontology\nconcepts. It achieves very close evaluation scores to another MMPLM NLLB from\nMeta-AI, which included Spanish as a high-resource setting in the pre-training.\nTo the best of our knowledge, this is the first work on using MMPLMs towards\n\\textit{clinical domain transfer-learning NMT} successfully for totally unseen\nlanguages during pre-training.\n","authors":["Lifeng Han","Gleb Erofeev","Irina Sorokina","Serge Gladkoff","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2210.06068v2.pdf","comment":"Accepted to ClinicalNLP-2023 WS@ACL-2023"},{"id":"http://arxiv.org/abs/2306.02457v1","updated":"2023-06-04T20:18:40Z","published":"2023-06-04T20:18:40Z","title":"Adaptive and Personalized Exercise Generation for Online Language\n  Learning","summary":"  Adaptive learning aims to provide customized educational activities (e.g.,\nexercises) to address individual learning needs. However, manual construction\nand delivery of such activities is a laborious process. Thus, in this paper, we\nstudy a novel task of adaptive and personalized exercise generation for online\nlanguage learning. To this end, we combine a knowledge tracing model that\nestimates each student's evolving knowledge states from their learning history\nand a controlled text generation model that generates exercise sentences based\non the student's current estimated knowledge state and instructor requirements\nof desired properties (e.g., domain knowledge and difficulty). We train and\nevaluate our model on real-world learner interaction data from Duolingo and\ndemonstrate that LMs guided by student states can generate superior exercises.\nThen, we discuss the potential use of our model in educational applications\nusing various simulations. These simulations show that our model can adapt to\nstudents' individual abilities and can facilitate their learning efficiency by\npersonalizing learning sequences.\n","authors":["Peng Cui","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2306.02457v1.pdf","comment":"To appear at ACL 2023"},{"id":"http://arxiv.org/abs/2306.02428v1","updated":"2023-06-04T18:21:44Z","published":"2023-06-04T18:21:44Z","title":"Taught by the Internet, Exploring Bias in OpenAIs GPT3","summary":"  This research delves into the current literature on bias in Natural Language\nProcessing Models and the techniques proposed to mitigate the problem of bias,\nincluding why it is important to tackle bias in the first place. Additionally,\nthese techniques are further analysed in the light of newly developed models\nthat tower in size over past editions. To achieve those aims, the authors of\nthis paper conducted their research on GPT3 by OpenAI, the largest NLP model\navailable to consumers today. With 175 billion parameters in contrast to BERTs\n340 million, GPT3 is the perfect model to test the common pitfalls of NLP\nmodels. Tests were conducted through the development of an Applicant Tracking\nSystem using GPT3. For the sake of feasibility and time constraints, the tests\nprimarily focused on gender bias, rather than all or multiple types of bias.\nFinally, current mitigation techniques are considered and tested to measure\ntheir degree of functionality.\n","authors":["Ali Ayaz","Aditya Nawalgaria","Ruilian Yin"],"pdf_url":"https://arxiv.org/pdf/2306.02428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03954v5","updated":"2023-06-04T17:40:32Z","published":"2022-04-08T09:28:20Z","title":"Are We Really Making Much Progress in Text Classification? A Comparative\n  Review","summary":"  This study reviews and compares methods for single-label and multi-label text\nclassification, categorized into bag-of-words, sequence-based, graph-based, and\nhierarchical methods. The comparison aggregates results from the literature\nover five single-label and seven multi-label datasets and complements them with\nnew experiments. The findings reveal that all recently proposed graph-based and\nhierarchy-based methods fail to outperform pre-trained language models and\nsometimes perform worse than standard machine learning methods like a\nmultilayer perceptron on a bag-of-words. To assess the true scientific progress\nin text classification, future work should thoroughly test against strong\nbag-of-words baselines and state-of-the-art pre-trained language models.\n","authors":["Lukas Galke","Andor Diera","Bao Xin Lin","Bhakti Khera","Tim Meuser","Tushar Singhal","Fabian Karl","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2204.03954v5.pdf","comment":"Update: revised text and new included methods. This work is an\n  extension of \"Bag-of-Words vs. Graph vs. Sequence in Text Classification:\n  Questioning the Necessity of Text-Graphs and the Surprising Strength of a\n  Wide MLP. ACL (1) 2022: 4038-4051\", URL:\n  https://aclanthology.org/2022.acl-long.279/"},{"id":"http://arxiv.org/abs/2306.02408v1","updated":"2023-06-04T17:02:59Z","published":"2023-06-04T17:02:59Z","title":"Evaluating and Improving Tool-Augmented Computation-Intensive Math\n  Reasoning","summary":"  Chain-of-thought prompting~(CoT) and tool augmentation have been validated in\nrecent work as effective practices for improving large language models~(LLMs)\nto perform step-by-step reasoning on complex math-related tasks. However, most\nexisting math reasoning datasets may be not able to fully evaluate and analyze\nthe ability of LLMs in manipulating tools and performing reasoning, as they may\nonly require very few invocations of tools or miss annotations for evaluating\nintermediate reasoning steps. To address the issue, we construct \\textbf{CARP},\na new Chinese dataset consisting of 4,886 computation-intensive algebra\nproblems with formulated annotations on intermediate steps. In CARP, we test\nfour LLMs with CoT prompting, and find that they are all prone to make mistakes\nat the early steps of the solution, leading to wrong answers. Based on this\nfinding, we propose a new approach that can deliberate the reasoning steps with\ntool interfaces, namely \\textbf{DELI}. In DELI, we first initialize a\nstep-by-step solution based on retrieved exemplars, then iterate two\ndeliberation procedures that check and refine the intermediate steps of the\ngenerated solution, from the perspectives of tool manipulation and natural\nlanguage reasoning, until obtaining converged solutions or reaching the maximum\nturn. Experimental results on CARP and six other datasets show that the\nproposed DELI mostly outperforms competitive baselines, and can further boost\nthe performance of existing CoT methods. Our data and code are available in\n\\url{https://github.com/RUCAIBox/CARP}.\n","authors":["Beichen Zhang","Kun Zhou","Xilin Wei","Wayne Xin Zhao","Jing Sha","Shijin Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2306.02408v1.pdf","comment":"17 pages, working in progress"},{"id":"http://arxiv.org/abs/2306.02405v1","updated":"2023-06-04T16:52:11Z","published":"2023-06-04T16:52:11Z","title":"An Information-Theoretic Analysis of Self-supervised Discrete\n  Representations of Speech","summary":"  Self-supervised representation learning for speech often involves a\nquantization step that transforms the acoustic input into discrete units.\nHowever, it remains unclear how to characterize the relationship between these\ndiscrete units and abstract phonetic categories such as phonemes. In this\npaper, we develop an information-theoretic framework whereby we represent each\nphonetic category as a distribution over discrete units. We then apply our\nframework to two different self-supervised models (namely wav2vec 2.0 and XLSR)\nand use American English speech as a case study. Our study demonstrates that\nthe entropy of phonetic distributions reflects the variability of the\nunderlying speech sounds, with phonetically similar sounds exhibiting similar\ndistributions. While our study confirms the lack of direct, one-to-one\ncorrespondence, we find an intriguing, indirect relationship between phonetic\ncategories and discrete units.\n","authors":["Badr M. Abdullah","Mohammed Maqsood Shaik","Bernd Möbius","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2306.02405v1.pdf","comment":"Accepted in Interspeech 2023"},{"id":"http://arxiv.org/abs/2305.13628v2","updated":"2023-06-04T16:32:41Z","published":"2023-05-23T02:52:16Z","title":"Improving Self-training for Cross-lingual Named Entity Recognition with\n  Contrastive and Prototype Learning","summary":"  In cross-lingual named entity recognition (NER), self-training is commonly\nused to bridge the linguistic gap by training on pseudo-labeled target-language\ndata. However, due to sub-optimal performance on target languages, the pseudo\nlabels are often noisy and limit the overall performance. In this work, we aim\nto improve self-training for cross-lingual NER by combining representation\nlearning and pseudo label refinement in one coherent framework. Our proposed\nmethod, namely ContProto mainly comprises two components: (1) contrastive\nself-training and (2) prototype-based pseudo-labeling. Our contrastive\nself-training facilitates span classification by separating clusters of\ndifferent classes, and enhances cross-lingual transferability by producing\nclosely-aligned representations between the source and target language.\nMeanwhile, prototype-based pseudo-labeling effectively improves the accuracy of\npseudo labels during training. We evaluate ContProto on multiple transfer\npairs, and experimental results show our method brings in substantial\nimprovements over current state-of-the-art methods.\n","authors":["Ran Zhou","Xin Li","Lidong Bing","Erik Cambria","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2305.13628v2.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.02388v1","updated":"2023-06-04T15:44:51Z","published":"2023-06-04T15:44:51Z","title":"Commonsense Knowledge Transfer for Pre-trained Language Models","summary":"  Despite serving as the foundation models for a wide range of NLP benchmarks,\npre-trained language models have shown limited capabilities of acquiring\nimplicit commonsense knowledge from self-supervision alone, compared to\nlearning linguistic and factual knowledge that appear more explicitly in the\nsurface patterns in text. In this work, we introduce commonsense knowledge\ntransfer, a framework to transfer the commonsense knowledge stored in a neural\ncommonsense knowledge model to a general-purpose pre-trained language model. It\nfirst exploits general texts to form queries for extracting commonsense\nknowledge from the neural commonsense knowledge model and then refines the\nlanguage model with two self-supervised objectives: commonsense mask infilling\nand commonsense relation prediction, which align human language with the\nunderlying commonsense knowledge. Empirical results show that our approach\nconsistently improves the model's performance on downstream tasks that require\ncommonsense reasoning. Moreover, we find that the improvement is more\nsignificant in the few-shot setting. This suggests that our approach helps\nlanguage models better transfer to downstream tasks without extensive\nsupervision by injecting commonsense knowledge into their parameters.\n","authors":["Wangchunshu Zhou","Ronan Le Bras","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2306.02388v1.pdf","comment":"ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.02383v1","updated":"2023-06-04T15:33:16Z","published":"2023-06-04T15:33:16Z","title":"Evolution of Efficient Symbolic Communication Codes","summary":"  The paper explores how the human natural language structure can be seen as a\nproduct of evolution of inter-personal communication code, targeting\nmaximisation of such culture-agnostic and cross-lingual metrics such as\nanti-entropy, compression factor and cross-split F1 score. The exploration is\ndone as part of a larger unsupervised language learning effort, the attempt is\nmade to perform meta-learning in a space of hyper-parameters maximising F1\nscore based on the \"ground truth\" language structure, by means of maximising\nthe metrics mentioned above. The paper presents preliminary results of\ncross-lingual word-level segmentation tokenisation study for Russian, Chinese\nand English as well as subword segmentation or morphological parsing study for\nEnglish. It is found that language structure form the word-level segmentation\nor tokenisation can be found as driven by all of these metrics, anti-entropy\nbeing more relevant to English and Russian while compression factor more\nspecific for Chinese. The study for subword segmentation or morphological\nparsing on English lexicon has revealed straight connection between the\ncompression been found to be associated with compression factor, while,\nsurprising, the same connection with anti-entropy has turned to be the inverse.\n","authors":["Anton Kolonin"],"pdf_url":"https://arxiv.org/pdf/2306.02383v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.02379v1","updated":"2023-06-04T15:26:28Z","published":"2023-06-04T15:26:28Z","title":"Modular Transformers: Compressing Transformers into Modularized Layers\n  for Flexible Efficient Inference","summary":"  Pre-trained Transformer models like T5 and BART have advanced the state of\nthe art on a wide range of text generation tasks. Compressing these models into\nsmaller ones has become critically important for practical use. Common neural\nnetwork compression techniques such as knowledge distillation or quantization\nare limited to static compression where the compression ratio is fixed. In this\npaper, we introduce Modular Transformers, a modularized encoder-decoder\nframework for flexible sequence-to-sequence model compression. Modular\nTransformers train modularized layers that have the same function of two or\nmore consecutive layers in the original model via module replacing and\nknowledge distillation. After training, the modularized layers can be flexibly\nassembled into sequence-to-sequence models that meet different\nperformance-efficiency trade-offs. Experimental results show that after a\nsingle training phase, by simply varying the assembling strategy, Modular\nTransformers can achieve flexible compression ratios from 1.1x to 6x with\nlittle to moderate relative performance drop.\n","authors":["Wangchunshu Zhou","Ronan Le Bras","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2306.02379v1.pdf","comment":"ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.02377v1","updated":"2023-06-04T15:23:16Z","published":"2023-06-04T15:23:16Z","title":"\"Are you telling me to put glasses on the dog?'' Content-Grounded\n  Annotation of Instruction Clarification Requests in the CoDraw Dataset","summary":"  Instruction Clarification Requests are a mechanism to solve communication\nproblems, which is very functional in instruction-following interactions.\nRecent work has argued that the CoDraw dataset is a valuable source of\nnaturally occurring iCRs. Beyond identifying when iCRs should be made, dialogue\nmodels should also be able to generate them with suitable form and content. In\nthis work, we introduce CoDraw-iCR (v2), which extends the existing iCR\nidentifiers fine-grained information grounded in the underlying dialogue game\nitems and possible actions. Our annotation can serve to model and evaluate\nrepair capabilities of dialogue agents.\n","authors":["Brielen Madureira","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2306.02377v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2205.15171v5","updated":"2023-06-04T14:40:45Z","published":"2022-05-30T15:21:25Z","title":"Modular and On-demand Bias Mitigation with Attribute-Removal Subnetworks","summary":"  Societal biases are reflected in large pre-trained language models and their\nfine-tuned versions on downstream tasks. Common in-processing bias mitigation\napproaches, such as adversarial training and mutual information removal,\nintroduce additional optimization criteria, and update the model to reach a new\ndebiased state. However, in practice, end-users and practitioners might prefer\nto switch back to the original model, or apply debiasing only on a specific\nsubset of protected attributes. To enable this, we propose a novel modular bias\nmitigation approach, consisting of stand-alone highly sparse debiasing\nsubnetworks, where each debiasing module can be integrated into the core model\non-demand at inference time. Our approach draws from the concept of \\emph{diff}\npruning, and proposes a novel training regime adaptable to various\nrepresentation disentanglement optimizations. We conduct experiments on three\nclassification tasks with gender, race, and age as protected attributes. The\nresults show that our modular approach, while maintaining task performance,\nimproves (or at least remains on-par with) the effectiveness of bias mitigation\nin comparison with baseline finetuning. Particularly on a two-attribute\ndataset, our approach with separately learned debiasing subnetworks shows\neffective utilization of either or both the subnetworks for selective bias\nmitigation.\n","authors":["Lukas Hauzenberger","Shahed Masoudian","Deepak Kumar","Markus Schedl","Navid Rekabsaz"],"pdf_url":"https://arxiv.org/pdf/2205.15171v5.pdf","comment":"Accepted in Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2305.16944v2","updated":"2023-06-04T14:30:19Z","published":"2023-05-26T13:59:45Z","title":"Learning to Imagine: Visually-Augmented Natural Language Generation","summary":"  People often imagine relevant scenes to aid in the writing process. In this\nwork, we aim to utilize visual information for composition in the same manner\nas humans. We propose a method, LIVE, that makes pre-trained language models\n(PLMs) Learn to Imagine for Visuallyaugmented natural language gEneration.\nFirst, we imagine the scene based on the text: we use a diffusion model to\nsynthesize high-quality images conditioned on the input texts. Second, we use\nCLIP to determine whether the text can evoke the imagination in a posterior\nway. Finally, our imagination is dynamic, and we conduct synthesis for each\nsentence rather than generate only one image for an entire paragraph.\nTechnically, we propose a novel plug-and-play fusion layer to obtain\nvisually-augmented representations for each text. Our vision-text fusion layer\nis compatible with Transformerbased architecture. We have conducted extensive\nexperiments on four generation tasks using BART and T5, and the automatic\nresults and human evaluation demonstrate the effectiveness of our proposed\nmethod. We will release the code, model, and data at the link:\nhttps://github.com/RUCAIBox/LIVE.\n","authors":["Tianyi Tang","Yushuo Chen","Yifan Du","Junyi Li","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2305.16944v2.pdf","comment":"Accepted by ACL 2023"},{"id":"http://arxiv.org/abs/2305.12258v3","updated":"2023-06-04T13:29:51Z","published":"2023-05-20T18:24:06Z","title":"Constructing Code-mixed Universal Dependency Forest for Unbiased\n  Cross-lingual Relation Extraction","summary":"  Latest efforts on cross-lingual relation extraction (XRE) aggressively\nleverage the language-consistent structural features from the universal\ndependency (UD) resource, while they may largely suffer from biased transfer\n(e.g., either target-biased or source-biased) due to the inevitable linguistic\ndisparity between languages. In this work, we investigate an unbiased UD-based\nXRE transfer by constructing a type of code-mixed UD forest. We first translate\nthe sentence of the source language to the parallel target-side language, for\nboth of which we parse the UD tree respectively. Then, we merge the\nsource-/target-side UD structures as a unified code-mixed UD forest. With such\nforest features, the gaps of UD-based XRE between the training and predicting\nphases can be effectively closed. We conduct experiments on the ACE XRE\nbenchmark datasets, where the results demonstrate that the proposed code-mixed\nUD forests help unbiased UD-based XRE transfer, with which we achieve\nsignificant XRE performance gains.\n","authors":["Hao Fei","Meishan Zhang","Min Zhang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2305.12258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.11194v2","updated":"2023-06-04T12:59:36Z","published":"2022-05-23T11:01:59Z","title":"UnifieR: A Unified Retriever for Large-Scale Retrieval","summary":"  Large-scale retrieval is to recall relevant documents from a huge collection\ngiven a query. It relies on representation learning to embed documents and\nqueries into a common semantic encoding space. According to the encoding space,\nrecent retrieval methods based on pre-trained language models (PLM) can be\ncoarsely categorized into either dense-vector or lexicon-based paradigms. These\ntwo paradigms unveil the PLMs' representation capability in different\ngranularities, i.e., global sequence-level compression and local word-level\ncontexts, respectively. Inspired by their complementary global-local\ncontextualization and distinct representing views, we propose a new learning\nframework, UnifieR which unifies dense-vector and lexicon-based retrieval in\none model with a dual-representing capability. Experiments on passage retrieval\nbenchmarks verify its effectiveness in both paradigms. A uni-retrieval scheme\nis further presented with even better retrieval quality. We lastly evaluate the\nmodel on BEIR benchmark to verify its transferability.\n","authors":["Tao Shen","Xiubo Geng","Chongyang Tao","Can Xu","Guodong Long","Kai Zhang","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2205.11194v2.pdf","comment":"To appear at KDD ADS 2023"},{"id":"http://arxiv.org/abs/2306.02349v1","updated":"2023-06-04T12:54:00Z","published":"2023-06-04T12:54:00Z","title":"bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark","summary":"  We present bgGLUE (Bulgarian General Language Understanding Evaluation), a\nbenchmark for evaluating language models on Natural Language Understanding\n(NLU) tasks in Bulgarian. Our benchmark includes NLU tasks targeting a variety\nof NLP problems (e.g., natural language inference, fact-checking, named entity\nrecognition, sentiment analysis, question answering, etc.) and machine learning\ntasks (sequence labeling, document-level classification, and regression). We\nrun the first systematic evaluation of pre-trained language models for\nBulgarian, comparing and contrasting results across the nine tasks in the\nbenchmark. The evaluation results show strong performance on sequence labeling\ntasks, but there is a lot of room for improvement for tasks that require more\ncomplex reasoning. We make bgGLUE publicly available together with the\nfine-tuning and the evaluation code, as well as a public leaderboard at\nhttps://bgglue.github.io/, and we hope that it will enable further advancements\nin developing NLU models for Bulgarian.\n","authors":["Momchil Hardalov","Pepa Atanasova","Todor Mihaylov","Galia Angelova","Kiril Simov","Petya Osenova","Ves Stoyanov","Ivan Koychev","Preslav Nakov","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2306.02349v1.pdf","comment":"Accepted to ACL 2023 (Main Conference)"},{"id":"http://arxiv.org/abs/2306.02348v1","updated":"2023-06-04T12:53:12Z","published":"2023-06-04T12:53:12Z","title":"Leverage Points in Modality Shifts: Comparing Language-only and\n  Multimodal Word Representations","summary":"  Multimodal embeddings aim to enrich the semantic information in neural\nrepresentations of language compared to text-only models. While different\nembeddings exhibit different applicability and performance on downstream tasks,\nlittle is known about the systematic representation differences attributed to\nthe visual modality. Our paper compares word embeddings from three\nvision-and-language models (CLIP, OpenCLIP and Multilingual CLIP) and three\ntext-only models, with static (FastText) as well as contextual representations\n(multilingual BERT; XLM-RoBERTa). This is the first large-scale study of the\neffect of visual grounding on language representations, including 46 semantic\nparameters. We identify meaning properties and relations that characterize\nwords whose embeddings are most affected by the inclusion of visual modality in\nthe training data; that is, points where visual grounding turns out most\nimportant. We find that the effect of visual modality correlates most with\ndenotational semantic properties related to concreteness, but is also detected\nfor several specific semantic classes, as well as for valence, a\nsentiment-related connotational property of linguistic expressions.\n","authors":["Aleksey Tikhonov","Lisa Bylinina","Denis Paperno"],"pdf_url":"https://arxiv.org/pdf/2306.02348v1.pdf","comment":"Accepted for StarSEM 2023"},{"id":"http://arxiv.org/abs/2306.02334v1","updated":"2023-06-04T11:52:36Z","published":"2023-06-04T11:52:36Z","title":"Long Text Generation Challenge","summary":"  We propose a shared task of human-like long text generation, LTG Challenge,\nthat asks models to output a consistent human-like long text (a Harry Potter\ngeneric audience fanfic in English), given a prompt of about 1000 tokens. We\nsuggest a novel statistical metric of the text structuredness, GloVe\nAutocorrelations Power/ Exponential Law Mean Absolute Percentage Error Ratio\n(GAPELMAPER) and a human evaluation protocol. We hope that LTG can open new\navenues for researchers to investigate sampling approaches, prompting\nstrategies, autoregressive and non-autoregressive text generation architectures\nand break the barrier to generate consistent long (40K+ token) texts.\n","authors":["Nikolay Mikhaylovskiy"],"pdf_url":"https://arxiv.org/pdf/2306.02334v1.pdf","comment":"Submitted to INLG 2023"},{"id":"http://arxiv.org/abs/2305.04505v2","updated":"2023-06-04T11:05:03Z","published":"2023-05-08T07:01:18Z","title":"Target-Side Augmentation for Document-Level Machine Translation","summary":"  Document-level machine translation faces the challenge of data sparsity due\nto its long input length and a small amount of training data, increasing the\nrisk of learning spurious patterns. To address this challenge, we propose a\ntarget-side augmentation method, introducing a data augmentation (DA) model to\ngenerate many potential translations for each source document. Learning on\nthese wider range translations, an MT model can learn a smoothed distribution,\nthereby reducing the risk of data sparsity. We demonstrate that the DA model,\nwhich estimates the posterior distribution, largely improves the MT\nperformance, outperforming the previous best system by 2.30 s-BLEU on News and\nachieving new state-of-the-art on News and Europarl benchmarks. Our code is\navailable at https://github.com/baoguangsheng/target-side-augmentation.\n","authors":["Guangsheng Bao","Zhiyang Teng","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.04505v2.pdf","comment":"Accepted by ACL2023 main conference"},{"id":"http://arxiv.org/abs/2306.02320v1","updated":"2023-06-04T10:10:54Z","published":"2023-06-04T10:10:54Z","title":"Arbitrary Few Parameters are Good Enough for Adapting Large-scale\n  Pre-trained Language Models","summary":"  Parameter-efficient tuning (PET) methods can effectively drive extremely\nlarge pre-trained language models (PLMs) by only training minimal parameters.\nDifferent PET methods utilize different manually designed modules. In a small\nPLM, there are usually noticeable performance differences among PET methods.\nNevertheless, when a PLM's scale grows up to tens of billions of parameters,\nall PET methods achieve almost the same performance and even perform on par\nwith the full-parameter fine-tuning method. Hence, we hypothesize that model\nscaling can mitigate the design differences (the module structures and the\nnumber of trainable parameters) among PET methods. To study this hypothesis, we\nintroduce a more flexible PET method - arbitrary PET (APET) method - to be\ncompatible with arbitrary module structures and any number of trainable\nparameters. Then, we experiment on $11$ NLP tasks of $5$ types and $2$\nrepresentative PLMs. From our investigations, we find that the model scaling\n(1) mitigates the effects of the arbitrary module structure on the performance\nof tuning methods, and (2) enables the tuning methods to optimize fewer\nparameters to achieve the full-parameter fine-tuning performance. Intriguingly,\nwe also observe that all tuning methods require almost the same number of\ntrainable parameters to drive PLMs. We discuss this phenomenon and the above\ntwo findings collectively from optimization perspectives to fathom the\nmechanisms behind them. These conclusions not only demonstrate the positive\nimpact of model scaling on tuning methods but disclose its mechanisms, which\nhelp us design more effective and efficient tuning methods on larger-scale\nPLMs.\n","authors":["Yusheng Su","Chi-Min Chan","Jiali Cheng","Yujia Qin","Yankai Lin","Shengding Hu","Zonghan Yang","Ning Ding","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2306.02320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02317v1","updated":"2023-06-04T10:00:12Z","published":"2023-06-04T10:00:12Z","title":"SpellMapper: A non-autoregressive neural spellchecker for ASR\n  customization with candidate retrieval based on n-gram mappings","summary":"  Contextual spelling correction models are an alternative to shallow fusion to\nimprove automatic speech recognition (ASR) quality given user vocabulary. To\ndeal with large user vocabularies, most of these models include candidate\nretrieval mechanisms, usually based on minimum edit distance between fragments\nof ASR hypothesis and user phrases. However, the edit-distance approach is\nslow, non-trainable, and may have low recall as it relies only on common\nletters. We propose: 1) a novel algorithm for candidate retrieval, based on\nmisspelled n-gram mappings, which gives up to 90% recall with just the top 10\ncandidates on Spoken Wikipedia; 2) a non-autoregressive neural model based on\nBERT architecture, where the initial transcript and ten candidates are combined\ninto one input. The experiments on Spoken Wikipedia show 21.4% word error rate\nimprovement compared to a baseline ASR system.\n","authors":["Alexandra Antonova","Evelina Bakhturina","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2306.02317v1.pdf","comment":"Accepted by INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2305.17182v2","updated":"2023-06-04T09:41:35Z","published":"2023-05-26T18:14:23Z","title":"On the Copying Problem of Unsupervised NMT: A Training Schedule with a\n  Language Discriminator Loss","summary":"  Although unsupervised neural machine translation (UNMT) has achieved success\nin many language pairs, the copying problem, i.e., directly copying some parts\nof the input sentence as the translation, is common among distant language\npairs, especially when low-resource languages are involved. We find this issue\nis closely related to an unexpected copying behavior during online\nback-translation (BT). In this work, we propose a simple but effective training\nschedule that incorporates a language discriminator loss. The loss imposes\nconstraints on the intermediate translation so that the translation is in the\ndesired language. By conducting extensive experiments on different language\npairs, including similar and distant, high and low-resource languages, we find\nthat our method alleviates the copying problem, thus improving the translation\nperformance on low-resource languages.\n","authors":["Yihong Liu","Alexandra Chronopoulou","Hinrich Schütze","Alexander Fraser"],"pdf_url":"https://arxiv.org/pdf/2305.17182v2.pdf","comment":"IWSLT 2023"},{"id":"http://arxiv.org/abs/2306.02307v1","updated":"2023-06-04T09:16:39Z","published":"2023-06-04T09:16:39Z","title":"Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference\n  in Low Resource Settings","summary":"  Adaptive inference is a simple method for reducing inference costs. The\nmethod works by maintaining multiple classifiers of different capacities, and\nallocating resources to each test instance according to its difficulty. In this\nwork, we compare the two main approaches for adaptive inference, Early-Exit and\nMulti-Model, when training data is limited. First, we observe that for models\nwith the same architecture and size, individual Multi-Model classifiers\noutperform their Early-Exit counterparts by an average of 2.3%. We show that\nthis gap is caused by Early-Exit classifiers sharing model parameters during\ntraining, resulting in conflicting gradient updates of model weights. We find\nthat despite this gap, Early-Exit still provides a better speed-accuracy\ntrade-off due to the overhead of the Multi-Model approach. To address these\nissues, we propose SWEET (Separating Weights in Early Exit Transformers), an\nEarly-Exit fine-tuning method that assigns each classifier its own set of\nunique model weights, not updated by other classifiers. We compare SWEET's\nspeed-accuracy curve to standard Early-Exit and Multi-Model baselines and find\nthat it outperforms both methods at fast speeds while maintaining comparable\nscores to Early-Exit at slow speeds. Moreover, SWEET individual classifiers\noutperform Early-Exit ones by 1.1% on average. SWEET enjoys the benefits of\nboth methods, paving the way for further reduction of inference costs in NLP.\n","authors":["Daniel Rotem","Michael Hassid","Jonathan Mamou","Roy Schwartz"],"pdf_url":"https://arxiv.org/pdf/2306.02307v1.pdf","comment":"Proceedings of ACL 2023"},{"id":"http://arxiv.org/abs/2304.13567v2","updated":"2023-06-04T09:11:03Z","published":"2023-04-26T13:57:25Z","title":"Technical Report on Token Position Bias in Transformers","summary":"  Language Models (LMs) have shown state-of-the-art performance in Natural\nLanguage Processing (NLP) tasks. Downstream tasks such as Named Entity\nRecognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data\nimbalance issues, specifically in terms of the ratio of positive to negative\nexamples, and class imbalance. In this paper, we investigate an additional\nspecific issue for language models, namely the position bias of positive\nexamples in token classification tasks. Therefore, we conduct an in-depth\nevaluation of the impact of position bias on the performance of LMs when\nfine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and\nOntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We\npropose an evaluation approach to investigate position bias in Transformer\nmodels. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as\nGPT2 and BLOOM can suffer from this bias with an average drop of 3\\% and 9\\% in\ntheir performance. To mitigate this effect, we propose two methods: Random\nPosition Shifting and Context Perturbation, that we apply on batches during the\ntraining process. The results show an improvement of $\\approx$ 2\\% in the\nperformance of the model on CoNLL03, UD_en, and TweeBank.\n","authors":["Mehdi Ben Amor","Michael Granitzer","Jelena Mitrović"],"pdf_url":"https://arxiv.org/pdf/2304.13567v2.pdf","comment":"Updated title of the preprint"},{"id":"http://arxiv.org/abs/2306.02302v1","updated":"2023-06-04T08:54:32Z","published":"2023-06-04T08:54:32Z","title":"Does Character-level Information Always Improve DRS-based Semantic\n  Parsing?","summary":"  Even in the era of massive language models, it has been suggested that\ncharacter-level representations improve the performance of neural models. The\nstate-of-the-art neural semantic parser for Discourse Representation Structures\nuses character-level representations, improving performance in the four\nlanguages (i.e., English, German, Dutch, and Italian) in the Parallel Meaning\nBank dataset. However, how and why character-level information improves the\nparser's performance remains unclear. This study provides an in-depth analysis\nof performance changes by order of character sequences. In the experiments, we\ncompare F1-scores by shuffling the order and randomizing character sequences\nafter testing the performance of character-level information. Our results\nindicate that incorporating character-level information does not improve the\nperformance in English and German. In addition, we find that the parser is not\nsensitive to correct character order in Dutch. Nevertheless, performance\nimprovements are observed when using character-level information.\n","authors":["Tomoya Kurosawa","Hitomi Yanaka"],"pdf_url":"https://arxiv.org/pdf/2306.02302v1.pdf","comment":"10 pages. To appear in the 12th Joint Conference on Lexical and\n  Computational Semantics (*SEM 2023) with ACL2023"},{"id":"http://arxiv.org/abs/2306.02295v1","updated":"2023-06-04T08:12:34Z","published":"2023-06-04T08:12:34Z","title":"A Mathematical Abstraction for Balancing the Trade-off Between\n  Creativity and Reality in Large Language Models","summary":"  Large Language Models have become popular for their remarkable capabilities\nin human-oriented tasks and traditional natural language processing tasks. Its\nefficient functioning is attributed to the attention mechanism in the\nTransformer architecture, enabling it to concentrate on particular aspects of\nthe input.\n  LLMs are increasingly being used in domains such as generating prose, poetry\nor art, which require the model to be creative (e.g. Adobe firefly). LLMs\npossess advanced language generation abilities that enable them to generate\ndistinctive and captivating content. This utilization of LLMs in generating\nnarratives shows their flexibility and potential for use in domains that extend\nbeyond conventional natural language processing duties.\n  In different contexts, we may expect the LLM to generate factually correct\nanswers, that match reality; e.g., question-answering systems or online\nassistants. In such situations, being correct is critical to LLMs being trusted\nin practice. The Bing Chatbot provides its users with the flexibility to select\none of the three output modes: creative, balanced, and precise. Each mode\nemphasizes creativity and factual accuracy differently.\n  In this work, we provide a mathematical abstraction to describe creativity\nand reality based on certain losses. A model trained on these losses balances\nthe trade-off between the creativity and reality of the model.\n","authors":["Ritwik Sinha","Zhao Song","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.02295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02294v1","updated":"2023-06-04T08:09:26Z","published":"2023-06-04T08:09:26Z","title":"Exposing Bias in Online Communities through Large-Scale Language Models","summary":"  Progress in natural language generation research has been shaped by the\never-growing size of language models. While large language models pre-trained\non web data can generate human-sounding text, they also reproduce social biases\nand contribute to the propagation of harmful stereotypes. This work utilises\nthe flaw of bias in language models to explore the biases of six different\nonline communities. In order to get an insight into the communities'\nviewpoints, we fine-tune GPT-Neo 1.3B with six social media datasets. The bias\nof the resulting models is evaluated by prompting the models with different\ndemographics and comparing the sentiment and toxicity values of these\ngenerations. Together, these methods reveal that bias differs in type and\nintensity for the various models. This work not only affirms how easily bias is\nabsorbed from training data but also presents a scalable method to identify and\ncompare the bias of different datasets or communities. Additionally, the\nexamples generated for this work demonstrate the limitations of using automated\nsentiment and toxicity classifiers in bias research.\n","authors":["Celine Wald","Lukas Pfahler"],"pdf_url":"https://arxiv.org/pdf/2306.02294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02282v1","updated":"2023-06-04T07:01:30Z","published":"2023-06-04T07:01:30Z","title":"Exploring and Verbalizing Academic Ideas by Concept Co-occurrence","summary":"  Researchers usually come up with new ideas only after thoroughly\ncomprehending vast quantities of literature. The difficulty of this procedure\nis exacerbated by the fact that the number of academic publications is growing\nexponentially. In this study, we devise a framework based on concept\nco-occurrence for academic idea inspiration, which has been integrated into a\nresearch assistant system. From our perspective, the fusion of two concepts\nthat co-occur in an academic paper can be regarded as an important way of the\nemergence of a new idea. We construct evolving concept graphs according to the\nco-occurrence relationship of concepts from 20 disciplines or topics. Then we\ndesign a temporal link prediction method based on masked language model to\nexplore potential connections between different concepts. To verbalize the\nnewly discovered connections, we also utilize the pretrained language model to\ngenerate a description of an idea based on a new data structure called\nco-occurrence citation quintuple. We evaluate our proposed system using both\nautomatic metrics and human assessment. The results demonstrate that our system\nhas broad prospects and can assist researchers in expediting the process of\ndiscovering new ideas.\n","authors":["Yi Xu","Shuqian Sheng","Bo Xue","Luoyi Fu","Xinbing Wang","Chenghu Zhou"],"pdf_url":"https://arxiv.org/pdf/2306.02282v1.pdf","comment":"Accepted by ACL 2023"},{"id":"http://arxiv.org/abs/2306.02273v1","updated":"2023-06-04T06:38:15Z","published":"2023-06-04T06:38:15Z","title":"End-to-End Joint Target and Non-Target Speakers ASR","summary":"  This paper proposes a novel automatic speech recognition (ASR) system that\ncan transcribe individual speaker's speech while identifying whether they are\ntarget or non-target speakers from multi-talker overlapped speech.\nTarget-speaker ASR systems are a promising way to only transcribe a target\nspeaker's speech by enrolling the target speaker's information. However, in\nconversational ASR applications, transcribing both the target speaker's speech\nand non-target speakers' ones is often required to understand interactive\ninformation. To naturally consider both target and non-target speakers in a\nsingle ASR model, our idea is to extend autoregressive modeling-based\nmulti-talker ASR systems to utilize the enrollment speech of the target\nspeaker. Our proposed ASR is performed by recursively generating both textual\ntokens and tokens that represent target or non-target speakers. Our experiments\ndemonstrate the effectiveness of our proposed method.\n","authors":["Ryo Masumura","Naoki Makishima","Taiga Yamane","Yoshihiko Yamazaki","Saki Mizuno","Mana Ihori","Mihiro Uchida","Keita Suzuki","Hiroshi Sato","Tomohiro Tanaka","Akihiko Takashima","Satoshi Suzuki","Takafumi Moriya","Nobukatsu Hojo","Atsushi Ando"],"pdf_url":"https://arxiv.org/pdf/2306.02273v1.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.02272v1","updated":"2023-06-04T06:33:13Z","published":"2023-06-04T06:33:13Z","title":"OWQ: Lessons learned from activation outliers for weight quantization in\n  large language models","summary":"  Large language models (LLMs) with hundreds of billions of parameters show\nimpressive results across various language tasks using simple prompt tuning and\nfew-shot examples, without the need for task-specific fine-tuning. However,\ntheir enormous size requires multiple server-grade GPUs even for inference,\ncreating a significant cost barrier. To address this limitation, we introduce a\nnovel post-training quantization method for weights with minimal quality\ndegradation. While activation outliers are known to be problematic in\nactivation quantization, our theoretical analysis suggests that we can identify\nfactors contributing to weight quantization errors by considering activation\noutliers. We propose an innovative PTQ scheme called outlier-aware weight\nquantization (OWQ), which identifies vulnerable weights and allocates\nhigh-precision to them. Our extensive experiments demonstrate that the 3.01-bit\nmodels produced by OWQ exhibit comparable quality to the 4-bit models generated\nby OPTQ.\n","authors":["Changhun Lee","Jungyu Jin","Taesu Kim","Hyungjun Kim","Eunhyeok Park"],"pdf_url":"https://arxiv.org/pdf/2306.02272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02258v1","updated":"2023-06-04T04:24:43Z","published":"2023-06-04T04:24:43Z","title":"Probing Physical Reasoning with Counter-Commonsense Context","summary":"  In this study, we create a CConS (Counter-commonsense Contextual Size\ncomparison) dataset to investigate how physical commonsense affects the\ncontextualized size comparison task; the proposed dataset consists of both\ncontexts that fit physical commonsense and those that do not. This dataset\ntests the ability of language models to predict the size relationship between\nobjects under various contexts generated from our curated noun list and\ntemplates. We measure the ability of several masked language models and\ngenerative models. The results show that while large language models can use\nprepositions such as ``in'' and ``into'' in the provided context to infer size\nrelationships, they fail to use verbs and thus make incorrect judgments led by\ntheir prior physical commonsense.\n","authors":["Kazushi Kondo","Saku Sugawara","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2306.02258v1.pdf","comment":"Accepted to ACL 2023(Short Paper)"},{"id":"http://arxiv.org/abs/2305.16380v2","updated":"2023-06-04T04:24:01Z","published":"2023-05-25T15:59:13Z","title":"Scan and Snap: Understanding Training Dynamics and Token Composition in\n  1-layer Transformer","summary":"  Transformer architecture has shown impressive performance in multiple\nresearch domains and has become the backbone of many neural network models.\nHowever, there is limited understanding on how it works. In particular, with a\nsimple predictive loss, how the representation emerges from the gradient\n\\emph{training dynamics} remains a mystery. In this paper, for 1-layer\ntransformer with one self-attention layer plus one decoder layer, we analyze\nits SGD training dynamics for the task of next token prediction in a\nmathematically rigorous manner. We open the black box of the dynamic process of\nhow the self-attention layer combines input tokens, and reveal the nature of\nunderlying inductive bias. More specifically, with the assumption (a) no\npositional encoding, (b) long input sequence, and (c) the decoder layer learns\nfaster than the self-attention layer, we prove that self-attention acts as a\n\\emph{discriminative scanning algorithm}: starting from uniform attention, it\ngradually attends more to distinct key tokens for a specific next token to be\npredicted, and pays less attention to common key tokens that occur across\ndifferent next tokens. Among distinct tokens, it progressively drops attention\nweights, following the order of low to high co-occurrence between the key and\nthe query token in the training set. Interestingly, this procedure does not\nlead to winner-takes-all, but decelerates due to a \\emph{phase transition} that\nis controllable by the learning rates of the two layers, leaving (almost) fixed\ntoken combination. We verify this \\textbf{\\emph{scan and snap}} dynamics on\nsynthetic and real-world data (WikiText).\n","authors":["Yuandong Tian","Yiping Wang","Beidi Chen","Simon Du"],"pdf_url":"https://arxiv.org/pdf/2305.16380v2.pdf","comment":"Fix minor issues in the proofs and figures. Update figures to reflect\n  the main conclusions more accurately"},{"id":"http://arxiv.org/abs/2306.02254v1","updated":"2023-06-04T04:04:04Z","published":"2023-06-04T04:04:04Z","title":"A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean\n  Language Models","summary":"  Polyglot is a pioneering project aimed at enhancing the non-English language\nperformance of multilingual language models. Despite the availability of\nvarious multilingual models such as mBERT (Devlin et al., 2019), XGLM (Lin et\nal., 2022), and BLOOM (Scao et al., 2022), researchers and developers often\nresort to building monolingual models in their respective languages due to the\ndissatisfaction with the current multilingual models non-English language\ncapabilities. Addressing this gap, we seek to develop advanced multilingual\nlanguage models that offer improved performance in non-English languages. In\nthis paper, we introduce the Polyglot Korean models, which represent a specific\nfocus rather than being multilingual in nature. In collaboration with TUNiB,\nour team collected 1.2TB of Korean data meticulously curated for our research\njourney. We made a deliberate decision to prioritize the development of Korean\nmodels before venturing into multilingual models. This choice was motivated by\nmultiple factors: firstly, the Korean models facilitated performance\ncomparisons with existing multilingual models; and finally, they catered to the\nspecific needs of Korean companies and researchers. This paper presents our\nwork in developing the Polyglot Korean models, which propose some steps towards\naddressing the non-English language performance gap in multilingual language\nmodels.\n","authors":["Hyunwoong Ko","Kichang Yang","Minho Ryu","Taekyoon Choi","Seungmu Yang","jiwung Hyun","Sungho Park"],"pdf_url":"https://arxiv.org/pdf/2306.02254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02250v1","updated":"2023-06-04T03:46:45Z","published":"2023-06-04T03:46:45Z","title":"Large Language Model Augmented Narrative Driven Recommendations","summary":"  Narrative-driven recommendation (NDR) presents an information access problem\nwhere users solicit recommendations with verbose descriptions of their\npreferences and context, for example, travelers soliciting recommendations for\npoints of interest while describing their likes/dislikes and travel\ncircumstances. These requests are increasingly important with the rise of\nnatural language-based conversational interfaces for search and recommendation\nsystems. However, NDR lacks abundant training data for models, and current\nplatforms commonly do not support these requests. Fortunately, classical\nuser-item interaction datasets contain rich textual data, e.g., reviews, which\noften describe user preferences and context - this may be used to bootstrap\ntraining for NDR models. In this work, we explore using large language models\n(LLMs) for data augmentation to train NDR models. We use LLMs for authoring\nsynthetic narrative queries from user-item interactions with few-shot prompting\nand train retrieval models for NDR on synthetic queries and user-item\ninteraction data. Our experiments demonstrate that this is an effective\nstrategy for training small-parameter retrieval models that outperform other\nretrieval and LLM baselines for narrative-driven recommendation.\n","authors":["Sheshera Mysore","Andrew McCallum","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2306.02250v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2306.02247v1","updated":"2023-06-04T03:26:43Z","published":"2023-06-04T03:26:43Z","title":"Sen2Pro: A Probabilistic Perspective to Sentence Embedding from\n  Pre-trained Language Model","summary":"  Sentence embedding is one of the most fundamental tasks in Natural Language\nProcessing and plays an important role in various tasks. The recent\nbreakthrough in sentence embedding is achieved by pre-trained language models\n(PLMs). Despite its success, an embedded vector (Sen2Vec) representing a point\nestimate does not naturally express uncertainty in a taskagnostic way. This\npaper thereby proposes an efficient framework on probabilistic sentence\nembedding (Sen2Pro) from PLMs, and it represents a sentence as a probability\ndensity distribution in an embedding space to reflect both model uncertainty\nand data uncertainty (i.e., many-to-one nature) in the sentence representation.\nThe proposed framework performs in a plug-and-play way without retraining PLMs\nanymore, and it is easy to implement and generally applied on top of any PLM.\nThe superiority of Sen2Pro over Sen2Vec has been theoretically verified and\npractically illustrated on different NLP tasks.\n","authors":["Lingfeng Shen","Haiyun Jiang","Lemao Liu","Shuming Shi"],"pdf_url":"https://arxiv.org/pdf/2306.02247v1.pdf","comment":"Accepted to ACL2023 workshop Rep4NLP"},{"id":"http://arxiv.org/abs/2306.02242v1","updated":"2023-06-04T03:05:25Z","published":"2023-06-04T03:05:25Z","title":"Extract and Attend: Improving Entity Translation in Neural Machine\n  Translation","summary":"  While Neural Machine Translation(NMT) has achieved great progress in recent\nyears, it still suffers from inaccurate translation of entities (e.g.,\nperson/organization name, location), due to the lack of entity training\ninstances. When we humans encounter an unknown entity during translation, we\nusually first look up in a dictionary and then organize the entity translation\ntogether with the translations of other parts to form a smooth target sentence.\nInspired by this translation process, we propose an Extract-and-Attend approach\nto enhance entity translation in NMT, where the translation candidates of\nsource entities are first extracted from a dictionary and then attended to by\nthe NMT model to generate the target sentence. Specifically, the translation\ncandidates are extracted by first detecting the entities in a source sentence\nand then translating the entities through looking up in a dictionary. Then, the\nextracted candidates are added as a prefix of the decoder input to be attended\nto by the decoder when generating the target sentence through self-attention.\nExperiments conducted on En-Zh and En-Ru demonstrate that the proposed method\nis effective on improving both the translation accuracy of entities and the\noverall translation quality, with up to 35% reduction on entity error rate and\n0.85 gain on BLEU and 13.8 gain on COMET.\n","authors":["Zixin Zeng","Rui Wang","Yichong Leng","Junliang Guo","Xu Tan","Tao Qin","Tie-yan Liu"],"pdf_url":"https://arxiv.org/pdf/2306.02242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03506v2","updated":"2023-06-04T03:04:05Z","published":"2023-05-04T10:13:15Z","title":"SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention\n  for Emotion Recognition in Conversation","summary":"  Emotion Recognition in Conversation~(ERC) across modalities is of vital\nimportance for a variety of applications, including intelligent healthcare,\nartificial intelligence for conversation, and opinion mining over chat history.\nThe crux of ERC is to model both cross-modality and cross-time interactions\nthroughout the conversation. Previous methods have made progress in learning\nthe time series information of conversation while lacking the ability to trace\ndown the different emotional states of each speaker in a conversation. In this\npaper, we propose a recurrent structure called Speaker Information Enhanced\nLong-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states\nof the distinct speaker can be tracked in a sequential way to enhance the\nlearning of the emotion in conversation. Further, to improve the learning of\nmultimodal features in ERC, we utilize a cross-modal attention component to\nfuse the features between different modalities and model the interaction of the\nimportant information from different modalities. Experimental results on two\nbenchmark datasets demonstrate the superiority of the proposed SI-LSTM against\nthe state-of-the-art baseline methods in the ERC task on multimodal data.\n","authors":["Xingwei Liang","You Zou","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2305.03506v2.pdf","comment":"Modification needed"},{"id":"http://arxiv.org/abs/2305.06566v2","updated":"2023-06-04T02:43:47Z","published":"2023-05-11T04:51:21Z","title":"A First Look at LLM-Powered Generative News Recommendation","summary":"  Personalized news recommendation systems have become essential tools for\nusers to navigate the vast amount of online news content, yet existing news\nrecommenders face significant challenges such as the cold-start problem, user\nprofile modeling, and news content understanding. Previous works have typically\nfollowed an inflexible routine to address a particular challenge through model\ndesign, but are limited in their ability to understand news content and capture\nuser interests. In this paper, we introduce GENRE, an LLM-powered generative\nnews recommendation framework, which leverages pretrained semantic knowledge\nfrom large language models to enrich news data. Our aim is to provide a\nflexible and unified solution for news recommendation by moving from model\ndesign to prompt design. We showcase the use of GENRE for personalized news\ngeneration, user profiling, and news summarization. Extensive experiments with\nvarious popular recommendation models demonstrate the effectiveness of GENRE.\nWe will publish our code and data for other researchers to reproduce our work.\n","authors":["Qijiong Liu","Nuo Chen","Tetsuya Sakai","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2305.06566v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2306.02231v1","updated":"2023-06-04T01:59:40Z","published":"2023-06-04T01:59:40Z","title":"Fine-Tuning Language Models with Advantage-Induced Policy Alignment","summary":"  Reinforcement learning from human feedback (RLHF) has emerged as a reliable\napproach to aligning large language models (LLMs) to human preferences. Among\nthe plethora of RLHF techniques, proximal policy optimization (PPO) is of the\nmost widely used methods. Despite its popularity, however, PPO may suffer from\nmode collapse, instability, and poor sample efficiency. We show that these\nissues can be alleviated by a novel algorithm that we refer to as\nAdvantage-Induced Policy Alignment (APA), which leverages a squared error loss\nfunction based on the estimated advantages. We demonstrate empirically that APA\nconsistently outperforms PPO in language tasks by a large margin, when a\nseparate reward model is employed as the evaluator. In addition, compared with\nPPO, APA offers a more stable form of control over the deviation from the\nmodel's initial policy, ensuring that the model improves its performance\nwithout collapsing to deterministic output. In addition to empirical results,\nwe also provide a theoretical justification supporting the design of our loss\nfunction.\n","authors":["Banghua Zhu","Hiteshi Sharma","Felipe Vieira Frujeri","Shi Dong","Chenguang Zhu","Michael I. Jordan","Jiantao Jiao"],"pdf_url":"https://arxiv.org/pdf/2306.02231v1.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2301.08203v3","updated":"2023-06-04T19:54:21Z","published":"2023-01-19T17:54:50Z","title":"An SDE for Modeling SAM: Theory and Insights","summary":"  We study the SAM (Sharpness-Aware Minimization) optimizer which has recently\nattracted a lot of interest due to its increased performance over more\nclassical variants of stochastic gradient descent. Our main contribution is the\nderivation of continuous-time models (in the form of SDEs) for SAM and two of\nits variants, both for the full-batch and mini-batch settings. We demonstrate\nthat these SDEs are rigorous approximations of the real discrete-time\nalgorithms (in a weak sense, scaling linearly with the learning rate). Using\nthese models, we then offer an explanation of why SAM prefers flat minima over\nsharp ones~--~by showing that it minimizes an implicitly regularized loss with\na Hessian-dependent noise structure. Finally, we prove that SAM is attracted to\nsaddle points under some realistic conditions. Our theoretical results are\nsupported by detailed experiments.\n","authors":["Enea Monzio Compagnoni","Luca Biggio","Antonio Orvieto","Frank Norbert Proske","Hans Kersting","Aurelien Lucchi"],"pdf_url":"https://arxiv.org/pdf/2301.08203v3.pdf","comment":"Accepted at ICML 2023 (Poster)"},{"id":"http://arxiv.org/abs/2306.02429v1","updated":"2023-06-04T18:21:53Z","published":"2023-06-04T18:21:53Z","title":"An Inexact Conditional Gradient Method for Constrained Bilevel\n  Optimization","summary":"  Bilevel optimization is an important class of optimization problems where one\noptimization problem is nested within another. This framework is widely used in\nmachine learning problems, including meta-learning, data hyper-cleaning, and\nmatrix completion with denoising. In this paper, we focus on a bilevel\noptimization problem with a strongly convex lower-level problem and a smooth\nupper-level objective function over a compact and convex constraint set.\nSeveral methods have been developed for tackling unconstrained bilevel\noptimization problems, but there is limited work on methods for the constrained\nsetting. In fact, for those methods that can handle constrained problems,\neither the convergence rate is slow or the computational cost per iteration is\nexpensive. To address this issue, in this paper, we introduce a novel\nsingle-loop projection-free method using a nested approximation technique. Our\nproposed method has an improved per-iteration complexity, surpassing existing\nmethods, and achieves optimal convergence rate guarantees matching the\nbest-known complexity of projection-free algorithms for solving convex\nconstrained single-level optimization problems. In particular, when the\nupper-level objective function is convex, our method requires\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ iterations to find an $\\epsilon$-optimal\nsolution. Moreover, when the upper-level objective function is non-convex the\ncomplexity of our method is $\\mathcal{O}(\\epsilon^{-2})$ to find an\n$\\epsilon$-stationary point. We also present numerical experiments to showcase\nthe superior performance of our method compared with state-of-the-art methods.\n","authors":["Nazanin Abolfazli","Ruichen Jiang","Aryan Mokhtari","Erfan Yazdandoost Hamedani"],"pdf_url":"https://arxiv.org/pdf/2306.02429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02422v1","updated":"2023-06-04T17:54:11Z","published":"2023-06-04T17:54:11Z","title":"A Generalized Alternating Method for Bilevel Optimization under the\n  Polyak-Łojasiewicz Condition","summary":"  Bilevel optimization has recently regained interest owing to its applications\nin emerging machine learning fields such as hyperparameter optimization,\nmeta-learning, and reinforcement learning. Recent results have shown that\nsimple alternating (implicit) gradient-based algorithms can achieve the same\nconvergence rate of single-level gradient descent (GD) for bilevel problems\nwith a strongly convex lower-level objective. However, it remains unclear\nwhether this result can be generalized to bilevel problems beyond this basic\nsetting. In this paper, we propose a Generalized ALternating mEthod for bilevel\nopTimization (GALET) with a nonconvex lower-level objective that satisfies the\nPolyak-{\\L}ojasiewicz (PL) condition. We first introduce a stationary metric\nfor the considered bilevel problems, which generalizes the existing metric. We\nthen establish that GALET achieves an $\\epsilon$-stationary metric for the\nconsidered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which\nmatches the iteration complexity of GD for smooth nonconvex problems.\n","authors":["Quan Xiao","Songtao Lu","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2306.02422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02420v1","updated":"2023-06-04T17:52:49Z","published":"2023-06-04T17:52:49Z","title":"Complexity of Block Coordinate Descent with Proximal Regularization and\n  Applications to Wasserstein CP-dictionary Learning","summary":"  We consider the block coordinate descent methods of Gauss-Seidel type with\nproximal regularization (BCD-PR), which is a classical method of minimizing\ngeneral nonconvex objectives under constraints that has a wide range of\npractical applications. We theoretically establish the worst-case complexity\nbound for this algorithm. Namely, we show that for general nonconvex smooth\nobjectives with block-wise constraints, the classical BCD-PR algorithm\nconverges to an epsilon-stationary point within O(1/epsilon) iterations. Under\na mild condition, this result still holds even if the algorithm is executed\ninexactly in each step. As an application, we propose a provable and efficient\nalgorithm for `Wasserstein CP-dictionary learning', which seeks a set of\nelementary probability distributions that can well-approximate a given set of\nd-dimensional joint probability distributions. Our algorithm is a version of\nBCD-PR that operates in the dual space, where the primal problem is regularized\nboth entropically and proximally.\n","authors":["Dohyun Kwon","Hanbaek Lyu"],"pdf_url":"https://arxiv.org/pdf/2306.02420v1.pdf","comment":"Proceedings of the 40th International Conference on Machine Learning"},{"id":"http://arxiv.org/abs/2104.12489v4","updated":"2023-06-04T13:58:16Z","published":"2021-04-26T11:38:42Z","title":"Control results for a model of resonant interaction between short and\n  long capillary-gravity waves","summary":"  The purpose of this article is the investigation of the global control\nproperties of a coupled nonlinear dispersive system posed in the periodic\ndomain $\\mathbb{T}$, a system with the structure of a nonlinear Schr\\\"odinger\nequation and a nonlinear Korteweg-de Vries equation. Combining estimates\nderived from Bourgain spaces and using microlocal analysis we show that this\nsystem has global control properties. The main novelty of this work is twofold.\nOne is that the global results for the nonlinear system are presented for the\nfirst time thanks to the propagation of singularities. The second one is that\nthese propagation results are shown to a coupled dispersive system with two\nequations defined by differential operators with principal symbols of different\norders.\n","authors":["Roberto de A. Capistrano-Filho","Ademir Pampu"],"pdf_url":"https://arxiv.org/pdf/2104.12489v4.pdf","comment":"To appear on Nonlinear Differential Equations and Applications\n  (NoDEA) - 28 pages"},{"id":"http://arxiv.org/abs/2306.02296v1","updated":"2023-06-04T08:13:33Z","published":"2023-06-04T08:13:33Z","title":"Onsite Job Scheduling by Adaptive Genetic Algorithm","summary":"  Onsite Job Scheduling is a specialized variant of Vehicle Routing Problem\n(VRP) with multiple depots. The objective of this problem is to execute jobs\nrequested by customers, belonging to different geographic locations by a\nlimited number of technicians, with minimum travel and overtime of technicians.\nEach job is expected to be completed within a specified time limit according to\nthe service level agreement with customers. Each technician is assumed to start\nfrom a base location, serve several customers and return to the starting place.\nTechnicians are allotted jobs based on their skill sets, expertise levels of\neach skill and availability slots. Although there are considerable number of\nliteratures on VRP we do not see any explicit work related to Onsite Job\nScheduling. In this paper we have proposed an Adaptive Genetic Algorithm to\nsolve the scheduling problem. We found an optimized travel route for a\nsubstantial number of jobs and technicians, minimizing travel distance,\novertime duration as well as meeting constraints related to SLA.\n","authors":["Avijit Basak","Subhas Acharya"],"pdf_url":"https://arxiv.org/pdf/2306.02296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18394v2","updated":"2023-06-04T04:35:03Z","published":"2023-05-28T12:34:07Z","title":"On Optimal Regularization Parameters via Bilevel Learning","summary":"  Variational regularization is commonly used to solve linear inverse problems,\nand involves augmenting a data fidelity by a regularizer. The regularizer is\nused to promote a priori information, and is weighted by a regularization\nparameter. Selection of an appropriate regularization parameter is critical,\nwith various choices leading to very different reconstructions. Existing\nstrategies such as the discrepancy principle and L-curve can be used to\ndetermine a suitable parameter value, but in recent years a supervised machine\nlearning approach called bilevel learning has been employed. Bilevel learning\nis a powerful framework to determine optimal parameters, and involves solving a\nnested optimisation problem. While previous strategies enjoy various\ntheoretical results, the well-posedness of bilevel learning in this setting is\nstill a developing field. One necessary property is positivity of the\ndetermined regularization parameter. In this work, we provide a new condition\nthat better characterises positivity of optimal regularization parameters than\nthe existing theory. Numerical results verify and explore this new condition\nfor both small and large dimensional problems.\n","authors":["Matthias J. Ehrhardt","Silvia Gazzola","Sebastian J. Scott"],"pdf_url":"https://arxiv.org/pdf/2305.18394v2.pdf","comment":"26 pages, 6 figures. Fixed typos in the header and Lemma 3"},{"id":"http://arxiv.org/abs/2305.17291v2","updated":"2023-06-04T04:28:15Z","published":"2023-05-26T22:21:44Z","title":"Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design\n  in Uncertain Nonconvex Environments","summary":"  In this paper, we address the trajectory planning problem in uncertain\nnonconvex static and dynamic environments that contain obstacles with\nprobabilistic location, size, and geometry. To address this problem, we provide\na risk bounded trajectory planning method that looks for continuous-time\ntrajectories with guaranteed bounded risk over the planning time horizon. Risk\nis defined as the probability of collision with uncertain obstacles. Existing\napproaches to address risk bounded trajectory planning problems either are\nlimited to Gaussian uncertainties and convex obstacles or rely on\nsampling-based methods that need uncertainty samples and time discretization.\nTo address the risk bounded trajectory planning problem, we leverage the notion\nof risk contours to transform the risk bounded planning problem into a\ndeterministic optimization problem. Risk contours are the set of all points in\nthe uncertain environment with guaranteed bounded risk. The obtained\ndeterministic optimization is, in general, nonlinear and nonconvex time-varying\noptimization. We provide convex methods based on sum-of-squares optimization to\nefficiently solve the obtained nonconvex time-varying optimization problem and\nobtain the continuous-time risk bounded trajectories without time\ndiscretization. The provided approach deals with arbitrary (and known)\nprobabilistic uncertainties, nonconvex and nonlinear, static and dynamic\nobstacles, and is suitable for online trajectory planning problems. In\naddition, we provide convex methods based on sum-of-squares optimization to\nbuild the max-sized tube with respect to its parameterization along the\ntrajectory so that any state inside the tube is guaranteed to have bounded\nrisk.\n","authors":["Ashkan Jasour","Weiqiao Han","Brian Williams"],"pdf_url":"https://arxiv.org/pdf/2305.17291v2.pdf","comment":"Accepted by IJRR (extension of RSS 2021 paper arXiv:2106.05489\n  invited to IJRR)"},{"id":"http://arxiv.org/abs/2109.11926v4","updated":"2023-06-04T02:55:11Z","published":"2021-09-24T12:40:48Z","title":"Sinkhorn Distributionally Robust Optimization","summary":"  We study distributionally robust optimization (DRO) with Sinkhorn distance --\na variant of Wasserstein distance based on entropic regularization. We derive\nconvex programming dual reformulation for general nominal distributions,\ntransport costs, and loss functions. Compared with Wasserstein DRO, our\nproposed approach offers enhanced computational tractability for a broader\nclass of loss functions, and the worst-case distribution exhibits greater\nplausibility in practical scenarios. To solve the dual reformulation, we\ndevelop a stochastic mirror descent algorithm with biased gradient oracles.\nRemarkably, this algorithm achieves near-optimal sample complexity for both\nsmooth and nonsmooth loss functions, nearly matching the sample complexity of\nthe Empirical Risk Minimization counterpart. Finally, we provide numerical\nexamples using synthetic and real data to demonstrate its superior performance.\n","authors":["Jie Wang","Rui Gao","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2109.11926v4.pdf","comment":"57 pages, 9 figures"},{"id":"http://arxiv.org/abs/2305.13664v2","updated":"2023-06-04T01:25:48Z","published":"2023-05-23T04:12:55Z","title":"Layer-wise Adaptive Step-Sizes for Stochastic First-Order Methods for\n  Deep Learning","summary":"  We propose a new per-layer adaptive step-size procedure for stochastic\nfirst-order optimization methods for minimizing empirical loss functions in\ndeep learning, eliminating the need for the user to tune the learning rate\n(LR). The proposed approach exploits the layer-wise stochastic curvature\ninformation contained in the diagonal blocks of the Hessian in deep neural\nnetworks (DNNs) to compute adaptive step-sizes (i.e., LRs) for each layer. The\nmethod has memory requirements that are comparable to those of first-order\nmethods, while its per-iteration time complexity is only increased by an amount\nthat is roughly equivalent to an additional gradient computation. Numerical\nexperiments show that SGD with momentum and AdamW combined with the proposed\nper-layer step-sizes are able to choose effective LR schedules and outperform\nfine-tuned LR versions of these methods as well as popular first-order and\nsecond-order algorithms for training DNNs on Autoencoder, Convolutional Neural\nNetwork (CNN) and Graph Convolutional Network (GCN) models. Finally, it is\nproved that an idealized version of SGD with the layer-wise step sizes\nconverges linearly when using full-batch gradients.\n","authors":["Achraf Bahamou","Donald Goldfarb"],"pdf_url":"https://arxiv.org/pdf/2305.13664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02223v1","updated":"2023-06-04T00:50:35Z","published":"2023-06-04T00:50:35Z","title":"Prescriptive PCA: Dimensionality Reduction for Two-stage Stochastic\n  Optimization","summary":"  In this paper, we consider the alignment between an upstream dimensionality\nreduction task of learning a low-dimensional representation of a set of\nhigh-dimensional data and a downstream optimization task of solving a\nstochastic program parameterized by said representation. In this case, standard\ndimensionality reduction methods (e.g., principal component analysis) may not\nperform well, as they aim to maximize the amount of information retained in the\nrepresentation and do not generally reflect the importance of such information\nin the downstream optimization problem. To address this problem, we develop a\nprescriptive dimensionality reduction framework that aims to minimize the\ndegree of suboptimality in the optimization phase. For the case where the\ndownstream stochastic optimization problem has an expected value objective, we\nshow that prescriptive dimensionality reduction can be performed via solving a\ndistributionally-robust optimization problem, which admits a semidefinite\nprogramming relaxation. Computational experiments based on a warehouse\ntransshipment problem and a vehicle repositioning problem show that our\napproach significantly outperforms principal component analysis with real and\nsynthetic data sets.\n","authors":["Long He","Ho-Yin Mak"],"pdf_url":"https://arxiv.org/pdf/2306.02223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10472v4","updated":"2023-06-04T00:26:01Z","published":"2023-03-18T19:07:14Z","title":"Practical and Matching Gradient Variance Bounds for Black-Box\n  Variational Bayesian Inference","summary":"  Understanding the gradient variance of black-box variational inference (BBVI)\nis a crucial step for establishing its convergence and developing algorithmic\nimprovements. However, existing studies have yet to show that the gradient\nvariance of BBVI satisfies the conditions used to study the convergence of\nstochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show\nthat BBVI satisfies a matching bound corresponding to the $ABC$ condition used\nin the SGD literature when applied to smooth and quadratically-growing\nlog-likelihoods. Our results generalize to nonlinear covariance\nparameterizations widely used in the practice of BBVI. Furthermore, we show\nthat the variance of the mean-field parameterization has provably superior\ndimensional dependence.\n","authors":["Kyurae Kim","Kaiwen Wu","Jisu Oh","Jacob R. Gardner"],"pdf_url":"https://arxiv.org/pdf/2303.10472v4.pdf","comment":"Accepted to ICML'23 for live oral presentation"},{"id":"http://arxiv.org/abs/2306.03638v1","updated":"2023-06-04T11:31:41Z","published":"2023-06-04T11:31:41Z","title":"Provable convergence guarantees for black-box variational inference","summary":"  While black-box variational inference is widely used, there is no proof that\nits stochastic optimization succeeds. We suggest this is due to a theoretical\ngap in existing stochastic optimization proofs-namely the challenge of gradient\nestimators with unusual noise bounds, and a composite non-smooth objective. For\ndense Gaussian variational families, we observe that existing gradient\nestimators based on reparameterization satisfy a quadratic noise bound and give\nnovel convergence guarantees for proximal and projected stochastic gradient\ndescent using this bound. This provides the first rigorous guarantee that\nblack-box variational inference converges for realistic inference problems.\n","authors":["Justin Domke","Guillaume Garrigos","Robert Gower"],"pdf_url":"https://arxiv.org/pdf/2306.03638v1.pdf","comment":"32 pages"}]},"2023-06-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.03907v1","updated":"2023-06-06T17:59:49Z","published":"2023-06-06T17:59:49Z","title":"CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\n  Fine-Tuning and Multi-Task Learning with Label Descriptions","summary":"  The widespread popularity of social media has led to an increase in hateful,\nabusive, and sexist language, motivating methods for the automatic detection of\nsuch phenomena. The goal of the SemEval shared task \\textit{Towards Explainable\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\nC). In this paper, we present our submitted systems for all three subtasks,\nbased on a multi-task model that has been fine-tuned on a range of related\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\nimplement multi-task learning by formulating each task as binary pairwise text\nclassification, where the dataset and label descriptions are given along with\nthe input text. The results show clear improvements over a fine-tuned\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\% in subtask A\n(rank 13/84), 64.8\\% in subtask B (rank 19/69), and 44.9\\% in subtask C\n(26/63).\n","authors":["Janis Goldzycher"],"pdf_url":"https://arxiv.org/pdf/2306.03907v1.pdf","comment":"11 pages, 4 figures, Accepted at The 17th International Workshop on\n  Semantic Evaluation, ACL 2023"},{"id":"http://arxiv.org/abs/2306.03902v1","updated":"2023-06-06T17:58:44Z","published":"2023-06-06T17:58:44Z","title":"Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis","summary":"  In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.\n","authors":["Yeldar Toleubay","Don Joven Agravante","Daiki Kimura","Baihan Lin","Djallel Bouneffouf","Michiaki Tatsubori"],"pdf_url":"https://arxiv.org/pdf/2306.03902v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.03901v1","updated":"2023-06-06T17:58:24Z","published":"2023-06-06T17:58:24Z","title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory","summary":"  Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .\n","authors":["Chenxu Hu","Jie Fu","Chenzhuang Du","Simian Luo","Junbo Zhao","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.03901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10226v3","updated":"2023-06-06T17:50:01Z","published":"2023-01-24T18:52:59Z","title":"A Watermark for Large Language Models","summary":"  Potential harms of large language models can be mitigated by watermarking\nmodel output, i.e., embedding signals into generated text that are invisible to\nhumans but algorithmically detectable from a short span of tokens. We propose a\nwatermarking framework for proprietary language models. The watermark can be\nembedded with negligible impact on text quality, and can be detected using an\nefficient open-source algorithm without access to the language model API or\nparameters. The watermark works by selecting a randomized set of \"green\" tokens\nbefore a word is generated, and then softly promoting use of green tokens\nduring sampling. We propose a statistical test for detecting the watermark with\ninterpretable p-values, and derive an information-theoretic framework for\nanalyzing the sensitivity of the watermark. We test the watermark using a\nmulti-billion parameter model from the Open Pretrained Transformer (OPT)\nfamily, and discuss robustness and security.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Jonathan Katz","Ian Miers","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2301.10226v3.pdf","comment":"13 pages in the main body. Published at ICML 2023. Code is available\n  at github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2306.03882v1","updated":"2023-06-06T17:36:43Z","published":"2023-06-06T17:36:43Z","title":"Causal interventions expose implicit situation models for commonsense\n  language understanding","summary":"  Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.\n","authors":["Takateru Yamakoshi","James L. McClelland","Adele E. Goldberg","Robert D. Hawkins"],"pdf_url":"https://arxiv.org/pdf/2306.03882v1.pdf","comment":"Findings of ACL"},{"id":"http://arxiv.org/abs/2306.03872v1","updated":"2023-06-06T17:18:56Z","published":"2023-06-06T17:18:56Z","title":"Deductive Verification of Chain-of-Thought Reasoning","summary":"  Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.\n","authors":["Zhan Ling","Yunhao Fang","Xuanlin Li","Zhiao Huang","Mingu Lee","Roland Memisevic","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2306.03872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03866v1","updated":"2023-06-06T17:09:29Z","published":"2023-06-06T17:09:29Z","title":"Correction of Errors in Preference Ratings from Automated Metrics for\n  Text Generation","summary":"  A major challenge in the field of Text Generation is evaluation: Human\nevaluations are cost-intensive, and automated metrics often display\nconsiderable disagreement with human judgments. In this paper, we propose a\nstatistical model of Text Generation evaluation that accounts for the\nerror-proneness of automated metrics when used to generate preference rankings\nbetween system outputs. We show that existing automated metrics are generally\nover-confident in assigning significant differences between systems in this\nsetting. However, our model enables an efficient combination of human and\nautomated ratings to remedy the error-proneness of the automated metrics. We\nshow that using this combination, we only require about 50% of the human\nannotations typically used in evaluations to arrive at robust and statistically\nsignificant results while yielding the same evaluation outcome as the pure\nhuman evaluation in 95% of cases. We showcase the benefits of approach for\nthree text generation tasks: dialogue systems, machine translation, and text\nsummarization.\n","authors":["Jan Deriu","Pius von Däniken","Don Tuggener","Mark Cieliebak"],"pdf_url":"https://arxiv.org/pdf/2306.03866v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12132v2","updated":"2023-06-06T17:07:23Z","published":"2023-01-28T08:51:23Z","title":"AutoPEFT: Automatic Configuration Search for Parameter-Efficient\n  Fine-Tuning","summary":"  Large pretrained language models are widely used in downstream NLP tasks via\ntask-specific fine-tuning, but such procedures can be costly. Recently,\nParameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task\nperformance while updating a much smaller number of parameters compared to full\nmodel fine-tuning (FFT). However, it is non-trivial to make informed design\nchoices on the PEFT configurations, such as their architecture, the number of\ntunable parameters, and even the layers in which the PEFT modules are inserted.\nConsequently, it is highly likely that the current, manually designed\nconfigurations are suboptimal in terms of their performance-efficiency\ntrade-off. Inspired by advances in neural architecture search, we propose\nAutoPEFT for automatic PEFT configuration selection: we first design an\nexpressive configuration search space with multiple representative PEFT modules\nas building blocks. Using multi-objective Bayesian optimisation in a low-cost\nsetup, we then discover a Pareto-optimal set of configurations with strong\nperformance-cost trade-offs across different numbers of parameters that are\nalso highly transferable across different tasks. Empirically, on GLUE and\nSuperGLUE tasks, we show that AutoPEFT-discovered configurations significantly\noutperform existing PEFT methods and are on par or better than FFT, without\nincurring substantial training efficiency costs.\n","authors":["Han Zhou","Xingchen Wan","Ivan Vulić","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2301.12132v2.pdf","comment":"17 pages, 7 figures, 9 tables"},{"id":"http://arxiv.org/abs/2306.03856v1","updated":"2023-06-06T16:51:03Z","published":"2023-06-06T16:51:03Z","title":"Iterative Translation Refinement with Large Language Models","summary":"  Large language models have shown surprising performances in understanding\ninstructions and performing natural language tasks. In this paper, we propose\niterative translation refinement to leverage the power of large language models\nfor more natural translation and post-editing. We show that by simply involving\na large language model in an iterative process, the output quality improves\nbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal that\nalthough iterations reduce string-based metric scores, neural metrics indicate\ncomparable if not improved translation quality. Further, human evaluations\ndemonstrate that our method effectively reduces translationese compared to\ninitial GPT translations and even human references, especially for into-English\ndirections. Ablation studies underscore the importance of anchoring the\nrefinement process to the source input and a reasonable initial translation.\n","authors":["Pinzhen Chen","Zhicheng Guo","Barry Haddow","Kenneth Heafield"],"pdf_url":"https://arxiv.org/pdf/2306.03856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03853v1","updated":"2023-06-06T16:45:44Z","published":"2023-06-06T16:45:44Z","title":"From Key Points to Key Point Hierarchy: Structured and Expressive\n  Opinion Summarization","summary":"  Key Point Analysis (KPA) has been recently proposed for deriving fine-grained\ninsights from collections of textual comments. KPA extracts the main points in\nthe data as a list of concise sentences or phrases, termed key points, and\nquantifies their prevalence. While key points are more expressive than word\nclouds and key phrases, making sense of a long, flat list of key points, which\noften express related ideas in varying levels of granularity, may still be\nchallenging. To address this limitation of KPA, we introduce the task of\norganizing a given set of key points into a hierarchy, according to their\nspecificity. Such hierarchies may be viewed as a novel type of Textual\nEntailment Graph. We develop ThinkP, a high quality benchmark dataset of key\npoint hierarchies for business and product reviews, obtained by consolidating\nmultiple annotations. We compare different methods for predicting pairwise\nrelations between key points, and for inferring a hierarchy from these pairwise\npredictions. In particular, for the task of computing pairwise key point\nrelations, we achieve significant gains over existing strong baselines by\napplying directional distributional similarity methods to a novel\ndistributional representation of key points, and further boost performance via\nweak supervision.\n","authors":["Arie Cattan","Lilach Eden","Yoav Kantor","Roy Bar-Haim"],"pdf_url":"https://arxiv.org/pdf/2306.03853v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2303.17612v3","updated":"2023-06-06T16:30:09Z","published":"2023-03-30T01:37:19Z","title":"oBERTa: Improving Sparse Transfer Learning via improved initialization,\n  distillation, and pruning regimes","summary":"  In this paper, we introduce the range of oBERTa language models, an\neasy-to-use set of language models which allows Natural Language Processing\n(NLP) practitioners to obtain between 3.8 and 24.3 times faster models without\nexpertise in model compression. Specifically, oBERTa extends existing work on\npruning, knowledge distillation, and quantization and leverages frozen\nembeddings improves distillation and model initialization to deliver higher\naccuracy on a broad range of transfer tasks. In generating oBERTa, we explore\nhow the highly optimized RoBERTa differs from the BERT for pruning during\npre-training and finetuning. We find it less amenable to compression during\nfine-tuning. We explore the use of oBERTa on seven representative NLP tasks and\nfind that the improved compression techniques allow a pruned oBERTa model to\nmatch the performance of BERTbase and exceed the performance of Prune OFA Large\non the SQUAD V1.1 Question Answering dataset, despite being 8x and 2x,\nrespectively faster in inference. We release our code, training regimes, and\nassociated model for broad usage to encourage usage and experimentation\n","authors":["Daniel Campos","Alexandre Marques","Mark Kurtz","ChengXiang Zhai"],"pdf_url":"https://arxiv.org/pdf/2303.17612v3.pdf","comment":"SustaiNLP2023 @ ACL 2023,9 pages, 2 figures, 45 tables"},{"id":"http://arxiv.org/abs/2306.00551v2","updated":"2023-06-06T16:27:57Z","published":"2023-06-01T11:14:15Z","title":"Enhancing Programming eTextbooks with ChatGPT Generated\n  Counterfactual-Thinking-Inspired Questions","summary":"  Digital textbooks have become an integral part of everyday learning tasks. In\nthis work, we consider the use of digital textbooks for programming classes.\nGenerally, students struggle with utilizing textbooks on programming to the\nmaximum, with a possible reason being that the example programs provided as\nillustration of concepts in these textbooks don't offer sufficient\ninteractivity for students, and thereby not sufficiently motivating to explore\nor understand these programming examples better. In our work, we explore the\nidea of enhancing the navigability of intelligent textbooks with the use of\n``counterfactual'' questions, to make students think critically about these\nprograms and enhance possible program comprehension. Inspired from previous\nworks on nudging students on counter factual thinking, we present the\npossibility to enhance digital textbooks with questions generated using GPT.\n","authors":["Arun Balajiee Lekshmi Narayanan","Rully Agus Hendrawan","Venktesh V"],"pdf_url":"https://arxiv.org/pdf/2306.00551v2.pdf","comment":"Paper Under Review"},{"id":"http://arxiv.org/abs/2103.00153v2","updated":"2023-06-06T16:22:16Z","published":"2021-02-27T08:01:10Z","title":"Detecting Harmful Content On Online Platforms: What Platforms Need Vs.\n  Where Research Efforts Go","summary":"  The proliferation of harmful content on online platforms is a major societal\nproblem, which comes in many different forms including hate speech, offensive\nlanguage, bullying and harassment, misinformation, spam, violence, graphic\ncontent, sexual abuse, self harm, and many other. Online platforms seek to\nmoderate such content to limit societal harm, to comply with legislation, and\nto create a more inclusive environment for their users. Researchers have\ndeveloped different methods for automatically detecting harmful content, often\nfocusing on specific sub-problems or on narrow communities, as what is\nconsidered harmful often depends on the platform and on the context. We argue\nthat there is currently a dichotomy between what types of harmful content\nonline platforms seek to curb, and what research efforts there are to\nautomatically detect such content. We thus survey existing methods as well as\ncontent moderation policies by online platforms in this light and we suggest\ndirections for future work.\n","authors":["Arnav Arora","Preslav Nakov","Momchil Hardalov","Sheikh Muhammad Sarwar","Vibha Nayak","Yoan Dinkov","Dimitrina Zlatkova","Kyle Dent","Ameya Bhatawdekar","Guillaume Bouchard","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2103.00153v2.pdf","comment":"The paper has been accepted for publication to ACM Computing Surveys\n  (CSUR)"},{"id":"http://arxiv.org/abs/2306.00477v2","updated":"2023-06-06T16:10:28Z","published":"2023-06-01T09:26:17Z","title":"Make Your Pre-trained Model Reversible: From Parameter to Memory\n  Efficient Fine-Tuning","summary":"  Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant with\nPEFT is not straightforward, since the reversible model has a distinct\narchitecture from the currently released PLMs. In this paper, we first\ninvestigate what is a key factor for the success of existing PEFT methods, and\nrealize that it's essential to preserve the PLM's starting point when\ninitializing a PEFT method. With this finding, we propose memory-efficient\nfine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM's\nstarting point and making it reversible without additional pre-training. We\nevaluate MEFT on the GLUE benchmark and five question-answering tasks with\nvarious backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces the\nactivation memory up to 84% of full fine-tuning with a negligible amount of\ntrainable parameters. Moreover, MEFT achieves the same score on GLUE and a\ncomparable score on the question-answering tasks as full fine-tuning.\n","authors":["Baohao Liao","Shaomu Tan","Christof Monz"],"pdf_url":"https://arxiv.org/pdf/2306.00477v2.pdf","comment":"Code at https://github.com/BaohaoLiao/mefts"},{"id":"http://arxiv.org/abs/2306.03819v1","updated":"2023-06-06T16:07:24Z","published":"2023-06-06T16:07:24Z","title":"LEACE: Perfect linear concept erasure in closed form","summary":"  Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.\n","authors":["Nora Belrose","David Schneider-Joseph","Shauli Ravfogel","Ryan Cotterell","Edward Raff","Stella Biderman"],"pdf_url":"https://arxiv.org/pdf/2306.03819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03799v1","updated":"2023-06-06T15:43:16Z","published":"2023-06-06T15:43:16Z","title":"Prompt Space Optimizing Few-shot Reasoning Success with Large Language\n  Models","summary":"  Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid theoretical foundation for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and fundamental theoretical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs.\n","authors":["Fobo Shi","Peijun Qing","Dong Yang","Nan Wang","Youbo Lei","Haonan Lu","Xiaodong Lin"],"pdf_url":"https://arxiv.org/pdf/2306.03799v1.pdf","comment":"Natural language processing (NLP)"},{"id":"http://arxiv.org/abs/2306.03774v1","updated":"2023-06-06T15:32:22Z","published":"2023-06-06T15:32:22Z","title":"Exploring Linguistic Features for Turkish Text Readability","summary":"  This paper presents the first comprehensive study on automatic readability\nassessment of Turkish texts. We combine state-of-the-art neural network models\nwith linguistic features at lexical, morphosyntactic, syntactic and discourse\nlevels to develop an advanced readability tool. We evaluate the effectiveness\nof traditional readability formulas compared to modern automated methods and\nidentify key linguistic features that determine the readability of Turkish\ntexts.\n","authors":["Ahmet Yavuz Uluslu","Gerold Schneider"],"pdf_url":"https://arxiv.org/pdf/2306.03774v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04990v3","updated":"2023-06-06T15:31:33Z","published":"2023-05-08T18:53:45Z","title":"Explanation-based Finetuning Makes Models More Robust to Spurious Cues","summary":"  Large Language Models (LLMs) are so powerful that they sometimes learn\ncorrelations between labels and features that are irrelevant to the task,\nleading to poor generalization on out-of-distribution data. We propose\nexplanation-based finetuning as a general approach to mitigate LLMs' reliance\non spurious correlations. Unlike standard finetuning where the model only\npredicts the answer given the input, we finetune the model to additionally\ngenerate a free-text explanation supporting its answer. To evaluate our method,\nwe finetune the model on artificially constructed training sets containing\ndifferent types of spurious cues, and test it on a test set without these cues.\nCompared to standard finetuning, our method makes GPT-3 (davinci) remarkably\nmore robust against spurious cues in terms of accuracy drop across four\nclassification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC\n(+6.5). The efficacy generalizes across multiple model families and scales,\nwith greater gains for larger models. Finally, our method also works well with\nexplanations generated by the model, implying its applicability to more\ndatasets without human-written explanations.\n","authors":["Josh Magnus Ludan","Yixuan Meng","Tai Nguyen","Saurabh Shah","Qing Lyu","Marianna Apidianaki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2305.04990v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10276v3","updated":"2023-06-06T15:15:22Z","published":"2023-05-17T15:07:50Z","title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models","summary":"  In this paper, we take the initiative to investigate the performance of LLMs\non complex planning tasks that require LLMs to understand a virtual spatial\nenvironment simulated via natural language and act correspondingly in text. We\npropose a benchmark named Natural Language Planning and Action (Natala)\ncomposed of a set of novel tasks: Brick World, NLVR-based Manipulations, and\nNatural Language Navigation. We found that current popular LLMs such as ChatGPT\nstill lack abilities in complex planning. This arises a question -- do the LLMs\nhave a good understanding of the environments described in natural language, or\nmaybe other alternatives such as symbolic representations are neater and hence\nbetter to be understood by LLMs? To this end, we propose a novel method called\nCoS (Chain-of-Symbol Prompting) that represents the complex environments with\ncondensed symbolic spatial representations during the chained intermediate\nthinking steps. CoS is easy to use and does not need additional training on\nLLMs. Extensive experiments indicate that CoS clearly surpasses the performance\nof the Chain-of-Thought (CoT) Prompting in all three planning tasks with even\nfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.\nThe performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)\non Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt\nobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate\nsteps from demonstrations on Brick World.\n","authors":["Hanxu Hu","Hongyuan Lu","Huajian Zhang","Wai Lam","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.10276v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03736v1","updated":"2023-06-06T14:52:47Z","published":"2023-06-06T14:52:47Z","title":"FinRED: A Dataset for Relation Extraction in Financial Domain","summary":"  Relation extraction models trained on a source domain cannot be applied on a\ndifferent target domain due to the mismatch between relation sets. In the\ncurrent literature, there is no extensive open-source relation extraction\ndataset specific to the finance domain. In this paper, we release FinRED, a\nrelation extraction dataset curated from financial news and earning call\ntranscripts containing relations from the finance domain. FinRED has been\ncreated by mapping Wikidata triplets using distance supervision method. We\nmanually annotate the test data to ensure proper evaluation. We also experiment\nwith various state-of-the-art relation extraction models on this dataset to\ncreate the benchmark. We see a significant drop in their performance on FinRED\ncompared to the general relation extraction datasets which tells that we need\nbetter models for financial relation extraction.\n","authors":["Soumya Sharma","Tapas Nayak","Arusarka Bose","Ajay Kumar Meena","Koustuv Dasgupta","Niloy Ganguly","Pawan Goyal"],"pdf_url":"https://arxiv.org/pdf/2306.03736v1.pdf","comment":"Accepted at FinWeb at WWW'22"},{"id":"http://arxiv.org/abs/2306.03734v1","updated":"2023-06-06T14:52:15Z","published":"2023-06-06T14:52:15Z","title":"A Cross-Linguistic Pressure for Uniform Information Density in Word\n  Order","summary":"  While natural languages differ widely in both canonical word order and word\norder flexibility, their word orders still follow shared cross-linguistic\nstatistical patterns, often attributed to functional pressures. In the effort\nto identify these pressures, prior work has compared real and counterfactual\nword orders. Yet one functional pressure has been overlooked in such\ninvestigations: the uniform information density (UID) hypothesis, which holds\nthat information should be spread evenly throughout an utterance. Here, we ask\nwhether a pressure for UID may have influenced word order patterns\ncross-linguistically. To this end, we use computational models to test whether\nreal orders lead to greater information uniformity than counterfactual orders.\nIn our empirical study of 10 typologically diverse languages, we find that: (i)\namong SVO languages, real word orders consistently have greater uniformity than\nreverse word orders, and (ii) only linguistically implausible counterfactual\norders consistently exceed the uniformity of real orders. These findings are\ncompatible with a pressure for information uniformity in the development and\nusage of natural languages.\n","authors":["Thomas Hikaru Clark","Clara Meister","Tiago Pimentel","Michael Hahn","Ryan Cotterell","Richard Futrell","Roger Levy"],"pdf_url":"https://arxiv.org/pdf/2306.03734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03733v1","updated":"2023-06-06T14:49:25Z","published":"2023-06-06T14:49:25Z","title":"A Novel Approach To User Agent String Parsing For Vulnerability Analysis\n  Using Mutli-Headed Attention","summary":"  The increasing reliance on the internet has led to the proliferation of a\ndiverse set of web-browsers and operating systems (OSs) capable of browsing the\nweb. User agent strings (UASs) are a component of web browsing that are\ntransmitted with every Hypertext Transfer Protocol (HTTP) request. They contain\ninformation about the client device and software, which is used by web servers\nfor various purposes such as content negotiation and security. However, due to\nthe proliferation of various browsers and devices, parsing UASs is a\nnon-trivial task due to a lack of standardization of UAS formats. Current\nrules-based approaches are often brittle and can fail when encountering such\nnon-standard formats. In this work, a novel methodology for parsing UASs using\nMulti-Headed Attention Based transformers is proposed. The proposed methodology\nexhibits strong performance in parsing a variety of UASs with differing\nformats. Furthermore, a framework to utilize parsed UASs to estimate the\nvulnerability scores for large sections of publicly visible IT networks or\nregions is also discussed. The methodology present here can also be easily\nextended or deployed for real-time parsing of logs in enterprise settings.\n","authors":["Dhruv Nandakumar","Sathvik Murli","Ankur Khosla","Kevin Choi","Abdul Rahman","Drew Walsh","Scott Riede","Eric Dull","Edward Bowen"],"pdf_url":"https://arxiv.org/pdf/2306.03733v1.pdf","comment":"Accepted to the International Conference on Machine Learning and\n  Cybernetics (ICMLC) 2023"},{"id":"http://arxiv.org/abs/2306.03723v1","updated":"2023-06-06T14:41:30Z","published":"2023-06-06T14:41:30Z","title":"Financial Numeric Extreme Labelling: A Dataset and Benchmarking for XBRL\n  Tagging","summary":"  The U.S. Securities and Exchange Commission (SEC) mandates all public\ncompanies to file periodic financial statements that should contain numerals\nannotated with a particular label from a taxonomy. In this paper, we formulate\nthe task of automating the assignment of a label to a particular numeral span\nin a sentence from an extremely large label set. Towards this task, we release\na dataset, Financial Numeric Extreme Labelling (FNXL), annotated with 2,794\nlabels. We benchmark the performance of the FNXL dataset by formulating the\ntask as (a) a sequence labelling problem and (b) a pipeline with span\nextraction followed by Extreme Classification. Although the two approaches\nperform comparably, the pipeline solution provides a slight edge for the least\nfrequent labels.\n","authors":["Soumya Sharma","Subhendu Khatuya","Manjunath Hegde","Afreen Shaikh. Koustuv Dasgupta","Pawan Goyal","Niloy Ganguly"],"pdf_url":"https://arxiv.org/pdf/2306.03723v1.pdf","comment":"Accepted to ACL'23 Findings Paper"},{"id":"http://arxiv.org/abs/2306.03722v1","updated":"2023-06-06T14:40:41Z","published":"2023-06-06T14:40:41Z","title":"Evaluating the Effectiveness of Natural Language Inference for Hate\n  Speech Detection in Languages with Limited Labeled Data","summary":"  Most research on hate speech detection has focused on English where a\nsizeable amount of labeled training data is available. However, to expand hate\nspeech detection into more languages, approaches that require minimal training\ndata are needed. In this paper, we test whether natural language inference\n(NLI) models which perform well in zero- and few-shot settings can benefit hate\nspeech detection performance in scenarios where only a limited amount of\nlabeled data is available in the target language. Our evaluation on five\nlanguages demonstrates large performance improvements of NLI fine-tuning over\ndirect fine-tuning in the target language. However, the effectiveness of\nprevious work that proposed intermediate fine-tuning on English data is hard to\nmatch. Only in settings where the English training data does not match the test\ndomain, can our customised NLI-formulation outperform intermediate fine-tuning\non English. Based on our extensive experiments, we propose a set of\nrecommendations for hate speech detection in languages where minimal labeled\ntraining data is available.\n","authors":["Janis Goldzycher","Moritz Preisig","Chantal Amrhein","Gerold Schneider"],"pdf_url":"https://arxiv.org/pdf/2306.03722v1.pdf","comment":"15 pages, 7 figures, Accepted at the 7th Workshop on Online Abuse and\n  Harms (WOAH), ACL 2023"},{"id":"http://arxiv.org/abs/2210.07523v3","updated":"2023-06-06T14:30:11Z","published":"2022-10-14T05:10:53Z","title":"Self-Adaptive Named Entity Recognition by Retrieving Unstructured\n  Knowledge","summary":"  Although named entity recognition (NER) helps us to extract domain-specific\nentities from text (e.g., artists in the music domain), it is costly to create\na large amount of training data or a structured knowledge base to perform\naccurate NER in the target domain. Here, we propose self-adaptive NER, which\nretrieves external knowledge from unstructured text to learn the usages of\nentities that have not been learned well. To retrieve useful knowledge for NER,\nwe design an effective two-stage model that retrieves unstructured knowledge\nusing uncertain entities as queries. Our model predicts the entities in the\ninput and then finds those of which the prediction is not confident. Then, it\nretrieves knowledge by using these uncertain entities as queries and\nconcatenates the retrieved text to the original input to revise the prediction.\nExperiments on CrossNER datasets demonstrated that our model outperforms strong\nbaselines by 2.35 points in F1 metric.\n","authors":["Kosuke Nishida","Naoki Yoshinaga","Kyosuke Nishida"],"pdf_url":"https://arxiv.org/pdf/2210.07523v3.pdf","comment":"EACL2023 (long)"},{"id":"http://arxiv.org/abs/2302.07636v2","updated":"2023-06-06T14:17:46Z","published":"2023-02-15T13:07:34Z","title":"DP-BART for Privatized Text Rewriting under Local Differential Privacy","summary":"  Privatized text rewriting with local differential privacy (LDP) is a recent\napproach that enables sharing of sensitive textual documents while formally\nguaranteeing privacy protection to individuals. However, existing systems face\nseveral issues, such as formal mathematical flaws, unrealistic privacy\nguarantees, privatization of only individual words, as well as a lack of\ntransparency and reproducibility. In this paper, we propose a new system\n'DP-BART' that largely outperforms existing LDP systems. Our approach uses a\nnovel clipping method, iterative pruning, and further training of internal\nrepresentations which drastically reduces the amount of noise required for DP\nguarantees. We run experiments on five textual datasets of varying sizes,\nrewriting them at different privacy guarantees and evaluating the rewritten\ntexts on downstream text classification tasks. Finally, we thoroughly discuss\nthe privatized text rewriting approach and its limitations, including the\nproblem of the strict text adjacency constraint in the LDP paradigm that leads\nto the high noise requirement.\n","authors":["Timour Igamberdiev","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2302.07636v2.pdf","comment":"Accepted at ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.00107v2","updated":"2023-06-06T14:06:02Z","published":"2023-05-31T18:27:43Z","title":"MERT: Acoustic Music Understanding Model with Large-Scale\n  Self-supervised Training","summary":"  Self-supervised learning (SSL) has recently emerged as a promising paradigm\nfor training generalisable models on large-scale data in the fields of vision,\ntext, and speech. Although SSL has been proven effective in speech and audio,\nits application to music audio has yet to be thoroughly explored. This is\nprimarily due to the distinctive challenges associated with modelling musical\nknowledge, particularly its tonal and pitched characteristics of music. To\naddress this research gap, we propose an acoustic Music undERstanding model\nwith large-scale self-supervised Training (MERT), which incorporates teacher\nmodels to provide pseudo labels in the masked language modelling (MLM) style\nacoustic pre-training. In our exploration, we identified a superior combination\nof teacher models, which outperforms conventional speech and audio approaches\nin terms of performance. This combination includes an acoustic teacher based on\nResidual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a musical\nteacher based on the Constant-Q Transform (CQT). These teachers effectively\nguide our student model, a BERT-style transformer encoder, to better model\nmusic audio. In addition, we introduce an in-batch noise mixture augmentation\nto enhance the representation robustness. Furthermore, we explore a wide range\nof settings to overcome the instability in acoustic language model\npre-training, which allows our designed paradigm to scale from 95M to 330M\nparameters. Experimental results indicate that our model can generalise and\nperform well on 14 music understanding tasks and attains state-of-the-art\n(SOTA) overall scores. The code and models are online:\nhttps://github.com/yizhilll/MERT.\n","authors":["Yizhi Li","Ruibin Yuan","Ge Zhang","Yinghao Ma","Xingran Chen","Hanzhi Yin","Chenghua Lin","Anton Ragni","Emmanouil Benetos","Norbert Gyenge","Roger Dannenberg","Ruibo Liu","Wenhu Chen","Gus Xia","Yemin Shi","Wenhao Huang","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.00107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03678v1","updated":"2023-06-06T13:41:09Z","published":"2023-06-06T13:41:09Z","title":"On the Difference of BERT-style and CLIP-style Text Encoders","summary":"  Masked language modeling (MLM) has been one of the most popular pretraining\nrecipes in natural language processing, e.g., BERT, one of the representative\nmodels. Recently, contrastive language-image pretraining (CLIP) has also\nattracted attention, especially its vision models that achieve excellent\nperformance on a broad range of vision tasks. However, few studies are\ndedicated to studying the text encoders learned by CLIP. In this paper, we\nanalyze the difference between BERT-style and CLIP-style text encoders from\nthree experiments: (i) general text understanding, (ii) vision-centric text\nunderstanding, and (iii) text-to-image generation. Experimental analyses show\nthat although CLIP-style text encoders underperform BERT-style ones for general\ntext understanding tasks, they are equipped with a unique ability, i.e.,\nsynesthesia, for the cross-modal association, which is more similar to the\nsenses of humans.\n","authors":["Zhihong Chen","Guiming Hardy Chen","Shizhe Diao","Xiang Wan","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2306.03678v1.pdf","comment":"Natural Language Processing. 10 pages, 1 figure. Findings of ACL-2023"},{"id":"http://arxiv.org/abs/2301.11462v2","updated":"2023-06-06T13:40:22Z","published":"2023-01-26T23:24:17Z","title":"How poor is the stimulus? Evaluating hierarchical generalization in\n  neural networks trained on child-directed speech","summary":"  When acquiring syntax, children consistently choose hierarchical rules over\ncompeting non-hierarchical possibilities. Is this preference due to a learning\nbias for hierarchical structure, or due to more general biases that interact\nwith hierarchical cues in children's linguistic input? We explore these\npossibilities by training LSTMs and Transformers - two types of neural networks\nwithout a hierarchical bias - on data similar in quantity and content to\nchildren's linguistic input: text from the CHILDES corpus. We then evaluate\nwhat these models have learned about English yes/no questions, a phenomenon for\nwhich hierarchical structure is crucial. We find that, though they perform well\nat capturing the surface statistics of child-directed speech (as measured by\nperplexity), both model types generalize in a way more consistent with an\nincorrect linear rule than the correct hierarchical rule. These results suggest\nthat human-like generalization from text alone requires stronger biases than\nthe general sequence-processing biases of standard neural network\narchitectures.\n","authors":["Aditya Yedetore","Tal Linzen","Robert Frank","R. Thomas McCoy"],"pdf_url":"https://arxiv.org/pdf/2301.11462v2.pdf","comment":"10 pages plus references and appendices; accepted to ACL"},{"id":"http://arxiv.org/abs/2306.03652v1","updated":"2023-06-06T13:13:27Z","published":"2023-06-06T13:13:27Z","title":"Injecting knowledge into language generation: a case study in\n  auto-charting after-visit care instructions from medical dialogue","summary":"  Factual correctness is often the limiting factor in practical applications of\nnatural language generation in high-stakes domains such as healthcare. An\nessential requirement for maintaining factuality is the ability to deal with\nrare tokens. This paper focuses on rare tokens that appear in both the source\nand the reference sequences, and which, when missed during generation, decrease\nthe factual correctness of the output text. For high-stake domains that are\nalso knowledge-rich, we show how to use knowledge to (a) identify which rare\ntokens that appear in both source and reference are important and (b) uplift\ntheir conditional probability. We introduce the ``utilization rate'' that\nencodes knowledge and serves as a regularizer by maximizing the marginal\nprobability of selected tokens. We present a study in a knowledge-rich domain\nof healthcare, where we tackle the problem of generating after-visit care\ninstructions based on patient-doctor dialogues. We verify that, in our dataset,\nspecific medical concepts with high utilization rates are underestimated by\nconventionally trained sequence-to-sequence models. We observe that correcting\nthis with our approach to knowledge injection reduces the uncertainty of the\nmodel as well as improves factuality and coherence without negatively impacting\nfluency.\n","authors":["Maksim Eremeev","Ilya Valmianski","Xavier Amatriain","Anitha Kannan"],"pdf_url":"https://arxiv.org/pdf/2306.03652v1.pdf","comment":"ACL 2023 (main conference)"},{"id":"http://arxiv.org/abs/2302.08215v2","updated":"2023-06-06T13:09:21Z","published":"2023-02-16T10:59:39Z","title":"Aligning Language Models with Preferences through f-divergence\n  Minimization","summary":"  Aligning language models with preferences can be posed as approximating a\ntarget distribution representing some desired behavior. Existing approaches\ndiffer both in the functional form of the target distribution and the algorithm\nused to approximate it. For instance, Reinforcement Learning from Human\nFeedback (RLHF) corresponds to minimizing a reverse KL from an implicit target\ndistribution arising from a KL penalty in the objective. On the other hand,\nGenerative Distributional Control (GDC) has an explicit target distribution and\nminimizes a forward KL from it using the Distributional Policy Gradient (DPG)\nalgorithm. In this paper, we propose a new approach, f-DPG, which allows the\nuse of any f-divergence to approximate any target distribution that can be\nevaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation\nmethods (DPG, RL with KL penalties). We show the practical benefits of various\nchoices of divergence objectives and demonstrate that there is no universally\noptimal objective but that different divergences present different alignment\nand diversity trade-offs. We show that Jensen-Shannon divergence strikes a good\nbalance between these objectives, and frequently outperforms forward KL\ndivergence by a wide margin, leading to significant improvements over prior\nwork. These distinguishing characteristics between divergences persist as the\nmodel size increases, highlighting the importance of selecting appropriate\ndivergence objectives.\n","authors":["Dongyoung Go","Tomasz Korbak","Germán Kruszewski","Jos Rozen","Nahyeon Ryu","Marc Dymetman"],"pdf_url":"https://arxiv.org/pdf/2302.08215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03650v1","updated":"2023-06-06T13:08:22Z","published":"2023-06-06T13:08:22Z","title":"A Quantum Probability Driven Framework for Joint Multi-Modal Sarcasm,\n  Sentiment and Emotion Analysis","summary":"  Sarcasm, sentiment, and emotion are three typical kinds of spontaneous\naffective responses of humans to external events and they are tightly\nintertwined with each other. Such events may be expressed in multiple\nmodalities (e.g., linguistic, visual and acoustic), e.g., multi-modal\nconversations. Joint analysis of humans' multi-modal sarcasm, sentiment, and\nemotion is an important yet challenging topic, as it is a complex cognitive\nprocess involving both cross-modality interaction and cross-affection\ncorrelation. From the probability theory perspective, cross-affection\ncorrelation also means that the judgments on sarcasm, sentiment, and emotion\nare incompatible. However, this exposed phenomenon cannot be sufficiently\nmodelled by classical probability theory due to its assumption of\ncompatibility. Neither do the existing approaches take it into consideration.\nIn view of the recent success of quantum probability (QP) in modeling human\ncognition, particularly contextual incompatible decision making, we take the\nfirst step towards introducing QP into joint multi-modal sarcasm, sentiment,\nand emotion analysis. Specifically, we propose a QUantum probabIlity driven\nmulti-modal sarcasm, sEntiment and emoTion analysis framework, termed QUIET.\nExtensive experiments on two datasets and the results show that the\neffectiveness and advantages of QUIET in comparison with a wide range of the\nstate-of-the-art baselines. We also show the great potential of QP in\nmulti-affect analysis.\n","authors":["Yaochen Liu","Yazhou Zhang","Dawei Song"],"pdf_url":"https://arxiv.org/pdf/2306.03650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03939v2","updated":"2023-06-06T12:48:48Z","published":"2022-04-08T08:59:33Z","title":"GigaST: A 10,000-hour Pseudo Speech Translation Corpus","summary":"  This paper introduces GigaST, a large-scale pseudo speech translation (ST)\ncorpus. We create the corpus by translating the text in GigaSpeech, an English\nASR corpus, into German and Chinese. The training set is translated by a strong\nmachine translation system and the test set is translated by human. ST models\ntrained with an addition of our corpus obtain new state-of-the-art results on\nthe MuST-C English-German benchmark test set. We provide a detailed description\nof the translation process and verify its quality. We make the translated text\ndata public and hope to facilitate research in speech translation.\nAdditionally, we also release the training scripts on NeurST to make it easy to\nreplicate our systems. GigaST dataset is available at\nhttps://st-benchmark.github.io/resources/GigaST.\n","authors":["Rong Ye","Chengqi Zhao","Tom Ko","Chutong Meng","Tao Wang","Mingxuan Wang","Jun Cao"],"pdf_url":"https://arxiv.org/pdf/2204.03939v2.pdf","comment":"Accepted at Interspeech 2023. GigaST dataset is available at\n  https://st-benchmark.github.io/resources/GigaST"},{"id":"http://arxiv.org/abs/2306.02051v2","updated":"2023-06-06T12:39:21Z","published":"2023-06-03T08:39:25Z","title":"A Comprehensive Survey on Deep Learning for Relation Extraction: Recent\n  Advances and New Frontiers","summary":"  Relation extraction (RE) involves identifying the relations between entities\nfrom unstructured texts. RE serves as the foundation for many natural language\nprocessing (NLP) applications, such as knowledge graph completion, question\nanswering, and information retrieval. In recent years, deep neural networks\nhave dominated the field of RE and made noticeable progress. Subsequently, the\nlarge pre-trained language models (PLMs) have taken the state-of-the-art of RE\nto a new level. This survey provides a comprehensive review of existing deep\nlearning techniques for RE. First, we introduce RE resources, including RE\ndatasets and evaluation metrics. Second, we propose a new taxonomy to\ncategorize existing works from three perspectives (text representation, context\nencoding, and triplet prediction). Third, we discuss several important\nchallenges faced by RE and summarize potential techniques to tackle these\nchallenges. Finally, we outline some promising future directions and prospects\nin this field. This survey is expected to facilitate researchers' collaborative\nefforts to tackle the challenges of real-life RE systems.\n","authors":["Xiaoyan Zhao","Yang Deng","Min Yang","Lingzhi Wang","Rui Zhang","Hong Cheng","Wai Lam","Ying Shen","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2306.02051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03628v1","updated":"2023-06-06T12:30:29Z","published":"2023-06-06T12:30:29Z","title":"Convergence and Diversity in the Control Hierarchy","summary":"  Weir has defined a hierarchy of language classes whose second member\n($\\mathcal{L}_2$) is generated by tree-adjoining grammars (TAG), linear indexed\ngrammars (LIG), combinatory categorial grammars, and head grammars. The\nhierarchy is obtained using the mechanism of control, and $\\mathcal{L}_2$ is\nobtained using a context-free grammar (CFG) whose derivations are controlled by\nanother CFG. We adapt Weir's definition of a controllable CFG to give a\ndefinition of controllable pushdown automata (PDAs). This yields three new\ncharacterizations of $\\mathcal{L}_2$ as the class of languages generated by\nPDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs. We\nshow that these four formalisms are not only weakly equivalent but equivalent\nin a stricter sense that we call d-weak equivalence. Furthermore, using an even\nstricter notion of equivalence called d-strong equivalence, we make precise the\nintuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an\nembedded PDA, and a PDA controlling a CFG is a LIG. The fourth member of this\nfamily, a CFG controlling a PDA, does not correspond to any formalism we know\nof, so we invent one and call it a Pushdown Adjoining Automaton.\n","authors":["Alexandra Butoi","Ryan Cotterell","David Chiang"],"pdf_url":"https://arxiv.org/pdf/2306.03628v1.pdf","comment":"18 pages, 7 figures. Accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2306.02858v2","updated":"2023-06-06T12:28:37Z","published":"2023-06-05T13:17:27Z","title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video\n  Understanding","summary":"  We present Video-LLaMA, a multi-modal framework that empowers Large Language\nModels (LLMs) with the capability of understanding both visual and auditory\ncontent in the video. Video-LLaMA bootstraps cross-modal training from the\nfrozen pre-trained visual & audio encoders and the frozen LLMs. Unlike previous\nvision-LLMs that focus on static image comprehensions such as MiniGPT-4 and\nLLaVA, Video-LLaMA mainly tackles two challenges in video understanding: (1)\ncapturing the temporal changes in visual scenes, (2) integrating audio-visual\nsignals. To counter the first challenge, we propose a Video Q-former to\nassemble the pre-trained image encoder into our video encoder and introduce a\nvideo-to-text generation task to learn video-language correspondence. For the\nsecond challenge, we leverage ImageBind, a universal embedding model aligning\nmultiple modalities as the pre-trained audio encoder, and introduce an Audio\nQ-former on top of ImageBind to learn reasonable auditory query embeddings for\nthe LLM module. To align the output of both visual & audio encoders with LLM's\nembedding space, we train Video-LLaMA on massive video/image-caption pairs as\nwell as visual-instruction-tuning datasets of moderate amount but higher\nquality. We found Video-LLaMA showcases the ability to perceive and comprehend\nvideo content, generating meaningful responses that are grounded in the visual\nand auditory information presented in the videos. This highlights the potential\nof Video-LLaMA as a promising prototype for audio-visual AI assistants.\n","authors":["Hang Zhang","Xin Li","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2306.02858v2.pdf","comment":"Technical Report; Code, Pretrained Model, and Dataset:\n  https://github.com/DAMO-NLP-SG/Video-LLaMA"},{"id":"http://arxiv.org/abs/2305.03506v3","updated":"2023-06-06T12:19:35Z","published":"2023-05-04T10:13:15Z","title":"SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention\n  for Emotion Recognition in Conversation","summary":"  Emotion Recognition in Conversation~(ERC) across modalities is of vital\nimportance for a variety of applications, including intelligent healthcare,\nartificial intelligence for conversation, and opinion mining over chat history.\nThe crux of ERC is to model both cross-modality and cross-time interactions\nthroughout the conversation. Previous methods have made progress in learning\nthe time series information of conversation while lacking the ability to trace\ndown the different emotional states of each speaker in a conversation. In this\npaper, we propose a recurrent structure called Speaker Information Enhanced\nLong-Short Term Memory (SI-LSTM) for the ERC task, where the emotional states\nof the distinct speaker can be tracked in a sequential way to enhance the\nlearning of the emotion in conversation. Further, to improve the learning of\nmultimodal features in ERC, we utilize a cross-modal attention component to\nfuse the features between different modalities and model the interaction of the\nimportant information from different modalities. Experimental results on two\nbenchmark datasets demonstrate the superiority of the proposed SI-LSTM against\nthe state-of-the-art baseline methods in the ERC task on multimodal data.\n","authors":["Xingwei Liang","You Zou","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2305.03506v3.pdf","comment":"modification needed"},{"id":"http://arxiv.org/abs/2212.01692v3","updated":"2023-06-06T12:09:47Z","published":"2022-12-03T21:14:32Z","title":"Can In-context Learners Learn a Reasoning Concept from Demonstrations?","summary":"  Large language models show an emergent ability to learn a new task from a\nsmall number of input-output demonstrations. However, recent work shows that\nin-context learners largely rely on their pre-trained knowledge, such as the\nsentiment of the labels, instead of finding new associations in the input.\nHowever, the commonly-used few-shot evaluation settings using a random\nselection of in-context demonstrations can not disentangle models' ability to\nlearn a new skill from demonstrations, as most of the randomly-selected\ndemonstrations do not present relations informative for prediction beyond\nexposing the new task distribution.\n  To disentangle models' in-context learning ability independent of models'\nmemory, we introduce a Conceptual few-shot learning method selecting the\ndemonstrations sharing a possibly-informative concept with the predicted\nsample. We extract a set of such concepts from annotated explanations and\nmeasure how much can models benefit from presenting these concepts in few-shot\ndemonstrations.\n  We find that smaller models are more sensitive to the presented concepts.\nWhile some of the models are able to benefit from concept-presenting\ndemonstrations for each assessed concept, we find that none of the assessed\nin-context learners can benefit from all presented reasoning concepts\nconsistently, leaving the in-context concept learning an open challenge.\n","authors":["Michal Štefánik","Marek Kadlčík"],"pdf_url":"https://arxiv.org/pdf/2212.01692v3.pdf","comment":"Accepted at ACL 2023 Natural Language Reasoning workshop"},{"id":"http://arxiv.org/abs/2304.06653v3","updated":"2023-06-06T11:56:27Z","published":"2023-04-13T16:28:07Z","title":"Graph2topic: an opensource topic modeling framework based on sentence\n  embedding and community detection","summary":"  It has been reported that clustering-based topic models, which cluster\nhigh-quality sentence embeddings with an appropriate word selection method, can\ngenerate better topics than generative probabilistic topic models. However,\nthese approaches suffer from the inability to select appropriate parameters and\nincomplete models that overlook the quantitative relation between words with\ntopics and topics with text. To solve these issues, we propose graph to topic\n(G2T), a simple but effective framework for topic modelling. The framework is\ncomposed of four modules. First, document representation is acquired using\npretrained language models. Second, a semantic graph is constructed according\nto the similarity between document representations. Third, communities in\ndocument semantic graphs are identified, and the relationship between topics\nand documents is quantified accordingly. Fourth, the word--topic distribution\nis computed based on a variant of TFIDF. Automatic evaluation suggests that G2T\nachieved state-of-the-art performance on both English and Chinese documents\nwith different lengths.\n","authors":["Leihang Zhang","Jiapeng Liu","Qiang Yan"],"pdf_url":"https://arxiv.org/pdf/2304.06653v3.pdf","comment":"11pages"},{"id":"http://arxiv.org/abs/2305.02770v3","updated":"2023-06-06T11:56:03Z","published":"2023-05-04T12:15:54Z","title":"The Politics of Language Choice: How the Russian-Ukrainian War\n  Influences Ukrainians' Language Use on Twitter","summary":"  The use of language is innately political and often a vehicle of cultural\nidentity as well as the basis for nation building. Here, we examine language\nchoice and tweeting activity of Ukrainian citizens based on more than 4 million\ngeo-tagged tweets from over 62,000 users before and during the\nRussian-Ukrainian War, from January 2020 to October 2022. Using statistical\nmodels, we disentangle sample effects, arising from the in- and outflux of\nusers on Twitter, from behavioural effects, arising from behavioural changes of\nthe users. We observe a steady shift from the Russian language towards the\nUkrainian language already before the war, which drastically speeds up with its\noutbreak. We attribute these shifts in large part to users' behavioural\nchanges. Notably, we find that more than half of the Russian-tweeting users\nshift towards Ukrainian as a result of the war.\n","authors":["Daniel Racek","Brittany I. Davidson","Paul W. Thurner","Xiao Xiang Zhu","Göran Kauermann"],"pdf_url":"https://arxiv.org/pdf/2305.02770v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03608v1","updated":"2023-06-06T11:54:48Z","published":"2023-06-06T11:54:48Z","title":"A Survey of Quantum-Cognitively Inspired Sentiment Analysis Models","summary":"  Quantum theory, originally proposed as a physical theory to describe the\nmotions of microscopic particles, has been applied to various non-physics\ndomains involving human cognition and decision-making that are inherently\nuncertain and exhibit certain non-classical, quantum-like characteristics.\nSentiment analysis is a typical example of such domains. In the last few years,\nby leveraging the modeling power of quantum probability (a non-classical\nprobability stemming from quantum mechanics methodology) and deep neural\nnetworks, a range of novel quantum-cognitively inspired models for sentiment\nanalysis have emerged and performed well. This survey presents a timely\noverview of the latest developments in this fascinating cross-disciplinary\narea. We first provide a background of quantum probability and quantum\ncognition at a theoretical level, analyzing their advantages over classical\ntheories in modeling the cognitive aspects of sentiment analysis. Then, recent\nquantum-cognitively inspired models are introduced and discussed in detail,\nfocusing on how they approach the key challenges of the sentiment analysis\ntask. Finally, we discuss the limitations of the current research and highlight\nfuture research directions.\n","authors":["Yaochen Liu","Qiuchi Li","Benyou Wang","Yazhou Zhang","Dawei Song"],"pdf_url":"https://arxiv.org/pdf/2306.03608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03598v1","updated":"2023-06-06T11:37:46Z","published":"2023-06-06T11:37:46Z","title":"CUE: An Uncertainty Interpretation Framework for Text Classifiers Built\n  on Pre-Trained Language Models","summary":"  Text classifiers built on Pre-trained Language Models (PLMs) have achieved\nremarkable progress in various tasks including sentiment analysis, natural\nlanguage inference, and question-answering. However, the occurrence of\nuncertain predictions by these classifiers poses a challenge to their\nreliability when deployed in practical applications. Much effort has been\ndevoted to designing various probes in order to understand what PLMs capture.\nBut few studies have delved into factors influencing PLM-based classifiers'\npredictive uncertainty. In this paper, we propose a novel framework, called\nCUE, which aims to interpret uncertainties inherent in the predictions of\nPLM-based models. In particular, we first map PLM-encoded representations to a\nlatent space via a variational auto-encoder. We then generate text\nrepresentations by perturbing the latent space which causes fluctuation in\npredictive uncertainty. By comparing the difference in predictive uncertainty\nbetween the perturbed and the original text representations, we are able to\nidentify the latent dimensions responsible for uncertainty and subsequently\ntrace back to the input features that contribute to such uncertainty. Our\nextensive experiments on four benchmark datasets encompassing linguistic\nacceptability classification, emotion classification, and natural language\ninference show the feasibility of our proposed framework. Our source code is\navailable at: https://github.com/lijiazheng99/CUE.\n","authors":["Jiazheng Li","Zhaoyue Sun","Bin Liang","Lin Gui","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2306.03598v1.pdf","comment":"Accepted to UAI 2023"},{"id":"http://arxiv.org/abs/2211.17223v3","updated":"2023-06-06T11:25:34Z","published":"2022-11-30T18:22:37Z","title":"Topological Data Analysis for Speech Processing","summary":"  We apply topological data analysis (TDA) to speech classification problems\nand to the introspection of a pretrained speech model, HuBERT. To this end, we\nintroduce a number of topological and algebraic features derived from\nTransformer attention maps and embeddings. We show that a simple linear\nclassifier built on top of such features outperforms a fine-tuned\nclassification head. In particular, we achieve an improvement of about $9\\%$\naccuracy and $5\\%$ ERR on four common datasets; on CREMA-D, the proposed\nfeature set reaches a new state of the art performance with accuracy $80.155$.\nWe also show that topological features are able to reveal functional roles of\nspeech Transformer heads; e.g., we find the heads capable to distinguish\nbetween pairs of sample sources (natural/synthetic) or voices without any\ndownstream fine-tuning. Our results demonstrate that TDA is a promising new\napproach for speech analysis, especially for tasks that require structural\nprediction. Appendices, an introduction to TDA, and other additional materials\nare available here - https://topohubert.github.io/speech-topology-webpages/\n","authors":["Eduard Tulchinskii","Kristian Kuznetsov","Laida Kushnareva","Daniil Cherniavskii","Serguei Barannikov","Irina Piontkovskaya","Sergey Nikolenko","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2211.17223v3.pdf","comment":"Accepted to INTERSPEECH 2023 conference"},{"id":"http://arxiv.org/abs/2306.03586v1","updated":"2023-06-06T11:08:20Z","published":"2023-06-06T11:08:20Z","title":"Language acquisition: do children and language models follow similar\n  learning stages?","summary":"  During language acquisition, children follow a typical sequence of learning\nstages, whereby they first learn to categorize phonemes before they develop\ntheir lexicon and eventually master increasingly complex syntactic structures.\nHowever, the computational principles that lead to this learning trajectory\nremain largely unknown. To investigate this, we here compare the learning\ntrajectories of deep language models to those of children. Specifically, we\ntest whether, during its training, GPT-2 exhibits stages of language\nacquisition comparable to those observed in children aged between 18 months and\n6 years. For this, we train 48 GPT-2 models from scratch and evaluate their\nsyntactic and semantic abilities at each training step, using 96 probes curated\nfrom the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these\nevaluations with the behavior of 54 children during language production. Our\nanalyses reveal three main findings. First, similarly to children, the language\nmodels tend to learn linguistic skills in a systematic order. Second, this\nlearning scheme is parallel: the language tasks that are learned last improve\nfrom the very first training steps. Third, some - but not all - learning stages\nare shared between children and these language models. Overall, these results\nshed new light on the principles of language acquisition, and highlight\nimportant divergences in how humans and modern algorithms learn to process\nnatural language.\n","authors":["Linnea Evanson","Yair Lakretz","Jean-Rémi King"],"pdf_url":"https://arxiv.org/pdf/2306.03586v1.pdf","comment":"Accepted to ACL 2023. *Equal Contribution"},{"id":"http://arxiv.org/abs/2210.02969v4","updated":"2023-06-06T11:03:31Z","published":"2022-10-06T15:00:47Z","title":"Guess the Instruction! Flipped Learning Makes Language Models Stronger\n  Zero-Shot Learners","summary":"  Meta-training, which fine-tunes the language model (LM) on various downstream\ntasks by maximizing the likelihood of the target label given the task\ninstruction and input instance, has improved the zero-shot task generalization\nperformance. However, meta-trained LMs still struggle to generalize to\nchallenging tasks containing novel labels unseen during meta-training. In this\npaper, we propose Flipped Learning, an alternative method of meta-training\nwhich trains the LM to generate the task instruction given the input instance\nand label. During inference, the LM trained with Flipped Learning, referred to\nas Flipped, selects the label option that is most likely to generate the task\ninstruction. On 14 tasks of the BIG-bench benchmark, the 11B-sized Flipped\noutperforms zero-shot T0-11B and even a 16 times larger 3-shot GPT-3 (175B) on\naverage by 8.4% and 9.7% points, respectively. Flipped gives particularly large\nimprovements on tasks with unseen labels, outperforming T0-11B by up to +20%\naverage F1 score. This indicates that the strong task generalization of Flipped\ncomes from improved generalization to novel labels. We release our code at\nhttps://github.com/seonghyeonye/Flipped-Learning.\n","authors":["Seonghyeon Ye","Doyoung Kim","Joel Jang","Joongbo Shin","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2210.02969v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2305.12464v2","updated":"2023-06-06T10:49:29Z","published":"2023-05-21T14:03:54Z","title":"Self-supervised Predictive Coding Models Encode Speaker and Phonetic\n  Information in Orthogonal Subspaces","summary":"  Self-supervised speech representations are known to encode both speaker and\nphonetic information, but how they are distributed in the high-dimensional\nspace remains largely unexplored. We hypothesize that they are encoded in\northogonal subspaces, a property that lends itself to simple disentanglement.\nApplying principal component analysis to representations of two predictive\ncoding models, we identify two subspaces that capture speaker and phonetic\nvariances, and confirm that they are nearly orthogonal. Based on this property,\nwe propose a new speaker normalization method which collapses the subspace that\nencodes speaker information, without requiring transcriptions. Probing\nexperiments show that our method effectively eliminates speaker information and\noutperforms a previous baseline in phone discrimination tasks. Moreover, the\napproach generalizes and can be used to remove information of unseen speakers.\n","authors":["Oli Liu","Hao Tang","Sharon Goldwater"],"pdf_url":"https://arxiv.org/pdf/2305.12464v2.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.03557v1","updated":"2023-06-06T10:18:17Z","published":"2023-06-06T10:18:17Z","title":"Take the Hint: Improving Arabic Diacritization with\n  Partially-Diacritized Text","summary":"  Automatic Arabic diacritization is useful in many applications, ranging from\nreading support for language learners to accurate pronunciation predictor for\ndownstream tasks like speech synthesis. While most of the previous works\nfocused on models that operate on raw non-diacritized text, production systems\ncan gain accuracy by first letting humans partly annotate ambiguous words. In\nthis paper, we propose 2SDiac, a multi-source model that can effectively\nsupport optional diacritics in input to inform all predictions. We also\nintroduce Guided Learning, a training scheme to leverage given diacritics in\ninput with different levels of random masking. We show that the provided hints\nduring test affect more output positions than those annotated. Moreover,\nexperiments on two common benchmarks show that our approach i) greatly\noutperforms the baseline also when evaluated on non-diacritized text; and ii)\nachieves state-of-the-art results while reducing the parameter count by over\n60%.\n","authors":["Parnia Bahar","Mattia Di Gangi","Nick Rossenbach","Mohammad Zeineldeen"],"pdf_url":"https://arxiv.org/pdf/2306.03557v1.pdf","comment":"Arabic text diacritization, partially-diacritized text, Arabic\n  natural language processing"},{"id":"http://arxiv.org/abs/2306.03535v1","updated":"2023-06-06T09:34:45Z","published":"2023-06-06T09:34:45Z","title":"SciLit: A Platform for Joint Scientific Literature Discovery,\n  Summarization and Citation Generation","summary":"  Scientific writing involves retrieving, summarizing, and citing relevant\npapers, which can be time-consuming processes in large and rapidly evolving\nfields. By making these processes inter-operable, natural language processing\n(NLP) provides opportunities for creating end-to-end assistive writing tools.\nWe propose SciLit, a pipeline that automatically recommends relevant papers,\nextracts highlights, and suggests a reference sentence as a citation of a\npaper, taking into consideration the user-provided context and keywords. SciLit\nefficiently recommends papers from large databases of hundreds of millions of\npapers using a two-stage pre-fetching and re-ranking literature search system\nthat flexibly deals with addition and removal of a paper database. We provide a\nconvenient user interface that displays the recommended papers as extractive\nsummaries and that offers abstractively-generated citing sentences which are\naligned with the provided context and which mention the chosen keyword(s). Our\nassistive tool for literature discovery and scientific writing is available at\nhttps://scilit.vercel.app\n","authors":["Nianlong Gu","Richard H. R. Hahnloser"],"pdf_url":"https://arxiv.org/pdf/2306.03535v1.pdf","comment":"Accepted at ACL 2023 System Demonstration"},{"id":"http://arxiv.org/abs/2210.05643v4","updated":"2023-06-06T09:06:42Z","published":"2022-10-11T17:34:32Z","title":"A Kernel-Based View of Language Model Fine-Tuning","summary":"  It has become standard to solve NLP tasks by fine-tuning pre-trained language\nmodels (LMs), especially in low-data settings. There is minimal theoretical\nunderstanding of empirical success, e.g., why fine-tuning a model with $10^8$\nor more parameters on a couple dozen training points does not result in\noverfitting. We investigate whether the Neural Tangent Kernel (NTK) - which\noriginated as a model to study the gradient descent dynamics of infinitely wide\nnetworks with suitable random initialization - describes fine-tuning of\npre-trained LMs. This study was inspired by the decent performance of NTK for\ncomputer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam\nand use Tensor Programs (Yang, 2020) to characterize conditions under which the\nNTK lens may describe fine-tuning updates to pre-trained language models.\nExtensive experiments on 14 NLP tasks validate our theory and show that\nformulating the downstream task as a masked word prediction problem through\nprompting often induces kernel-based dynamics during fine-tuning. Finally, we\nuse this kernel view to propose an explanation for the success of\nparameter-efficient subspace-based fine-tuning methods.\n","authors":["Sadhika Malladi","Alexander Wettig","Dingli Yu","Danqi Chen","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2210.05643v4.pdf","comment":"Accepted at ICML 2023. Code and pre-computed kernels are publicly\n  available at https://github.com/princeton-nlp/LM-Kernel-FT"},{"id":"http://arxiv.org/abs/2306.03507v1","updated":"2023-06-06T08:53:01Z","published":"2023-06-06T08:53:01Z","title":"\"A Little is Enough\": Few-Shot Quality Estimation based Corpus Filtering\n  improves Machine Translation","summary":"  Quality Estimation (QE) is the task of evaluating the quality of a\ntranslation when reference translation is not available. The goal of QE aligns\nwith the task of corpus filtering, where we assign the quality score to the\nsentence pairs present in the pseudo-parallel corpus. We propose a Quality\nEstimation based Filtering approach to extract high-quality parallel data from\nthe pseudo-parallel corpus. To the best of our knowledge, this is a novel\nadaptation of the QE framework to extract quality parallel corpus from the\npseudo-parallel corpus. By training with this filtered corpus, we observe an\nimprovement in the Machine Translation (MT) system's performance by up to 1.8\nBLEU points, for English-Marathi, Chinese-English, and Hindi-Bengali language\npairs, over the baseline model. The baseline model is the one that is trained\non the whole pseudo-parallel corpus. Our Few-shot QE model transfer learned\nfrom the English-Marathi QE model and fine-tuned on only 500 Hindi-Bengali\ntraining instances, shows an improvement of up to 0.6 BLEU points for\nHindi-Bengali language pair, compared to the baseline model. This demonstrates\nthe promise of transfer learning in the setting under discussion. QE systems\ntypically require in the order of (7K-25K) of training data. Our Hindi-Bengali\nQE is trained on only 500 instances of training that is 1/40th of the normal\nrequirement and achieves comparable performance. All the scripts and datasets\nutilized in this study will be publicly available.\n","authors":["Akshay Batheja","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2306.03507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03503v1","updated":"2023-06-06T08:47:42Z","published":"2023-06-06T08:47:42Z","title":"Applying Standards to Advance Upstream & Downstream Ethics in Large\n  Language Models","summary":"  This paper explores how AI-owners can develop safeguards for AI-generated\ncontent by drawing from established codes of conduct and ethical standards in\nother content-creation industries. It delves into the current state of ethical\nawareness on Large Language Models (LLMs). By dissecting the mechanism of\ncontent generation by LLMs, four key areas (upstream/downstream and at user\nprompt/answer), where safeguards could be effectively applied, are identified.\nA comparative analysis of these four areas follows and includes an evaluation\nof the existing ethical safeguards in terms of cost, effectiveness, and\nalignment with established industry practices. The paper's key argument is that\nexisting IT-related ethical codes, while adequate for traditional IT\nengineering, are inadequate for the challenges posed by LLM-based content\ngeneration. Drawing from established practices within journalism, we propose\npotential standards for businesses involved in distributing and selling\nLLM-generated content. Finally, potential conflicts of interest between dataset\ncuration at upstream and ethical benchmarking downstream are highlighted to\nunderscore the need for a broader evaluation beyond mere output. This study\nprompts a nuanced conversation around ethical implications in this rapidly\nevolving field of content generation.\n","authors":["Jose Berengueres","Marybeth Sandell"],"pdf_url":"https://arxiv.org/pdf/2306.03503v1.pdf","comment":"8 pages, 4 tables, 2 figures"},{"id":"http://arxiv.org/abs/2306.03500v1","updated":"2023-06-06T08:38:10Z","published":"2023-06-06T08:38:10Z","title":"Towards Adaptable and Interactive Image Captioning with Data\n  Augmentation and Episodic Memory","summary":"  Interactive machine learning (IML) is a beneficial learning paradigm in cases\nof limited data availability, as human feedback is incrementally integrated\ninto the training process. In this paper, we present an IML pipeline for image\ncaptioning which allows us to incrementally adapt a pre-trained image\ncaptioning model to a new data distribution based on user input. In order to\nincorporate user input into the model, we explore the use of a combination of\nsimple data augmentation methods to obtain larger data batches for each newly\nannotated data instance and implement continual learning methods to prevent\ncatastrophic forgetting from repeated updates. For our experiments, we split a\ndomain-specific image captioning dataset, namely VizWiz, into non-overlapping\nparts to simulate an incremental input flow for continually adapting the model\nto new data. We find that, while data augmentation worsens results, even when\nrelatively small amounts of data are available, episodic memory is an effective\nstrategy to retain knowledge from previously seen clusters.\n","authors":["Aliki Anagnostopoulou","Mareike Hartmann","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2306.03500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00093v3","updated":"2023-06-06T08:36:20Z","published":"2023-01-31T20:48:57Z","title":"Large Language Models Can Be Easily Distracted by Irrelevant Context","summary":"  Large language models have achieved impressive performance on various natural\nlanguage processing tasks. However, so far they have been evaluated primarily\non benchmarks where all information in the input context is relevant for\nsolving the task. In this work, we investigate the distractibility of large\nlanguage models, i.e., how the model problem-solving accuracy can be influenced\nby irrelevant context. In particular, we introduce Grade-School Math with\nIrrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant\ninformation in the problem description. We use this benchmark to measure the\ndistractibility of cutting-edge prompting techniques for large language models,\nand find that the model performance is dramatically decreased when irrelevant\ninformation is included. We also identify several approaches for mitigating\nthis deficiency, such as decoding with self-consistency and adding to the\nprompt an instruction that tells the language model to ignore the irrelevant\ninformation.\n","authors":["Freda Shi","Xinyun Chen","Kanishka Misra","Nathan Scales","David Dohan","Ed Chi","Nathanael Schärli","Denny Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.00093v3.pdf","comment":"Published in ICML 2023"},{"id":"http://arxiv.org/abs/2306.03491v1","updated":"2023-06-06T08:16:16Z","published":"2023-06-06T08:16:16Z","title":"SciCap+: A Knowledge Augmented Dataset to Study the Challenges of\n  Scientific Figure Captioning","summary":"  In scholarly documents, figures provide a straightforward way of\ncommunicating scientific findings to readers. Automating figure caption\ngeneration helps move model understandings of scientific documents beyond text\nand will help authors write informative captions that facilitate communicating\nscientific findings. Unlike previous studies, we reframe scientific figure\ncaptioning as a knowledge-augmented image captioning task that models need to\nutilize knowledge embedded across modalities for caption generation. To this\nend, we extended the large-scale SciCap\ndataset~\\cite{hsu-etal-2021-scicap-generating} to SciCap+ which includes\nmention-paragraphs (paragraphs mentioning figures) and OCR tokens. Then, we\nconduct experiments with the M4C-Captioner (a multimodal transformer-based\nmodel with a pointer network) as a baseline for our study. Our results indicate\nthat mention-paragraphs serves as additional context knowledge, which\nsignificantly boosts the automatic standard image caption evaluation scores\ncompared to the figure-only baselines. Human evaluations further reveal the\nchallenges of generating figure captions that are informative to readers. The\ncode and SciCap+ dataset will be publicly available at\nhttps://github.com/ZhishenYang/scientific_figure_captioning_dataset\n","authors":["Zhishen Yang","Raj Dabre","Hideki Tanaka","Naoaki Okazaki"],"pdf_url":"https://arxiv.org/pdf/2306.03491v1.pdf","comment":"Published in SDU workshop at AAAI23"},{"id":"http://arxiv.org/abs/2212.10015v2","updated":"2023-06-06T08:08:29Z","published":"2022-12-20T06:03:51Z","title":"Benchmarking Spatial Relationships in Text-to-Image Generation","summary":"  Spatial understanding is a fundamental aspect of computer vision and integral\nfor human-level reasoning about images, making it an important component for\ngrounded language understanding. While recent text-to-image synthesis (T2I)\nmodels have shown unprecedented improvements in photorealism, it is unclear\nwhether they have reliable spatial understanding capabilities. We investigate\nthe ability of T2I models to generate correct spatial relationships among\nobjects and present VISOR, an evaluation metric that captures how accurately\nthe spatial relationship described in text is generated in the image. To\nbenchmark existing models, we introduce a dataset, SR2D, that contains\nsentences describing two objects and the spatial relationship between them. We\nconstruct an automated evaluation pipeline to recognize objects and their\nspatial relationships, and employ it in a large-scale evaluation of T2I models.\nOur experiments reveal a surprising finding that, although state-of-the-art T2I\nmodels exhibit high image quality, they are severely limited in their ability\nto generate multiple objects or the specified spatial relations between them.\nOur analyses demonstrate several biases and artifacts of T2I models such as the\ndifficulty with generating multiple objects, a bias towards generating the\nfirst object mentioned, spatially inconsistent outputs for equivalent\nrelationships, and a correlation between object co-occurrence and spatial\nunderstanding capabilities. We conduct a human study that shows the alignment\nbetween VISOR and human judgement about spatial understanding. We offer the\nSR2D dataset and the VISOR metric to the community in support of T2I reasoning\nresearch.\n","authors":["Tejas Gokhale","Hamid Palangi","Besmira Nushi","Vibhav Vineet","Eric Horvitz","Ece Kamar","Chitta Baral","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2212.10015v2.pdf","comment":"preprint; Code and Data at https://github.com/microsoft/VISOR and\n  https://huggingface.co/datasets/tgokhale/sr2d_visor"},{"id":"http://arxiv.org/abs/2306.03476v1","updated":"2023-06-06T07:50:46Z","published":"2023-06-06T07:50:46Z","title":"Putting Humans in the Image Captioning Loop","summary":"  Image Captioning (IC) models can highly benefit from human feedback in the\ntraining process, especially in cases where data is limited. We present\nwork-in-progress on adapting an IC system to integrate human feedback, with the\ngoal to make it easily adaptable to user-specific data. Our approach builds on\na base IC model pre-trained on the MS COCO dataset, which generates captions\nfor unseen images. The user will then be able to offer feedback on the image\nand the generated/predicted caption, which will be augmented to create\nadditional training instances for the adaptation of the model. The additional\ninstances are integrated into the model using step-wise updates, and a sparse\nmemory replay component is used to avoid catastrophic forgetting. We hope that\nthis approach, while leading to improved results, will also result in\ncustomizable IC models.\n","authors":["Aliki Anagnostopoulou","Mareike Hartmann","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2306.03476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07981v2","updated":"2023-06-06T07:45:27Z","published":"2022-12-15T17:26:05Z","title":"Revisiting the Gold Standard: Grounding Summarization Evaluation with\n  Robust Human Evaluation","summary":"  Human evaluation is the foundation upon which the evaluation of both\nsummarization systems and automatic metrics rests. However, existing human\nevaluation studies for summarization either exhibit a low inter-annotator\nagreement or have insufficient scale, and an in-depth analysis of human\nevaluation is lacking. Therefore, we address the shortcomings of existing\nsummarization evaluation along the following axes: (1) We propose a modified\nsummarization salience protocol, Atomic Content Units (ACUs), which is based on\nfine-grained semantic units and allows for a high inter-annotator agreement.\n(2) We curate the Robust Summarization Evaluation (RoSE) benchmark, a large\nhuman evaluation dataset consisting of 22,000 summary-level annotations over 28\ntop-performing systems on three datasets. (3) We conduct a comparative study of\nfour human evaluation protocols, underscoring potential confounding factors in\nevaluation setups. (4) We evaluate 50 automatic metrics and their variants\nusing the collected human annotations across evaluation protocols and\ndemonstrate how our benchmark leads to more statistically stable and\nsignificant results. The metrics we benchmarked include recent methods based on\nlarge language models (LLMs), GPTScore and G-Eval. Furthermore, our findings\nhave important implications for evaluating LLMs, as we show that LLMs adjusted\nby human feedback (e.g., GPT-3.5) may overfit unconstrained human evaluation,\nwhich is affected by the annotators' prior, input-agnostic preferences, calling\nfor more robust, targeted evaluation methods.\n","authors":["Yixin Liu","Alexander R. Fabbri","Pengfei Liu","Yilun Zhao","Linyong Nan","Ruilin Han","Simeng Han","Shafiq Joty","Chien-Sheng Wu","Caiming Xiong","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2212.07981v2.pdf","comment":"ACL 2023 Camera Ready"},{"id":"http://arxiv.org/abs/2306.03469v1","updated":"2023-06-06T07:42:39Z","published":"2023-06-06T07:42:39Z","title":"Joint Event Extraction via Structural Semantic Matching","summary":"  Event Extraction (EE) is one of the essential tasks in information\nextraction, which aims to detect event mentions from text and find the\ncorresponding argument roles. The EE task can be abstracted as a process of\nmatching the semantic definitions and argument structures of event types with\nthe target text. This paper encodes the semantic features of event types and\nmakes structural matching with target text. Specifically, Semantic Type\nEmbedding (STE) and Dynamic Structure Encoder (DSE) modules are proposed. Also,\nthe Joint Structural Semantic Matching (JSSM) model is built to jointly perform\nevent detection and argument extraction tasks through a bidirectional attention\nlayer. The experimental results on the ACE2005 dataset indicate that our model\nachieves a significant performance improvement\n","authors":["Haochen Li","Tianhao Gao","Jingkun Wang","Weiping Li"],"pdf_url":"https://arxiv.org/pdf/2306.03469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14953v2","updated":"2023-06-06T07:35:17Z","published":"2023-04-28T16:12:18Z","title":"CCpdf: Building a High Quality Corpus for Visually Rich Documents from\n  Web Crawl Data","summary":"  In recent years, the field of document understanding has progressed a lot. A\nsignificant part of this progress has been possible thanks to the use of\nlanguage models pretrained on large amounts of documents. However, pretraining\ncorpora used in the domain of document understanding are single domain,\nmonolingual, or nonpublic. Our goal in this paper is to propose an efficient\npipeline for creating a big-scale, diverse, multilingual corpus of PDF files\nfrom all over the Internet using Common Crawl, as PDF files are the most\ncanonical types of documents as considered in document understanding. We\nanalysed extensively all of the steps of the pipeline and proposed a solution\nwhich is a trade-off between data quality and processing time. We also share a\nCCpdf corpus in a form or an index of PDF files along with a script for\ndownloading them, which produces a collection useful for language model\npretraining. The dataset and tools published with this paper offer researchers\nthe opportunity to develop even better multilingual language models.\n","authors":["Michał Turski","Tomasz Stanisławek","Karol Kaczmarek","Paweł Dyda","Filip Graliński"],"pdf_url":"https://arxiv.org/pdf/2304.14953v2.pdf","comment":"Accepted at ICDAR 2023"},{"id":"http://arxiv.org/abs/2306.03460v1","updated":"2023-06-06T07:28:49Z","published":"2023-06-06T07:28:49Z","title":"Natural Language Commanding via Program Synthesis","summary":"  We present Semantic Interpreter, a natural language-friendly AI system for\nproductivity software such as Microsoft Office that leverages large language\nmodels (LLMs) to execute user intent across application features. While LLMs\nare excellent at understanding user intent expressed as natural language, they\nare not sufficient for fulfilling application-specific user intent that\nrequires more than text-to-text transformations. We therefore introduce the\nOffice Domain Specific Language (ODSL), a concise, high-level language\nspecialized for performing actions in and interacting with entities in Office\napplications. Semantic Interpreter leverages an Analysis-Retrieval prompt\nconstruction method with LLMs for program synthesis, translating natural\nlanguage user utterances to ODSL programs that can be transpiled to application\nAPIs and then executed. We focus our discussion primarily on a research\nexploration for Microsoft PowerPoint.\n","authors":["Apurva Gandhi","Thong Q. Nguyen","Huitian Jiao","Robert Steen","Ameya Bhatawdekar"],"pdf_url":"https://arxiv.org/pdf/2306.03460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03457v1","updated":"2023-06-06T07:20:51Z","published":"2023-06-06T07:20:51Z","title":"Phonetically-Grounded Language Generation: The Case of Tongue Twisters","summary":"  Previous work in phonetically-grounded language generation has mainly focused\non domains such as lyrics and poetry. In this paper, we present work on the\ngeneration of tongue twisters - a form of language that is required to be\nphonetically conditioned to maximise sound overlap, whilst maintaining semantic\nconsistency with an input topic, and still being grammatically correct. We\npresent \\textbf{TwistList}, a large annotated dataset of tongue twisters,\nconsisting of 2.1K+ human-authored examples. We additionally present several\nbenchmark systems (referred to as TwisterMisters) for the proposed task of\ntongue twister generation, including models that both do and do not require\ntraining on in-domain data. We present the results of automatic and human\nevaluation to demonstrate the performance of existing mainstream pre-trained\nmodels in this task with limited (or no) task specific training and data, and\nno explicit phonetic knowledge. We find that the task of tongue twister\ngeneration is challenging for models under these conditions, yet some models\nare still capable of generating acceptable examples of this language type.\n","authors":["Tyler Loakman","Chen Tang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2306.03457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03444v1","updated":"2023-06-06T06:49:58Z","published":"2023-06-06T06:49:58Z","title":"Automatic Assessment of Oral Reading Accuracy for Reading Diagnostics","summary":"  Automatic assessment of reading fluency using automatic speech recognition\n(ASR) holds great potential for early detection of reading difficulties and\nsubsequent timely intervention. Precise assessment tools are required,\nespecially for languages other than English. In this study, we evaluate six\nstate-of-the-art ASR-based systems for automatically assessing Dutch oral\nreading accuracy using Kaldi and Whisper. Results show our most successful\nsystem reached substantial agreement with human evaluations (MCC = .63). The\nsame system reached the highest correlation between forced decoding confidence\nscores and word correctness (r = .45). This system's language model (LM)\nconsisted of manual orthographic transcriptions and reading prompts of the test\ndata, which shows that including reading errors in the LM improves assessment\nperformance. We discuss the implications for developing automatic assessment\nsystems and identify possible avenues of future research.\n","authors":["Bo Molenaar","Cristian Tejedor-Garcia","Helmer Strik","Catia Cucchiarini"],"pdf_url":"https://arxiv.org/pdf/2306.03444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03443v1","updated":"2023-06-06T06:49:41Z","published":"2023-06-06T06:49:41Z","title":"Alzheimer Disease Classification through ASR-based Transcriptions:\n  Exploring the Impact of Punctuation and Pauses","summary":"  Alzheimer's Disease (AD) is the world's leading neurodegenerative disease,\nwhich often results in communication difficulties. Analysing speech can serve\nas a diagnostic tool for identifying the condition. The recent ADReSS challenge\nprovided a dataset for AD classification and highlighted the utility of manual\ntranscriptions. In this study, we used the new state-of-the-art Automatic\nSpeech Recognition (ASR) model Whisper to obtain the transcriptions, which also\ninclude automatic punctuation. The classification models achieved test accuracy\nscores of 0.854 and 0.833 combining the pretrained FastText word embeddings and\nrecurrent neural networks on manual and ASR transcripts respectively.\nAdditionally, we explored the influence of including pause information and\npunctuation in the transcriptions. We found that punctuation only yielded minor\nimprovements in some cases, whereas pause encoding aided AD classification for\nboth manual and ASR transcriptions across all approaches investigated.\n","authors":["Lucía Gómez-Zaragozá","Simone Wills","Cristian Tejedor-Garcia","Javier Marín-Morales","Mariano Alcañiz","Helmer Strik"],"pdf_url":"https://arxiv.org/pdf/2306.03443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02069v2","updated":"2023-06-06T06:43:07Z","published":"2023-06-03T10:10:38Z","title":"MultiLegalPile: A 689GB Multilingual Legal Corpus","summary":"  Large, high-quality datasets are crucial for training Large Language Models\n(LLMs). However, so far, there are few datasets available for specialized\ncritical domains such as law and the available ones are often only for the\nEnglish language. We curate and release MultiLegalPile, a 689GB corpus in 24\nlanguages from 17 jurisdictions. The MultiLegalPile corpus, which includes\ndiverse legal data sources with varying licenses, allows for pretraining NLP\nmodels under fair use, with more permissive licenses for the Eurlex Resources\nand Legal mC4 subsets. We pretrain two RoBERTa models and one Longformer\nmultilingually, and 24 monolingual models on each of the language-specific\nsubsets and evaluate them on LEXTREME. Additionally, we evaluate the English\nand multilingual models on LexGLUE. Our multilingual models set a new SotA on\nLEXTREME and our English models on LexGLUE. We release the dataset, the trained\nmodels, and all of the code under the most open possible licenses.\n","authors":["Joel Niklaus","Veton Matoshi","Matthias Stürmer","Ilias Chalkidis","Daniel E. Ho"],"pdf_url":"https://arxiv.org/pdf/2306.02069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03438v1","updated":"2023-06-06T06:35:27Z","published":"2023-06-06T06:35:27Z","title":"Large Language Models of Code Fail at Completing Code with Potential\n  Bugs","summary":"  Large language models of code (Code-LLMs) have recently brought tremendous\nadvances to code completion, a fundamental feature of programming assistance\nand code intelligence. However, most existing works ignore the possible\npresence of bugs in the code context for generation, which are inevitable in\nsoftware development. Therefore, we introduce and study the buggy-code\ncompletion problem, inspired by the realistic scenario of real-time code\nsuggestion where the code context contains potential bugs -- anti-patterns that\ncan become bugs in the completed program. To systematically study the task, we\nintroduce two datasets: one with synthetic bugs derived from semantics-altering\noperator changes (buggy-HumanEval) and one with realistic bugs derived from\nuser submissions to coding problems (buggy-FixEval). We find that the presence\nof potential bugs significantly degrades the generation performance of the\nhigh-performing Code-LLMs. For instance, the passing rates of CodeGen-2B-mono\non test cases of buggy-HumanEval drop more than 50% given a single potential\nbug in the context. Finally, we investigate several post-hoc methods for\nmitigating the adverse effect of potential bugs and find that there remains a\nlarge gap in post-mitigation performance.\n","authors":["Tuan Dinh","Jinman Zhao","Samson Tan","Renato Negrinho","Leonard Lausen","Sheng Zha","George Karypis"],"pdf_url":"https://arxiv.org/pdf/2306.03438v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2306.03435v1","updated":"2023-06-06T06:23:38Z","published":"2023-06-06T06:23:38Z","title":"On the Role of Attention in Prompt-tuning","summary":"  Prompt-tuning is an emerging strategy to adapt large language models (LLM) to\ndownstream tasks by learning a (soft-)prompt parameter from data. Despite its\nsuccess in LLMs, there is limited theoretical understanding of the power of\nprompt-tuning and the role of the attention mechanism in prompting. In this\nwork, we explore prompt-tuning for one-layer attention architectures and study\ncontextual mixture-models where each input token belongs to a context-relevant\nor -irrelevant set. We isolate the role of prompt-tuning through a\nself-contained prompt-attention model. Our contributions are as follows: (1) We\nshow that softmax-prompt-attention is provably more expressive than\nsoftmax-self-attention and linear-prompt-attention under our contextual data\nmodel. (2) We analyze the initial trajectory of gradient descent and show that\nit learns the prompt and prediction head with near-optimal sample complexity\nand demonstrate how prompt can provably attend to sparse context-relevant\ntokens. (3) Assuming a known prompt but an unknown prediction head, we\ncharacterize the exact finite sample performance of prompt-attention which\nreveals the fundamental performance limits and the precise benefit of the\ncontext information. We also provide experiments that verify our theoretical\ninsights on real datasets and demonstrate how prompt-tuning enables the model\nto attend to context-relevant information.\n","authors":["Samet Oymak","Ankit Singh Rawat","Mahdi Soltanolkotabi","Christos Thrampoulidis"],"pdf_url":"https://arxiv.org/pdf/2306.03435v1.pdf","comment":"Published at ICML 2023"},{"id":"http://arxiv.org/abs/2304.11766v3","updated":"2023-06-06T06:02:42Z","published":"2023-04-23T23:03:58Z","title":"NAIST-SIC-Aligned: Automatically-Aligned English-Japanese Simultaneous\n  Interpretation Corpus","summary":"  It remains a question that how simultaneous interpretation (SI) data affects\nsimultaneous machine translation (SiMT). Research has been limited due to the\nlack of a large-scale training corpus. In this work, we aim to fill in the gap\nby introducing NAIST-SIC-Aligned, which is an automatically-aligned parallel\nEnglish-Japanese SI dataset. Starting with a non-aligned corpus NAIST-SIC, we\npropose a two-stage alignment approach to make the corpus parallel and thus\nsuitable for model training. The first stage is coarse alignment where we\nperform a many-to-many mapping between source and target sentences, and the\nsecond stage is fine-grained alignment where we perform intra- and\ninter-sentence filtering to improve the quality of aligned pairs. To ensure the\nquality of the corpus, each step has been validated either quantitatively or\nqualitatively. This is the first open-sourced large-scale parallel SI dataset\nin the literature. We also manually curated a small test set for evaluation\npurposes. We hope our work advances research on SI corpora construction and\nSiMT. Please find our data at \\url{https://github.com/mingzi151/AHC-SI}.\n","authors":["Jinming Zhao","Yuka Ko","Kosuke Doi","Ryo Fukuda","Katsuhito Sudoh","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2304.11766v3.pdf","comment":"Fixed typos"},{"id":"http://arxiv.org/abs/2306.03415v1","updated":"2023-06-06T05:30:49Z","published":"2023-06-06T05:30:49Z","title":"Efficient and Interpretable Compressive Text Summarisation with\n  Unsupervised Dual-Agent Reinforcement Learning","summary":"  Recently, compressive text summarisation offers a balance between the\nconciseness issue of extractive summarisation and the factual hallucination\nissue of abstractive summarisation. However, most existing compressive\nsummarisation methods are supervised, relying on the expensive effort of\ncreating a new training dataset with corresponding compressive summaries. In\nthis paper, we propose an efficient and interpretable compressive summarisation\nmethod that utilises unsupervised dual-agent reinforcement learning to optimise\na summary's semantic coverage and fluency by simulating human judgment on\nsummarisation quality. Our model consists of an extractor agent and a\ncompressor agent, and both agents have a multi-head attentional pointer-based\nstructure. The extractor agent first chooses salient sentences from a document,\nand then the compressor agent compresses these extracted sentences by selecting\nsalient words to form a summary without using reference summaries to compute\nthe summary reward. To our best knowledge, this is the first work on\nunsupervised compressive summarisation. Experimental results on three widely\nused datasets (e.g., Newsroom, CNN/DM, and XSum) show that our model achieves\npromising performance and a significant improvement on Newsroom in terms of the\nROUGE metric, as well as interpretability of semantic coverage of summarisation\nresults.\n","authors":["Peggy Tang","Junbin Gao","Lei Zhang","Zhiyong Wang"],"pdf_url":"https://arxiv.org/pdf/2306.03415v1.pdf","comment":"The 4th Workshop on Simple and Efficient Natural Language Processing\n  (SustaiNLP 2023), co-located with ACL 2023"},{"id":"http://arxiv.org/abs/2306.03411v1","updated":"2023-06-06T05:18:21Z","published":"2023-06-06T05:18:21Z","title":"Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search","summary":"  Customers interacting with product search engines are increasingly\nformulating information-seeking queries. Frequently Asked Question (FAQ)\nretrieval aims to retrieve common question-answer pairs for a user query with\nquestion intent. Integrating FAQ retrieval in product search can not only\nempower users to make more informed purchase decisions, but also enhance user\nretention through efficient post-purchase support. Determining when an FAQ\nentry can satisfy a user's information need within product search, without\ndisrupting their shopping experience, represents an important challenge. We\npropose an intent-aware FAQ retrieval system consisting of (1) an intent\nclassifier that predicts when a user's information need can be answered by an\nFAQ; (2) a reformulation model that rewrites a query into a natural question.\nOffline evaluation demonstrates that our approach improves Hit@1 by 13% on\nretrieving ground-truth FAQs, while reducing latency by 95% compared to\nbaseline systems. These improvements are further validated by real user\nfeedback, where 71% of displayed FAQs on top of product search results received\nexplicit positive user feedback. Overall, our findings show promising\ndirections for integrating FAQ retrieval into product search at scale.\n","authors":["Zhiyu Chen","Jason Choi","Besnik Fetahu","Oleg Rokhlenko","Shervin Malmasi"],"pdf_url":"https://arxiv.org/pdf/2306.03411v1.pdf","comment":"ACL 2023 Industry Track"},{"id":"http://arxiv.org/abs/2212.08724v3","updated":"2023-06-06T04:13:03Z","published":"2022-12-16T21:44:34Z","title":"DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text\n  Generation","summary":"  Self-training (ST) has prospered again in language understanding by\naugmenting the fine-tuning of pre-trained language models when labeled data is\ninsufficient. However, it remains challenging to incorporate ST into\nattribute-controllable language generation. Augmented by only self-generated\npseudo text, generation models over-emphasize exploitation of the previously\nlearned space, suffering from a constrained generalization boundary. We revisit\nST and propose a novel method, DuNST to alleviate this problem. DuNST jointly\nmodels text generation and classification with a shared Variational AutoEncoder\nand corrupts the generated pseudo text by two kinds of flexible noise to\ndisturb the space. In this way, our model could construct and utilize both\npseudo text from given labels and pseudo labels from available unlabeled text,\nwhich are gradually refined during the ST process. We theoretically demonstrate\nthat DuNST can be regarded as enhancing exploration towards the potential real\ntext space, providing a guarantee of improved performance. Experiments on three\ncontrollable generation tasks show that DuNST could significantly boost control\naccuracy while maintaining comparable generation fluency and diversity against\nseveral strong baselines.\n","authors":["Yuxi Feng","Xiaoyuan Yi","Xiting Wang","Laks V. S. Lakshmanan","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2212.08724v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01707v2","updated":"2023-06-06T04:08:04Z","published":"2023-06-02T17:29:22Z","title":"Learning Multi-Step Reasoning by Solving Arithmetic Tasks","summary":"  Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT which is composed of Multi-step Arithmetic Tasks. Our experiments on four\nmath word problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.\n","authors":["Tianduo Wang","Wei Lu"],"pdf_url":"https://arxiv.org/pdf/2306.01707v2.pdf","comment":"ACL 2023. Code and data are available at\n  https://github.com/TianduoWang/MsAT"},{"id":"http://arxiv.org/abs/2306.00301v2","updated":"2023-06-06T03:41:05Z","published":"2023-06-01T02:40:44Z","title":"CapText: Large Language Model-based Caption Generation From Image\n  Context and Description","summary":"  While deep-learning models have been shown to perform well on image-to-text\ndatasets, it is difficult to use them in practice for captioning images. This\nis because captions traditionally tend to be context-dependent and offer\ncomplementary information about an image, while models tend to produce\ndescriptions that describe the visual features of the image. Prior research in\ncaption generation has explored the use of models that generate captions when\nprovided with the images alongside their respective descriptions or contexts.\nWe propose and evaluate a new approach, which leverages existing large language\nmodels to generate captions from textual descriptions and context alone,\nwithout ever processing the image directly. We demonstrate that after\nfine-tuning, our approach outperforms current state-of-the-art image-text\nalignment models like OSCAR-VinVL on this task on the CIDEr metric.\n","authors":["Shinjini Ghosh","Sagnik Anupam"],"pdf_url":"https://arxiv.org/pdf/2306.00301v2.pdf","comment":"Update 6/6/23: Fixed typographic error in abstract"},{"id":"http://arxiv.org/abs/2306.03377v1","updated":"2023-06-06T03:37:41Z","published":"2023-06-06T03:37:41Z","title":"TextFormer: A Query-based End-to-End Text Spotter with Mixed Supervision","summary":"  End-to-end text spotting is a vital computer vision task that aims to\nintegrate scene text detection and recognition into a unified framework.\nTypical methods heavily rely on Region-of-Interest (RoI) operations to extract\nlocal features and complex post-processing steps to produce final predictions.\nTo address these limitations, we propose TextFormer, a query-based end-to-end\ntext spotter with Transformer architecture. Specifically, using query embedding\nper text instance, TextFormer builds upon an image encoder and a text decoder\nto learn a joint semantic understanding for multi-task modeling. It allows for\nmutual training and optimization of classification, segmentation, and\nrecognition branches, resulting in deeper feature sharing without sacrificing\nflexibility or simplicity. Additionally, we design an Adaptive Global\naGgregation (AGG) module to transfer global features into sequential features\nfor reading arbitrarily-shaped texts, which overcomes the sub-optimization\nproblem of RoI operations. Furthermore, potential corpus information is\nutilized from weak annotations to full labels through mixed supervision,\nfurther improving text detection and end-to-end text spotting results.\nExtensive experiments on various bilingual (i.e., English and Chinese)\nbenchmarks demonstrate the superiority of our method. Especially on TDA-ReCTS\ndataset, TextFormer surpasses the state-of-the-art method in terms of 1-NED by\n13.2%.\n","authors":["Yukun Zhai","Xiaoqiang Zhang","Xiameng Qin","Sanyuan Zhao","Xingping Dong","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2306.03377v1.pdf","comment":"MIR 2023, 15 pages"},{"id":"http://arxiv.org/abs/2306.02254v2","updated":"2023-06-06T03:27:33Z","published":"2023-06-04T04:04:04Z","title":"A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean\n  Language Models","summary":"  Polyglot is a pioneering project aimed at enhancing the non-English language\nperformance of multilingual language models. Despite the availability of\nvarious multilingual models such as mBERT (Devlin et al., 2019), XGLM (Lin et\nal., 2022), and BLOOM (Scao et al., 2022), researchers and developers often\nresort to building monolingual models in their respective languages due to the\ndissatisfaction with the current multilingual models non-English language\ncapabilities. Addressing this gap, we seek to develop advanced multilingual\nlanguage models that offer improved performance in non-English languages. In\nthis paper, we introduce the Polyglot Korean models, which represent a specific\nfocus rather than being multilingual in nature. In collaboration with TUNiB,\nour team collected 1.2TB of Korean data meticulously curated for our research\njourney. We made a deliberate decision to prioritize the development of Korean\nmodels before venturing into multilingual models. This choice was motivated by\nmultiple factors: firstly, the Korean models facilitated performance\ncomparisons with existing multilingual models; and finally, they catered to the\nspecific needs of Korean companies and researchers. This paper presents our\nwork in developing the Polyglot Korean models, which propose some steps towards\naddressing the non-English language performance gap in multilingual language\nmodels.\n","authors":["Hyunwoong Ko","Kichang Yang","Minho Ryu","Taekyoon Choi","Seungmu Yang","Jiwung Hyun","Sungho Park","Kyubyong Park"],"pdf_url":"https://arxiv.org/pdf/2306.02254v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16806v4","updated":"2023-06-06T03:15:43Z","published":"2023-05-26T10:38:31Z","title":"Do GPTs Produce Less Literal Translations?","summary":"  Large Language Models (LLMs) such as GPT-3 have emerged as general-purpose\nlanguage models capable of addressing many natural language generation or\nunderstanding tasks. On the task of Machine Translation (MT), multiple works\nhave investigated few-shot prompting mechanisms to elicit better translations\nfrom LLMs. However, there has been relatively little investigation on how such\ntranslations differ qualitatively from the translations generated by standard\nNeural Machine Translation (NMT) models. In this work, we investigate these\ndifferences in terms of the literalness of translations produced by the two\nsystems. Using literalness measures involving word alignment and monotonicity,\nwe find that translations out of English (E-X) from GPTs tend to be less\nliteral, while exhibiting similar or better scores on MT quality metrics. We\ndemonstrate that this finding is borne out in human evaluations as well. We\nthen show that these differences are especially pronounced when translating\nsentences that contain idiomatic expressions.\n","authors":["Vikas Raunak","Arul Menezes","Matt Post","Hany Hassan Awadalla"],"pdf_url":"https://arxiv.org/pdf/2305.16806v4.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2211.08099v2","updated":"2023-06-06T03:01:43Z","published":"2022-11-15T12:33:31Z","title":"A Universal Discriminator for Zero-Shot Generalization","summary":"  Generative modeling has been the dominant approach for large-scale\npretraining and zero-shot generalization. In this work, we challenge this\nconvention by showing that discriminative approaches perform substantially\nbetter than generative ones on a large number of NLP tasks. Technically, we\ntrain a single discriminator to predict whether a text sample comes from the\ntrue data distribution, similar to GANs. Since many NLP tasks can be formulated\nas selecting from a few options, we use this discriminator to predict the\nconcatenation of input and which option has the highest probability of coming\nfrom the true data distribution. This simple formulation achieves\nstate-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by\n16.0\\%, 7.8\\%, and 11.5\\% respectively on different scales. In the finetuning\nsetting, our approach also achieves new state-of-the-art results on a wide\nrange of NLP tasks, with only 1/4 parameters of previous methods. Meanwhile,\nour approach requires minimal prompting efforts, which largely improves\nrobustness and is essential for real-world applications. Furthermore, we also\njointly train a generalized UD in combination with generative tasks, which\nmaintains its advantage on discriminative tasks and simultaneously works on\ngenerative tasks.\n","authors":["Haike Xu","Zongyu Lin","Jing Zhou","Yanan Zheng","Zhilin Yang"],"pdf_url":"https://arxiv.org/pdf/2211.08099v2.pdf","comment":"ACL 2023 main conference (Long paper)"},{"id":"http://arxiv.org/abs/2306.03361v1","updated":"2023-06-06T02:28:38Z","published":"2023-06-06T02:28:38Z","title":"$\\textit{WHAT}$, $\\textit{WHEN}$, and $\\textit{HOW}$ to Ground:\n  Designing User Persona-Aware Conversational Agents for Engaging Dialogue","summary":"  This paper presents a method for building a personalized open-domain dialogue\nsystem to address the $\\textit{WWH}$ ($\\textit{WHAT}$, $\\textit{WHEN}$, and\n$\\textit{HOW}$) problem for natural response generation in a commercial\nsetting, where personalized dialogue responses are heavily interleaved with\ncasual response turns. The proposed approach involves weighted dataset\nblending, negative persona information augmentation methods, and the design of\npersonalized conversation datasets to address the challenges of $\\textit{WWH}$\nin personalized, open-domain dialogue systems. Our work effectively balances\ndialogue fluency and tendency to ground, while also introducing a response-type\nlabel to improve the controllability and explainability of the grounded\nresponses. The combination of these methods leads to more fluent conversations,\nas evidenced by subjective human evaluations as well as objective evaluations.\n","authors":["Deuksin Kwon","Sunwoo Lee","Ki Hyun Kim","Seojin Lee","Taeyoon Kim","Eric Davis"],"pdf_url":"https://arxiv.org/pdf/2306.03361v1.pdf","comment":"Accepted in ACL 2023 Industry Track"},{"id":"http://arxiv.org/abs/2304.06447v5","updated":"2023-06-06T02:26:42Z","published":"2023-04-13T12:28:14Z","title":"PDFVQA: A New Dataset for Real-World VQA on PDF Documents","summary":"  Document-based Visual Question Answering examines the document understanding\nof document images in conditions of natural language questions. We proposed a\nnew document-based VQA dataset, PDF-VQA, to comprehensively examine the\ndocument understanding from various aspects, including document element\nrecognition, document layout structural understanding as well as contextual\nunderstanding and key information extraction. Our PDF-VQA dataset extends the\ncurrent scale of document understanding that limits on the single document page\nto the new scale that asks questions over the full document of multiple pages.\nWe also propose a new graph-based VQA model that explicitly integrates the\nspatial and hierarchically structural relationships between different document\nelements to boost the document structural understanding. The performances are\ncompared with several baselines over different question types and\ntasks\\footnote{The full dataset will be released after paper acceptance.\n","authors":["Yihao Ding","Siwen Luo","Hyunsuk Chung","Soyeon Caren Han"],"pdf_url":"https://arxiv.org/pdf/2304.06447v5.pdf","comment":"Accepted by ECML-PKDD 2023"},{"id":"http://arxiv.org/abs/2210.04185v4","updated":"2023-06-06T02:19:08Z","published":"2022-10-09T06:32:58Z","title":"Controllable Dialogue Simulation with In-Context Learning","summary":"  Building dialogue systems requires a large corpus of annotated dialogues.\nSuch datasets are usually created via crowdsourcing, which is expensive and\ntime-consuming. In this paper, we propose \\textsc{Dialogic}, a novel dialogue\nsimulation method based on large language model in-context learning to automate\ndataset creation. Seeded with a few annotated dialogues, \\textsc{Dialogic}\nautomatically selects in-context examples for demonstration and prompts GPT-3\nto generate new dialogues and annotations in a controllable way. Our method can\nrapidly expand a small set of dialogue data with minimum or zero \\textit{human\ninvolvement} and \\textit{parameter update} and is thus much more cost-efficient\nand time-saving than crowdsourcing. Experimental results on the MultiWOZ\ndataset demonstrate that training a model on the simulated dialogues leads to\neven better performance than using the same amount of human-generated dialogues\nunder the challenging low-resource settings, with as few as 85 dialogues as a\nseed. When enough data is available, our method can still serve as an effective\ndata augmentation method. Human evaluation results also show that our simulated\ndialogues have near-human fluency and annotation accuracy. The code and data\nare available at \\textbf{\\url{https://github.com/Leezekun/dialogic}}.\n","authors":["Zekun Li","Wenhu Chen","Shiyang Li","Hong Wang","Jing Qian","Xifeng Yan"],"pdf_url":"https://arxiv.org/pdf/2210.04185v4.pdf","comment":"EMNLP 2022 Findings, code and data are available at\n  https://github.com/Leezekun/dialogic"},{"id":"http://arxiv.org/abs/2306.03355v1","updated":"2023-06-06T02:13:27Z","published":"2023-06-06T02:13:27Z","title":"BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision,\n  Language, and Graphs","summary":"  In-Batch contrastive learning is a state-of-the-art self-supervised method\nthat brings semantically-similar instances close while pushing dissimilar\ninstances apart within a mini-batch. Its key to success is the negative sharing\nstrategy, in which every instance serves as a negative for the others within\nthe mini-batch. Recent studies aim to improve performance by sampling hard\nnegatives \\textit{within the current mini-batch}, whose quality is bounded by\nthe mini-batch itself. In this work, we propose to improve contrastive learning\nby sampling mini-batches from the input data. We present\nBatchSampler\\footnote{The code is available at\n\\url{https://github.com/THUDM/BatchSampler}} to sample mini-batches of\nhard-to-distinguish (i.e., hard and true negatives to each other) instances. To\nmake each mini-batch have fewer false negatives, we design the proximity graph\nof randomly-selected instances. To form the mini-batch, we leverage random walk\nwith restart on the proximity graph to help sample hard-to-distinguish\ninstances. BatchSampler is a simple and general technique that can be directly\nplugged into existing contrastive learning models in vision, language, and\ngraphs. Extensive experiments on datasets of three modalities show that\nBatchSampler can consistently improve the performance of powerful contrastive\nmodels, as shown by significant improvements of SimCLR on ImageNet-100, SimCSE\non STS (language), and GraphCL and MVGRL on graph datasets.\n","authors":["Zhen Yang","Tinglin Huang","Ming Ding","Yuxiao Dong","Rex Ying","Yukuo Cen","Yangliao Geng","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2306.03355v1.pdf","comment":"17 pages, 16 figures"},{"id":"http://arxiv.org/abs/2306.03350v1","updated":"2023-06-06T01:56:44Z","published":"2023-06-06T01:56:44Z","title":"Click: Controllable Text Generation with Sequence Likelihood Contrastive\n  Learning","summary":"  It has always been an important yet challenging problem to control language\nmodels to avoid generating texts with undesirable attributes, such as toxic\nlanguage and unnatural repetition. We introduce Click for controllable text\ngeneration, which needs no modification to the model architecture and\nfacilitates out-of-the-box use of trained models. It employs a contrastive loss\non sequence likelihood, which fundamentally decreases the generation\nprobability of negative samples (i.e., generations with undesirable\nattributes). It also adopts a novel likelihood ranking-based strategy to\nconstruct contrastive samples from model generations. On the tasks of language\ndetoxification, sentiment steering, and repetition reduction, we show that\nClick outperforms strong baselines of controllable text generation and\ndemonstrate the superiority of Click's sample construction strategy.\n","authors":["Chujie Zheng","Pei Ke","Zheng Zhang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2306.03350v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2210.05901v2","updated":"2023-06-06T01:42:47Z","published":"2022-10-12T03:33:49Z","title":"Zero-Shot Prompting for Implicit Intent Prediction and Recommendation\n  with Commonsense Reasoning","summary":"  Intelligent virtual assistants are currently designed to perform tasks or\nservices explicitly mentioned by users, so multiple related domains or tasks\nneed to be performed one by one through a long conversation with many explicit\nintents. Instead, human assistants are capable of reasoning (multiple) implicit\nintents based on user utterances via commonsense knowledge, reducing complex\ninteractions and improving practicality. Therefore, this paper proposes a\nframework of multi-domain dialogue systems, which can automatically infer\nimplicit intents based on user utterances and then perform zero-shot prompting\nusing a large pre-trained language model to trigger suitable single\ntask-oriented bots. The proposed framework is demonstrated effective to realize\nimplicit intents and recommend associated bots in a zero-shot manner.\n","authors":["Hui-Chi Kuo","Yun-Nung Chen"],"pdf_url":"https://arxiv.org/pdf/2210.05901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03341v1","updated":"2023-06-06T01:26:53Z","published":"2023-06-06T01:26:53Z","title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language\n  Model","summary":"  We introduce Inference-Time Intervention (ITI), a technique designed to\nenhance the truthfulness of large language models (LLMs). ITI operates by\nshifting model activations during inference, following a set of directions\nacross a limited number of attention heads. This intervention significantly\nimproves the performance of LLaMA models on the TruthfulQA benchmark. On an\ninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from\n32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and\ndemonstrate how to balance it by tuning the intervention strength. ITI is\nminimally invasive and computationally inexpensive. Moreover, the technique is\ndata efficient: while approaches like RLHF require extensive annotations, ITI\nlocates truthful directions using only few hundred examples. Our findings\nsuggest that LLMs may have an internal representation of the likelihood of\nsomething being true, even as they produce falsehoods on the surface.\n","authors":["Kenneth Li","Oam Patel","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2306.03341v1.pdf","comment":"code: https://github.com/likenneth/honest_llama"},{"id":"http://arxiv.org/abs/2304.14590v2","updated":"2023-06-06T00:46:49Z","published":"2023-04-28T01:53:54Z","title":"A logical word embedding for learning grammar","summary":"  We introduce the logical grammar emdebbing (LGE), a model inspired by\npregroup grammars and categorial grammars to enable unsupervised inference of\nlexical categories and syntactic rules from a corpus of text. LGE produces\ncomprehensible output summarizing its inferences, has a completely transparent\nprocess for producing novel sentences, and can learn from as few as a hundred\nsentences.\n","authors":["Sean Deyo","Veit Elser"],"pdf_url":"https://arxiv.org/pdf/2304.14590v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12561v2","updated":"2023-06-06T00:28:34Z","published":"2022-11-22T20:26:44Z","title":"Retrieval-Augmented Multimodal Language Modeling","summary":"  Recent multimodal models such as DALL-E and CM3 have achieved remarkable\nprogress in text-to-image and image-to-text generation. However, these models\nstore all learned knowledge (e.g., the appearance of the Eiffel Tower) in the\nmodel parameters, requiring increasingly larger models and training data to\ncapture more knowledge. To integrate knowledge in a more scalable and modular\nway, we propose a retrieval-augmented multimodal model, which enables a base\nmultimodal model (generator) to refer to relevant text and images fetched by a\nretriever from external memory (e.g., documents on the web). Specifically, for\nthe retriever, we use a pretrained CLIP, and for the generator, we train a CM3\nTransformer on the LAION dataset. Our resulting model, named\nRetrieval-Augmented CM3 (RA-CM3), is the first multimodal model that can\nretrieve and generate both text and images. We show that RA-CM3 significantly\noutperforms baseline multimodal models such as DALL-E and CM3 on both image and\ncaption generation tasks (12 FID and 17 CIDEr improvements on MS-COCO), while\nrequiring much less compute for training (<30% of DALL-E). Moreover, we show\nthat RA-CM3 exhibits novel capabilities, such as faithful image generation and\nmultimodal in-context learning (e.g., image generation from demonstrations).\n","authors":["Michihiro Yasunaga","Armen Aghajanyan","Weijia Shi","Rich James","Jure Leskovec","Percy Liang","Mike Lewis","Luke Zettlemoyer","Wen-tau Yih"],"pdf_url":"https://arxiv.org/pdf/2211.12561v2.pdf","comment":"Published at ICML 2023. Blog post available at\n  https://cs.stanford.edu/~myasu/blog/racm3/"},{"id":"http://arxiv.org/abs/2306.04067v1","updated":"2023-06-06T23:56:18Z","published":"2023-06-06T23:56:18Z","title":"An Empirical Analysis of Parameter-Efficient Methods for Debiasing\n  Pre-Trained Language Models","summary":"  The increasingly large size of modern pretrained language models not only\nmakes them inherit more human-like biases from the training corpora, but also\nmakes it computationally expensive to mitigate such biases. In this paper, we\ninvestigate recent parameter-efficient methods in combination with\ncounterfactual data augmentation (CDA) for bias mitigation. We conduct\nextensive experiments with prefix tuning, prompt tuning, and adapter tuning on\ndifferent language models and bias types to evaluate their debiasing\nperformance and abilities to preserve the internal knowledge of a pre-trained\nmodel. We find that the parameter-efficient methods (i) are effective in\nmitigating gender bias, where adapter tuning is consistently the most effective\none and prompt tuning is more suitable for GPT-2 than BERT, (ii) are less\neffective when it comes to racial and religious bias, which may be attributed\nto the limitations of CDA, and (iii) can perform similarly to or sometimes\nbetter than full fine-tuning with improved time and memory efficiency, as well\nas maintain the internal knowledge in BERT and GPT-2, evaluated via fact\nretrieval and downstream fine-tuning.\n","authors":["Zhongbin Xie","Thomas Lukasiewicz"],"pdf_url":"https://arxiv.org/pdf/2306.04067v1.pdf","comment":"accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2302.03162v2","updated":"2023-06-06T23:46:10Z","published":"2023-02-06T23:42:03Z","title":"Protecting Language Generation Models via Invisible Watermarking","summary":"  Language generation models have been an increasingly powerful enabler for\nmany applications. Many such models offer free or affordable API access, which\nmakes them potentially vulnerable to model extraction attacks through\ndistillation. To protect intellectual property (IP) and ensure fair use of\nthese models, various techniques such as lexical watermarking and synonym\nreplacement have been proposed. However, these methods can be nullified by\nobvious countermeasures such as \"synonym randomization\". To address this issue,\nwe propose GINSEW, a novel method to protect text generation models from being\nstolen through distillation. The key idea of our method is to inject secret\nsignals into the probability vector of the decoding steps for each target\ntoken. We can then detect the secret message by probing a suspect model to tell\nif it is distilled from the protected one. Experimental results show that\nGINSEW can effectively identify instances of IP infringement with minimal\nimpact on the generation quality of protected APIs. Our method demonstrates an\nabsolute improvement of 19 to 29 points on mean average precision (mAP) in\ndetecting suspects compared to previous methods against watermark removal\nattacks.\n","authors":["Xuandong Zhao","Yu-Xiang Wang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2302.03162v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.04059v1","updated":"2023-06-06T23:15:59Z","published":"2023-06-06T23:15:59Z","title":"Augmenting Reddit Posts to Determine Wellness Dimensions impacting\n  Mental Health","summary":"  Amid ongoing health crisis, there is a growing necessity to discern possible\nsigns of Wellness Dimensions (WD) manifested in self-narrated text. As the\ndistribution of WD on social media data is intrinsically imbalanced, we\nexperiment the generative NLP models for data augmentation to enable further\nimprovement in the pre-screening task of classifying WD. To this end, we\npropose a simple yet effective data augmentation approach through prompt-based\nGenerative NLP models, and evaluate the ROUGE scores and syntactic/semantic\nsimilarity among existing interpretations and augmented data. Our approach with\nChatGPT model surpasses all the other methods and achieves improvement over\nbaselines such as Easy-Data Augmentation and Backtranslation. Introducing data\naugmentation to generate more training samples and balanced dataset, results in\nthe improved F-score and the Matthew's Correlation Coefficient for upto 13.11%\nand 15.95%, respectively.\n","authors":["Chandreen Liyanage","Muskan Garg","Vijay Mago","Sunghwan Sohn"],"pdf_url":"https://arxiv.org/pdf/2306.04059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02231v2","updated":"2023-06-06T23:04:34Z","published":"2023-06-04T01:59:40Z","title":"Fine-Tuning Language Models with Advantage-Induced Policy Alignment","summary":"  Reinforcement learning from human feedback (RLHF) has emerged as a reliable\napproach to aligning large language models (LLMs) to human preferences. Among\nthe plethora of RLHF techniques, proximal policy optimization (PPO) is of the\nmost widely used methods. Despite its popularity, however, PPO may suffer from\nmode collapse, instability, and poor sample efficiency. We show that these\nissues can be alleviated by a novel algorithm that we refer to as\nAdvantage-Induced Policy Alignment (APA), which leverages a squared error loss\nfunction based on the estimated advantages. We demonstrate empirically that APA\nconsistently outperforms PPO in language tasks by a large margin, when a\nseparate reward model is employed as the evaluator. In addition, compared with\nPPO, APA offers a more stable form of control over the deviation from the\nmodel's initial policy, ensuring that the model improves its performance\nwithout collapsing to deterministic output. In addition to empirical results,\nwe also provide a theoretical justification supporting the design of our loss\nfunction.\n","authors":["Banghua Zhu","Hiteshi Sharma","Felipe Vieira Frujeri","Shi Dong","Chenguang Zhu","Michael I. Jordan","Jiantao Jiao"],"pdf_url":"https://arxiv.org/pdf/2306.02231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04047v1","updated":"2023-06-06T22:32:49Z","published":"2023-06-06T22:32:49Z","title":"Active Sparse Conversations for Improved Audio-Visual Embodied\n  Navigation","summary":"  Efficient navigation towards an audio-goal necessitates an embodied agent to\nnot only possess the ability to use audio-visual cues effectively, but also be\nequipped to actively (but occasionally) seek human/oracle assistance without\nsacrificing autonomy, e.g., when it is uncertain of where to navigate towards\nlocating a noisy or sporadic audio goal. To this end, we present CAVEN -- a\nconversational audio-visual embodied navigation agent that is capable of posing\nnavigation questions to a human/oracle and processing the oracle responses;\nboth in free-form natural language. At the core of CAVEN is a multimodal\nhierarchical reinforcement learning (RL) setup that is equipped with a\nhigh-level policy that is trained to choose from one of three low-level\npolicies (at every step), namely: (i) to navigate using audio-visual cues, or\n(ii) to frame a question to the oracle and receive a short or detailed\nresponse, or (iii) ask generic questions (when unsure of what to ask) and\nreceive instructions. Key to generating the agent's questions is our novel\nTrajectoryNet that forecasts the most likely next steps to the goal and a\nQuestionNet that uses these steps to produce a question. All the policies are\nlearned end-to-end via the RL setup, with penalties to enforce sparsity in\nreceiving navigation instructions from the oracle. To evaluate the performance\nof CAVEN, we present extensive experiments on the SoundSpaces framework for the\ntask of semantic audio-visual navigation. Our results show that CAVEN achieves\nupto 12% gain in performance over competing methods, especially in localizing\nnew sound sources, even in the presence of auditory distractions.\n","authors":["Xiulong Liu","Sudipta Paul","Moitreya Chatterjee","Anoop Cherian"],"pdf_url":"https://arxiv.org/pdf/2306.04047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04043v1","updated":"2023-06-06T22:14:59Z","published":"2023-06-06T22:14:59Z","title":"An Analysis of Reader Engagement in Literary Fiction through Eye\n  Tracking and Linguistic Features","summary":"  Capturing readers' engagement in fiction is a challenging but important\naspect of narrative understanding. In this study, we collected 23 readers'\nreactions to 2 short stories through eye tracking, sentence-level annotations,\nand an overall engagement scale survey. We analyzed the significance of various\nqualities of the text in predicting how engaging a reader is likely to find it.\nAs enjoyment of fiction is highly contextual, we also investigated individual\ndifferences in our data. Furthering our understanding of what captivates\nreaders in fiction will help better inform models used in creative narrative\ngeneration and collaborative writing tools.\n","authors":["Rose Neis","Karin de Langis","Zae Myung Kim","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2306.04043v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.04009v1","updated":"2023-06-06T20:45:18Z","published":"2023-06-06T20:45:18Z","title":"Triggering Multi-Hop Reasoning for Question Answering in Language Models\n  using Soft Prompts and Random Walks","summary":"  Despite readily memorizing world knowledge about entities, pre-trained\nlanguage models (LMs) struggle to compose together two or more facts to perform\nmulti-hop reasoning in question-answering tasks. In this work, we propose\ntechniques that improve upon this limitation by relying on random walks over\nstructured knowledge graphs. Specifically, we use soft prompts to guide LMs to\nchain together their encoded knowledge by learning to map multi-hop questions\nto random walk paths that lead to the answer. Applying our methods on two T5\nLMs shows substantial improvements over standard tuning approaches in answering\nquestions that require 2-hop reasoning.\n","authors":["Kanishka Misra","Cicero Nogueira dos Santos","Siamak Shakeri"],"pdf_url":"https://arxiv.org/pdf/2306.04009v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2305.16718v2","updated":"2023-06-06T20:42:10Z","published":"2023-05-26T08:05:01Z","title":"People and Places of Historical Europe: Bootstrapping Annotation\n  Pipeline and a New Corpus of Named Entities in Late Medieval Texts","summary":"  Although pre-trained named entity recognition (NER) models are highly\naccurate on modern corpora, they underperform on historical texts due to\ndifferences in language OCR errors. In this work, we develop a new NER corpus\nof 3.6M sentences from late medieval charters written mainly in Czech, Latin,\nand German.\n  We show that we can start with a list of known historical figures and\nlocations and an unannotated corpus of historical texts, and use information\nretrieval techniques to automatically bootstrap a NER-annotated corpus. Using\nour corpus, we train a NER model that achieves entity-level Precision of\n72.81-93.98% with 58.14-81.77% Recall on a manually-annotated test dataset.\nFurthermore, we show that using a weighted loss function helps to combat class\nimbalance in token classification tasks. To make it easy for others to\nreproduce and build upon our work, we publicly release our corpus, models, and\nexperimental code.\n","authors":["Vít Novotný","Kristýna Luger","Michal Štefánik","Tereza Vrabcová","Aleš Horák"],"pdf_url":"https://arxiv.org/pdf/2305.16718v2.pdf","comment":"To appear in the Findings of the Association for Computational\n  Linguistics: ACL 2023"},{"id":"http://arxiv.org/abs/2306.03997v1","updated":"2023-06-06T20:19:33Z","published":"2023-06-06T20:19:33Z","title":"Sentiment Analysis in Finance: From Transformers Back to eXplainable\n  Lexicons (XLex)","summary":"  Lexicon-based sentiment analysis (SA) in finance leverages specialized,\nmanually annotated lexicons created by human experts to extract sentiment from\nfinancial texts. Although lexicon-based methods are simple to implement and\nfast to operate on textual data, they require considerable manual annotation\nefforts to create, maintain, and update the lexicons. These methods are also\nconsidered inferior to the deep learning-based approaches, such as transformer\nmodels, which have become dominant in various NLP tasks due to their remarkable\nperformance. However, transformers require extensive data and computational\nresources for both training and testing. Additionally, they involve significant\nprediction times, making them unsuitable for real-time production environments\nor systems with limited processing capabilities. In this paper, we introduce a\nnovel methodology named eXplainable Lexicons (XLex) that combines the\nadvantages of both lexicon-based methods and transformer models. We propose an\napproach that utilizes transformers and SHapley Additive exPlanations (SHAP)\nfor explainability to learn financial lexicons. Our study presents four main\ncontributions. Firstly, we demonstrate that transformer-aided explainable\nlexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald\n(LM) lexicon, reducing the human involvement in annotating, maintaining, and\nupdating the lexicons. Secondly, we show that the resulting lexicon outperforms\nthe standard LM lexicon in SA of financial datasets. Thirdly, we illustrate\nthat the lexicon-based approach is significantly more efficient in terms of\nmodel speed and size compared to transformers. Lastly, the XLex approach is\ninherently more interpretable than transformer models as lexicon models rely on\npredefined rules, allowing for better insights into the results of SA and\nmaking the XLex approach a viable tool for financial decision-making.\n","authors":["Maryan Rizinski","Hristijan Peshov","Kostadin Mishev","Milos Jovanovik","Dimitar Trajanov"],"pdf_url":"https://arxiv.org/pdf/2306.03997v1.pdf","comment":"Submitted to IEEE Access"},{"id":"http://arxiv.org/abs/2212.10520v2","updated":"2023-06-06T20:04:30Z","published":"2022-12-20T18:35:21Z","title":"Privacy-Preserving Domain Adaptation of Semantic Parsers","summary":"  Task-oriented dialogue systems often assist users with personal or\nconfidential matters. For this reason, the developers of such a system are\ngenerally prohibited from observing actual usage. So how can they know where\nthe system is failing and needs more training data or new functionality? In\nthis work, we study ways in which realistic user utterances can be generated\nsynthetically, to help increase the linguistic and functional coverage of the\nsystem, without compromising the privacy of actual users. To this end, we\npropose a two-stage Differentially Private (DP) generation method which first\ngenerates latent semantic parses, and then generates utterances based on the\nparses. Our proposed approach improves MAUVE by 2.5X and parse tree function\ntype overlap by 1.3X relative to current approaches for private synthetic data\ngeneration, improving both on fluency and semantic coverage. We further\nvalidate our approach on a realistic domain adaptation task of adding new\nfunctionality from private user data to a semantic parser, and show overall\ngains of 8.5% points in accuracy with the new feature.\n","authors":["Fatemehsadat Mireshghallah","Richard Shin","Yu Su","Tatsunori Hashimoto","Jason Eisner"],"pdf_url":"https://arxiv.org/pdf/2212.10520v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03984v1","updated":"2023-06-06T19:43:29Z","published":"2023-06-06T19:43:29Z","title":"Toward More Accurate and Generalizable Evaluation Metrics for\n  Task-Oriented Dialogs","summary":"  Measurement of interaction quality is a critical task for the improvement of\nspoken dialog systems. Existing approaches to dialog quality estimation either\nfocus on evaluating the quality of individual turns, or collect dialog-level\nquality measurements from end users immediately following an interaction. In\ncontrast to these approaches, we introduce a new dialog-level annotation\nworkflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate\nthe quality of dialogs as a whole, and also label dialogs for attributes such\nas goal completion and user sentiment. In this contribution, we show that: (i)\nwhile dialog quality cannot be completely decomposed into dialog-level\nattributes, there is a strong relationship between some objective dialog\nattributes and judgments of dialog quality; (ii) for the task of dialog-level\nquality estimation, a supervised model trained on dialog-level annotations\noutperforms methods based purely on aggregating turn-level features; and (iii)\nthe proposed evaluation model shows better domain generalization ability\ncompared to the baselines. On the basis of these results, we argue that having\nhigh-quality human-annotated data is an important component of evaluating\ninteraction quality for large industrial-scale voice assistant platforms.\n","authors":["Abishek Komma","Nagesh Panyam Chandrasekarasastry","Timothy Leffel Anuj Goyal","Angeliki Metallinou","Spyros Matsoukas","Aram Galstyan"],"pdf_url":"https://arxiv.org/pdf/2306.03984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03978v1","updated":"2023-06-06T19:31:08Z","published":"2023-06-06T19:31:08Z","title":"Büyük dil modellerinin Türkçe verisetleri ile\n  eğitilmesi ve ince ayarlanması","summary":"  Large language models have advanced enormously, gained vast attraction and\nare having a phase of intensed research. Some of the developed models and\ntraining datasets have been made open-accessible. Hence these may be further\nfine-tuned with some techniques to obtain specialized models for specific\ntasks. When it comes to Turkish language, open-access models do not provide\nsatisfactory coverage. This is also observed over published datasets. In this\nwork, we propose some ideas to mitigate this issue: creating large Turkish\ndatasets, training LLMs with these and fine-tuning pre-trained models with\nTurkish inputs. We report our findings on Turkish-based trainings with the\nproblems encountered along the way. We conclude with outcomes of these\nexperiments and propose ideas for further works.\n  --\n  B\\\"uy\\\"uk dil modelleri inan{\\i}lmaz \\\"ol\\c{c}\\\"ude geli\\c{s}mekte, b\\\"uy\\\"uk\nilgi toplayarak ve \\\"uzerlerinde yo\\u{g}un ara\\c{s}tirmalarin yapildi\\u{g}i bir\nd\\\"onemdedirler. Geli\\c{s}tirilen modeller ve e\\u{g}itimde kullanilan\nverisetlerinden bazilari a\\c{c}ik eri\\c{s}imli olarak sunulmaktadir. B\\\"oylece\nince ayarlama teknikleri uygulayarak \\\"ozelle\\c{s}mi\\c{s} g\\\"orevler i\\c{c}in\n\\c{c}ali\\c{s}abilir modeller elde edilmektedir. T\\\"urk\\c{c}e s\\\"oz konusu\noldu\\u{g}unda bu modellerinin kapsayicili\\u{g}i yeterli d\\\"uzeyde de\\u{g}ildir.\nBu durum, yayimlanan verisetlerinde de g\\\"ozlemlenebilir. Bunu a\\c{s}manin\nyollari T\\\"urk\\c{c}e i\\c{c}erikli b\\\"uy\\\"uk verisetlerinin olu\\c{s}turulmasi,\nb\\\"uy\\\"uk dil modellerinin bunlarla e\\u{g}itilmesi ve \\\"onceden\ne\\u{g}itilmi\\c{s} modellerin T\\\"urk\\c{c}e girdilerle ince ayarlanmalari\nolabilir. Bu \\c{c}ali\\c{s}mada a\\c{c}ik eri\\c{s}imli dil modelleri ve\nverisetleri \\\"uzerinde durulmakta ve T\\\"urk\\c{c}e temelli bazi deneyler,\nkar\\c{s}ila\\c{s}ilan sorunlar ve sonu\\c{c}lar irdelenmektedir.\n","authors":["A. Taha Arslan"],"pdf_url":"https://arxiv.org/pdf/2306.03978v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2306.03975v1","updated":"2023-06-06T19:17:47Z","published":"2023-06-06T19:17:47Z","title":"Revisiting Conversation Discourse for Dialogue Disentanglement","summary":"  Dialogue disentanglement aims to detach the chronologically ordered\nutterances into several independent sessions. Conversation utterances are\nessentially organized and described by the underlying discourse, and thus\ndialogue disentanglement requires the full understanding and harnessing of the\nintrinsic discourse attribute. In this paper, we propose enhancing dialogue\ndisentanglement by taking full advantage of the dialogue discourse\ncharacteristics. First of all, \\textbf{in feature encoding stage}, we construct\nthe heterogeneous graph representations to model the various dialogue-specific\ndiscourse structural features, including the static speaker-role structures\n(i.e., speaker-utterance and speaker-mentioning structure) and the dynamic\ncontextual structures (i.e., the utterance-distance and partial-replying\nstructure). We then develop a structure-aware framework to integrate the rich\nstructural features for better modeling the conversational semantic context.\nSecond, \\textbf{in model learning stage}, we perform optimization with a\nhierarchical ranking loss mechanism, which groups dialogue utterances into\ndifferent discourse levels and carries training covering pair-wise and\nsession-wise levels hierarchically. Third, \\textbf{in inference stage}, we\ndevise an easy-first decoding algorithm, which performs utterance pairing under\nthe easy-to-hard manner with a global context, breaking the constraint of\ntraditional sequential decoding order. On two benchmark datasets, our overall\nsystem achieves new state-of-the-art performances on all evaluations. In-depth\nanalyses further demonstrate the efficacy of each proposed idea and also reveal\nhow our methods help advance the task. Our work has great potential to\nfacilitate broader multi-party multi-thread dialogue applications.\n","authors":["Bobo Li","Hao Fei","Fei Li","Shengqiong Wu","Lizi Liao","Yinwei Wei","Tat-Seng Chua","Donghong Ji"],"pdf_url":"https://arxiv.org/pdf/2306.03975v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2306.00217v2","updated":"2023-06-06T19:17:14Z","published":"2023-05-31T22:23:20Z","title":"FEED PETs: Further Experimentation and Expansion on the Disambiguation\n  of Potentially Euphemistic Terms","summary":"  Transformers have been shown to work well for the task of English euphemism\ndisambiguation, in which a potentially euphemistic term (PET) is classified as\neuphemistic or non-euphemistic in a particular context. In this study, we\nexpand on the task in two ways. First, we annotate PETs for vagueness, a\nlinguistic property associated with euphemisms, and find that transformers are\ngenerally better at classifying vague PETs, suggesting linguistic differences\nin the data that impact performance. Second, we present novel euphemism corpora\nin three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform\neuphemism disambiguation experiments in each language using multilingual\ntransformer models mBERT and XLM-RoBERTa, establishing preliminary results from\nwhich to launch future work.\n","authors":["Patrick Lee","Iyanuoluwa Shode","Alain Chirino Trujillo","Yuan Zhao","Olumide Ebenezer Ojo","Diana Cuevas Plancarte","Anna Feldman","Jing Peng"],"pdf_url":"https://arxiv.org/pdf/2306.00217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03974v1","updated":"2023-06-06T19:11:59Z","published":"2023-06-06T19:11:59Z","title":"TKDP: Threefold Knowledge-enriched Deep Prompt Tuning for Few-shot Named\n  Entity Recognition","summary":"  Few-shot named entity recognition (NER) exploits limited annotated instances\nto identify named mentions. Effectively transferring the internal or external\nresources thus becomes the key to few-shot NER. While the existing prompt\ntuning methods have shown remarkable few-shot performances, they still fail to\nmake full use of knowledge. In this work, we investigate the integration of\nrich knowledge to prompt tuning for stronger few-shot NER. We propose\nincorporating the deep prompt tuning framework with threefold knowledge (namely\nTKDP), including the internal 1) context knowledge and the external 2) label\nknowledge & 3) sememe knowledge. TKDP encodes the three feature sources and\nincorporates them into the soft prompt embeddings, which are further injected\ninto an existing pre-trained language model to facilitate predictions. On five\nbenchmark datasets, our knowledge-enriched model boosts by at most 11.53% F1\nover the raw deep prompt method, and significantly outperforms 8\nstrong-performing baseline systems in 5-/10-/20-shot settings, showing great\npotential in few-shot NER. Our TKDP can be broadly adapted to other few-shot\ntasks without effort.\n","authors":["Jiang Liu","Hao Fei","Fei Li","Jingye Li","Bobo Li","Liang Zhao","Chong Teng","Donghong Ji"],"pdf_url":"https://arxiv.org/pdf/2306.03974v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2306.03969v1","updated":"2023-06-06T19:04:30Z","published":"2023-06-06T19:04:30Z","title":"ECQED: Emotion-Cause Quadruple Extraction in Dialogs","summary":"  The existing emotion-cause pair extraction (ECPE) task, unfortunately,\nignores extracting the emotion type and cause type, while these fine-grained\nmeta-information can be practically useful in real-world applications, i.e.,\nchat robots and empathic dialog generation. Also the current ECPE is limited to\nthe scenario of single text piece, while neglecting the studies at dialog level\nthat should have more realistic values. In this paper, we extend the ECPE task\nwith a broader definition and scenario, presenting a new task, Emotion-Cause\nQuadruple Extraction in Dialogs (ECQED), which requires detecting emotion-cause\nutterance pairs and emotion and cause types. We present an ECQED model based on\na structural and semantic heterogeneous graph as well as a parallel grid\ntagging scheme, which advances in effectively incorporating the dialog context\nstructure, meanwhile solving the challenging overlapped quadruple issue. Via\nexperiments we show that introducing the fine-grained emotion and cause\nfeatures evidently helps better dialog generation. Also our proposed ECQED\nsystem shows exceptional superiority over baselines on both the emotion-cause\nquadruple or pair extraction tasks, meanwhile being highly efficient.\n","authors":["Li Zheng","Donghong Ji","Fei Li","Hao Fei","Shengqiong Wu","Jingye Li","Bobo Li","Chong Teng"],"pdf_url":"https://arxiv.org/pdf/2306.03969v1.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2306.03959v1","updated":"2023-06-06T18:42:08Z","published":"2023-06-06T18:42:08Z","title":"Leveraging Explicit Procedural Instructions for Data-Efficient Action\n  Prediction","summary":"  Task-oriented dialogues often require agents to enact complex, multi-step\nprocedures in order to meet user requests. While large language models have\nfound success automating these dialogues in constrained environments, their\nwidespread deployment is limited by the substantial quantities of task-specific\ndata required for training. The following paper presents a data-efficient\nsolution to constructing dialogue systems, leveraging explicit instructions\nderived from agent guidelines, such as company policies or customer service\nmanuals. Our proposed Knowledge-Augmented Dialogue System (KADS) combines a\nlarge language model with a knowledge retrieval module that pulls documents\noutlining relevant procedures from a predefined set of policies, given a\nuser-agent interaction. To train this system, we introduce a semi-supervised\npre-training scheme that employs dialogue-document matching and action-oriented\nmasked language modeling with partial parameter freezing. We evaluate the\neffectiveness of our approach on prominent task-oriented dialogue datasets,\nAction-Based Conversations Dataset and Schema-Guided Dialogue, for two dialogue\ntasks: action state tracking and workflow discovery. Our results demonstrate\nthat procedural knowledge augmentation improves accuracy predicting in- and\nout-of-distribution actions while preserving high performance in settings with\nlow or sparse data.\n","authors":["Julia White","Arushi Raghuvanshi","Yada Pruksachatkun"],"pdf_url":"https://arxiv.org/pdf/2306.03959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03954v1","updated":"2023-06-06T18:30:51Z","published":"2023-06-06T18:30:51Z","title":"Recognition of Handwritten Japanese Characters Using Ensemble of\n  Convolutional Neural Networks","summary":"  The Japanese writing system is complex, with three character types of\nHiragana, Katakana, and Kanji. Kanji consists of thousands of unique\ncharacters, further adding to the complexity of character identification and\nliterature understanding. Being able to translate handwritten Japanese\ncharacters into digital text is useful for data analysis, translation, learning\nand cultural preservation. In this study, a machine learning approach to\nanalyzing and recognizing handwritten Japanese characters (Kanji) is proposed.\nThe study used an ensemble of three convolutional neural networks (CNNs) for\nrecognizing handwritten Kanji characters and utilized four datasets of MNIST,\nK-MNIST, Kuzushiji-49 (K49) and the top 150 represented classes in the\nKuzushiji-Kanji (K-Kanji) dataset for its performance evaluation. The results\nindicate feasibility of using proposed CNN-ensemble architecture for\nrecognizing handwritten characters, achieving 99.4%, 96.4%, 95.0% and 96.4%\nclassification accuracy on MNIST, K-MNIS, K49, and K-Kanji datasets\nrespectively.\n","authors":["Angel I. Solis","Justin Zarkovacki","John Ly","Adham Atyabi"],"pdf_url":"https://arxiv.org/pdf/2306.03954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03950v1","updated":"2023-06-06T18:27:52Z","published":"2023-06-06T18:27:52Z","title":"MISGENDERED: Limits of Large Language Models in Understanding Pronouns","summary":"  Content Warning: This paper contains examples of misgendering and erasure\nthat could be offensive and potentially triggering.\n  Gender bias in language technologies has been widely studied, but research\nhas mostly been restricted to a binary paradigm of gender. It is essential also\nto consider non-binary gender identities, as excluding them can cause further\nharm to an already marginalized group. In this paper, we comprehensively\nevaluate popular language models for their ability to correctly use English\ngender-neutral pronouns (e.g., singular they, them) and neo-pronouns (e.g., ze,\nxe, thon) that are used by individuals whose gender identity is not represented\nby binary pronouns. We introduce MISGENDERED, a framework for evaluating large\nlanguage models' ability to correctly use preferred pronouns, consisting of (i)\ninstances declaring an individual's pronoun, followed by a sentence with a\nmissing pronoun, and (ii) an experimental setup for evaluating masked and\nauto-regressive language models using a unified method. When prompted\nout-of-the-box, language models perform poorly at correctly predicting\nneo-pronouns (averaging 7.6% accuracy) and gender-neutral pronouns (averaging\n31.0% accuracy). This inability to generalize results from a lack of\nrepresentation of non-binary pronouns in training data and memorized\nassociations. Few-shot adaptation with explicit examples in the prompt improves\nthe performance but plateaus at only 45.4% for neo-pronouns. We release the\nfull dataset, code, and demo at\nhttps://tamannahossainkay.github.io/misgendered/\n","authors":["Tamanna Hossain","Sunipa Dev","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2306.03950v1.pdf","comment":"Accepted at ACL 2023 as a long paper"},{"id":"http://arxiv.org/abs/2306.03917v1","updated":"2023-06-06T18:00:01Z","published":"2023-06-06T18:00:01Z","title":"Turning large language models into cognitive models","summary":"  Large language models are powerful systems that excel at many tasks, ranging\nfrom translation to mathematical reasoning. Yet, at the same time, these models\noften show unhuman-like characteristics. In the present paper, we address this\ngap and ask whether large language models can be turned into cognitive models.\nWe find that -- after finetuning them on data from psychological experiments --\nthese models offer accurate representations of human behavior, even\noutperforming traditional cognitive models in two decision-making domains. In\naddition, we show that their representations contain the information necessary\nto model behavior on the level of individual subjects. Finally, we demonstrate\nthat finetuning on multiple tasks enables large language models to predict\nhuman behavior in a previously unseen task. Taken together, these results\nsuggest that large, pre-trained models can be adapted to become generalist\ncognitive models, thereby opening up new research directions that could\ntransform cognitive psychology and the behavioral sciences as a whole.\n","authors":["Marcel Binz","Eric Schulz"],"pdf_url":"https://arxiv.org/pdf/2306.03917v1.pdf","comment":null}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2302.01186v2","updated":"2023-06-06T16:36:11Z","published":"2023-02-02T16:13:27Z","title":"The Power of Preconditioning in Overparameterized Low-Rank Matrix\n  Sensing","summary":"  We propose $\\textsf{ScaledGD($\\lambda$)}$, a preconditioned gradient descent\nmethod to tackle the low-rank matrix sensing problem when the true rank is\nunknown, and when the matrix is possibly ill-conditioned. Using\noverparametrized factor representations, $\\textsf{ScaledGD($\\lambda$)}$ starts\nfrom a small random initialization, and proceeds by gradient descent with a\nspecific form of damped preconditioning to combat bad curvatures induced by\noverparameterization and ill-conditioning. At the expense of light\ncomputational overhead incurred by preconditioners,\n$\\textsf{ScaledGD($\\lambda$)}$ is remarkably robust to ill-conditioning\ncompared to vanilla gradient descent ($\\textsf{GD}$) even with\noverprameterization. Specifically, we show that, under the Gaussian design,\n$\\textsf{ScaledGD($\\lambda$)}$ converges to the true low-rank matrix at a\nconstant linear rate after a small number of iterations that scales only\nlogarithmically with respect to the condition number and the problem dimension.\nThis significantly improves over the convergence rate of vanilla $\\textsf{GD}$\nwhich suffers from a polynomial dependency on the condition number. Our work\nprovides evidence on the power of preconditioning in accelerating the\nconvergence without hurting generalization in overparameterized learning.\n","authors":["Xingyu Xu","Yandi Shen","Yuejie Chi","Cong Ma"],"pdf_url":"https://arxiv.org/pdf/2302.01186v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03843v1","updated":"2023-06-06T16:30:48Z","published":"2023-06-06T16:30:48Z","title":"Characterization of transport optimizers via graphs and applications to\n  Stackelberg-Cournot-Nash equilibria","summary":"  We introduce graphs associated to transport problems between discrete\nmarginals, that allow to characterize the set of all optimizers given one\nprimal optimizer. In particular, we establish that connectivity of those graphs\nis a necessary and sufficient condition for uniqueness of the dual optimizers.\nMoreover, we provide an algorithm that can efficiently compute the dual\noptimizer that is the limit, as the regularization parameter goes to zero, of\nthe dual entropic optimizers. Our results find an application in a\nStackelberg-Cournot-Nash game, for which we obtain existence and\ncharacterization of the equilibria.\n","authors":["Beatrice Acciaio","Berenice Anne Neumann"],"pdf_url":"https://arxiv.org/pdf/2306.03843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03808v1","updated":"2023-06-06T15:50:49Z","published":"2023-06-06T15:50:49Z","title":"Weak KAM Theory and Aubry-Mather Theory for sub-Riemannian control\n  systems","summary":"  The aim of this work is to provide a systemic study and generalization of the\ncelebrated weak KAM theory and Aubry-Mather theory in sub-Riemannian setting,\nor equivalently, on a Carnot-Caratheodory metric space. In this framework we\nconsider an optimal control problem with state equation of sub-Riemannian type,\nnamely, admissible trajectories are solutions of a linear in control and\nnonlinear in space ODE. Such a nonlinearity is given by a family of smooth\nvector fields satisfying the Hormander condition which implies the\ncontrollability of the system. In this case, the Hamiltonian function\nassociated with the above control problem fails to be coercive and thus the\nresults in the Tonelli setting can not be applied. In order to overcome this\nissue, our approach is based on metric properties of the geometry induced on\nthe state space by the sub-Riemannian structure.\n","authors":["Piermarco Cannarsa","Cristian Mendico"],"pdf_url":"https://arxiv.org/pdf/2306.03808v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2204.12544"},{"id":"http://arxiv.org/abs/2301.06428v2","updated":"2023-06-06T15:37:45Z","published":"2023-01-16T13:33:37Z","title":"Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic\n  Optimization","summary":"  We consider the optimization problem of the form $\\min_{x \\in \\mathbb{R}^d}\nf(x) \\triangleq \\mathbb{E}_{\\xi} [F(x; \\xi)]$, where the component $F(x;\\xi)$\nis $L$-mean-squared Lipschitz but possibly nonconvex and nonsmooth. The\nrecently proposed gradient-free method requires at most $\\mathcal{O}( L^4\nd^{3/2} \\epsilon^{-4} + \\Delta L^3 d^{3/2} \\delta^{-1} \\epsilon^{-4})$\nstochastic zeroth-order oracle complexity to find a\n$(\\delta,\\epsilon)$-Goldstein stationary point of objective function, where\n$\\Delta = f(x_0) - \\inf_{x \\in \\mathbb{R}^d} f(x)$ and $x_0$ is the initial\npoint of the algorithm. This paper proposes a more efficient algorithm using\nstochastic recursive gradient estimators, which improves the complexity to\n$\\mathcal{O}(L^3 d^{3/2} \\epsilon^{-3}+ \\Delta L^2 d^{3/2} \\delta^{-1}\n\\epsilon^{-3})$.\n","authors":["Lesi Chen","Jing Xu","Luo Luo"],"pdf_url":"https://arxiv.org/pdf/2301.06428v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2210.03357v2","updated":"2023-06-06T15:11:57Z","published":"2022-10-07T07:04:49Z","title":"Queue replacement principle for corridor problems with heterogeneous\n  commuters","summary":"  This study investigates the theoretical properties of a departure time choice\nproblem considering commuters' heterogeneity with respect to the value of\nschedule delay in corridor networks. Specifically, we develop an analytical\nmethod to solve the dynamic system optimal (DSO) and dynamic user equilibrium\n(DUE) problems. To derive the DSO solution, we first demonstrate the\nbottleneck-based decomposition property, i.e., the DSO problem can be\ndecomposed into multiple single bottleneck problems. Subsequently, we obtain\nthe analytical solution by applying the theory of optimal transport to each\ndecomposed problem and derive optimal congestion prices to achieve the DSO\nstate. To derive the DUE solution, we prove the queue replacement principle\n(QRP) that the time-varying optimal congestion prices are equal to the queueing\ndelay in the DUE state at every bottleneck. This principle enables us to derive\na closed-form DUE solution based on the DSO solution. Moreover, as an\napplication of the QRP, we prove that the equilibrium solution under various\npolicies (e.g., on-ramp metering, on-ramp pricing, and its partial\nimplementation) can be obtained analytically. Finally, we compare these\nequilibria with the DSO state.\n","authors":["Takara Sakai","Takashi Akamatsu","Koki Satsukawa"],"pdf_url":"https://arxiv.org/pdf/2210.03357v2.pdf","comment":"38 pages, 15 figures"},{"id":"http://arxiv.org/abs/2112.14123v2","updated":"2023-06-06T14:58:44Z","published":"2021-12-28T12:49:18Z","title":"Control of dynamic systems with restrictions on input and output signals","summary":"  The paper considers the generalization of the method proposed by I.B. Furtat,\nP.A. Gushchin in \"Automation and Remote Control\", 2021, No. 4 for systems with\nan arbitrary ratio of the number of input and output signals and with a\nguarantee of their being in a given set. To solve the problem, two coordinate\nchanges are proposed. The first coordinate change reduces the output variable\nof the system to a new variable which dimension does not exceed the control\ndimension. The second coordinate change allows one to pass from a constrained\ncontrol problem to an unconstrained one. In order to illustrate the efficiency\nof the method, the solution of two problems is considered. The first task is\nstate feedback control of linear systems, taking into account the constraints\non the control signal and phase variables. The second task is output feedback\ncontrol of linear systems with a restriction on output and control. In both\nproblems, checking the stability of the closed-loop system is formulated in\nterms of the solvability of linear matrix inequalities. The obtained results\nare accompanied by examples of modeling that illustrate the efficiency of the\nproposed method.\n","authors":["Igor Furtat","Pavel Gushchin","Nguyen Ba Huy"],"pdf_url":"https://arxiv.org/pdf/2112.14123v2.pdf","comment":"in Russian"},{"id":"http://arxiv.org/abs/2306.02422v2","updated":"2023-06-06T14:23:42Z","published":"2023-06-04T17:54:11Z","title":"A Generalized Alternating Method for Bilevel Learning under the\n  Polyak-Łojasiewicz Condition","summary":"  Bilevel optimization has recently regained interest owing to its applications\nin emerging machine learning fields such as hyperparameter optimization,\nmeta-learning, and reinforcement learning. Recent results have shown that\nsimple alternating (implicit) gradient-based algorithms can achieve the same\nconvergence rate of single-level gradient descent (GD) for bilevel problems\nwith a strongly convex lower-level objective. However, it remains unclear\nwhether this result can be generalized to bilevel problems beyond this basic\nsetting. In this paper, we propose a Generalized ALternating mEthod for bilevel\nopTimization (GALET) with a nonconvex lower-level objective that satisfies the\nPolyak-{\\L}ojasiewicz (PL) condition. We first introduce a stationary metric\nfor the considered bilevel problems, which generalizes the existing metric. We\nthen establish that GALET achieves an $\\epsilon$-stationary metric for the\nconsidered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which\nmatches the iteration complexity of GD for smooth nonconvex problems.\n","authors":["Quan Xiao","Songtao Lu","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2306.02422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03712v1","updated":"2023-06-06T14:21:57Z","published":"2023-06-06T14:21:57Z","title":"Exact controllability of incompressible ideal magnetohydrodynamics in\n  $2$D","summary":"  This work examines the controllability of planar incompressible ideal\nmagnetohydrodynamics (MHD). Interior controls are obtained for problems posed\nin doubly-connected regions; simply-connected configurations are driven by\nboundary controls. Up to now, only straight channels regulated at opposing\nwalls have been studied. Hence, the present program adds to the literature an\nexploration of interior controllability, extends the known boundary\ncontrollability results, and contributes ideas for treating general domains. To\ntransship obstacles stemming from the MHD coupling and the magnetic field\ntopology, a divide-and-control strategy is proposed. This leads to a family of\nnonlinear velocity-controlled sub-problems which are solved using J.-M. Coron's\nreturn method. The latter is here developed based on a reference trajectory in\nthe domain's first cohomology space.\n","authors":["Manuel Rissel"],"pdf_url":"https://arxiv.org/pdf/2306.03712v1.pdf","comment":"41 pages, 11 figures"},{"id":"http://arxiv.org/abs/2306.03655v1","updated":"2023-06-06T13:15:01Z","published":"2023-06-06T13:15:01Z","title":"Online Learning under Adversarial Nonlinear Constraints","summary":"  In many applications, learning systems are required to process continuous\nnon-stationary data streams. We study this problem in an online learning\nframework and propose an algorithm that can deal with adversarial time-varying\nand nonlinear constraints. As we show in our work, the algorithm called\nConstraint Violation Velocity Projection (CVV-Pro) achieves $\\sqrt{T}$ regret\nand converges to the feasible set at a rate of $1/\\sqrt{T}$, despite the fact\nthat the feasible set is slowly time-varying and a priori unknown to the\nlearner. CVV-Pro only relies on local sparse linear approximations of the\nfeasible set and therefore avoids optimizing over the entire set at each\niteration, which is in sharp contrast to projected gradients or Frank-Wolfe\nmethods. We also empirically evaluate our algorithm on two-player games, where\nthe players are subjected to a shared constraint.\n","authors":["Pavel Kolev","Georg Martius","Michael Muehlebach"],"pdf_url":"https://arxiv.org/pdf/2306.03655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03626v1","updated":"2023-06-06T12:27:54Z","published":"2023-06-06T12:27:54Z","title":"Understanding Progressive Training Through the Framework of Randomized\n  Coordinate Descent","summary":"  We propose a Randomized Progressive Training algorithm (RPT) -- a stochastic\nproxy for the well-known Progressive Training method (PT) (Karras et al.,\n2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was\nproposed as a heuristic, with no convergence analysis even for the simplest\nobjective functions. On the contrary, to the best of our knowledge, RPT is the\nfirst PT-type algorithm with rigorous and sound theoretical guarantees for\ngeneral smooth objective functions. We cast our method into the established\nframework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richt\\'arik &\nTak\\'a\\v{c}, 2014), for which (as a by-product of our investigations) we also\npropose a novel, simple and general convergence analysis encapsulating\nstrongly-convex, convex and nonconvex objectives. We then use this framework to\nestablish a convergence theory for RPT. Finally, we validate the effectiveness\nof our method through extensive computational experiments.\n","authors":["Rafał Szlendak","Elnur Gasanov","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2306.03626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17500v2","updated":"2023-06-06T12:19:09Z","published":"2023-05-27T15:44:39Z","title":"Forward-Reflected-Backward and Shadow-Douglas--Rachford with partial\n  inverse for Solving Monotone Inclusions","summary":"  In this article, we study two methods for solving monotone inclusions in real\nHilbert spaces involving the sum of a maximally monotone operator, a\nmonotone-Lipschitzian operator, a cocoercive operator, and a normal cone to a\nvector subspace. Our algorithms split and exploits the intrinsic properties of\neach operator involved in the inclusion. We derive our methods by combining\npartial inverse techniques with the forward-reflected-backward algorithm and\nwith the shadow-Douglas--Rachford algorithm, respectively. Our methods inherit\nthe advantages of those methods, requiring only one activation of the\nLipschitzian operator, one activation of the cocoercive operator, two\nprojections onto the closed vector subspace, and one calculation of the\nresolvent of the maximally monotone operator. Furthermore, we develop methods\nfor solving primal-dual inclusions involving a mixtureof sums, linear\ncompositions, parallel sums, Lipschitzian operators, cocoercive operators, and\nnormal cones. We apply our methods to constrained composite convex optimization\nproblems as a specific example. Finally, in order to compare our methods with\nexisting methods in the literature, we provide numerical experiments on\nconstrained total variation least-squares optimization problems. We obtain\npromising numerical results.\n","authors":["Fernando Roldán"],"pdf_url":"https://arxiv.org/pdf/2305.17500v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03613v1","updated":"2023-06-06T12:02:38Z","published":"2023-06-06T12:02:38Z","title":"From coordinate subspaces over finite fields to ideal multipartite\n  uniform clutters","summary":"  Take a prime power $q$, an integer $n\\geq 2$, and a coordinate subspace\n$S\\subseteq GF(q)^n$ over the Galois field $GF(q)$. One can associate with $S$\nan $n$-partite $n$-uniform clutter $\\mathcal{C}$, where every part has size $q$\nand there is a bijection between the vectors in $S$ and the members of\n$\\mathcal{C}$.\n  In this paper, we determine when the clutter $\\mathcal{C}$ is ideal, a\nproperty developed in connection to Packing and Covering problems in the areas\nof Integer Programming and Combinatorial Optimization. Interestingly, the\ncharacterization differs depending on whether $q$ is $2,4$, a higher power of\n$2$, or otherwise. Each characterization uses crucially that idealness is a\nminor-closed property: first the list of excluded minors is identified, and\nonly then is the global structure determined. A key insight is that idealness\nof $\\mathcal{C}$ depends solely on the underlying matroid of $S$.\n  Our theorems also extend from idealness to the stronger max-flow min-cut\nproperty. As a consequence, we prove the Replication and $\\tau=2$ Conjectures\nfor this class of clutters.\n","authors":["Ahmad Abdi","Dabeen Lee"],"pdf_url":"https://arxiv.org/pdf/2306.03613v1.pdf","comment":"32 pages, 6 figures"},{"id":"http://arxiv.org/abs/2209.04157v2","updated":"2023-06-06T11:52:26Z","published":"2022-09-09T07:28:36Z","title":"A Fast Algorithm for Onboard Atmospheric Powered Descent Guidance","summary":"  Atmospheric powered descent guidance can be solved by successive\nconvexification; however, its onboard application is impeded by the sharp\nincrease in computation caused by nonlinear aerodynamic forces. The problem has\nto be converted into a sequence of convex subproblems instead of a single\nconvex problem when aerodynamic forces are ignored. Besides, each subproblem is\nsignificantly more complicated, which increases computation. A fast real-time\ninterior point method was presented to solve the correlated convex subproblems\nonboard in the work. The main contributions are as follows: Firstly, an\nalgorithm was proposed to accelerate the solution of linear systems that cost\nmost of the computation in each iterative step by exploiting the specific\nproblem structure. Secondly, a warm-starting scheme was introduced to refine\nthe initial value of a subproblem with a rough approximate solution of the\nformer subproblem, which lessened the iterative steps required for each\nsubproblem. The method proposed reduced the run time by a factor of 9 compared\nwith the fastest publicly available solver tested in Monte Carlo simulations to\nevaluate the efficiency of solvers. Runtimes on the order of 0.6 s are achieved\non a radiation-hardened flight processor, which demonstrated the potential of\nthe real-time onboard application.\n","authors":["Yushu Chen","Guangwen Yang","Lu Wang","Qingzhong Gan","Haipeng Chen","Quanyong Xu"],"pdf_url":"https://arxiv.org/pdf/2209.04157v2.pdf","comment":"The paper is accepted by IEEE Transactions on Aerospace and\n  Electronic Systems, 2023"},{"id":"http://arxiv.org/abs/2202.10397v5","updated":"2023-06-06T11:49:13Z","published":"2022-02-21T17:51:10Z","title":"Dissipative Control of Linear Time-Delay Systems: Full State Feedback","summary":"  The problem of dissipative control of autonomous linear delay systems remains\nopen when an unlimited number of delays and general distributed delays (DDs)\nare considered. Existing results suffer from theoretical constraints or\nnumerical barriers, or are unable to cope with the complexity of DD kernels. We\npropose an effective method as a first step to solve this open problem for the\ncase of dissipative full-state feedback using the Krasovski\\u{\\i} functional\n(KF) approach, where all DDs can contain any number of square-integrable\nfunctions. To circumvent the difficulties posed by the infinite dimensionality\nof DDs, we introduce an equivalent decomposition-approximation approach that\nallows for the factorization or approximation of any DD kernel without\nintroducing conservatism. The method can be effectively applied to construct a\ncomplete-type KF whose integral kernels can include any number of\ndifferentiable and linearly independent functions, supported by novel integral\ninequalities derived from the least-squares principle. The proposed\noptimization-based solution is presented in several theorems, along with an\niterative algorithm that can be used together to compute controller gains\nwithout requiring nonlinear solvers. A challenging numerical example, which\ncannot be addressed by existing methods, show the effectiveness of the proposed\nmethod.\n","authors":["Qian Feng","Feng Xiao","Xiaoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2202.10397v5.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2306.03563v1","updated":"2023-06-06T10:26:19Z","published":"2023-06-06T10:26:19Z","title":"New Relaxation Modulus Based Iterative Method for Large and Sparse\n  Implicit Complementarity Problem","summary":"  This article presents a class of new relaxation modulus-based iterative\nmethods to process the large and sparse implicit complementarity problem (ICP).\nUsing two positive diagonal matrices, we formulate a fixed-point equation and\nprove that it is equivalent to ICP. Also, we provide sufficient convergence\nconditions for the proposed methods when the system matrix is a $P$-matrix or\nan $H_+$-matrix.\n  Keyword: Implicit complementarity problem, $H_{+}$-matrix, $P$-matrix, matrix\nsplitting, convergence\n","authors":["Bharat Kumar"," Deepmala","A. K. Das"],"pdf_url":"https://arxiv.org/pdf/2306.03563v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2303.12519"},{"id":"http://arxiv.org/abs/2302.14836v2","updated":"2023-06-06T10:11:31Z","published":"2023-02-28T18:34:39Z","title":"A Generalization of the Riccati Recursion for Equality-Constrained\n  Linear Quadratic Optimal Control","summary":"  This paper introduces a generalization of the well-known Riccati recursion\nfor solving the discrete-time equality-constrained linear quadratic optimal\ncontrol problem. The recursion can be used to compute the solutions as well as\noptimal feedback control policies. Unlike other tailored approaches for this\nproblem class, the proposed method does not require restrictive regularity\nconditions on the problem. This allows its use in nonlinear optimal control\nproblem solvers that use exact Lagrangian Hessian information. We demonstrate\nthat our approach can be implemented in a highly efficient algorithm that\nscales linearly with the horizon length. Numerical tests show a significant\nspeed-up of up to two orders of magnitude with respect to state-of-the-art\ngeneral-purpose sparse linear solvers. Based on the proposed approach, faster\nnonlinear optimal control problem solvers can be developed that are suitable\nfor more complex applications or for implementations on low-cost or low-power\ncomputational platforms. The implementation of the proposed algorithm is made\navailable as open-source software.\n","authors":["Lander Vanroye","Joris De Schutter","Wilm Decré"],"pdf_url":"https://arxiv.org/pdf/2302.14836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05924v3","updated":"2023-06-06T10:10:51Z","published":"2023-03-09T00:47:30Z","title":"Variational formulations of ODE-Net as a mean-field optimal control\n  problem and existence results","summary":"  This paper presents a mathematical analysis of ODE-Net, a continuum model of\ndeep neural networks (DNNs). In recent years, Machine Learning researchers have\nintroduced ideas of replacing the deep structure of DNNs with ODEs as a\ncontinuum limit. These studies regard the \"learning\" of ODE-Net as the\nminimization of a \"loss\" constrained by a parametric ODE. Although the\nexistence of a minimizer for this minimization problem needs to be assumed,\nonly a few studies have investigated its existence analytically in detail. In\nthe present paper, the existence of a minimizer is discussed based on a\nformulation of ODE-Net as a measure-theoretic mean-field optimal control\nproblem. The existence result is proved when a neural network, which describes\na vector field of ODE-Net, is linear with respect to learnable parameters. The\nproof employs the measure-theoretic formulation combined with the direct method\nof Calculus of Variations. Secondly, an idealized minimization problem is\nproposed to remove the above linearity assumption. Such a problem is inspired\nby a kinetic regularization associated with the Benamou--Brenier formula and\nuniversal approximation theorems for neural networks. The proofs of these\nexistence results use variational methods, differential equations, and\nmean-field optimal control theory. They will stand for a new analytic way to\ninvestigate the learning process of deep neural networks.\n","authors":["Noboru Isobe","Mizuho Okumura"],"pdf_url":"https://arxiv.org/pdf/2303.05924v3.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2004.13612v4","updated":"2023-06-06T09:37:37Z","published":"2020-04-28T15:45:21Z","title":"Denise: Deep Robust Principal Component Analysis for Positive\n  Semidefinite Matrices","summary":"  The robust PCA of covariance matrices plays an essential role when isolating\nkey explanatory features. The currently available methods for performing such a\nlow-rank plus sparse decomposition are matrix specific, meaning, those\nalgorithms must re-run for every new matrix. Since these algorithms are\ncomputationally expensive, it is preferable to learn and store a function that\nnearly instantaneously performs this decomposition when evaluated. Therefore,\nwe introduce Denise, a deep learning-based algorithm for robust PCA of\ncovariance matrices, or more generally, of symmetric positive semidefinite\nmatrices, which learns precisely such a function. Theoretical guarantees for\nDenise are provided. These include a novel universal approximation theorem\nadapted to our geometric deep learning problem and convergence to an optimal\nsolution to the learning problem. Our experiments show that Denise matches\nstate-of-the-art performance in terms of decomposition quality, while being\napproximately $2000\\times$ faster than the state-of-the-art, principal\ncomponent pursuit (PCP), and $200 \\times$ faster than the current\nspeed-optimized method, fast PCP.\n","authors":["Calypso Herrera","Florian Krach","Anastasis Kratsios","Pierre Ruyssen","Josef Teichmann"],"pdf_url":"https://arxiv.org/pdf/2004.13612v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14471v4","updated":"2023-06-06T09:01:04Z","published":"2023-02-28T10:29:42Z","title":"Safe Peeling for L0-Regularized Least-Squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of L0-regularized least-squares problems via a Branch-and-Bound\n(BnB) algorithm. Our procedure enables to tighten the convex relaxation\nconsidered at each node of the BnB decision tree and therefore potentially\nallows for more aggressive pruning. Numerical simulations show that our\nproposed methodology leads to significant gains in terms of number of nodes\nexplored and overall solving time.s show that our proposed methodology leads to\nsignificant gains in terms of number of nodes explored and overall solving\ntime.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14665v3","updated":"2023-06-06T08:18:04Z","published":"2022-12-30T12:56:54Z","title":"Sizing Grid-Connected Wind Power Generation and Energy Storage\n  Considering Wake Effect and Endogenous Uncertainty: A Distributionally Robust\n  Method","summary":"  Wind power, as a green energy resource, is growing rapidly worldwide, along\nwith energy storage systems (ESSs) to mitigate its volatility. Sizing of wind\npower generation and ESSs has become an important problem to be addressed. Wake\neffect in a wind farm can cause wind speed deficits and a drop in downstream\nwind turbine power generation, which however was rarely considered in the\nsizing problem in power systems. In this paper, a bi-objective distributionally\nrobust optimization (DRO) model is proposed to determine the capacities of wind\npower generation and ESSs considering the wake effect. An ambiguity set based\non Wasserstein metric is established to characterize the wind power and demand\nuncertainties. In particular, wind power uncertainty is affected by the wind\npower generation capacity which is determined in the first stage. Thus, the\nproposed model is a DRO with endogenous uncertainty (or decision-dependent\nuncertainty). To solve the proposed model, a stochastic programming\napproximation method based on minimum Lipschitz constants is developed to turn\nthe DRO model into a linear program. Then, an iterative algorithm is built,\nembedded with methods for evaluating the minimum Lipschitz constants. Case\nstudies demonstrate the necessity of considering wake effect and the\neffectiveness of the proposed method.\n","authors":["Rui Xie","Wei Wei","Yue Chen"],"pdf_url":"https://arxiv.org/pdf/2212.14665v3.pdf","comment":"27 pages, 6 figures"},{"id":"http://arxiv.org/abs/2212.12677v2","updated":"2023-06-06T07:55:13Z","published":"2022-12-24T07:49:11Z","title":"Towards a Multimodal Charging Network: Joint Planning of Charging\n  Stations and Battery Swapping Stations for Electrified Ride-Hailing Fleets","summary":"  This paper considers a multimodal charging network in which charging stations\nand battery swapping stations are jointly built to support the electrified\nride-hailing fleet in a synergistic manner. Our central thesis is predicated on\nthe observation that charging stations are cost-effective, making them ideal\nfor scaling up electric vehicles in ride-hailing fleets in the beginning, while\nbattery swapping stations offer quick turnaround and can be deployed in tandem\nwith charging stations to improve fleet utilization and reduce operational\ncosts for the ride-hailing platform. To fulfill this vision, we consider a\nride-hailing platform that expands the multimodal charging network with a\nmulti-stage investment budget and operates a ride-hailing fleet to maximize its\nprofit. A multi-stage network expansion model is proposed to characterize the\ncoupled planning and operational decisions, which captures demand elasticity,\npassenger waiting time, charging and swapping waiting times, as well as their\ndependence on fleet status and charging infrastructure. The overall problem is\nformulated as a nonconvex program. Instead of pursuing the globally optimal\nsolution, we establish a theoretical upper bound through relaxation,\nreformulation, and decomposition so that the global optimality of solutions to\nthe nonconvex problem is verifiable. In the case study for Manhattan, we find\nthat ...\n","authors":["Zhijie Lai","Sen Li"],"pdf_url":"https://arxiv.org/pdf/2212.12677v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09471v4","updated":"2023-06-06T07:43:16Z","published":"2023-05-16T14:30:47Z","title":"Time-Consistent Asset Allocation for Risk Measures in a Lévy Market","summary":"  Focusing on gains instead of terminal wealth, we consider an asset allocation\nproblem to maximize time-consistently a mean-risk reward function with a\ngeneral risk measure which is i) law-invariant, ii) cash- or shift-invariant,\nand iii) positively homogeneous, and possibly plugged into a general function.\nWe model the market via a generalized version of the multi-dimensional\nBlack-Scholes model using $\\alpha$-stable L\\'evy processes and give\nsupplementary results for the classical Black-Scholes model. The optimal\nsolution to this problem is a Nash subgame equilibrium given by the solution of\nan extended Hamilton-Jacobi-Bellman equation. Moreover, we show that the\noptimal solution is deterministic and unique under appropriate assumptions.\n","authors":["Felix Fießinger","Mitja Stadje"],"pdf_url":"https://arxiv.org/pdf/2305.09471v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03466v1","updated":"2023-06-06T07:36:47Z","published":"2023-06-06T07:36:47Z","title":"Convergent Bregman Plug-and-Play Image Restoration for Poisson Inverse\n  Problems","summary":"  Plug-and-Play (PnP) methods are efficient iterative algorithms for solving\nill-posed image inverse problems. PnP methods are obtained by using deep\nGaussian denoisers instead of the proximal operator or the gradient-descent\nstep within proximal algorithms. Current PnP schemes rely on data-fidelity\nterms that have either Lipschitz gradients or closed-form proximal operators,\nwhich is not applicable to Poisson inverse problems. Based on the observation\nthat the Gaussian noise is not the adequate noise model in this setting, we\npropose to generalize PnP using theBregman Proximal Gradient (BPG) method. BPG\nreplaces the Euclidean distance with a Bregman divergence that can better\ncapture the smoothness properties of the problem. We introduce the Bregman\nScore Denoiser specifically parametrized and trained for the new Bregman\ngeometry and prove that it corresponds to the proximal operator of a nonconvex\npotential. We propose two PnP algorithms based on the Bregman Score Denoiser\nfor solving Poisson inverse problems. Extending the convergence results of BPG\nin the nonconvex settings, we show that the proposed methods converge,\ntargeting stationary points of an explicit global functional. Experimental\nevaluations conducted on various Poisson inverse problems validate the\nconvergence results and showcase effective restoration performance.\n","authors":["Samuel Hurault","Ulugbek Kamilov","Arthur Leclaire","Nicolas Papadakis"],"pdf_url":"https://arxiv.org/pdf/2306.03466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03458v1","updated":"2023-06-06T07:23:57Z","published":"2023-06-06T07:23:57Z","title":"The Unscented Kalman Filter for Nonlinear Parameter Identification of\n  Adaptive Cruise Control Systems","summary":"  This paper develops and investigates a dual unscented Kalman filter (DUKF)\nfor the joint nonlinear state and parameter identification of commercial\nadaptive cruise control (ACC) systems. Although the core functionality of stock\nACC systems, including their proprietary control logic and parameters, is not\npublicly available, this work considers a car-following scenario with a\nhuman-driven vehicle (leader) and an ACC engaged ego vehicle (follower) that\nemploys a constant time-headway policy (CTHP). The objective of the DUKF is to\ndetermine the CTHP parameters of the ACC by using real-time observations of\nspace-gap and relative velocity from the vehicle's onboard sensors. Real-time\nparameter identification of stock ACC systems is essential for assessing their\nstring stability, large-scale deployment on motorways, and impact on traffic\nflow and throughput. In this regard, $L_2$ and $L_\\infty$ string stability\nconditions are considered. The observability rank condition for nonlinear\nsystems is adopted to evaluate the ability of the proposed estimation scheme to\nestimate stock ACC system parameters using empirical data. The proposed filter\nis evaluated using empirical data collected from the onboard sensors of two\n2019 SUV vehicles, namely Hyundai Nexo and SsangYong Rexton, equipped with\nstock ACC systems; and is compared with batch and recursive least-squares\noptimization. The set of ACC model parameters obtained from the proposed filter\nrevealed that the commercially implemented ACC system of the considered vehicle\n(Hyundai Nexo) is neither $L_2$ nor $L_\\infty$ string stable.\n","authors":["Konstantinos Ampountolas"],"pdf_url":"https://arxiv.org/pdf/2306.03458v1.pdf","comment":"11 papes, 3 Figures"},{"id":"http://arxiv.org/abs/2111.13263v3","updated":"2023-06-06T06:12:04Z","published":"2021-11-25T21:54:52Z","title":"Negative curvature obstructs acceleration for geodesically convex\n  optimization, even with exact first-order oracles","summary":"  Hamilton and Moitra (2021) showed that, in certain regimes, it is not\npossible to accelerate Riemannian gradient descent in the hyperbolic plane if\nwe restrict ourselves to algorithms which make queries in a (large) bounded\ndomain and which receive gradients and function values corrupted by a (small)\namount of noise. We show that acceleration remains unachievable for any\ndeterministic algorithm which receives exact gradient and function-value\ninformation (unbounded queries, no noise). Our results hold for the classes of\nstrongly and nonstrongly geodesically convex functions, and for a large class\nof Hadamard manifolds including hyperbolic spaces and the symmetric space\n$\\mathrm{SL}(n) / \\mathrm{SO}(n)$ of positive definite $n \\times n$ matrices of\ndeterminant one. This cements a surprising gap between the complexity of convex\noptimization and geodesically convex optimization: for hyperbolic spaces,\nRiemannian gradient descent is optimal on the class of smooth and and strongly\ngeodesically convex functions, in the regime where the condition number scales\nwith the radius of the optimization domain. The key idea for proving the lower\nbound consists of perturbing the hard functions of Hamilton and Moitra (2021)\nwith sums of bump functions chosen by a resisting oracle.\n","authors":["Christopher Criscitiello","Nicolas Boumal"],"pdf_url":"https://arxiv.org/pdf/2111.13263v3.pdf","comment":"Updated and shortened to reflect the version published at COLT 2022.\n  The results on (a) the nonstrongly g-convex case and (b) reduction to\n  Euclidean convexity can now be found in the follow-up work \"Curvature and\n  Complexity: Better lower bounds for geodesically convex optimization\"\n  published at COLT 2023 (arXiv:2306.02959)"},{"id":"http://arxiv.org/abs/2010.14314v4","updated":"2023-06-06T05:11:47Z","published":"2020-10-27T14:23:59Z","title":"Faster Lagrangian-Based Methods in Convex Optimization","summary":"  In this paper, we aim at unifying, simplifying and improving the convergence\nrate analysis of Lagrangian-based methods for convex optimization problems. We\nfirst introduce the notion of nice primal algorithmic map, which plays a\ncentral role in the unification and in the simplification of the analysis of\nmost Lagrangian-based methods. Equipped with a nice primal algorithmic map, we\nthen introduce a versatile generic scheme, which allows for the design and\nanalysis of Faster LAGrangian (FLAG) methods with new provably sublinear rate\nof convergence expressed in terms of function values and feasibility violation\nof the original (non-ergodic) generated sequence. To demonstrate the power and\nversatility of our approach and results, we show that most well-known iconic\nLagrangian-based schemes admit a nice primal algorithmic map, and hence share\nthe new faster rate of convergence results within their corresponding FLAG.\n","authors":["Shoham Sabach","Marc Teboulle"],"pdf_url":"https://arxiv.org/pdf/2010.14314v4.pdf","comment":"Minor corrections"},{"id":"http://arxiv.org/abs/2306.03401v1","updated":"2023-06-06T04:32:10Z","published":"2023-06-06T04:32:10Z","title":"A Lightweight Method for Tackling Unknown Participation Probabilities in\n  Federated Averaging","summary":"  In federated learning (FL), clients usually have diverse participation\nprobabilities that are unknown a priori, which can significantly harm the\nperformance of FL if not handled properly. Existing works aiming at addressing\nthis problem are usually based on global variance reduction, which requires a\nsubstantial amount of additional memory in a multiplicative factor equal to the\ntotal number of clients. An important open problem is to find a lightweight\nmethod for FL in the presence of clients with unknown participation rates. In\nthis paper, we address this problem by adapting the aggregation weights in\nfederated averaging (FedAvg) based on the participation history of each client.\nWe first show that, with heterogeneous participation probabilities, FedAvg with\nnon-optimal aggregation weights can diverge from the optimal solution of the\noriginal FL objective, indicating the need of finding optimal aggregation\nweights. However, it is difficult to compute the optimal weights when the\nparticipation probabilities are unknown. To address this problem, we present a\nnew algorithm called FedAU, which improves FedAvg by adaptively weighting the\nclient updates based on online estimates of the optimal weights without knowing\nthe probabilities of client participation. We provide a theoretical convergence\nanalysis of FedAU using a novel methodology to connect the estimation error and\nconvergence. Our theoretical results reveal important and interesting insights,\nwhile showing that FedAU converges to an optimal solution of the original\nobjective and has desirable properties such as linear speedup. Our experimental\nresults also verify the advantage of FedAU over baseline methods.\n","authors":["Shiqiang Wang","Mingyue Ji"],"pdf_url":"https://arxiv.org/pdf/2306.03401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03394v1","updated":"2023-06-06T04:14:31Z","published":"2023-06-06T04:14:31Z","title":"Predicting oscillations in relay feedback systems, using fixed points of\n  Poincaré maps, and Hopf bifurcations","summary":"  The relay autotuning method identifies plant parameters, from oscillations of\nthe plant under relay feedback. To predict the presence and nature of such\noscillations, we apply the following two approaches: (a) analysis of the\nswitching dynamics, while using an ideal relay, and (b) bifurcation analysis,\nwhile using a smooth approximation of the relay. For stable plants with\npositive DC gains, our analyses predict that: (i) a periodic orbit is\nguaranteed, for a class of non-minimum phase plants of relative degree one,\nwhose step response starts with an inverse response, and (ii) for a wider class\nof plants, whose root locus diagrams cross the imaginary axis at complex\nconjugate values, limit cycles are merely suggested.\n","authors":["Maben Rabi"],"pdf_url":"https://arxiv.org/pdf/2306.03394v1.pdf","comment":"submitted to the IEEE transactions on Automatic Control"},{"id":"http://arxiv.org/abs/2201.13387v3","updated":"2023-06-06T02:59:25Z","published":"2022-01-31T17:52:01Z","title":"L-SVRG and L-Katyusha with Adaptive Sampling","summary":"  Stochastic gradient-based optimization methods, such as L-SVRG and its\naccelerated variant L-Katyusha (Kovalev et al., 2020), are widely used to train\nmachine learning models.The theoretical and empirical performance of L-SVRG and\nL-Katyusha can be improved by sampling observations from a non-uniform\ndistribution (Qian et al., 2021). However,designing a desired sampling\ndistribution requires prior knowledge of smoothness constants, which can be\ncomputationally intractable to obtain in practice when the dimension of the\nmodel parameter is high. To address this issue, we propose an adaptive sampling\nstrategy for L-SVRG and L-Katyusha that can learn the sampling distribution\nwith little computational overhead, while allowing it to change with iterates,\nand at the same time does not require any prior knowledge of the problem\nparameters. We prove convergence guarantees for L-SVRG and L-Katyusha for\nconvex objectives when the sampling distribution changes with iterates. Our\nresults show that even without prior information, the proposed adaptive\nsampling strategy matches, and in some cases even surpasses, the performance of\nthe sampling scheme in Qian et al. (2021). Extensive simulations support our\ntheory and the practical utility of the proposed sampling scheme on real data.\n","authors":["Boxin Zhao","Boxiang Lyu","Mladen Kolar"],"pdf_url":"https://arxiv.org/pdf/2201.13387v3.pdf","comment":"Published in Transactions on Machine Learning Research (03/2023)"},{"id":"http://arxiv.org/abs/2306.00267v2","updated":"2023-06-06T02:19:58Z","published":"2023-06-01T00:59:19Z","title":"Provable Benefit of Mixup for Finding Optimal Decision Boundaries","summary":"  We investigate how pair-wise data augmentation techniques like Mixup affect\nthe sample complexity of finding optimal decision boundaries in a binary linear\nclassification problem. For a family of data distributions with a separability\nconstant $\\kappa$, we analyze how well the optimal classifier in terms of\ntraining loss aligns with the optimal one in test accuracy (i.e., Bayes optimal\nclassifier). For vanilla training without augmentation, we uncover an\ninteresting phenomenon named the curse of separability. As we increase $\\kappa$\nto make the data distribution more separable, the sample complexity of vanilla\ntraining increases exponentially in $\\kappa$; perhaps surprisingly, the task of\nfinding optimal decision boundaries becomes harder for more separable\ndistributions. For Mixup training, we show that Mixup mitigates this problem by\nsignificantly reducing the sample complexity. To this end, we develop new\nconcentration results applicable to $n^2$ pair-wise augmented data points\nconstructed from $n$ independent data, by carefully dealing with dependencies\nbetween overlapping pairs. Lastly, we study other masking-based Mixup-style\ntechniques and show that they can distort the training loss and make its\nminimizer converge to a suboptimal classifier in terms of test accuracy.\n","authors":["Junsoo Oh","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2306.00267v2.pdf","comment":"ICML 2023 camera-ready version; 48 pages"},{"id":"http://arxiv.org/abs/2304.03470v2","updated":"2023-06-06T02:02:23Z","published":"2023-04-07T04:12:57Z","title":"Stochastic Verification Theorems for Stochastic Control Problems of\n  Reflected FBSDEs","summary":"  In this paper, the stochastic verification theorems for stochastic control\nproblems of reflected forward-backward stochastic differential equations are\nstudied. We carry out the work within the frameworks of classical and viscosity\nsolutions. The sufficient conditions of verifying the controls to be optimal\nare given. We also construct the feedback optimal control laws from the\nclassical and viscosity solutions of the associated Hamilton-Jacobi-Bellman\nequations with obstacles. Finally, we apply the theoretical results in two\nconcrete examples. One is for the case of the classical solution, and the other\nis for the case of the viscosity solution.\n","authors":["Lu Liu","Xinlei Hu","Qingmeng Wei"],"pdf_url":"https://arxiv.org/pdf/2304.03470v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01647v3","updated":"2023-06-06T21:18:03Z","published":"2022-03-03T11:13:51Z","title":"Complexity of a Class of First-Order Objective-Function-Free\n  Optimization Algorithms","summary":"  A parametric class of trust-region algorithms for unconstrained nonconvex\noptimization is considered where the value of the objective function is never\ncomputed. The class contains a deterministic version of the first-order Adagrad\nmethod typically used for minimization of noisy function, but also allows the\nuse of (possibly approximate) second-order information when available. The rate\nof convergence of methods in the class is analyzed and is shown to be identical\nto that known for first-order optimization methods using both function and\ngradients values, recovering existing results for purely-first order variants\nand improving the explicit dependence on problem dimension. This rate is shown\nto be essentially sharp. A new class of methods is also presented, for which a\nslightly worse and essentially sharp complexity result holds. Limited numerical\nexperiments show that the new methods' performance may be comparable to that of\nstandard steepest descent, despite using significantly less information, and\nthat this performance is relatively insensitive to noise.\n","authors":["S. Gratton","S. Jerad","Ph. L. Toint"],"pdf_url":"https://arxiv.org/pdf/2203.01647v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04016v1","updated":"2023-06-06T21:14:29Z","published":"2023-06-06T21:14:29Z","title":"On seeded subgraph-to-subgraph matching: The ssSGM Algorithm and\n  matchability information theory","summary":"  The subgraph-subgraph matching problem is, given a pair of graphs and a\npositive integer $K$, to find $K$ vertices in the first graph, $K$ vertices in\nthe second graph, and a bijection between them, so as to minimize the number of\nadjacency disagreements across the bijection; it is ``seeded\" if some of this\nbijection is fixed. The problem is intractable, and we present the ssSGM\nalgorithm, which uses Frank-Wolfe methodology to efficiently find an\napproximate solution. Then, in the context of a generalized correlated random\nBernoulli graph model, in which the pair of graphs naturally have a core of $K$\nmatched pairs of vertices, we provide and prove mild conditions for the\nsubgraph-subgraph matching problem solution to almost always be the correct $K$\nmatched pairs of vertices.\n","authors":["Lingyao Meng","Mengqi Lou","Jianyu Lin","Vince Lyzinski","Donniell E. Fishkind"],"pdf_url":"https://arxiv.org/pdf/2306.04016v1.pdf","comment":"27 pages, 16 figures"},{"id":"http://arxiv.org/abs/2211.02727v2","updated":"2023-06-06T20:07:57Z","published":"2022-11-04T20:01:31Z","title":"Compressing Branch-and-Bound Trees","summary":"  A branch-and-bound (BB) tree certifies a dual bound on the value of an\ninteger program. In this work, we introduce the tree compression problem (TCP):\nGiven a BB tree T that certifies a dual bound, can we obtain a smaller tree\nwith the same (or stronger) bound by either (1) applying a different\ndisjunction at some node in T or (2) removing leaves from T? We believe such\npost-hoc analysis of BB trees may assist in identifying helpful general\ndisjunctions in BB algorithms. We initiate our study by considering\ncomputational complexity and limitations of TCP. We then conduct experiments to\nevaluate the compressibility of realistic branch-and-bound trees generated by\ncommonly-used branching strategies, using both an exact and a heuristic\ncompression algorithm.\n","authors":["Gonzalo Muñoz","Joseph Paat","Álinson S. Xavier"],"pdf_url":"https://arxiv.org/pdf/2211.02727v2.pdf","comment":"A short version of this article was accepted for publication at IPCO\n  2023. This extended version contains more detailed discussions and proofs,\n  and new computational contributions and experiments"},{"id":"http://arxiv.org/abs/2306.03976v1","updated":"2023-06-06T19:18:46Z","published":"2023-06-06T19:18:46Z","title":"Explainable AI using expressive Boolean formulas","summary":"  We propose and implement an interpretable machine learning classification\nmodel for Explainable AI (XAI) based on expressive Boolean formulas. Potential\napplications include credit scoring and diagnosis of medical conditions. The\nBoolean formula defines a rule with tunable complexity (or interpretability),\naccording to which input data are classified. Such a formula can include any\noperator that can be applied to one or more Boolean variables, thus providing\nhigher expressivity compared to more rigid rule-based and tree-based\napproaches. The classifier is trained using native local optimization\ntechniques, efficiently searching the space of feasible formulas. Shallow rules\ncan be determined by fast Integer Linear Programming (ILP) or Quadratic\nUnconstrained Binary Optimization (QUBO) solvers, potentially powered by\nspecial purpose hardware or quantum devices. We combine the expressivity and\nefficiency of the native local optimizer with the fast operation of these\ndevices by executing non-local moves that optimize over subtrees of the full\nBoolean formula. We provide extensive numerical benchmarking results featuring\nseveral baselines on well-known public datasets. Based on the results, we find\nthat the native local rule classifier is generally competitive with the other\nclassifiers. The addition of non-local moves achieves similar results with\nfewer iterations, and therefore using specialized or quantum hardware could\nlead to a speedup by fast proposal of non-local moves.\n","authors":["Gili Rosenberg","J. Kyle Brubaker","Martin J. A. Schuetz","Grant Salton","Zhihuai Zhu","Elton Yechao Zhu","Serdar Kadıoğlu","Sima E. Borujeni","Helmut G. Katzgraber"],"pdf_url":"https://arxiv.org/pdf/2306.03976v1.pdf","comment":"28 pages, 16 figures, 4 tables"},{"id":"http://arxiv.org/abs/2306.03965v1","updated":"2023-06-06T19:01:00Z","published":"2023-06-06T19:01:00Z","title":"Optimality conditions in control problems with random state constraints\n  in probabilistic or almost-sure form","summary":"  In this paper, we discuss optimality conditions for optimization problems\nsubject to random state constraints, which are modeled in probabilistic or\nalmost sure form. While the latter can be understood as the limiting case of\nthe former, the derivation of optimality conditions requires substantially\ndifferent approaches. We apply them to a linear elliptic partial differential\nequation (PDE) with random inputs. In the probabilistic case, we rely on the\nspherical-radial decomposition of Gaussian random vectors in order to formulate\nfully explicit optimality conditions involving a spherical integral. In the\nalmost sure case, we derive optimality conditions and compare them to a model\nbased on robust constraints with respect to the (compact) support of the given\ndistribution.\n","authors":["Caroline Geiersbach","René Henrion"],"pdf_url":"https://arxiv.org/pdf/2306.03965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05433v1","updated":"2023-06-06T15:47:16Z","published":"2023-06-06T15:47:16Z","title":"Equilibrium in Functional Stochastic Games with Mean-Field Interaction","summary":"  We consider a general class of finite-player stochastic games with mean-field\ninteraction, in which the linear-quadratic cost functional includes linear\noperators acting on controls in $L^2$. We propose a novel approach for deriving\nthe Nash equilibrium of the game explicitly in terms of operator resolvents, by\nreducing the associated first order conditions to a system of stochastic\nFredholm equations of the second kind and deriving their closed form solution.\nFurthermore, by proving stability results for the system of stochastic Fredholm\nequations we derive the convergence of the equilibrium of the $N$-player game\nto the corresponding mean-field equilibrium. As a by-product we also derive an\n$\\varepsilon$-Nash equilibrium for the mean-field game, which is valuable in\nthis setting as we show that the conditions for existence of an equilibrium in\nthe mean-field limit are less restrictive than in the finite-player game.\nFinally we apply our general framework to solve various examples, such as\nstochastic Volterra linear-quadratic games, models of systemic risk and\nadvertising with delay, and optimal liquidation games with transient price\nimpact.\n","authors":["Eduardo Abi Jaber","Eyal Neuman","Moritz Voß"],"pdf_url":"https://arxiv.org/pdf/2306.05433v1.pdf","comment":"48 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.03901v1","updated":"2023-06-06T17:58:24Z","published":"2023-06-06T17:58:24Z","title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory","summary":"  Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .\n","authors":["Chenxu Hu","Jie Fu","Chenzhuang Du","Simian Luo","Junbo Zhao","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.03901v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03900v1","updated":"2023-06-06T17:58:12Z","published":"2023-06-06T17:58:12Z","title":"Model Spider: Learning to Rank Pre-Trained Models Efficiently","summary":"  Figuring out which Pre-Trained Model (PTM) from a model zoo fits the target\ntask is essential to take advantage of plentiful model resources. With the\navailability of numerous heterogeneous PTMs from diverse fields, efficiently\nselecting the most suitable PTM is challenging due to the time-consuming costs\nof carrying out forward or backward passes over all PTMs. In this paper, we\npropose Model Spider, which tokenizes both PTMs and tasks by summarizing their\ncharacteristics into vectors to enable efficient PTM selection. By leveraging\nthe approximated performance of PTMs on a separate set of training tasks, Model\nSpider learns to construct tokens and measure the fitness score between a\nmodel-task pair via their tokens. The ability to rank relevant PTMs higher than\nothers generalizes to new tasks. With the top-ranked PTM candidates, we further\nlearn to enrich task tokens with their PTM-specific semantics to re-rank the\nPTMs for better selection. Model Spider balances efficiency and selection\nability, making PTM selection like a spider preying on a web. Model Spider\ndemonstrates promising performance in various configurations of model zoos.\n","authors":["Yi-Kai Zhang","Ting-Ji Huang","Yao-Xiang Ding","De-Chuan Zhan","Han-Jia Ye"],"pdf_url":"https://arxiv.org/pdf/2306.03900v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.08209v3","updated":"2023-06-06T17:54:34Z","published":"2022-05-17T10:13:27Z","title":"blob loss: instance imbalance aware loss functions for semantic\n  segmentation","summary":"  Deep convolutional neural networks (CNN) have proven to be remarkably\neffective in semantic segmentation tasks. Most popular loss functions were\nintroduced targeting improved volumetric scores, such as the Dice coefficient\n(DSC). By design, DSC can tackle class imbalance, however, it does not\nrecognize instance imbalance within a class. As a result, a large foreground\ninstance can dominate minor instances and still produce a satisfactory DSC.\nNevertheless, detecting tiny instances is crucial for many applications, such\nas disease monitoring. For example, it is imperative to locate and surveil\nsmall-scale lesions in the follow-up of multiple sclerosis patients. We propose\na novel family of loss functions, \\emph{blob loss}, primarily aimed at\nmaximizing instance-level detection metrics, such as F1 score and sensitivity.\n\\emph{Blob loss} is designed for semantic segmentation problems where detecting\nmultiple instances matters. We extensively evaluate a DSC-based \\emph{blob\nloss} in five complex 3D semantic segmentation tasks featuring pronounced\ninstance heterogeneity in terms of texture and morphology. Compared to soft\nDice loss, we achieve 5% improvement for MS lesions, 3% improvement for liver\ntumor, and an average 2% improvement for microscopy segmentation tasks\nconsidering F1 score.\n","authors":["Florian Kofler","Suprosanna Shit","Ivan Ezhov","Lucas Fidon","Izabela Horvath","Rami Al-Maskari","Hongwei Li","Harsharan Bhatia","Timo Loehr","Marie Piraud","Ali Erturk","Jan Kirschke","Jan C. Peeken","Tom Vercauteren","Claus Zimmer","Benedikt Wiestler","Bjoern Menze"],"pdf_url":"https://arxiv.org/pdf/2205.08209v3.pdf","comment":"23 pages, 7 figures // corrected one mistake where it said beta\n  instead of alpha in the text"},{"id":"http://arxiv.org/abs/2301.10226v3","updated":"2023-06-06T17:50:01Z","published":"2023-01-24T18:52:59Z","title":"A Watermark for Large Language Models","summary":"  Potential harms of large language models can be mitigated by watermarking\nmodel output, i.e., embedding signals into generated text that are invisible to\nhumans but algorithmically detectable from a short span of tokens. We propose a\nwatermarking framework for proprietary language models. The watermark can be\nembedded with negligible impact on text quality, and can be detected using an\nefficient open-source algorithm without access to the language model API or\nparameters. The watermark works by selecting a randomized set of \"green\" tokens\nbefore a word is generated, and then softly promoting use of green tokens\nduring sampling. We propose a statistical test for detecting the watermark with\ninterpretable p-values, and derive an information-theoretic framework for\nanalyzing the sensitivity of the watermark. We test the watermark using a\nmulti-billion parameter model from the Open Pretrained Transformer (OPT)\nfamily, and discuss robustness and security.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Jonathan Katz","Ian Miers","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2301.10226v3.pdf","comment":"13 pages in the main body. Published at ICML 2023. Code is available\n  at github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2306.03887v1","updated":"2023-06-06T17:46:48Z","published":"2023-06-06T17:46:48Z","title":"Fast Context Adaptation in Cost-Aware Continual Learning","summary":"  In the past few years, DRL has become a valuable solution to automatically\nlearn efficient resource management strategies in complex networks with\ntime-varying statistics. However, the increased complexity of 5G and Beyond\nnetworks requires correspondingly more complex learning agents and the learning\nprocess itself might end up competing with users for communication and\ncomputational resources. This creates friction: on the one hand, the learning\nprocess needs resources to quickly convergence to an effective strategy; on the\nother hand, the learning process needs to be efficient, i.e., take as few\nresources as possible from the user's data plane, so as not to throttle users'\nQoS. In this paper, we investigate this trade-off and propose a dynamic\nstrategy to balance the resources assigned to the data plane and those reserved\nfor learning. With the proposed approach, a learning agent can quickly converge\nto an efficient resource allocation strategy and adapt to changes in the\nenvironment as for the CL paradigm, while minimizing the impact on the users'\nQoS. Simulation results show that the proposed method outperforms static\nallocation methods with minimal learning overhead, almost reaching the\nperformance of an ideal out-of-band CL solution.\n","authors":["Seyyidahmed Lahmer","Federico Mason","Federico Chiariotti","Andrea Zanella"],"pdf_url":"https://arxiv.org/pdf/2306.03887v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2211.16915"},{"id":"http://arxiv.org/abs/2306.03872v1","updated":"2023-06-06T17:18:56Z","published":"2023-06-06T17:18:56Z","title":"Deductive Verification of Chain-of-Thought Reasoning","summary":"  Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.\n","authors":["Zhan Ling","Yunhao Fang","Xuanlin Li","Zhiao Huang","Mingu Lee","Roland Memisevic","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2306.03872v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02586v3","updated":"2023-06-06T17:17:15Z","published":"2022-03-04T22:11:40Z","title":"Concept-based Explanations for Out-Of-Distribution Detectors","summary":"  Out-of-distribution (OOD) detection plays a crucial role in ensuring the safe\ndeployment of deep neural network (DNN) classifiers. While a myriad of methods\nhave focused on improving the performance of OOD detectors, a critical gap\nremains in interpreting their decisions. We help bridge this gap by providing\nexplanations for OOD detectors based on learned high-level concepts. We first\npropose two new metrics for assessing the effectiveness of a particular set of\nconcepts for explaining OOD detectors: 1) detection completeness, which\nquantifies the sufficiency of concepts for explaining an OOD-detector's\ndecisions, and 2) concept separability, which captures the distributional\nseparation between in-distribution and OOD data in the concept space. Based on\nthese metrics, we propose an unsupervised framework for learning a set of\nconcepts that satisfy the desired properties of high detection completeness and\nconcept separability, and demonstrate its effectiveness in providing\nconcept-based explanations for diverse off-the-shelf OOD detectors. We also\nshow how to identify prominent concepts contributing to the detection results,\nand provide further reasoning about their decisions.\n","authors":["Jihye Choi","Jayaram Raghuram","Ryan Feng","Jiefeng Chen","Somesh Jha","Atul Prakash"],"pdf_url":"https://arxiv.org/pdf/2203.02586v3.pdf","comment":"Paper published at International Conference on Machine Learning\n  (ICML'23)"},{"id":"http://arxiv.org/abs/2301.08839v4","updated":"2023-06-06T17:16:48Z","published":"2023-01-21T00:48:18Z","title":"A Trustworthiness Score to Evaluate CNNs Predictions","summary":"  Due to the black box nature of Convolutional Neural Networks (CNNs), the\ncontinuous validation of CNNs during operation is challenging with the absence\nof a human monitor. As a result this makes it difficult for developers and\nregulators to gain confidence in the deployment of autonomous systems employing\nCNNs. It is critical for safety during operation to know when CNN's predictions\nare trustworthy or suspicious. With the absence of a human monitor, the basic\napproach is to use the model's output confidence score to assess if predictions\nare trustworthy or suspicious. However, the model's confidence score is a\nresult of computations coming from a black box, therefore lacks transparency\nand makes it challenging to automatedly credit trustworthiness to predictions.\nWe introduce the trustworthiness score (TS), a simple metric that provides a\nmore transparent and effective way of providing confidence in CNNs predictions\ncompared to model's confidence score. The metric quantifies the trustworthiness\nin a prediction by checking for the existence of certain features in the\npredictions made by the CNN. We also use the underlying idea of the TS metric,\nto provide a suspiciousness score (SS) in the overall input frame to help in\nthe detection of suspicious frames where false negatives exist. We conduct a\ncase study using YOLOv5 on persons detection to demonstrate our method and\nusage of TS and SS. The case study shows that using our method consistently\nimproves the precision of predictions compared to relying on model confidence\nscore alone, for both 1) approving of trustworthy predictions (~20%\nimprovement) and 2) detecting suspicious frames (~5% improvement).\n","authors":["Abanoub Ghobrial","Darryl Hond","Hamid Asgari","Kerstin Eder"],"pdf_url":"https://arxiv.org/pdf/2301.08839v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02209v2","updated":"2023-06-06T17:15:23Z","published":"2023-02-04T17:40:03Z","title":"A Theory of Link Prediction via Relational Weisfeiler-Leman","summary":"  Graph neural networks are prominent models for representation learning over\ngraph-structured data. While the capabilities and limitations of these models\nare well-understood for simple graphs, our understanding remains incomplete in\nthe context of knowledge graphs. Our goal is to provide a systematic\nunderstanding of the landscape of graph neural networks for knowledge graphs\npertaining to the prominent task of link prediction. Our analysis entails a\nunifying perspective on seemingly unrelated models and unlocks a series of\nother models. The expressive power of various models is characterized via a\ncorresponding relational Weisfeiler-Leman algorithm. This analysis is extended\nto provide a precise logical characterization of the class of functions\ncaptured by a class of graph neural networks. The theoretical findings\npresented in this paper explain the benefits of some widely employed practical\ndesign choices, which are validated empirically.\n","authors":["Xingyue Huang","Miguel Romero Orth","İsmail İlkan Ceylan","Pablo Barceló"],"pdf_url":"https://arxiv.org/pdf/2302.02209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12132v2","updated":"2023-06-06T17:07:23Z","published":"2023-01-28T08:51:23Z","title":"AutoPEFT: Automatic Configuration Search for Parameter-Efficient\n  Fine-Tuning","summary":"  Large pretrained language models are widely used in downstream NLP tasks via\ntask-specific fine-tuning, but such procedures can be costly. Recently,\nParameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task\nperformance while updating a much smaller number of parameters compared to full\nmodel fine-tuning (FFT). However, it is non-trivial to make informed design\nchoices on the PEFT configurations, such as their architecture, the number of\ntunable parameters, and even the layers in which the PEFT modules are inserted.\nConsequently, it is highly likely that the current, manually designed\nconfigurations are suboptimal in terms of their performance-efficiency\ntrade-off. Inspired by advances in neural architecture search, we propose\nAutoPEFT for automatic PEFT configuration selection: we first design an\nexpressive configuration search space with multiple representative PEFT modules\nas building blocks. Using multi-objective Bayesian optimisation in a low-cost\nsetup, we then discover a Pareto-optimal set of configurations with strong\nperformance-cost trade-offs across different numbers of parameters that are\nalso highly transferable across different tasks. Empirically, on GLUE and\nSuperGLUE tasks, we show that AutoPEFT-discovered configurations significantly\noutperform existing PEFT methods and are on par or better than FFT, without\nincurring substantial training efficiency costs.\n","authors":["Han Zhou","Xingchen Wan","Ivan Vulić","Anna Korhonen"],"pdf_url":"https://arxiv.org/pdf/2301.12132v2.pdf","comment":"17 pages, 7 figures, 9 tables"},{"id":"http://arxiv.org/abs/2305.10748v2","updated":"2023-06-06T16:52:52Z","published":"2023-05-18T06:39:07Z","title":"Physics Inspired Approaches To Understanding Gaussian Processes","summary":"  Prior beliefs about the latent function to shape inductive biases can be\nincorporated into a Gaussian Process (GP) via the kernel. However, beyond\nkernel choices, the decision-making process of GP models remains poorly\nunderstood. In this work, we contribute an analysis of the loss landscape for\nGP models using methods from physics. We demonstrate $\\nu$-continuity for\nMatern kernels and outline aspects of catastrophe theory at critical points in\nthe loss landscape. By directly including $\\nu$ in the hyperparameter\noptimisation for Matern kernels, we find that typical values of $\\nu$ are far\nfrom optimal in terms of performance, yet prevail in the literature due to the\nincreased computational speed. We also provide an a priori method for\nevaluating the effect of GP ensembles and discuss various voting approaches\nbased on physical properties of the loss landscape. The utility of these\napproaches is demonstrated for various synthetic and real datasets. Our\nfindings provide an enhanced understanding of the decision-making process\nbehind GPs and offer practical guidance for improving their performance and\ninterpretability in a range of applications.\n","authors":["Maximilian P. Niroomand","Luke Dicks","Edward O. Pyzer-Knapp","David J. Wales"],"pdf_url":"https://arxiv.org/pdf/2305.10748v2.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.02563v2","updated":"2023-06-06T16:45:47Z","published":"2023-02-06T04:56:05Z","title":"Stochastic Gradient Descent-Induced Drift of Representation in a\n  Two-Layer Neural Network","summary":"  Representational drift refers to over-time changes in neural activation\naccompanied by a stable task performance. Despite being observed in the brain\nand in artificial networks, the mechanisms of drift and its implications are\nnot fully understood. Motivated by recent experimental findings of\nstimulus-dependent drift in the piriform cortex, we use theory and simulations\nto study this phenomenon in a two-layer linear feedforward network.\nSpecifically, in a continual online learning scenario, we study the drift\ninduced by the noise inherent in the Stochastic Gradient Descent (SGD). By\ndecomposing the learning dynamics into the normal and tangent spaces of the\nminimum-loss manifold, we show the former corresponds to a finite variance\nfluctuation, while the latter could be considered as an effective diffusion\nprocess on the manifold. We analytically compute the fluctuation and the\ndiffusion coefficients for the stimuli representations in the hidden layer as\nfunctions of network parameters and input distribution. Further, consistent\nwith experiments, we show that the drift rate is slower for a more frequently\npresented stimulus. Overall, our analysis yields a theoretical framework for\nbetter understanding of the drift phenomenon in biological and artificial\nneural networks.\n","authors":["Farhad Pashakhanloo","Alexei Koulakov"],"pdf_url":"https://arxiv.org/pdf/2302.02563v2.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2301.13293v3","updated":"2023-06-06T16:45:31Z","published":"2023-01-30T21:11:13Z","title":"Overcoming Simplicity Bias in Deep Networks using a Feature Sieve","summary":"  Simplicity bias is the concerning tendency of deep networks to over-depend on\nsimple, weakly predictive features, to the exclusion of stronger, more complex\nfeatures. This is exacerbated in real-world applications by limited training\ndata and spurious feature-label correlations, leading to biased, incorrect\npredictions. We propose a direct, interventional method for addressing\nsimplicity bias in DNNs, which we call the feature sieve. We aim to\nautomatically identify and suppress easily-computable spurious features in\nlower layers of the network, thereby allowing the higher network levels to\nextract and utilize richer, more meaningful representations. We provide\nconcrete evidence of this differential suppression & enhancement of relevant\nfeatures on both controlled datasets and real-world images, and report\nsubstantial gains on many real-world debiasing benchmarks (11.4% relative gain\non Imagenet-A; 3.2% on BAR, etc). Crucially, we do not depend on prior\nknowledge of spurious attributes or features, and in fact outperform many\nbaselines that explicitly incorporate such information. We believe that our\nfeature sieve work opens up exciting new research directions in automated\nadversarial feature extraction and representation learning for deep networks.\n","authors":["Rishabh Tiwari","Pradeep Shenoy"],"pdf_url":"https://arxiv.org/pdf/2301.13293v3.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2305.10880v2","updated":"2023-06-06T16:41:35Z","published":"2023-05-18T11:18:48Z","title":"Functional sufficient dimension reduction through information\n  maximization with application to classification","summary":"  Considering the case where the response variable is a categorical variable\nand the predictor is a random function, two novel functional sufficient\ndimensional reduction (FSDR) methods are proposed based on mutual information\nand square loss mutual information. Compared to the classical FSDR methods,\nsuch as functional sliced inverse regression and functional sliced average\nvariance estimation, the proposed methods are appealing because they are\ncapable of estimating multiple effective dimension reduction directions in the\ncase of a relatively small number of categories, especially for the binary\nresponse. Moreover, the proposed methods do not require the restrictive linear\nconditional mean assumption and the constant covariance assumption. They avoid\nthe inverse problem of the covariance operator which is often encountered in\nthe functional sufficient dimension reduction. The functional principal\ncomponent analysis with truncation be used as a regularization mechanism. Under\nsome mild conditions, the statistical consistency of the proposed methods is\nestablished. It is demonstrated that the two methods are competitive compared\nwith some existing FSDR methods by simulations and real data analyses.\n","authors":["Xinyu Li","Jianjun Xu","Wenquan Cui","Haoyang Cheng"],"pdf_url":"https://arxiv.org/pdf/2305.10880v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01186v2","updated":"2023-06-06T16:36:11Z","published":"2023-02-02T16:13:27Z","title":"The Power of Preconditioning in Overparameterized Low-Rank Matrix\n  Sensing","summary":"  We propose $\\textsf{ScaledGD($\\lambda$)}$, a preconditioned gradient descent\nmethod to tackle the low-rank matrix sensing problem when the true rank is\nunknown, and when the matrix is possibly ill-conditioned. Using\noverparametrized factor representations, $\\textsf{ScaledGD($\\lambda$)}$ starts\nfrom a small random initialization, and proceeds by gradient descent with a\nspecific form of damped preconditioning to combat bad curvatures induced by\noverparameterization and ill-conditioning. At the expense of light\ncomputational overhead incurred by preconditioners,\n$\\textsf{ScaledGD($\\lambda$)}$ is remarkably robust to ill-conditioning\ncompared to vanilla gradient descent ($\\textsf{GD}$) even with\noverprameterization. Specifically, we show that, under the Gaussian design,\n$\\textsf{ScaledGD($\\lambda$)}$ converges to the true low-rank matrix at a\nconstant linear rate after a small number of iterations that scales only\nlogarithmically with respect to the condition number and the problem dimension.\nThis significantly improves over the convergence rate of vanilla $\\textsf{GD}$\nwhich suffers from a polynomial dependency on the condition number. Our work\nprovides evidence on the power of preconditioning in accelerating the\nconvergence without hurting generalization in overparameterized learning.\n","authors":["Xingyu Xu","Yandi Shen","Yuejie Chi","Cong Ma"],"pdf_url":"https://arxiv.org/pdf/2302.01186v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17612v3","updated":"2023-06-06T16:30:09Z","published":"2023-03-30T01:37:19Z","title":"oBERTa: Improving Sparse Transfer Learning via improved initialization,\n  distillation, and pruning regimes","summary":"  In this paper, we introduce the range of oBERTa language models, an\neasy-to-use set of language models which allows Natural Language Processing\n(NLP) practitioners to obtain between 3.8 and 24.3 times faster models without\nexpertise in model compression. Specifically, oBERTa extends existing work on\npruning, knowledge distillation, and quantization and leverages frozen\nembeddings improves distillation and model initialization to deliver higher\naccuracy on a broad range of transfer tasks. In generating oBERTa, we explore\nhow the highly optimized RoBERTa differs from the BERT for pruning during\npre-training and finetuning. We find it less amenable to compression during\nfine-tuning. We explore the use of oBERTa on seven representative NLP tasks and\nfind that the improved compression techniques allow a pruned oBERTa model to\nmatch the performance of BERTbase and exceed the performance of Prune OFA Large\non the SQUAD V1.1 Question Answering dataset, despite being 8x and 2x,\nrespectively faster in inference. We release our code, training regimes, and\nassociated model for broad usage to encourage usage and experimentation\n","authors":["Daniel Campos","Alexandre Marques","Mark Kurtz","ChengXiang Zhai"],"pdf_url":"https://arxiv.org/pdf/2303.17612v3.pdf","comment":"SustaiNLP2023 @ ACL 2023,9 pages, 2 figures, 45 tables"},{"id":"http://arxiv.org/abs/2306.03838v1","updated":"2023-06-06T16:27:17Z","published":"2023-06-06T16:27:17Z","title":"Spherical Fourier Neural Operators: Learning Stable Dynamics on the\n  Sphere","summary":"  Fourier Neural Operators (FNOs) have proven to be an efficient and effective\nmethod for resolution-independent operator learning in a broad variety of\napplication areas across scientific machine learning. A key reason for their\nsuccess is their ability to accurately model long-range dependencies in\nspatio-temporal data by learning global convolutions in a computationally\nefficient manner. To this end, FNOs rely on the discrete Fourier transform\n(DFT), however, DFTs cause visual and spectral artifacts as well as pronounced\ndissipation when learning operators in spherical coordinates since they\nincorrectly assume a flat geometry. To overcome this limitation, we generalize\nFNOs on the sphere, introducing Spherical FNOs (SFNOs) for learning operators\non spherical geometries. We apply SFNOs to forecasting atmospheric dynamics,\nand demonstrate stable auto\\-regressive rollouts for a year of simulated time\n(1,460 steps), while retaining physically plausible dynamics. The SFNO has\nimportant implications for machine learning-based simulation of climate\ndynamics that could eventually help accelerate our response to climate change.\n","authors":["Boris Bonev","Thorsten Kurth","Christian Hundt","Jaideep Pathak","Maximilian Baust","Karthik Kashinath","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2306.03838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03835v1","updated":"2023-06-06T16:25:29Z","published":"2023-06-06T16:25:29Z","title":"Atrial Septal Defect Detection in Children Based on Ultrasound Video\n  Using Multiple Instances Learning","summary":"  Purpose: Congenital heart defect (CHD) is the most common birth defect.\nThoracic echocardiography (TTE) can provide sufficient cardiac structure\ninformation, evaluate hemodynamics and cardiac function, and is an effective\nmethod for atrial septal defect (ASD) examination. This paper aims to study a\ndeep learning method based on cardiac ultrasound video to assist in ASD\ndiagnosis. Materials and methods: We select two standard views of the atrial\nseptum (subAS) and low parasternal four-compartment view (LPS4C) as the two\nviews to identify ASD. We enlist data from 300 children patients as part of a\ndouble-blind experiment for five-fold cross-validation to verify the\nperformance of our model. In addition, data from 30 children patients (15\npositives and 15 negatives) are collected for clinician testing and compared to\nour model test results (these 30 samples do not participate in model training).\nWe propose an echocardiography video-based atrial septal defect diagnosis\nsystem. In our model, we present a block random selection, maximal agreement\ndecision and frame sampling strategy for training and testing respectively,\nresNet18 and r3D networks are used to extract the frame features and aggregate\nthem to build a rich video-level representation. Results: We validate our model\nusing our private dataset by five-cross validation. For ASD detection, we\nachieve 89.33 AUC, 84.95 accuracy, 85.70 sensitivity, 81.51 specificity and\n81.99 F1 score. Conclusion: The proposed model is multiple instances\nlearning-based deep learning model for video atrial septal defect detection\nwhich effectively improves ASD detection accuracy when compared to the\nperformances of previous networks and clinical doctors.\n","authors":["Yiman Liu","Qiming Huang","Xiaoxiang Han","Tongtong Liang","Zhifang Zhang","Lijun Chen","Jinfeng Wang","Angelos Stefanidis","Jionglong Su","Jiangang Chen","Qingli Li","Yuqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.03835v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03834v1","updated":"2023-06-06T16:24:27Z","published":"2023-06-06T16:24:27Z","title":"MTS2Graph: Interpretable Multivariate Time Series Classification with\n  Temporal Evolving Graphs","summary":"  Conventional time series classification approaches based on bags of patterns\nor shapelets face significant challenges in dealing with a vast amount of\nfeature candidates from high-dimensional multivariate data. In contrast, deep\nneural networks can learn low-dimensional features efficiently, and in\nparticular, Convolutional Neural Networks (CNN) have shown promising results in\nclassifying Multivariate Time Series (MTS) data. A key factor in the success of\ndeep neural networks is this astonishing expressive power. However, this power\ncomes at the cost of complex, black-boxed models, conflicting with the goals of\nbuilding reliable and human-understandable models. An essential criterion in\nunderstanding such predictive deep models involves quantifying the contribution\nof time-varying input variables to the classification. Hence, in this work, we\nintroduce a new framework for interpreting multivariate time series data by\nextracting and clustering the input representative patterns that highly\nactivate CNN neurons. This way, we identify each signal's role and\ndependencies, considering all possible combinations of signals in the MTS\ninput. Then, we construct a graph that captures the temporal relationship\nbetween the extracted patterns for each layer. An effective graph merging\nstrategy finds the connection of each node to the previous layer's nodes.\nFinally, a graph embedding algorithm generates new representations of the\ncreated interpretable time-series features. To evaluate the performance of our\nproposed framework, we run extensive experiments on eight datasets of the\nUCR/UEA archive, along with HAR and PAM datasets. The experiments indicate the\nbenefit of our time-aware graph-based representation in MTS classification\nwhile enriching them with more interpretability.\n","authors":["Raneen Younis","Abdul Hakmeh","Zahra Ahmadi"],"pdf_url":"https://arxiv.org/pdf/2306.03834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03833v1","updated":"2023-06-06T16:23:00Z","published":"2023-06-06T16:23:00Z","title":"Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic\n  Knowledge Graph and Text Mining Approach","summary":"  Virtual health has been acclaimed as a transformative force in healthcare\ndelivery. Yet, its dropout issue is critical that leads to poor health\noutcomes, increased health, societal, and economic costs. Timely prediction of\npatient dropout enables stakeholders to take proactive steps to address\npatients' concerns, potentially improving retention rates. In virtual health,\nthe information asymmetries inherent in its delivery format, between different\nstakeholders, and across different healthcare delivery systems hinder the\nperformance of existing predictive methods. To resolve those information\nasymmetries, we propose a Multimodal Dynamic Knowledge-driven Dropout\nPrediction (MDKDP) framework that learns implicit and explicit knowledge from\ndoctor-patient dialogues and the dynamic and complex networks of various\nstakeholders in both online and offline healthcare delivery systems. We\nevaluate MDKDP by partnering with one of the largest virtual health platforms\nin China. MDKDP improves the F1-score by 3.26 percentage points relative to the\nbest benchmark. Comprehensive robustness analyses show that integrating\nstakeholder attributes, knowledge dynamics, and compact bilinear pooling\nsignificantly improves the performance. Our work provides significant\nimplications for healthcare IT by revealing the value of mining relations and\nknowledge across different service modalities. Practically, MDKDP offers a\nnovel design artifact for virtual health platforms in patient dropout\nmanagement.\n","authors":["Shuang Geng","Wenli Zhang","Jiaheng Xie","Gemin Liang","Ben Niu"],"pdf_url":"https://arxiv.org/pdf/2306.03833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19525v2","updated":"2023-06-06T16:21:25Z","published":"2023-05-31T03:26:18Z","title":"Discovering New Interpretable Conservation Laws as Sparse Invariants","summary":"  Discovering conservation laws for a given dynamical system is important but\nchallenging. In a theorist setup (differential equations and basis functions\nare both known), we propose the Sparse Invariant Detector (SID), an algorithm\nthat auto-discovers conservation laws from differential equations. Its\nalgorithmic simplicity allows robustness and interpretability of the discovered\nconserved quantities. We show that SID is able to rediscover known and even\ndiscover new conservation laws in a variety of systems. For two examples in\nfluid mechanics and atmospheric chemistry, SID discovers 14 and 3 conserved\nquantities, respectively, where only 12 and 2 were previously known to domain\nexperts.\n","authors":["Ziming Liu","Patrick Obin Sturm","Saketh Bharadwaj","Sam Silva","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2305.19525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03832v1","updated":"2023-06-06T16:20:44Z","published":"2023-06-06T16:20:44Z","title":"Sequential Principal-Agent Problems with Communication: Efficient\n  Computation and Learning","summary":"  We study a sequential decision making problem between a principal and an\nagent with incomplete information on both sides. In this model, the principal\nand the agent interact in a stochastic environment, and each is privy to\nobservations about the state not available to the other. The principal has the\npower of commitment, both to elicit information from the agent and to provide\nsignals about her own information. The principal and the agent communicate\ntheir signals to each other, and select their actions independently based on\nthis communication. Each player receives a payoff based on the state and their\njoint actions, and the environment moves to a new state. The interaction\ncontinues over a finite time horizon, and both players act to optimize their\nown total payoffs over the horizon. Our model encompasses as special cases\nstochastic games of incomplete information and POMDPs, as well as sequential\nBayesian persuasion and mechanism design problems. We study both computation of\noptimal policies and learning in our setting. While the general problems are\ncomputationally intractable, we study algorithmic solutions under a conditional\nindependence assumption on the underlying state-observation distributions. We\npresent an polynomial-time algorithm to compute the principal's optimal policy\nup to an additive approximation. Additionally, we show an efficient learning\nalgorithm in the case where the transition probabilities are not known\nbeforehand. The algorithm guarantees sublinear regret for both players.\n","authors":["Jiarui Gan","Rupak Majumdar","Debmalya Mandal","Goran Radanovic"],"pdf_url":"https://arxiv.org/pdf/2306.03832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.02986v2","updated":"2023-06-06T16:20:30Z","published":"2022-05-06T02:33:24Z","title":"Optimally tackling covariate shift in RKHS-based nonparametric\n  regression","summary":"  We study the covariate shift problem in the context of nonparametric\nregression over a reproducing kernel Hilbert space (RKHS). We focus on two\nnatural families of covariate shift problems defined using the likelihood\nratios between the source and target distributions. When the likelihood ratios\nare uniformly bounded, we prove that the kernel ridge regression (KRR)\nestimator with a carefully chosen regularization parameter is minimax\nrate-optimal (up to a log factor) for a large family of RKHSs with regular\nkernel eigenvalues. Interestingly, KRR does not require full knowledge of\nlikelihood ratios apart from an upper bound on them. In striking contrast to\nthe standard statistical setting without covariate shift, we also demonstrate\nthat a naive estimator, which minimizes the empirical risk over the function\nclass, is strictly sub-optimal under covariate shift as compared to KRR. We\nthen address the larger class of covariate shift problems where the likelihood\nratio is possibly unbounded yet has a finite second moment. Here, we propose a\nreweighted KRR estimator that weights samples based on a careful truncation of\nthe likelihood ratios. Again, we are able to show that this estimator is\nminimax rate-optimal, up to logarithmic factors.\n","authors":["Cong Ma","Reese Pathak","Martin J. Wainwright"],"pdf_url":"https://arxiv.org/pdf/2205.02986v2.pdf","comment":"to appear in the Annals of Statistics"},{"id":"http://arxiv.org/abs/2206.01132v2","updated":"2023-06-06T16:17:23Z","published":"2022-06-02T16:31:16Z","title":"A Communication-efficient Algorithm with Linear Convergence for\n  Federated Minimax Learning","summary":"  In this paper, we study a large-scale multi-agent minimax optimization\nproblem, which models many interesting applications in statistical learning and\ngame theory, including Generative Adversarial Networks (GANs). The overall\nobjective is a sum of agents' private local objective functions. We first\nanalyze an important special case, empirical minimax problem, where the overall\nobjective approximates a true population minimax risk by statistical samples.\nWe provide generalization bounds for learning with this objective through\nRademacher complexity analysis. Then, we focus on the federated setting, where\nagents can perform local computation and communicate with a central server.\nMost existing federated minimax algorithms either require communication per\niteration or lack performance guarantees with the exception of Local Stochastic\nGradient Descent Ascent (SGDA), a multiple-local-update descent ascent\nalgorithm which guarantees convergence under a diminishing stepsize. By\nanalyzing Local SGDA under the ideal condition of no gradient noise, we show\nthat generally it cannot guarantee exact convergence with constant stepsizes\nand thus suffers from slow rates of convergence. To tackle this issue, we\npropose FedGDA-GT, an improved Federated (Fed) Gradient Descent Ascent (GDA)\nmethod based on Gradient Tracking (GT). When local objectives are Lipschitz\nsmooth and strongly-convex-strongly-concave, we prove that FedGDA-GT converges\nlinearly with a constant stepsize to global $\\epsilon$-approximation solution\nwith $\\mathcal{O}(\\log (1/\\epsilon))$ rounds of communication, which matches\nthe time complexity of centralized GDA method. Finally, we numerically show\nthat FedGDA-GT outperforms Local SGDA.\n","authors":["Zhenyu Sun","Ermin Wei"],"pdf_url":"https://arxiv.org/pdf/2206.01132v2.pdf","comment":"Accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2306.03831v1","updated":"2023-06-06T16:16:05Z","published":"2023-06-06T16:16:05Z","title":"GEO-Bench: Toward Foundation Models for Earth Monitoring","summary":"  Recent progress in self-supervision has shown that pre-training large neural\nnetworks on vast amounts of unsupervised data can lead to substantial increases\nin generalization to downstream tasks. Such models, recently coined foundation\nmodels, have been transformational to the field of natural language processing.\nVariants have also been proposed for image data, but their applicability to\nremote sensing tasks is limited. To stimulate the development of foundation\nmodels for Earth monitoring, we propose a benchmark comprised of six\nclassification and six segmentation tasks, which were carefully curated and\nadapted to be both relevant to the field and well-suited for model evaluation.\nWe accompany this benchmark with a robust methodology for evaluating models and\nreporting aggregated results to enable a reliable assessment of progress.\nFinally, we report results for 20 baselines to gain information about the\nperformance of existing models. We believe that this benchmark will be a driver\nof progress across a variety of Earth monitoring tasks.\n","authors":["Alexandre Lacoste","Nils Lehmann","Pau Rodriguez","Evan David Sherwin","Hannah Kerner","Björn Lütjens","Jeremy Andrew Irvin","David Dao","Hamed Alemohammad","Alexandre Drouin","Mehmet Gunturkun","Gabriel Huang","David Vazquez","Dava Newman","Yoshua Bengio","Stefano Ermon","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.03831v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03830v1","updated":"2023-06-06T16:15:56Z","published":"2023-06-06T16:15:56Z","title":"Inductive Bias for Emergent Communication in a Continuous Setting","summary":"  We study emergent communication in a multi-agent reinforcement learning\nsetting, where the agents solve cooperative tasks and have access to a\ncommunication channel. The communication channel may consist of either discrete\nsymbols or continuous variables. We introduce an inductive bias to aid with the\nemergence of good communication protocols for continuous messages, and we look\nat the effect this type of inductive bias has for continuous and discrete\nmessages in itself or when used in combination with reinforcement learning. We\ndemonstrate that this type of inductive bias has a beneficial effect on the\ncommunication protocols learnt in two toy environments, Negotiation and\nSequence Guess.\n","authors":["John Isak Fjellvang Villanger","Troels Arnfred Bojesen"],"pdf_url":"https://arxiv.org/pdf/2306.03830v1.pdf","comment":"NIPS 2023 Preprint. 12 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.04791v2","updated":"2023-06-06T16:15:34Z","published":"2023-03-08T18:41:27Z","title":"Ewald-based Long-Range Message Passing for Molecular Graphs","summary":"  Neural architectures that learn potential energy surfaces from molecular data\nhave undergone fast improvement in recent years. A key driver of this success\nis the Message Passing Neural Network (MPNN) paradigm. Its favorable scaling\nwith system size partly relies upon a spatial distance limit on messages. While\nthis focus on locality is a useful inductive bias, it also impedes the learning\nof long-range interactions such as electrostatics and van der Waals forces. To\naddress this drawback, we propose Ewald message passing: a nonlocal Fourier\nspace scheme which limits interactions via a cutoff on frequency instead of\ndistance, and is theoretically well-founded in the Ewald summation method. It\ncan serve as an augmentation on top of existing MPNN architectures as it is\ncomputationally inexpensive and agnostic to architectural details. We test the\napproach with four baseline models and two datasets containing diverse periodic\n(OC20) and aperiodic structures (OE62). We observe robust improvements in\nenergy mean absolute errors across all models and datasets, averaging 10% on\nOC20 and 16% on OE62. Our analysis shows an outsize impact of these\nimprovements on structures with high long-range contributions to the ground\ntruth energy.\n","authors":["Arthur Kosmala","Johannes Gasteiger","Nicholas Gao","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2303.04791v2.pdf","comment":"Published at the 40th International Conference on Machine Learning\n  (ICML 2023)"},{"id":"http://arxiv.org/abs/2306.03828v1","updated":"2023-06-06T16:15:26Z","published":"2023-06-06T16:15:26Z","title":"Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How","summary":"  With the ever-increasing number of pretrained models, machine learning\npractitioners are continuously faced with which pretrained model to use, and\nhow to finetune it for a new dataset. In this paper, we propose a methodology\nthat jointly searches for the optimal pretrained model and the hyperparameters\nfor finetuning it. Our method transfers knowledge about the performance of many\npretrained models with multiple hyperparameter configurations on a series of\ndatasets. To this aim, we evaluated over 20k hyperparameter configurations for\nfinetuning 24 pretrained image classification models on 87 datasets to generate\na large-scale meta-dataset. We meta-learn a multi-fidelity performance\npredictor on the learning curves of this meta-dataset and use it for fast\nhyperparameter optimization on new datasets. We empirically demonstrate that\nour resulting approach can quickly select an accurate pretrained model for a\nnew dataset together with its optimal hyperparameters.\n","authors":["Sebastian Pineda Arango","Fabio Ferreira","Arlind Kadra","Frank Hutter Josif Grabocka"],"pdf_url":"https://arxiv.org/pdf/2306.03828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10118v2","updated":"2023-06-06T16:13:53Z","published":"2023-05-17T10:50:38Z","title":"Bridging the Gap: Enhancing the Utility of Synthetic Data via\n  Post-Processing Techniques","summary":"  Acquiring and annotating suitable datasets for training deep learning models\nis challenging. This often results in tedious and time-consuming efforts that\ncan hinder research progress. However, generative models have emerged as a\npromising solution for generating synthetic datasets that can replace or\naugment real-world data. Despite this, the effectiveness of synthetic data is\nlimited by their inability to fully capture the complexity and diversity of\nreal-world data. To address this issue, we explore the use of Generative\nAdversarial Networks to generate synthetic datasets for training classifiers\nthat are subsequently evaluated on real-world images. To improve the quality\nand diversity of the synthetic dataset, we propose three novel post-processing\ntechniques: Dynamic Sample Filtering, Dynamic Dataset Recycle, and Expansion\nTrick. In addition, we introduce a pipeline called Gap Filler (GaFi), which\napplies these techniques in an optimal and coordinated manner to maximise\nclassification accuracy on real-world data. Our experiments show that GaFi\neffectively reduces the gap with real-accuracy scores to an error of 2.03%,\n1.78%, and 3.99% on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets,\nrespectively. These results represent a new state of the art in Classification\nAccuracy Score and highlight the effectiveness of post-processing techniques in\nimproving the quality of synthetic datasets.\n","authors":["Andrea Lampis","Eugenio Lomurno","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2305.10118v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03824v1","updated":"2023-06-06T16:12:35Z","published":"2023-06-06T16:12:35Z","title":"Understanding Generalization of Federated Learning via Stability:\n  Heterogeneity Matters","summary":"  Generalization performance is a key metric in evaluating machine learning\nmodels when applied to real-world applications. Good generalization indicates\nthe model can predict unseen data correctly when trained under a limited number\nof data. Federated learning (FL), which has emerged as a popular distributed\nlearning framework, allows multiple devices or clients to train a shared model\nwithout violating privacy requirements. While the existing literature has\nstudied extensively the generalization performances of centralized machine\nlearning algorithms, similar analysis in the federated settings is either\nabsent or with very restrictive assumptions on the loss functions. In this\npaper, we aim to analyze the generalization performances of federated learning\nby means of algorithmic stability, which measures the change of the output\nmodel of an algorithm when perturbing one data point. Three widely-used\nalgorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex\nand non-convex loss functions. Our analysis shows that the generalization\nperformances of models trained by these three algorithms are closely related to\nthe heterogeneity of clients' datasets as well as the convergence behaviors of\nthe algorithms. Particularly, in the i.i.d. setting, our results recover the\nclassical results of stochastic gradient descent (SGD).\n","authors":["Zhenyu Sun","Xiaochun Niu","Ermin Wei"],"pdf_url":"https://arxiv.org/pdf/2306.03824v1.pdf","comment":"Submitted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.00698v2","updated":"2023-06-06T16:12:01Z","published":"2023-06-01T14:08:05Z","title":"Prediction of Post-Operative Renal and Pulmonary Complications Using\n  Transformers","summary":"  Postoperative complications pose a significant challenge in the healthcare\nindustry, resulting in elevated healthcare expenses and prolonged hospital\nstays, and in rare instances, patient mortality. To improve patient outcomes\nand reduce healthcare costs, healthcare providers rely on various perioperative\nrisk scores to guide clinical decisions and prioritize care. In recent years,\nmachine learning techniques have shown promise in predicting postoperative\ncomplications and fatality, with deep learning models achieving remarkable\nsuccess in healthcare applications. However, research on the application of\ndeep learning models to intra-operative anesthesia management data is limited.\nIn this paper, we evaluate the performance of transformer-based models in\npredicting postoperative acute renal failure, postoperative pulmonary\ncomplications, and postoperative in-hospital mortality. We compare our method's\nperformance with state-of-the-art tabular data prediction models, including\ngradient boosting trees and sequential attention models, on a clinical dataset.\nOur results demonstrate that transformer-based models can achieve superior\nperformance in predicting postoperative complications and outperform\ntraditional machine learning models. This work highlights the potential of deep\nlearning techniques, specifically transformer-based models, in revolutionizing\nthe healthcare industry's approach to postoperative care.\n","authors":["Reza Shirkavand","Fei Zhang","Heng Huang"],"pdf_url":"https://arxiv.org/pdf/2306.00698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08746v3","updated":"2023-06-06T16:11:42Z","published":"2023-05-04T17:56:42Z","title":"Seeing is Believing: Brain-Inspired Modular Training for Mechanistic\n  Interpretability","summary":"  We introduce Brain-Inspired Modular Training (BIMT), a method for making\nneural networks more modular and interpretable. Inspired by brains, BIMT embeds\nneurons in a geometric space and augments the loss function with a cost\nproportional to the length of each neuron connection. We demonstrate that BIMT\ndiscovers useful modular neural networks for many simple tasks, revealing\ncompositional structures in symbolic formulas, interpretable decision\nboundaries and features for classification, and mathematical structure in\nalgorithmic datasets. The ability to directly see modules with the naked eye\ncan complement current mechanistic interpretability strategies such as probes,\ninterventions or staring at all weights.\n","authors":["Ziming Liu","Eric Gan","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2305.08746v3.pdf","comment":"Codes are available here: https://github.com/KindXiaoming/BIMT"},{"id":"http://arxiv.org/abs/2306.00477v2","updated":"2023-06-06T16:10:28Z","published":"2023-06-01T09:26:17Z","title":"Make Your Pre-trained Model Reversible: From Parameter to Memory\n  Efficient Fine-Tuning","summary":"  Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant with\nPEFT is not straightforward, since the reversible model has a distinct\narchitecture from the currently released PLMs. In this paper, we first\ninvestigate what is a key factor for the success of existing PEFT methods, and\nrealize that it's essential to preserve the PLM's starting point when\ninitializing a PEFT method. With this finding, we propose memory-efficient\nfine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM's\nstarting point and making it reversible without additional pre-training. We\nevaluate MEFT on the GLUE benchmark and five question-answering tasks with\nvarious backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces the\nactivation memory up to 84% of full fine-tuning with a negligible amount of\ntrainable parameters. Moreover, MEFT achieves the same score on GLUE and a\ncomparable score on the question-answering tasks as full fine-tuning.\n","authors":["Baohao Liao","Shaomu Tan","Christof Monz"],"pdf_url":"https://arxiv.org/pdf/2306.00477v2.pdf","comment":"Code at https://github.com/BaohaoLiao/mefts"},{"id":"http://arxiv.org/abs/2302.00141v2","updated":"2023-06-06T16:09:23Z","published":"2023-01-31T23:14:25Z","title":"Revisiting Bellman Errors for Offline Model Selection","summary":"  Offline model selection (OMS), that is, choosing the best policy from a set\nof many policies given only logged data, is crucial for applying offline RL in\nreal-world settings. One idea that has been extensively explored is to select\npolicies based on the mean squared Bellman error (MSBE) of the associated\nQ-functions. However, previous work has struggled to obtain adequate OMS\nperformance with Bellman errors, leading many researchers to abandon the idea.\nTo this end, we elucidate why previous work has seen pessimistic results with\nBellman errors and identify conditions under which OMS algorithms based on\nBellman errors will perform well. Moreover, we develop a new estimator of the\nMSBE that is more accurate than prior methods. Our estimator obtains impressive\nOMS performance on diverse discrete control tasks, including Atari games.\n","authors":["Joshua P. Zitovsky","Daniel de Marchi","Rishabh Agarwal","Michael R. Kosorok"],"pdf_url":"https://arxiv.org/pdf/2302.00141v2.pdf","comment":"Published in ICML 2023"},{"id":"http://arxiv.org/abs/2306.03819v1","updated":"2023-06-06T16:07:24Z","published":"2023-06-06T16:07:24Z","title":"LEACE: Perfect linear concept erasure in closed form","summary":"  Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.\n","authors":["Nora Belrose","David Schneider-Joseph","Shauli Ravfogel","Ryan Cotterell","Edward Raff","Stella Biderman"],"pdf_url":"https://arxiv.org/pdf/2306.03819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03812v1","updated":"2023-06-06T15:58:09Z","published":"2023-06-06T15:58:09Z","title":"Computation with Sequences in the Brain","summary":"  Even as machine learning exceeds human-level performance on many\napplications, the generality, robustness, and rapidity of the brain's learning\ncapabilities remain unmatched. How cognition arises from neural activity is a\ncentral open question in neuroscience, inextricable from the study of\nintelligence itself. A simple formal model of neural activity was proposed in\nPapadimitriou [2020] and has been subsequently shown, through both mathematical\nproofs and simulations, to be capable of implementing certain simple cognitive\noperations via the creation and manipulation of assemblies of neurons. However,\nmany intelligent behaviors rely on the ability to recognize, store, and\nmanipulate temporal sequences of stimuli (planning, language, navigation, to\nlist a few). Here we show that, in the same model, time can be captured\nnaturally as precedence through synaptic weights and plasticity, and, as a\nresult, a range of computations on sequences of assemblies can be carried out.\nIn particular, repeated presentation of a sequence of stimuli leads to the\nmemorization of the sequence through corresponding neural assemblies: upon\nfuture presentation of any stimulus in the sequence, the corresponding assembly\nand its subsequent ones will be activated, one after the other, until the end\nof the sequence. Finally, we show that any finite state machine can be learned\nin a similar way, through the presentation of appropriate patterns of\nsequences. Through an extension of this mechanism, the model can be shown to be\ncapable of universal computation. We support our analysis with a number of\nexperiments to probe the limits of learning in this model in key ways. Taken\ntogether, these results provide a concrete hypothesis for the basis of the\nbrain's remarkable abilities to compute and learn, with sequences playing a\nvital role.\n","authors":["Max Dabagia","Christos H. Papadimitriou","Santosh S. Vempala"],"pdf_url":"https://arxiv.org/pdf/2306.03812v1.pdf","comment":"24 pages, 12 figures"},{"id":"http://arxiv.org/abs/1902.00778v4","updated":"2023-06-06T15:52:30Z","published":"2019-02-02T20:09:32Z","title":"Certified Reinforcement Learning with Logic Guidance","summary":"  Reinforcement Learning (RL) is a widely employed machine learning\narchitecture that has been applied to a variety of control problems. However,\napplications in safety-critical domains require a systematic and formal\napproach to specifying requirements as tasks or goals. We propose a model-free\nRL algorithm that enables the use of Linear Temporal Logic (LTL) to formulate a\ngoal for unknown continuous-state/action Markov Decision Processes (MDPs). The\ngiven LTL property is translated into a Limit-Deterministic Generalised Buchi\nAutomaton (LDGBA), which is then used to shape a synchronous reward function\non-the-fly. Under certain assumptions, the algorithm is guaranteed to\nsynthesise a control policy whose traces satisfy the LTL specification with\nmaximal probability.\n","authors":["Hosein Hasanbeig","Daniel Kroening","Alessandro Abate"],"pdf_url":"https://arxiv.org/pdf/1902.00778v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03805v1","updated":"2023-06-06T15:49:09Z","published":"2023-06-06T15:49:09Z","title":"The Emergence of Essential Sparsity in Large Pre-trained Models: The\n  Weights that Matter","summary":"  Large pre-trained transformers are show-stealer in modern-day deep learning,\nand it becomes crucial to comprehend the parsimonious patterns that exist\nwithin them as they grow in scale. With exploding parameter counts, Lottery\nTicket Hypothesis (LTH) and its variants, have lost their pragmatism in\nsparsifying them due to high computation and memory bottleneck of the\nrepetitive train-prune-retrain routine of iterative magnitude pruning (IMP)\nwhich worsens with increasing model size. In this paper, we comprehensively\nstudy induced sparse patterns across multiple large pre-trained vision and\nlanguage transformers. We propose the existence of -- essential sparsity\ndefined with a sharp dropping point beyond which the performance declines much\nfaster w.r.t the rise of sparsity level, when we directly remove weights with\nthe smallest magnitudes in one-shot. In the sparsity-performance curve We also\npresent an intriguing emerging phenomenon of abrupt sparsification during the\npre-training of BERT, i.e., BERT suddenly becomes heavily sparse in\npre-training after certain iterations. Moreover, our observations also indicate\na counter-intuitive finding that BERT trained with a larger amount of\npre-training data tends to have a better ability to condense knowledge in\ncomparatively relatively fewer parameters. Lastly, we investigate the effect of\nthe pre-training loss on essential sparsity and discover that self-supervised\nlearning (SSL) objectives trigger stronger emergent sparsification properties\nthan supervised learning (SL). Our codes are available at\n\\url{https://github.com/VITA-Group/essential\\_sparsity}.\n","authors":["Ajay Jaiswal","Shiwei Liu","Tianlong Chen","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.03805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18885v4","updated":"2023-06-06T15:45:30Z","published":"2023-05-30T09:27:36Z","title":"Criteria Tell You More than Ratings: Criteria Preference-Aware Light\n  Graph Convolution for Effective Multi-Criteria Recommendation","summary":"  The multi-criteria (MC) recommender system, which leverages MC rating\ninformation in a wide range of e-commerce areas, is ubiquitous nowadays.\nSurprisingly, although graph neural networks (GNNs) have been widely applied to\ndevelop various recommender systems due to GNN's high expressive capability in\nlearning graph representations, it has been still unexplored how to design MC\nrecommender systems with GNNs. In light of this, we make the first attempt\ntowards designing a GNN-aided MC recommender system. Specifically, rather than\nstraightforwardly adopting existing GNN-based recommendation methods, we devise\na novel criteria preference-aware light graph convolution CPA-LGC method, which\nis capable of precisely capturing the criteria preference of users as well as\nthe collaborative signal in complex high-order connectivities. To this end, we\nfirst construct an MC expansion graph that transforms user--item MC ratings\ninto an expanded bipartite graph to potentially learn from the collaborative\nsignal in MC ratings. Next, to strengthen the capability of criteria preference\nawareness, CPA-LGC incorporates newly characterized embeddings, including\nuser-specific criteria-preference embeddings and item-specific criterion\nembeddings, into our graph convolution model. Through comprehensive evaluations\nusing four real-world datasets, we demonstrate (a) the superiority over\nbenchmark MC recommendation methods and benchmark recommendation methods using\nGNNs with tremendous gains, (b) the effectiveness of core components in\nCPA-LGC, and (c) the computational efficiency.\n","authors":["Jin-Duk Park","Siqing Li","Xin Cao","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2305.18885v4.pdf","comment":"12 pages, 10 figures, 5 tables; 29th ACM SIGKDD Conference on\n  Knowledge Discovery & Data (KDD 2023) (to appear) (Please cite our conference\n  version.)"},{"id":"http://arxiv.org/abs/2306.03801v1","updated":"2023-06-06T15:45:07Z","published":"2023-06-06T15:45:07Z","title":"Stable Vectorization of Multiparameter Persistent Homology using Signed\n  Barcodes as Measures","summary":"  Persistent homology (PH) provides topological descriptors for geometric data,\nsuch as weighted graphs, which are interpretable, stable to perturbations, and\ninvariant under, e.g., relabeling. Most applications of PH focus on the\none-parameter case -- where the descriptors summarize the changes in topology\nof data as it is filtered by a single quantity of interest -- and there is now\na wide array of methods enabling the use of one-parameter PH descriptors in\ndata science, which rely on the stable vectorization of these descriptors as\nelements of a Hilbert space. Although the multiparameter PH (MPH) of data that\nis filtered by several quantities of interest encodes much richer information\nthan its one-parameter counterpart, the scarceness of stability results for MPH\ndescriptors has so far limited the available options for the stable\nvectorization of MPH. In this paper, we aim to bring together the best of both\nworlds by showing how the interpretation of signed barcodes -- a recent family\nof MPH descriptors -- as signed measures leads to natural extensions of\nvectorization strategies from one parameter to multiple parameters. The\nresulting feature vectors are easy to define and to compute, and provably\nstable. While, as a proof of concept, we focus on simple choices of signed\nbarcodes and vectorizations, we already see notable performance improvements\nwhen comparing our feature vectors to state-of-the-art topology-based methods\non various types of data.\n","authors":["David Loiseaux","Luis Scoccola","Mathieu Carrière","Magnus Bakke Botnan","Steve Oudot"],"pdf_url":"https://arxiv.org/pdf/2306.03801v1.pdf","comment":"23 pages, 3 figures, 8 tables"},{"id":"http://arxiv.org/abs/2207.14443v2","updated":"2023-06-06T15:44:14Z","published":"2022-07-29T02:34:19Z","title":"A Survey of Learning on Small Data: Generalization, Optimization, and\n  Challenge","summary":"  Learning on big data brings success for artificial intelligence (AI), but the\nannotation and training costs are expensive. In future, learning on small data\nthat approximates the generalization ability of big data is one of the ultimate\npurposes of AI, which requires machines to recognize objectives and scenarios\nrelying on small data as humans. A series of learning topics is going on this\nway such as active learning and few-shot learning. However, there are few\ntheoretical guarantees for their generalization performance. Moreover, most of\ntheir settings are passive, that is, the label distribution is explicitly\ncontrolled by finite training resources from known distributions. This survey\nfollows the agnostic active sampling theory under a PAC (Probably Approximately\nCorrect) framework to analyze the generalization error and label complexity of\nlearning on small data in model-agnostic supervised and unsupervised fashion.\nConsidering multiple learning communities could produce small data\nrepresentation and related topics have been well surveyed, we thus subjoin\nnovel geometric representation perspectives for small data: the Euclidean and\nnon-Euclidean (hyperbolic) mean, where the optimization solutions including the\nEuclidean gradients, non-Euclidean gradients, and Stein gradient are presented\nand discussed. Later, multiple learning communities that may be improved by\nlearning on small data are summarized, which yield data-efficient\nrepresentations, such as transfer learning, contrastive learning, graph\nrepresentation learning. Meanwhile, we find that the meta-learning may provide\neffective parameter update policies for learning on small data. Then, we\nexplore multiple challenging scenarios for small data, such as the weak\nsupervision and multi-label. Finally, multiple data applications that may\nbenefit from efficient small data representation are surveyed.\n","authors":["Xiaofeng Cao","Weixin Bu","Shengjun Huang","Minling Zhang","Ivor W. Tsang","Yew Soon Ong","James T. Kwok"],"pdf_url":"https://arxiv.org/pdf/2207.14443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03795v1","updated":"2023-06-06T15:40:27Z","published":"2023-06-06T15:40:27Z","title":"AI-Supported Assessment of Load Safety","summary":"  Load safety assessment and compliance is an essential step in the corporate\nprocess of every logistics service provider. In 2020, a total of 11,371 police\nchecks of trucks were carried out, during which 9.6% (1091) violations against\nthe load safety regulations were detected. For a logistic service provider,\nevery load safety violation results in height fines and damage to reputation.\nAn assessment of load safety supported by artificial intelligence (AI) will\nreduce the risk of accidents by unsecured loads and fines during safety\nassessments. This work shows how photos of the load, taken by the truck driver\nor the loadmaster after the loading process, can be used to assess load safety.\nBy a trained two-stage artificial neural network (ANN), these photos are\nclassified into three different classes I) cargo loaded safely, II) cargo\nloaded unsafely, and III) unusable image. By applying several architectures of\nconvolutional neural networks (CNN), it can be shown that it is possible to\ndistinguish between unusable and usable images for cargo safety assessment.\nThis distinction is quite crucial since the truck driver and the loadmaster\nsometimes provide photos without the essential image features like the case\nstructure of the truck and the whole cargo. A human operator or another ANN\nwill then assess the load safety within the second stage.\n","authors":["Julius Schöning","Niklas Kruse"],"pdf_url":"https://arxiv.org/pdf/2306.03795v1.pdf","comment":"9 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2306.03792v1","updated":"2023-06-06T15:39:54Z","published":"2023-06-06T15:39:54Z","title":"FAMO: Fast Adaptive Multitask Optimization","summary":"  One of the grand enduring goals of AI is to create generalist agents that can\nlearn multiple different tasks from diverse data via multitask learning (MTL).\nHowever, gradient descent (GD) on the average loss across all tasks may yield\npoor multitask performance due to severe under-optimization of certain tasks.\nPrevious approaches that manipulate task gradients for a more balanced loss\ndecrease require storing and computing all task gradients (O(K) space and time\nwhere K is the number of tasks), limiting their use in large-scale scenarios.\nIn this work, we introduce Fast Adaptive Multitask Optimization (FAMO), a\ndynamic weighting method that decreases task losses in a balanced way using\nO(1) space and time. We conduct an extensive set of experiments covering\nmulti-task supervised and reinforcement learning problems. Our results indicate\nthat FAMO achieves comparable or superior performance to state-of-the-art\ngradient manipulation techniques while offering significant improvements in\nspace and computational efficiency. Code is available at\nhttps://github.com/Cranial-XIX/FAMO.\n","authors":["Bo Liu","Yihao Feng","Peter Stone","Qiang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.03792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09836v2","updated":"2023-06-06T15:39:51Z","published":"2023-04-19T17:38:42Z","title":"Regions of Reliability in the Evaluation of Multivariate Probabilistic\n  Forecasts","summary":"  Multivariate probabilistic time series forecasts are commonly evaluated via\nproper scoring rules, i.e., functions that are minimal in expectation for the\nground-truth distribution. However, this property is not sufficient to\nguarantee good discrimination in the non-asymptotic regime. In this paper, we\nprovide the first systematic finite-sample study of proper scoring rules for\ntime-series forecasting evaluation. Through a power analysis, we identify the\n\"region of reliability\" of a scoring rule, i.e., the set of practical\nconditions where it can be relied on to identify forecasting errors. We carry\nout our analysis on a comprehensive synthetic benchmark, specifically designed\nto test several key discrepancies between ground-truth and forecast\ndistributions, and we gauge the generalizability of our findings to real-world\ntasks with an application to an electricity production problem. Our results\nreveal critical shortcomings in the evaluation of multivariate probabilistic\nforecasts as commonly performed in the literature.\n","authors":["Étienne Marcotte","Valentina Zantedeschi","Alexandre Drouin","Nicolas Chapados"],"pdf_url":"https://arxiv.org/pdf/2304.09836v2.pdf","comment":"47 pages, 37 figures, camera-ready version, Fortieth International\n  Conference on Machine Learning (ICML 2023)"},{"id":"http://arxiv.org/abs/2301.06428v2","updated":"2023-06-06T15:37:45Z","published":"2023-01-16T13:33:37Z","title":"Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic\n  Optimization","summary":"  We consider the optimization problem of the form $\\min_{x \\in \\mathbb{R}^d}\nf(x) \\triangleq \\mathbb{E}_{\\xi} [F(x; \\xi)]$, where the component $F(x;\\xi)$\nis $L$-mean-squared Lipschitz but possibly nonconvex and nonsmooth. The\nrecently proposed gradient-free method requires at most $\\mathcal{O}( L^4\nd^{3/2} \\epsilon^{-4} + \\Delta L^3 d^{3/2} \\delta^{-1} \\epsilon^{-4})$\nstochastic zeroth-order oracle complexity to find a\n$(\\delta,\\epsilon)$-Goldstein stationary point of objective function, where\n$\\Delta = f(x_0) - \\inf_{x \\in \\mathbb{R}^d} f(x)$ and $x_0$ is the initial\npoint of the algorithm. This paper proposes a more efficient algorithm using\nstochastic recursive gradient estimators, which improves the complexity to\n$\\mathcal{O}(L^3 d^{3/2} \\epsilon^{-3}+ \\Delta L^2 d^{3/2} \\delta^{-1}\n\\epsilon^{-3})$.\n","authors":["Lesi Chen","Jing Xu","Luo Luo"],"pdf_url":"https://arxiv.org/pdf/2301.06428v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.03783v1","updated":"2023-06-06T15:36:15Z","published":"2023-06-06T15:36:15Z","title":"Asymptotics of Bayesian Uncertainty Estimation in Random Features\n  Regression","summary":"  In this paper we compare and contrast the behavior of the posterior\npredictive distribution to the risk of the maximum a posteriori estimator for\nthe random features regression model in the overparameterized regime. We will\nfocus on the variance of the posterior predictive distribution (Bayesian model\naverage) and compare its asymptotics to that of the risk of the MAP estimator.\nIn the regime where the model dimensions grow faster than any constant multiple\nof the number of samples, asymptotic agreement between these two quantities is\ngoverned by the phase transition in the signal-to-noise ratio. They also\nasymptotically agree with each other when the number of samples grow faster\nthan any constant multiple of model dimensions. Numerical simulations\nillustrate finer distributional properties of the two quantities for finite\ndimensions. We conjecture they have Gaussian fluctuations and exhibit similar\nproperties as found by previous authors in a Gaussian sequence model, which is\nof independent theoretical interest.\n","authors":["Youngsoo Baek","Samuel I. Berchuck","Sayan Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2306.03783v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.03775v1","updated":"2023-06-06T15:32:30Z","published":"2023-06-06T15:32:30Z","title":"Matched Pair Calibration for Ranking Fairness","summary":"  We propose a test of fairness in score-based ranking systems called matched\npair calibration. Our approach constructs a set of matched item pairs with\nminimal confounding differences between subgroups before computing an\nappropriate measure of ranking error over the set. The matching step ensures\nthat we compare subgroup outcomes between identically scored items so that\nmeasured performance differences directly imply unfairness in subgroup-level\nexposures. We show how our approach generalizes the fairness intuitions of\ncalibration from a binary classification setting to ranking and connect our\napproach to other proposals for ranking fairness measures. Moreover, our\nstrategy shows how the logic of marginal outcome tests extends to cases where\nthe analyst has access to model scores. Lastly, we provide an example of\napplying matched pair calibration to a real-word ranking data set to\ndemonstrate its efficacy in detecting ranking bias.\n","authors":["Hannah Korevaar","Chris McConnell","Edmund Tong","Erik Brinkman","Alana Shine","Misam Abbas","Blossom Metevier","Sam Corbett-Davies","Khalid El-Arini"],"pdf_url":"https://arxiv.org/pdf/2306.03775v1.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2305.04990v3","updated":"2023-06-06T15:31:33Z","published":"2023-05-08T18:53:45Z","title":"Explanation-based Finetuning Makes Models More Robust to Spurious Cues","summary":"  Large Language Models (LLMs) are so powerful that they sometimes learn\ncorrelations between labels and features that are irrelevant to the task,\nleading to poor generalization on out-of-distribution data. We propose\nexplanation-based finetuning as a general approach to mitigate LLMs' reliance\non spurious correlations. Unlike standard finetuning where the model only\npredicts the answer given the input, we finetune the model to additionally\ngenerate a free-text explanation supporting its answer. To evaluate our method,\nwe finetune the model on artificially constructed training sets containing\ndifferent types of spurious cues, and test it on a test set without these cues.\nCompared to standard finetuning, our method makes GPT-3 (davinci) remarkably\nmore robust against spurious cues in terms of accuracy drop across four\nclassification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC\n(+6.5). The efficacy generalizes across multiple model families and scales,\nwith greater gains for larger models. Finally, our method also works well with\nexplanations generated by the model, implying its applicability to more\ndatasets without human-written explanations.\n","authors":["Josh Magnus Ludan","Yixuan Meng","Tai Nguyen","Saurabh Shah","Qing Lyu","Marianna Apidianaki","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2305.04990v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03770v1","updated":"2023-06-06T15:31:05Z","published":"2023-06-06T15:31:05Z","title":"Graph Classification Gaussian Processes via Spectral Features","summary":"  Graph classification aims to categorise graphs based on their structure and\nnode attributes. In this work, we propose to tackle this task using tools from\ngraph signal processing by deriving spectral features, which we then use to\ndesign two variants of Gaussian process models for graph classification. The\nfirst variant uses spectral features based on the distribution of energy of a\nnode feature signal over the spectrum of the graph. We show that even such a\nsimple approach, having no learned parameters, can yield competitive\nperformance compared to strong neural network and graph kernel baselines. A\nsecond, more sophisticated variant is designed to capture multi-scale and\nlocalised patterns in the graph by learning spectral graph wavelet filters,\nobtaining improved performance on synthetic and real-world data sets. Finally,\nwe show that both models produce well calibrated uncertainty estimates,\nenabling reliable decision making based on the model predictions.\n","authors":["Felix L. Opolka","Yin-Cong Zhi","Pietro Liò","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2306.03770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10226v3","updated":"2023-06-06T15:25:37Z","published":"2023-04-20T11:40:21Z","title":"Domain Generalization for Mammographic Image Analysis via Contrastive\n  Learning","summary":"  The deep learning technique has been shown to be effective in addressing\nseveral image analysis tasks within the computer-aided diagnosis scheme for\nmammography. The training of an efficacious deep learning model requires large\namounts of data with sufficient diversity in terms of image style and quality.\nIn particular, the diversity of image styles may be primarily attributed to the\nvendor factor. However, the collection of mammograms from large and diverse\nvendors is very expensive and sometimes impractical. Motivatedly, a novel\ncontrastive learning method is developed to equip the deep learning models with\nbetter generalization capability. Specifically, the multi-style and multi-view\nunsupervised self-learning scheme is carried out to seek robust feature\nembedding against various vendor styles as a pre-trained model. Afterward, the\npre-trained network is further fine-tuned to the downstream tasks, e.g., mass\ndetection, matching, BI-RADS rating, and breast density classification. The\nproposed method has been extensively and rigorously evaluated with mammograms\nfrom various vendor-style domains and several public datasets. The experimental\nresults suggest that the proposed domain generalization method can effectively\nimprove the performance of four mammographic image tasks on data from either\nseen or unseen domains and outperform many state-of-the-art (SOTA)\ngeneralization methods.\n","authors":["Zheren Li","Zhiming Cui","Lichi Zhang","Sheng Wang","Chenjin Lei","Xi Ouyang","Dongdong Chen","Xiangyu Zhao","Yajia Gu","Zaiyi Liu","Chunling Liu","Dinggang Shen","Jie-Zhi Cheng"],"pdf_url":"https://arxiv.org/pdf/2304.10226v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2111.10827"},{"id":"http://arxiv.org/abs/2306.03757v1","updated":"2023-06-06T15:17:34Z","published":"2023-06-06T15:17:34Z","title":"Exploring the effects of robotic design on learning and neural control","summary":"  The ongoing deep learning revolution has allowed computers to outclass humans\nin various games and perceive features imperceptible to humans during\nclassification tasks. Current machine learning techniques have clearly\ndistinguished themselves in specialized tasks. However, we have yet to see\nrobots capable of performing multiple tasks at an expert level. Most work in\nthis field is focused on the development of more sophisticated learning\nalgorithms for a robot's controller given a largely static and presupposed\nrobotic design. By focusing on the development of robotic bodies, rather than\nneural controllers, I have discovered that robots can be designed such that\nthey overcome many of the current pitfalls encountered by neural controllers in\nmultitask settings. Through this discovery, I also present novel metrics to\nexplicitly measure the learning ability of a robotic design and its resistance\nto common problems such as catastrophic interference.\n  Traditionally, the physical robot design requires human engineers to plan\nevery aspect of the system, which is expensive and often relies on human\nintuition. In contrast, within the field of evolutionary robotics, evolutionary\nalgorithms are used to automatically create optimized designs, however, such\ndesigns are often still limited in their ability to perform in a multitask\nsetting. The metrics created and presented here give a novel path to automated\ndesign that allow evolved robots to synergize with their controller to improve\nthe computational efficiency of their learning while overcoming catastrophic\ninterference.\n  Overall, this dissertation intimates the ability to automatically design\nrobots that are more general purpose than current robots and that can perform\nvarious tasks while requiring less computation.\n","authors":["Joshua Paul Powers"],"pdf_url":"https://arxiv.org/pdf/2306.03757v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2008.06397"},{"id":"http://arxiv.org/abs/2211.09801v3","updated":"2023-06-06T15:06:15Z","published":"2022-11-17T18:59:03Z","title":"Machine Learned Calabi-Yau Metrics and Curvature","summary":"  Finding Ricci-flat (Calabi-Yau) metrics is a long standing problem in\ngeometry with deep implications for string theory and phenomenology. A new\nattack on this problem uses neural networks to engineer approximations to the\nCalabi-Yau metric within a given K\\\"ahler class. In this paper we investigate\nnumerical Ricci-flat metrics over smooth and singular K3 surfaces and\nCalabi-Yau threefolds. Using these Ricci-flat metric approximations for the\nCefal\\'u family of quartic twofolds and the Dwork family of quintic threefolds,\nwe study characteristic forms on these geometries. We observe that the\nnumerical stability of the numerically computed topological characteristic is\nheavily influenced by the choice of the neural network model, in particular, we\nbriefly discuss a different neural network model, namely Spectral networks,\nwhich correctly approximate the topological characteristic of a Calabi-Yau.\nUsing persistent homology, we show that high curvature regions of the manifolds\nform clusters near the singular points. For our neural network approximations,\nwe observe a Bogomolov--Yau type inequality $3c_2 \\geq c_1^2$ and observe an\nidentity when our geometries have isolated $A_1$ type singularities. We sketch\na proof that $\\chi(X~\\smallsetminus~\\mathrm{Sing}\\,{X}) +\n2~|\\mathrm{Sing}\\,{X}| = 24$ also holds for our numerical approximations.\n","authors":["Per Berglund","Giorgi Butbaia","Tristan Hübsch","Vishnu Jejjala","Damián Mayorga Peña","Challenger Mishra","Justin Tan"],"pdf_url":"https://arxiv.org/pdf/2211.09801v3.pdf","comment":"Version accepted for publication: 48 pages, 32 figures, 8 tables, 3\n  appendices"},{"id":"http://arxiv.org/abs/2306.03745v1","updated":"2023-06-06T15:04:31Z","published":"2023-06-06T15:04:31Z","title":"Soft Merging of Experts with Adaptive Routing","summary":"  Sparsely activated neural networks with conditional computation learn to\nroute their inputs through different \"expert\" subnetworks, providing a form of\nmodularity that densely activated models lack. Despite their possible benefits,\nmodels with learned routing often underperform their parameter-matched densely\nactivated counterparts as well as models that use non-learned heuristic routing\nstrategies. In this paper, we hypothesize that these shortcomings stem from the\ngradient estimation techniques used to train sparsely activated models that use\nnon-differentiable discrete routing decisions. To address this issue, we\nintroduce Soft Merging of Experts with Adaptive Routing (SMEAR), which avoids\ndiscrete routing by using a single \"merged\" expert constructed via a weighted\naverage of all of the experts' parameters. By routing activations through a\nsingle merged expert, SMEAR does not incur a significant increase in\ncomputational costs and enables standard gradient-based training. We\nempirically validate that models using SMEAR outperform models that route based\non metadata or learn sparse routing through gradient estimation. Furthermore,\nwe provide qualitative analysis demonstrating that the experts learned via\nSMEAR exhibit a significant amount of specialization. All of the code used in\nour experiments is publicly available.\n","authors":["Mohammed Muqeeth","Haokun Liu","Colin Raffel"],"pdf_url":"https://arxiv.org/pdf/2306.03745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05608v2","updated":"2023-06-06T15:02:00Z","published":"2023-05-09T16:58:23Z","title":"The Role of Relevance in Fair Ranking","summary":"  Online platforms mediate access to opportunity: relevance-based rankings\ncreate and constrain options by allocating exposure to job openings and job\ncandidates in hiring platforms, or sellers in a marketplace. In order to do so\nresponsibly, these socially consequential systems employ various fairness\nmeasures and interventions, many of which seek to allocate exposure based on\nworthiness. Because these constructs are typically not directly observable,\nplatforms must instead resort to using proxy scores such as relevance and infer\nthem from behavioral signals such as searcher clicks. Yet, it remains an open\nquestion whether relevance fulfills its role as such a worthiness score in\nhigh-stakes fair rankings. In this paper, we combine perspectives and tools\nfrom the social sciences, information retrieval, and fairness in machine\nlearning to derive a set of desired criteria that relevance scores should\nsatisfy in order to meaningfully guide fairness interventions. We then\nempirically show that not all of these criteria are met in a case study of\nrelevance inferred from biased user click data. We assess the impact of these\nviolations on the estimated system fairness and analyze whether existing\nfairness interventions may mitigate the identified issues. Our analyses and\nresults surface the pressing need for new approaches to relevance collection\nand generation that are suitable for use in fair ranking.\n","authors":["Aparna Balagopalan","Abigail Z. Jacobs","Asia Biega"],"pdf_url":"https://arxiv.org/pdf/2305.05608v2.pdf","comment":"Published in SIGIR 2023"},{"id":"http://arxiv.org/abs/2306.01788v2","updated":"2023-06-06T15:00:21Z","published":"2023-05-31T15:47:12Z","title":"Responsible Design Patterns for Machine Learning Pipelines","summary":"  Integrating ethical practices into the AI development process for artificial\nintelligence (AI) is essential to ensure safe, fair, and responsible operation.\nAI ethics involves applying ethical principles to the entire life cycle of AI\nsystems. This is essential to mitigate potential risks and harms associated\nwith AI, such as algorithm biases. To achieve this goal, responsible design\npatterns (RDPs) are critical for Machine Learning (ML) pipelines to guarantee\nethical and fair outcomes. In this paper, we propose a comprehensive framework\nincorporating RDPs into ML pipelines to mitigate risks and ensure the ethical\ndevelopment of AI systems. Our framework comprises new responsible AI design\npatterns for ML pipelines identified through a survey of AI ethics and data\nmanagement experts and validated through real-world scenarios with expert\nfeedback. The framework guides AI developers, data scientists, and\npolicy-makers to implement ethical practices in AI development and deploy\nresponsible AI systems in production.\n","authors":["Saud Hakem Al Harbi","Lionel Nganyewou Tidjon","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2306.01788v2.pdf","comment":"20 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.03739v1","updated":"2023-06-06T14:56:47Z","published":"2023-06-06T14:56:47Z","title":"Learning to Do or Learning While Doing: Reinforcement Learning and\n  Bayesian Optimisation for Online Continuous Tuning","summary":"  Online tuning of real-world plants is a complex optimisation problem that\ncontinues to require manual intervention by experienced human operators.\nAutonomous tuning is a rapidly expanding field of research, where\nlearning-based methods, such as Reinforcement Learning-trained Optimisation\n(RLO) and Bayesian optimisation (BO), hold great promise for achieving\noutstanding plant performance and reducing tuning times. Which algorithm to\nchoose in different scenarios, however, remains an open question. Here we\npresent a comparative study using a routine task in a real particle accelerator\nas an example, showing that RLO generally outperforms BO, but is not always the\nbest choice. Based on the study's results, we provide a clear set of criteria\nto guide the choice of algorithm for a given tuning task. These can ease the\nadoption of learning-based autonomous tuning solutions to the operation of\ncomplex real-world plants, ultimately improving the availability and pushing\nthe limits of operability of these facilities, thereby enabling scientific and\nengineering advancements.\n","authors":["Jan Kaiser","Chenran Xu","Annika Eichler","Andrea Santamaria Garcia","Oliver Stein","Erik Bründermann","Willi Kuropka","Hannes Dinter","Frank Mayet","Thomas Vinatier","Florian Burkart","Holger Schlarb"],"pdf_url":"https://arxiv.org/pdf/2306.03739v1.pdf","comment":"17 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2306.02157v2","updated":"2023-06-06T14:48:36Z","published":"2023-06-03T16:56:18Z","title":"Transforming to Yoked Neural Networks to Improve ANN Structure","summary":"  Most existing classical artificial neural networks (ANN) are designed as a\ntree structure to imitate neural networks. In this paper, we argue that the\nconnectivity of a tree is not sufficient to characterize a neural network. The\nnodes of the same level of a tree cannot be connected with each other, i.e.,\nthese neural unit cannot share information with each other, which is a major\ndrawback of ANN. Although ANN has been significantly improved in recent years\nto more complex structures, such as the directed acyclic graph (DAG), these\nmethods also have unidirectional and acyclic bias for ANN. In this paper, we\npropose a method to build a bidirectional complete graph for the nodes in the\nsame level of an ANN, which yokes the nodes of the same level to formulate a\nneural module. We call our model as YNN in short. YNN promotes the information\ntransfer significantly which obviously helps in improving the performance of\nthe method. Our YNN can imitate neural networks much better compared with the\ntraditional ANN. In this paper, we analyze the existing structural bias of ANN\nand propose a model YNN to efficiently eliminate such structural bias. In our\nmodel, nodes also carry out aggregation and transformation of features, and\nedges determine the flow of information. We further impose auxiliary sparsity\nconstraint to the distribution of connectedness, which promotes the learned\nstructure to focus on critical connections. Finally, based on the optimized\nstructure, we also design small neural module structure based on the minimum\ncut technique to reduce the computational burden of the YNN model. This\nlearning process is compatible with the existing networks and different tasks.\nThe obtained quantitative experimental results reflect that the learned\nconnectivity is superior to the traditional NN structure.\n","authors":["Xinshun Liu","Yizhi Fang","Yichao Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.02157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.14771v2","updated":"2023-06-06T14:47:01Z","published":"2023-03-26T16:35:45Z","title":"Prototype-Sample Relation Distillation: Towards Replay-Free Continual\n  Learning","summary":"  In Continual learning (CL) balancing effective adaptation while combating\ncatastrophic forgetting is a central challenge. Many of the recent\nbest-performing methods utilize various forms of prior task data, e.g. a replay\nbuffer, to tackle the catastrophic forgetting problem. Having access to\nprevious task data can be restrictive in many real-world scenarios, for example\nwhen task data is sensitive or proprietary. To overcome the necessity of using\nprevious tasks' data, in this work, we start with strong representation\nlearning methods that have been shown to be less prone to forgetting. We\npropose a holistic approach to jointly learn the representation and class\nprototypes while maintaining the relevance of old class prototypes and their\nembedded similarities. Specifically, samples are mapped to an embedding space\nwhere the representations are learned using a supervised contrastive loss.\nClass prototypes are evolved continually in the same latent space, enabling\nlearning and prediction at any point. To continually adapt the prototypes\nwithout keeping any prior task data, we propose a novel distillation loss that\nconstrains class prototypes to maintain relative similarities as compared to\nnew task data. This method yields state-of-the-art performance in the\ntask-incremental setting, outperforming methods relying on large amounts of\ndata, and provides strong performance in the class-incremental setting without\nusing any stored data points.\n","authors":["Nader Asadi","MohammadReza Davari","Sudhir Mudur","Rahaf Aljundi","Eugene Belilovsky"],"pdf_url":"https://arxiv.org/pdf/2303.14771v2.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.03727v1","updated":"2023-06-06T14:45:44Z","published":"2023-06-06T14:45:44Z","title":"Towards Visual Foundational Models of Physical Scenes","summary":"  We describe a first step towards learning general-purpose visual\nrepresentations of physical scenes using only image prediction as a training\ncriterion. To do so, we first define \"physical scene\" and show that, even\nthough different agents may maintain different representations of the same\nscene, the underlying physical scene that can be inferred is unique. Then, we\nshow that NeRFs cannot represent the physical scene, as they lack extrapolation\nmechanisms. Those, however, could be provided by Diffusion Models, at least in\ntheory. To test this hypothesis empirically, NeRFs can be combined with\nDiffusion Models, a process we refer to as NeRF Diffusion, used as unsupervised\nrepresentations of the physical scene. Our analysis is limited to visual data,\nwithout external grounding mechanisms that can be provided by independent\nsensory modalities.\n","authors":["Chethan Parameshwara","Alessandro Achille","Matthew Trager","Xiaolong Li","Jiawei Mo","Matthew Trager","Ashwin Swaminathan","CJ Taylor","Dheera Venkatraman","Xiaohan Fei","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2306.03727v1.pdf","comment":"TLDR: Physical scenes are equivalence classes of sufficient\n  statistics, and can be inferred uniquely by any agent measuring the same\n  finite data; We formalize and implement an approach to representation\n  learning that overturns \"naive realism\" in favor of an analytical approach of\n  Russell and Koenderink. NeRFs cannot capture the physical scenes, but\n  combined with Diffusion Models they can"},{"id":"http://arxiv.org/abs/2306.03726v1","updated":"2023-06-06T14:45:24Z","published":"2023-06-06T14:45:24Z","title":"Exploring Model Dynamics for Accumulative Poisoning Discovery","summary":"  Adversarial poisoning attacks pose huge threats to various machine learning\napplications. Especially, the recent accumulative poisoning attacks show that\nit is possible to achieve irreparable harm on models via a sequence of\nimperceptible attacks followed by a trigger batch. Due to the limited\ndata-level discrepancy in real-time data streaming, current defensive methods\nare indiscriminate in handling the poison and clean samples. In this paper, we\ndive into the perspective of model dynamics and propose a novel information\nmeasure, namely, Memorization Discrepancy, to explore the defense via the\nmodel-level information. By implicitly transferring the changes in the data\nmanipulation to that in the model outputs, Memorization Discrepancy can\ndiscover the imperceptible poison samples based on their distinct dynamics from\nthe clean samples. We thoroughly explore its properties and propose\nDiscrepancy-aware Sample Correction (DSC) to defend against accumulative\npoisoning attacks. Extensive experiments comprehensively characterized\nMemorization Discrepancy and verified its effectiveness. The code is publicly\navailable at: https://github.com/tmlr-group/Memorization-Discrepancy.\n","authors":["Jianing Zhu","Xiawei Guo","Jiangchao Yao","Chao Du","Li He","Shuo Yuan","Tongliang Liu","Liang Wang","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2306.03726v1.pdf","comment":"accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.03725v1","updated":"2023-06-06T14:44:52Z","published":"2023-06-06T14:44:52Z","title":"Towards Memory-Efficient Training for Extremely Large Output Spaces --\n  Learning with 500k Labels on a Single Commodity GPU","summary":"  In classification problems with large output spaces (up to millions of\nlabels), the last layer can require an enormous amount of memory. Using sparse\nconnectivity would drastically reduce the memory requirements, but as we show\nbelow, it can result in much diminished predictive performance of the model.\nFortunately, we found that this can be mitigated by introducing a penultimate\nlayer of intermediate size. We further demonstrate that one can constrain the\nconnectivity of the sparse layer to be uniform, in the sense that each output\nneuron will have the exact same number of incoming connections. This allows for\nefficient implementations of sparse matrix multiplication and connection\nredistribution on GPU hardware. Via a custom CUDA implementation, we show that\nthe proposed approach can scale to datasets with 670,000 labels on a single\ncommodity GPU with only 4GB memory.\n","authors":["Erik Schultheis","Rohit Babbar"],"pdf_url":"https://arxiv.org/pdf/2306.03725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03718v1","updated":"2023-06-06T14:28:57Z","published":"2023-06-06T14:28:57Z","title":"Emotion-Conditioned Melody Harmonization with Hierarchical Variational\n  Autoencoder","summary":"  Existing melody harmonization models have made great progress in improving\nthe quality of generated harmonies, but most of them ignored the emotions\nbeneath the music. Meanwhile, the variability of harmonies generated by\nprevious methods is insufficient. To solve these problems, we propose a novel\nLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the\ninfluence of emotional conditions on melody harmonization, while improving the\nquality of generated harmonies and capturing the abundant variability of chord\nprogressions. Specifically, LHVAE incorporates latent variables and emotional\nconditions at different levels (piece- and bar-level) to model the global and\nlocal music properties. Additionally, we introduce an attention-based melody\ncontext vector at each step to better learn the correspondence between melodies\nand harmonies. Experimental results of the objective evaluation show that our\nproposed model outperforms other LSTM-based models. Through subjective\nevaluation, we conclude that only altering the chords hardly changes the\noverall emotion of the music. The qualitative analysis demonstrates the ability\nof our model to generate variable harmonies.\n","authors":["Shulei Ji","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03718v1.pdf","comment":"Accepted by IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2301.13757v2","updated":"2023-06-06T14:28:43Z","published":"2023-01-31T16:45:49Z","title":"Toward Efficient Gradient-Based Value Estimation","summary":"  Gradient-based methods for value estimation in reinforcement learning have\nfavorable stability properties, but they are typically much slower than\nTemporal Difference (TD) learning methods. We study the root causes of this\nslowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned\nloss function in the sense that its Hessian has large condition-number. To\nresolve the adverse effect of poor conditioning of MSBE on gradient based\nmethods, we propose a low complexity batch-free proximal method that\napproximately follows the Gauss-Newton direction and is asymptotically robust\nto parameterization. Our main algorithm, called RANS, is efficient in the sense\nthat it is significantly faster than the residual gradient methods while having\nalmost the same computational complexity, and is competitive with TD on the\nclassic problems that we tested.\n","authors":["Arsalan Sharifnassab","Richard Sutton"],"pdf_url":"https://arxiv.org/pdf/2301.13757v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2007.06676v4","updated":"2023-06-06T14:26:28Z","published":"2020-07-13T20:35:05Z","title":"UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a\n  Generic Framework for Handling Common Camera Distortion Models","summary":"  In classical computer vision, rectification is an integral part of multi-view\ndepth estimation. It typically includes epipolar rectification and lens\ndistortion correction. This process simplifies the depth estimation\nsignificantly, and thus it has been adopted in CNN approaches. However,\nrectification has several side effects, including a reduced field of view\n(FOV), resampling distortion, and sensitivity to calibration errors. The\neffects are particularly pronounced in case of significant distortion (e.g.,\nwide-angle fisheye cameras). In this paper, we propose a generic scale-aware\nself-supervised pipeline for estimating depth, euclidean distance, and visual\nodometry from unrectified monocular videos. We demonstrate a similar level of\nprecision on the unrectified KITTI dataset with barrel distortion comparable to\nthe rectified KITTI dataset. The intuition being that the rectification step\ncan be implicitly absorbed within the CNN model, which learns the distortion\nmodel without increasing complexity. Our approach does not suffer from a\nreduced field of view and avoids computational costs for rectification at\ninference time. To further illustrate the general applicability of the proposed\nframework, we apply it to wide-angle fisheye cameras with 190$^\\circ$\nhorizontal field of view. The training framework UnRectDepthNet takes in the\ncamera distortion model as an argument and adapts projection and unprojection\nfunctions accordingly. The proposed algorithm is evaluated further on the KITTI\nrectified dataset, and we achieve state-of-the-art results that improve upon\nour previous work FisheyeDistanceNet. Qualitative results on a distorted test\nscene video sequence indicate excellent performance\nhttps://youtu.be/K6pbx3bU4Ss.\n","authors":["Varun Ravi Kumar","Senthil Yogamani","Markus Bach","Christian Witt","Stefan Milz","Patrick Mader"],"pdf_url":"https://arxiv.org/pdf/2007.06676v4.pdf","comment":"Minor fixes added after IROS 2020 Camera ready submission. IROS 2020\n  presentation video - https://www.youtube.com/watch?v=3Br2KSWZRrY"},{"id":"http://arxiv.org/abs/2306.02422v2","updated":"2023-06-06T14:23:42Z","published":"2023-06-04T17:54:11Z","title":"A Generalized Alternating Method for Bilevel Learning under the\n  Polyak-Łojasiewicz Condition","summary":"  Bilevel optimization has recently regained interest owing to its applications\nin emerging machine learning fields such as hyperparameter optimization,\nmeta-learning, and reinforcement learning. Recent results have shown that\nsimple alternating (implicit) gradient-based algorithms can achieve the same\nconvergence rate of single-level gradient descent (GD) for bilevel problems\nwith a strongly convex lower-level objective. However, it remains unclear\nwhether this result can be generalized to bilevel problems beyond this basic\nsetting. In this paper, we propose a Generalized ALternating mEthod for bilevel\nopTimization (GALET) with a nonconvex lower-level objective that satisfies the\nPolyak-{\\L}ojasiewicz (PL) condition. We first introduce a stationary metric\nfor the considered bilevel problems, which generalizes the existing metric. We\nthen establish that GALET achieves an $\\epsilon$-stationary metric for the\nconsidered problem within $\\tilde{\\cal O}(\\epsilon^{-1})$ iterations, which\nmatches the iteration complexity of GD for smooth nonconvex problems.\n","authors":["Quan Xiao","Songtao Lu","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2306.02422v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03715v1","updated":"2023-06-06T14:23:34Z","published":"2023-06-06T14:23:34Z","title":"Unleashing Mask: Explore the Intrinsic Out-of-Distribution Detection\n  Capability","summary":"  Out-of-distribution (OOD) detection is an indispensable aspect of secure AI\nwhen deploying machine learning models in real-world applications. Previous\nparadigms either explore better scoring functions or utilize the knowledge of\noutliers to equip the models with the ability of OOD detection. However, few of\nthem pay attention to the intrinsic OOD detection capability of the given\nmodel. In this work, we generally discover the existence of an intermediate\nstage of a model trained on in-distribution (ID) data having higher OOD\ndetection performance than that of its final stage across different settings,\nand further identify one critical data-level attribution to be learning with\nthe atypical samples. Based on such insights, we propose a novel method,\nUnleashing Mask, which aims to restore the OOD discriminative capabilities of\nthe well-trained model with ID data. Our method utilizes a mask to figure out\nthe memorized atypical samples, and then finetune the model or prune it with\nthe introduced mask to forget them. Extensive experiments and analysis\ndemonstrate the effectiveness of our method. The code is available at:\nhttps://github.com/tmlr-group/Unleashing-Mask.\n","authors":["Jianing Zhu","Hengzhuang Li","Jiangchao Yao","Tongliang Liu","Jianliang Xu","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2306.03715v1.pdf","comment":"accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.03013v2","updated":"2023-06-06T14:20:42Z","published":"2023-06-05T16:29:54Z","title":"Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated\n  Learning","summary":"  Malicious server (MS) attacks have enabled the scaling of data stealing in\nfederated learning to large batch sizes and secure aggregation, settings\npreviously considered private. However, many concerns regarding client-side\ndetectability of MS attacks were raised, questioning their practicality once\nthey are publicly known. In this work, for the first time, we thoroughly study\nthe problem of client-side detectability.We demonstrate that most prior MS\nattacks, which fundamentally rely on one of two key principles, are detectable\nby principled client-side checks. Further, we formulate desiderata for\npractical MS attacks and propose SEER, a novel attack framework that satisfies\nall desiderata, while stealing user data from gradients of realistic networks,\neven for large batch sizes (up to 512 in our experiments) and under secure\naggregation. The key insight of SEER is the use of a secret decoder, which is\njointly trained with the shared model. Our work represents a promising first\nstep towards more principled treatment of MS attacks, paving the way for\nrealistic data stealing that can compromise user privacy in real-world\ndeployments.\n","authors":["Kostadin Garov","Dimitar I. Dimitrov","Nikola Jovanović","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2306.03013v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03702v1","updated":"2023-06-06T14:15:29Z","published":"2023-06-06T14:15:29Z","title":"Bayesian post-hoc regularization of random forests","summary":"  Random Forests are powerful ensemble learning algorithms widely used in\nvarious machine learning tasks. However, they have a tendency to overfit noisy\nor irrelevant features, which can result in decreased generalization\nperformance. Post-hoc regularization techniques aim to mitigate this issue by\nmodifying the structure of the learned ensemble after its training. Here, we\npropose Bayesian post-hoc regularization to leverage the reliable patterns\ncaptured by leaf nodes closer to the root, while potentially reducing the\nimpact of more specific and potentially noisy leaf nodes deeper in the tree.\nThis approach allows for a form of pruning that does not alter the general\nstructure of the trees but rather adjusts the influence of leaf nodes based on\ntheir proximity to the root node. We have evaluated the performance of our\nmethod on various machine learning data sets. Our approach demonstrates\ncompetitive performance with the state-of-the-art methods and, in certain\ncases, surpasses them in terms of predictive accuracy and generalization.\n","authors":["Bastian Pfeifer"],"pdf_url":"https://arxiv.org/pdf/2306.03702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03698v1","updated":"2023-06-06T14:12:23Z","published":"2023-06-06T14:12:23Z","title":"Fine-grained Expressivity of Graph Neural Networks","summary":"  Numerous recent works have analyzed the expressive power of message-passing\ngraph neural networks (MPNNs), primarily utilizing combinatorial techniques\nsuch as the $1$-dimensional Weisfeiler-Leman test ($1$-WL) for the graph\nisomorphism problem. However, the graph isomorphism objective is inherently\nbinary, not giving insights into the degree of similarity between two given\ngraphs. This work resolves this issue by considering continuous extensions of\nboth $1$-WL and MPNNs to graphons. Concretely, we show that the continuous\nvariant of $1$-WL delivers an accurate topological characterization of the\nexpressive power of MPNNs on graphons, revealing which graphs these networks\ncan distinguish and the level of difficulty in separating them. We identify the\nfinest topology where MPNNs separate points and prove a universal approximation\ntheorem. Consequently, we provide a theoretical framework for graph and graphon\nsimilarity combining various topological variants of classical\ncharacterizations of the $1$-WL. In particular, we characterize the expressive\npower of MPNNs in terms of the tree distance, which is a graph distance based\non the concepts of fractional isomorphisms, and substructure counts via tree\nhomomorphisms, showing that these concepts have the same expressive power as\nthe $1$-WL and MPNNs on graphons. Empirically, we validate our theoretical\nfindings by showing that randomly initialized MPNNs, without training, exhibit\ncompetitive performance compared to their trained counterparts. Moreover, we\nevaluate different MPNN architectures based on their ability to preserve graph\ndistances, highlighting the significance of our continuous $1$-WL test in\nunderstanding MPNNs' expressivity.\n","authors":["Jan Böker","Ron Levie","Ningyuan Huang","Soledad Villar","Christopher Morris"],"pdf_url":"https://arxiv.org/pdf/2306.03698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2101.12588v5","updated":"2023-06-06T14:06:09Z","published":"2021-01-29T13:56:51Z","title":"No-Regret Caching via Online Mirror Descent","summary":"  We study an online caching problem in which requests can be served by a local\ncache to avoid retrieval costs from a remote server. The cache can update its\nstate after a batch of requests and store an arbitrarily small fraction of each\nfile. We study no-regret algorithms based on Online Mirror Descent (OMD)\nstrategies. We show that bounds for the regret crucially depend on the\ndiversity of the request process, provided by the diversity ratio R/h, where R\nis the size of the batch, and h is the maximum multiplicity of a request in a\ngiven batch. We characterize the optimality of OMD caching policies w.r.t.\nregret under different diversity regimes. We also prove that, when the cache\nmust store the entire file, rather than a fraction, OMD strategies can be\ncoupled with a randomized rounding scheme that preserves regret guarantees,\neven when update costs cannot be neglected. We provide a formal\ncharacterization of the rounding problem through optimal transport theory, and\nmoreover we propose a computationally efficient randomized rounding scheme.\n","authors":["T. Si Salem","G. Neglia","S. Ioannidis"],"pdf_url":"https://arxiv.org/pdf/2101.12588v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00107v2","updated":"2023-06-06T14:06:02Z","published":"2023-05-31T18:27:43Z","title":"MERT: Acoustic Music Understanding Model with Large-Scale\n  Self-supervised Training","summary":"  Self-supervised learning (SSL) has recently emerged as a promising paradigm\nfor training generalisable models on large-scale data in the fields of vision,\ntext, and speech. Although SSL has been proven effective in speech and audio,\nits application to music audio has yet to be thoroughly explored. This is\nprimarily due to the distinctive challenges associated with modelling musical\nknowledge, particularly its tonal and pitched characteristics of music. To\naddress this research gap, we propose an acoustic Music undERstanding model\nwith large-scale self-supervised Training (MERT), which incorporates teacher\nmodels to provide pseudo labels in the masked language modelling (MLM) style\nacoustic pre-training. In our exploration, we identified a superior combination\nof teacher models, which outperforms conventional speech and audio approaches\nin terms of performance. This combination includes an acoustic teacher based on\nResidual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a musical\nteacher based on the Constant-Q Transform (CQT). These teachers effectively\nguide our student model, a BERT-style transformer encoder, to better model\nmusic audio. In addition, we introduce an in-batch noise mixture augmentation\nto enhance the representation robustness. Furthermore, we explore a wide range\nof settings to overcome the instability in acoustic language model\npre-training, which allows our designed paradigm to scale from 95M to 330M\nparameters. Experimental results indicate that our model can generalise and\nperform well on 14 music understanding tasks and attains state-of-the-art\n(SOTA) overall scores. The code and models are online:\nhttps://github.com/yizhilll/MERT.\n","authors":["Yizhi Li","Ruibin Yuan","Ge Zhang","Yinghao Ma","Xingran Chen","Hanzhi Yin","Chenghua Lin","Anton Ragni","Emmanouil Benetos","Norbert Gyenge","Roger Dannenberg","Ruibo Liu","Wenhu Chen","Gus Xia","Yemin Shi","Wenhao Huang","Yike Guo","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2306.00107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05783v3","updated":"2023-06-06T13:57:12Z","published":"2023-02-11T21:07:30Z","title":"ConCerNet: A Contrastive Learning Based Framework for Automated\n  Conservation Law Discovery and Trustworthy Dynamical System Prediction","summary":"  Deep neural networks (DNN) have shown great capacity of modeling a dynamical\nsystem; nevertheless, they usually do not obey physics constraints such as\nconservation laws. This paper proposes a new learning framework named ConCerNet\nto improve the trustworthiness of the DNN based dynamics modeling to endow the\ninvariant properties. ConCerNet consists of two steps: (i) a contrastive\nlearning method to automatically capture the system invariants (i.e.\nconservation properties) along the trajectory observations; (ii) a neural\nprojection layer to guarantee that the learned dynamics models preserve the\nlearned invariants. We theoretically prove the functional relationship between\nthe learned latent representation and the unknown system invariant function.\nExperiments show that our method consistently outperforms the baseline neural\nnetworks in both coordinate error and conservation metrics by a large margin.\nWith neural network based parameterization and no dependence on prior\nknowledge, our method can be extended to complex and large-scale dynamics by\nleveraging an autoencoder.\n","authors":["Wang Zhang","Tsui-Wei Weng","Subhro Das","Alexandre Megretski","Luca Daniel","Lam M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.05783v3.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2301.08987v3","updated":"2023-06-06T13:51:08Z","published":"2023-01-21T18:05:59Z","title":"Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors","summary":"  The pursuit of long-term fairness involves the interplay between\ndecision-making and the underlying data generating process. In this paper,\nthrough causal modeling with a directed acyclic graph (DAG) on the\ndecision-distribution interplay, we investigate the possibility of achieving\nlong-term fairness from a dynamic perspective. We propose Tier Balancing, a\ntechnically more challenging but more natural notion to achieve in the context\nof long-term, dynamic fairness analysis. Different from previous fairness\nnotions that are defined purely on observed variables, our notion goes one step\nfurther, capturing behind-the-scenes situation changes on the unobserved latent\ncausal factors that directly carry out the influence from the current decision\nto the future data distribution. Under the specified dynamics, we prove that in\ngeneral one cannot achieve the long-term fairness goal only through one-step\ninterventions. Furthermore, in the effort of approaching long-term fairness, we\nconsider the mission of \"getting closer to\" the long-term fairness goal and\npresent possibility and impossibility results accordingly.\n","authors":["Zeyu Tang","Yatong Chen","Yang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08987v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00949v2","updated":"2023-06-06T13:48:11Z","published":"2022-10-03T14:03:56Z","title":"Block-wise Training of Residual Networks via the Minimizing Movement\n  Scheme","summary":"  End-to-end backpropagation has a few shortcomings: it requires loading the\nentire model during training, which can be impossible in constrained settings,\nand suffers from three locking problems (forward locking, update locking and\nbackward locking), which prohibit training the layers in parallel. Solving\nlayer-wise optimization problems can address these problems and has been used\nin on-device training of neural networks. We develop a layer-wise training\nmethod, particularly welladapted to ResNets, inspired by the minimizing\nmovement scheme for gradient flows in distribution space. The method amounts to\na kinetic energy regularization of each block that makes the blocks optimal\ntransport maps and endows them with regularity. It works by alleviating the\nstagnation problem observed in layer-wise training, whereby greedily-trained\nearly layers overfit and deeper layers stop increasing test accuracy after a\ncertain depth. We show on classification tasks that the test accuracy of\nblock-wise trained ResNets is improved when using our method, whether the\nblocks are trained sequentially or in parallel.\n","authors":["Skander Karkar","Ibrahim Ayed","Emmanuel de Bézenac","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2210.00949v2.pdf","comment":"1st International Workshop on Practical Deep Learning in the Wild at\n  AAAI 2022"},{"id":"http://arxiv.org/abs/2306.02050v2","updated":"2023-06-06T13:46:22Z","published":"2023-06-03T08:32:35Z","title":"Provable Dynamic Fusion for Low-Quality Multimodal Data","summary":"  The inherent challenge of multimodal fusion is to precisely capture the\ncross-modal correlation and flexibly conduct cross-modal interaction. To fully\nrelease the value of each modality and mitigate the influence of low-quality\nmultimodal data, dynamic multimodal fusion emerges as a promising learning\nparadigm. Despite its widespread use, theoretical justifications in this field\nare still notably lacking. Can we design a provably robust multimodal fusion\nmethod? This paper provides theoretical understandings to answer this question\nunder a most popular multimodal fusion framework from the generalization\nperspective. We proceed to reveal that several uncertainty estimation solutions\nare naturally available to achieve robust multimodal fusion. Then a novel\nmultimodal fusion framework termed Quality-aware Multimodal Fusion (QMF) is\nproposed, which can improve the performance in terms of classification accuracy\nand model robustness. Extensive experimental results on multiple benchmarks can\nsupport our findings.\n","authors":["Qingyang Zhang","Haitao Wu","Changqing Zhang","Qinghua Hu","Huazhu Fu","Joey Tianyi Zhou","Xi Peng"],"pdf_url":"https://arxiv.org/pdf/2306.02050v2.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.03680v1","updated":"2023-06-06T13:43:09Z","published":"2023-06-06T13:43:09Z","title":"Mildly Constrained Evaluation Policy for Offline Reinforcement Learning","summary":"  Offline reinforcement learning (RL) methodologies enforce constraints on the\npolicy to adhere closely to the behavior policy, thereby stabilizing value\nlearning and mitigating the selection of out-of-distribution (OOD) actions\nduring test time. Conventional approaches apply identical constraints for both\nvalue learning and test time inference. However, our findings indicate that the\nconstraints suitable for value estimation may in fact be excessively\nrestrictive for action selection during test time. To address this issue, we\npropose a Mildly Constrained Evaluation Policy (MCEP) for test time inference\nwith a more constrained target policy for value estimation. Since the target\npolicy has been adopted in various prior approaches, MCEP can be seamlessly\nintegrated with them as a plug-in. We instantiate MCEP based on TD3-BC\n[Fujimoto and Gu, 2021] and AWAC [Nair et al., 2020] algorithms. The empirical\nresults on MuJoCo locomotion tasks show that the MCEP significantly outperforms\nthe target policy and achieves competitive results to state-of-the-art offline\nRL methods. The codes are open-sourced at https://github.com/egg-west/MCEP.git.\n","authors":["Linjie Xu","Zhengyao Jiang","Jinyu Wang","Lei Song","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2306.03680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03679v1","updated":"2023-06-06T13:41:37Z","published":"2023-06-06T13:41:37Z","title":"Human-imperceptible, Machine-recognizable Images","summary":"  Massive human-related data is collected to train neural networks for computer\nvision tasks. A major conflict is exposed relating to software engineers\nbetween better developing AI systems and distancing from the sensitive training\ndata. To reconcile this conflict, this paper proposes an efficient\nprivacy-preserving learning paradigm, where images are first encrypted to\nbecome ``human-imperceptible, machine-recognizable'' via one of the two\nencryption strategies: (1) random shuffling to a set of equally-sized patches\nand (2) mixing-up sub-patches of the images. Then, minimal adaptations are made\nto vision transformer to enable it to learn on the encrypted images for vision\ntasks, including image classification and object detection. Extensive\nexperiments on ImageNet and COCO show that the proposed paradigm achieves\ncomparable accuracy with the competitive methods. Decrypting the encrypted\nimages requires solving an NP-hard jigsaw puzzle or an ill-posed inverse\nproblem, which is empirically shown intractable to be recovered by various\nattackers, including the powerful vision transformer-based attacker. We thus\nshow that the proposed paradigm can ensure the encrypted images have become\nhuman-imperceptible while preserving machine-recognizable information. The code\nis available at \\url{https://github.com/FushengHao/PrivacyPreservingML.}\n","authors":["Fusheng Hao","Fengxiang He","Yikai Wang","Fuxiang Wu","Jing Zhang","Jun Cheng","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.03679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.11355v2","updated":"2023-06-06T13:39:49Z","published":"2022-09-23T00:35:22Z","title":"Learning to predict 3D rotational dynamics from images of a rigid body\n  with unknown mass distribution","summary":"  In many real-world settings, image observations of freely rotating 3D rigid\nbodies, may be available when low-dimensional measurements are not. However,\nthe high-dimensionality of image data precludes the use of classical estimation\ntechniques to learn the dynamics. The usefulness of standard deep learning\nmethods is also limited because an image of a rigid body reveals nothing about\nthe distribution of mass inside the body, which, together with initial angular\nvelocity, is what determines how the body will rotate. We present a\nphysics-informed neural network model to estimate and predict 3D rotational\ndynamics from image sequences. We achieve this using a multi-stage prediction\npipeline that maps individual images to a latent representation homeomorphic to\n$\\mathbf{SO}(3)$, computes angular velocities from latent pairs, and predicts\nfuture latent states using the Hamiltonian equations of motion. We demonstrate\nthe efficacy of our approach on new rotating rigid-body datasets of sequences\nof synthetic images of rotating objects, including cubes, prisms and\nsatellites, with unknown uniform and non-uniform mass distributions.\n","authors":["Justice Mason","Christine Allen-Blanchette","Nicholas Zolman","Elizabeth Davison","Naomi Leonard"],"pdf_url":"https://arxiv.org/pdf/2209.11355v2.pdf","comment":"21 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.08059v2","updated":"2023-06-06T13:35:42Z","published":"2023-03-14T16:51:14Z","title":"Fast Rates for Maximum Entropy Exploration","summary":"  We address the challenge of exploration in reinforcement learning (RL) when\nthe agent operates in an unknown environment with sparse or no rewards. In this\nwork, we study the maximum entropy exploration problem of two different types.\nThe first type is visitation entropy maximization previously considered by\nHazan et al.(2019) in the discounted setting. For this type of exploration, we\npropose a game-theoretic algorithm that has\n$\\widetilde{\\mathcal{O}}(H^3S^2A/\\varepsilon^2)$ sample complexity thus\nimproving the $\\varepsilon$-dependence upon existing results, where $S$ is a\nnumber of states, $A$ is a number of actions, $H$ is an episode length, and\n$\\varepsilon$ is a desired accuracy. The second type of entropy we study is the\ntrajectory entropy. This objective function is closely related to the\nentropy-regularized MDPs, and we propose a simple algorithm that has a sample\ncomplexity of order\n$\\widetilde{\\mathcal{O}}(\\mathrm{poly}(S,A,H)/\\varepsilon)$. Interestingly, it\nis the first theoretical result in RL literature that establishes the potential\nstatistical advantage of regularized MDPs for exploration. Finally, we apply\ndeveloped regularization techniques to reduce sample complexity of visitation\nentropy maximization to $\\widetilde{\\mathcal{O}}(H^2SA/\\varepsilon^2)$,\nyielding a statistical separation between maximum entropy exploration and\nreward-free exploration.\n","authors":["Daniil Tiapkin","Denis Belomestny","Daniele Calandriello","Eric Moulines","Remi Munos","Alexey Naumov","Pierre Perrault","Yunhao Tang","Michal Valko","Pierre Menard"],"pdf_url":"https://arxiv.org/pdf/2303.08059v2.pdf","comment":"ICML-2023"},{"id":"http://arxiv.org/abs/2305.11509v3","updated":"2023-06-06T13:28:39Z","published":"2023-05-19T08:18:49Z","title":"From Random Search to Bandit Learning in Metric Measure Spaces","summary":"  Random Search is one of the most widely-used method for Hyperparameter\nOptimization, and is critical to the success of deep learning models. Despite\nits astonishing performance, little non-heuristic theory has been developed to\ndescribe the underlying working mechanism. This paper gives a theoretical\naccounting of Random Search. We introduce the concept of \\emph{scattering\ndimension} that describes the landscape of the underlying function, and\nquantifies the performance of random search. We show that, when the environment\nis noise-free, the output of random search converges to the optimal value in\nprobability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left( \\frac{1}{T}\n\\right)^{ \\frac{1}{d_s} } \\right) $, where $ d_s \\ge 0 $ is the scattering\ndimension of the underlying function. When the observed function values are\ncorrupted by bounded $iid$ noise, the output of random search converges to the\noptimal value in probability at rate $ \\widetilde{\\mathcal{O}} \\left( \\left(\n\\frac{1}{T} \\right)^{ \\frac{1}{d_s + 1} } \\right) $. In addition, based on the\nprinciples of random search, we introduce an algorithm, called BLiN-MOS, for\nLipschitz bandits in doubling metric spaces that are also endowed with a Borel\nmeasure, and show that BLiN-MOS achieves a regret rate of order $\n\\widetilde{\\mathcal{O}} \\left( T^{ \\frac{d_z}{d_z + 1} } \\right) $, where $d_z$\nis the zooming dimension of the problem instance. Our results show that under\ncertain conditions, the known information-theoretical lower bounds for\nLipschitz bandits $\\Omega \\left( T^{\\frac{d_z+1}{d_z+2}} \\right)$ can be\nimproved.\n","authors":["Chuying Han","Yasong Feng","Tianyu Wang"],"pdf_url":"https://arxiv.org/pdf/2305.11509v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03659v1","updated":"2023-06-06T13:22:54Z","published":"2023-06-06T13:22:54Z","title":"Schema First! Learn Versatile Knowledge Graph Embeddings by Capturing\n  Semantics with MASCHInE","summary":"  Knowledge graph embedding models (KGEMs) have gained considerable traction in\nrecent years. These models learn a vector representation of knowledge graph\nentities and relations, a.k.a. knowledge graph embeddings (KGEs). Learning\nversatile KGEs is desirable as it makes them useful for a broad range of tasks.\nHowever, KGEMs are usually trained for a specific task, which makes their\nembeddings task-dependent. In parallel, the widespread assumption that KGEMs\nactually create a semantic representation of the underlying entities and\nrelations (e.g., project similar entities closer than dissimilar ones) has been\nchallenged. In this work, we design heuristics for generating protographs --\nsmall, modified versions of a KG that leverage schema-based information. The\nlearnt protograph-based embeddings are meant to encapsulate the semantics of a\nKG, and can be leveraged in learning KGEs that, in turn, also better capture\nsemantics. Extensive experiments on various evaluation benchmarks demonstrate\nthe soundness of this approach, which we call Modular and Agnostic SCHema-based\nIntegration of protograph Embeddings (MASCHInE). In particular, MASCHInE helps\nproduce more versatile KGEs that yield substantially better performance for\nentity clustering and node classification tasks. For link prediction, using\nMASCHInE has little impact on rank-based performance but increases the number\nof semantically valid predictions.\n","authors":["Nicolas Hubert","Heiko Paulheim","Pierre Monnin","Armelle Brun","Davy Monticolo"],"pdf_url":"https://arxiv.org/pdf/2306.03659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07580v2","updated":"2023-06-06T13:20:34Z","published":"2023-05-12T16:15:30Z","title":"Fisher Information Embedding for Node and Graph Learning","summary":"  Attention-based graph neural networks (GNNs), such as graph attention\nnetworks (GATs), have become popular neural architectures for processing\ngraph-structured data and learning node embeddings. Despite their empirical\nsuccess, these models rely on labeled data and the theoretical properties of\nthese models have yet to be fully understood. In this work, we propose a novel\nattention-based node embedding framework for graphs. Our framework builds upon\na hierarchical kernel for multisets of subgraphs around nodes (e.g.\nneighborhoods) and each kernel leverages the geometry of a smooth statistical\nmanifold to compare pairs of multisets, by \"projecting\" the multisets onto the\nmanifold. By explicitly computing node embeddings with a manifold of Gaussian\nmixtures, our method leads to a new attention mechanism for neighborhood\naggregation. We provide theoretical insights into generalizability and\nexpressivity of our embeddings, contributing to a deeper understanding of\nattention-based GNNs. We propose both efficient unsupervised and supervised\nmethods for learning the embeddings. Through experiments on several node\nclassification benchmarks, we demonstrate that our proposed method outperforms\nexisting attention-based graph models like GATs. Our code is available at\nhttps://github.com/BorgwardtLab/fisher_information_embedding.\n","authors":["Dexiong Chen","Paolo Pellizzoni","Karsten Borgwardt"],"pdf_url":"https://arxiv.org/pdf/2305.07580v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.00390v2","updated":"2023-06-06T13:18:50Z","published":"2023-06-01T06:50:47Z","title":"Learning Gaussian Mixture Representations for Tensor Time Series\n  Forecasting","summary":"  Tensor time series (TTS) data, a generalization of one-dimensional time\nseries on a high-dimensional space, is ubiquitous in real-world scenarios,\nespecially in monitoring systems involving multi-source spatio-temporal data\n(e.g., transportation demands and air pollutants). Compared to modeling time\nseries or multivariate time series, which has received much attention and\nachieved tremendous progress in recent years, tensor time series has been paid\nless effort. Properly coping with the tensor time series is a much more\nchallenging task, due to its high-dimensional and complex inner structure. In\nthis paper, we develop a novel TTS forecasting framework, which seeks to\nindividually model each heterogeneity component implied in the time, the\nlocation, and the source variables. We name this framework as GMRL, short for\nGaussian Mixture Representation Learning. Experiment results on two real-world\nTTS datasets verify the superiority of our approach compared with the\nstate-of-the-art baselines. Code and data are published on\nhttps://github.com/beginner-sketch/GMRL.\n","authors":["Jiewen Deng","Jinliang Deng","Renhe Jiang","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2306.00390v2.pdf","comment":"Accepted by IJCAI 2023 Main Track"},{"id":"http://arxiv.org/abs/2306.03655v1","updated":"2023-06-06T13:15:01Z","published":"2023-06-06T13:15:01Z","title":"Online Learning under Adversarial Nonlinear Constraints","summary":"  In many applications, learning systems are required to process continuous\nnon-stationary data streams. We study this problem in an online learning\nframework and propose an algorithm that can deal with adversarial time-varying\nand nonlinear constraints. As we show in our work, the algorithm called\nConstraint Violation Velocity Projection (CVV-Pro) achieves $\\sqrt{T}$ regret\nand converges to the feasible set at a rate of $1/\\sqrt{T}$, despite the fact\nthat the feasible set is slowly time-varying and a priori unknown to the\nlearner. CVV-Pro only relies on local sparse linear approximations of the\nfeasible set and therefore avoids optimizing over the entire set at each\niteration, which is in sharp contrast to projected gradients or Frank-Wolfe\nmethods. We also empirically evaluate our algorithm on two-player games, where\nthe players are subjected to a shared constraint.\n","authors":["Pavel Kolev","Georg Martius","Michael Muehlebach"],"pdf_url":"https://arxiv.org/pdf/2306.03655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08215v2","updated":"2023-06-06T13:09:21Z","published":"2023-02-16T10:59:39Z","title":"Aligning Language Models with Preferences through f-divergence\n  Minimization","summary":"  Aligning language models with preferences can be posed as approximating a\ntarget distribution representing some desired behavior. Existing approaches\ndiffer both in the functional form of the target distribution and the algorithm\nused to approximate it. For instance, Reinforcement Learning from Human\nFeedback (RLHF) corresponds to minimizing a reverse KL from an implicit target\ndistribution arising from a KL penalty in the objective. On the other hand,\nGenerative Distributional Control (GDC) has an explicit target distribution and\nminimizes a forward KL from it using the Distributional Policy Gradient (DPG)\nalgorithm. In this paper, we propose a new approach, f-DPG, which allows the\nuse of any f-divergence to approximate any target distribution that can be\nevaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation\nmethods (DPG, RL with KL penalties). We show the practical benefits of various\nchoices of divergence objectives and demonstrate that there is no universally\noptimal objective but that different divergences present different alignment\nand diversity trade-offs. We show that Jensen-Shannon divergence strikes a good\nbalance between these objectives, and frequently outperforms forward KL\ndivergence by a wide margin, leading to significant improvements over prior\nwork. These distinguishing characteristics between divergences persist as the\nmodel size increases, highlighting the importance of selecting appropriate\ndivergence objectives.\n","authors":["Dongyoung Go","Tomasz Korbak","Germán Kruszewski","Jos Rozen","Nahyeon Ryu","Marc Dymetman"],"pdf_url":"https://arxiv.org/pdf/2302.08215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.12067v2","updated":"2023-06-06T13:08:55Z","published":"2022-07-25T11:22:48Z","title":"Homomorphism Autoencoder -- Learning Group Structured Representations\n  from Observed Transitions","summary":"  How can agents learn internal models that veridically represent interactions\nwith the real world is a largely open question. As machine learning is moving\ntowards representations containing not just observational but also\ninterventional knowledge, we study this problem using tools from representation\nlearning and group theory. We propose methods enabling an agent acting upon the\nworld to learn internal representations of sensory information that are\nconsistent with actions that modify it. We use an autoencoder equipped with a\ngroup representation acting on its latent space, trained using an\nequivariance-derived loss in order to enforce a suitable homomorphism property\non the group representation. In contrast to existing work, our approach does\nnot require prior knowledge of the group and does not restrict the set of\nactions the agent can perform. We motivate our method theoretically, and show\nempirically that it can learn a group representation of the actions, thereby\ncapturing the structure of the set of transformations applied to the\nenvironment. We further show that this allows agents to predict the effect of\nsequences of future actions with improved accuracy.\n","authors":["Hamza Keurti","Hsiao-Ru Pan","Michel Besserve","Benjamin F. Grewe","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2207.12067v2.pdf","comment":"ICML2023, 26 pages, 17 figures"},{"id":"http://arxiv.org/abs/2306.03648v1","updated":"2023-06-06T13:04:05Z","published":"2023-06-06T13:04:05Z","title":"Supervised Knowledge May Hurt Novel Class Discovery Performance","summary":"  Novel class discovery (NCD) aims to infer novel categories in an unlabeled\ndataset by leveraging prior knowledge of a labeled set comprising disjoint but\nrelated classes. Given that most existing literature focuses primarily on\nutilizing supervised knowledge from a labeled set at the methodology level,\nthis paper considers the question: Is supervised knowledge always helpful at\ndifferent levels of semantic relevance? To proceed, we first establish a novel\nmetric, so-called transfer flow, to measure the semantic similarity between\nlabeled/unlabeled datasets. To show the validity of the proposed metric, we\nbuild up a large-scale benchmark with various degrees of semantic similarities\nbetween labeled/unlabeled datasets on ImageNet by leveraging its hierarchical\nclass structure. The results based on the proposed benchmark show that the\nproposed transfer flow is in line with the hierarchical class structure; and\nthat NCD performance is consistent with the semantic similarities (measured by\nthe proposed metric). Next, by using the proposed transfer flow, we conduct\nvarious empirical experiments with different levels of semantic similarity,\nyielding that supervised knowledge may hurt NCD performance. Specifically,\nusing supervised information from a low-similarity labeled set may lead to a\nsuboptimal result as compared to using pure self-supervised knowledge. These\nresults reveal the inadequacy of the existing NCD literature which usually\nassumes that supervised knowledge is beneficial. Finally, we develop a\npseudo-version of the transfer flow as a practical reference to decide if\nsupervised knowledge should be used in NCD. Its effectiveness is supported by\nour empirical studies, which show that the pseudo transfer flow (with or\nwithout supervised knowledge) is consistent with the corresponding accuracy\nbased on various datasets. Code is released at\nhttps://github.com/J-L-O/SK-Hurt-NCD\n","authors":["Ziyun Li","Jona Otholt","Ben Dai","Di Hu","Christoph Meinel","Haojin Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03648v1.pdf","comment":"TMLR 2023 accepted paper. arXiv admin note: substantial text overlap\n  with arXiv:2209.09120"},{"id":"http://arxiv.org/abs/2306.03647v1","updated":"2023-06-06T13:03:24Z","published":"2023-06-06T13:03:24Z","title":"Proximal Symmetric Non-negative Latent Factor Analysis: A Novel Approach\n  to Highly-Accurate Representation of Undirected Weighted Networks","summary":"  An Undirected Weighted Network (UWN) is commonly found in big data-related\napplications. Note that such a network's information connected with its nodes,\nand edges can be expressed as a Symmetric, High-Dimensional and Incomplete\n(SHDI) matrix. However, existing models fail in either modeling its intrinsic\nsymmetry or low-data density, resulting in low model scalability or\nrepresentation learning ability. For addressing this issue, a Proximal\nSymmetric Nonnegative Latent-factor-analysis (PSNL) model is proposed. It\nincorporates a proximal term into symmetry-aware and data density-oriented\nobjective function for high representation accuracy. Then an adaptive\nAlternating Direction Method of Multipliers (ADMM)-based learning scheme is\nimplemented through a Tree-structured of Parzen Estimators (TPE) method for\nhigh computational efficiency. Empirical studies on four UWNs demonstrate that\nPSNL achieves higher accuracy gain than state-of-the-art models, as well as\nhighly competitive computational efficiency.\n","authors":["Yurong Zhong","Zhe Xie","Weiling Li","Xin Luo"],"pdf_url":"https://arxiv.org/pdf/2306.03647v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.11640v2","updated":"2023-06-06T13:01:29Z","published":"2023-05-19T12:44:34Z","title":"Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern","summary":"  This paper studies the open problem of conformalized entry prediction in a\nrow/column-exchangeable matrix. The matrix setting presents novel and unique\nchallenges, but there exists little work on this interesting topic. We\nmeticulously define the problem, differentiate it from closely related\nproblems, and rigorously delineate the boundary between achievable and\nimpossible goals. We then propose two practical algorithms. The first method\nprovides a fast emulation of the full conformal prediction, while the second\nmethod leverages the technique of algorithmic stability for acceleration. Both\nmethods are computationally efficient and can effectively safeguard coverage\nvalidity in presence of arbitrary missing pattern. Further, we quantify the\nimpact of missingness on prediction accuracy and establish fundamental limit\nresults. Empirical evidence from synthetic and real-world data sets\ncorroborates the superior performance of our proposed methods.\n","authors":["Meijia Shao","Yuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.11640v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.03646v1","updated":"2023-06-06T13:00:47Z","published":"2023-06-06T13:00:47Z","title":"Dance Generation by Sound Symbolic Words","summary":"  This study introduces a novel approach to generate dance motions using\nonomatopoeia as input, with the aim of enhancing creativity and diversity in\ndance generation. Unlike text and music, onomatopoeia conveys rhythm and\nmeaning through abstract word expressions without constraints on expression and\nwithout need for specialized knowledge. We adapt the AI Choreographer framework\nand employ the Sakamoto system, a feature extraction method for onomatopoeia\nfocusing on phonemes and syllables. Additionally, we present a new dataset of\n40 onomatopoeia-dance motion pairs collected through a user survey. Our results\ndemonstrate that the proposed method enables more intuitive dance generation\nand can create dance motions using sound-symbolic words from a variety of\nlanguages, including those without onomatopoeia. This highlights the potential\nfor diverse dance creation across different languages and cultures, accessible\nto a wider audience. Qualitative samples from our model can be found at:\nhttps://sites.google.com/view/onomatopoeia-dance/home/.\n","authors":["Miki Okamura","Naruya Kondo","Tatsuki Fushimi Maki Sakamoto","Yoichi Ochiai"],"pdf_url":"https://arxiv.org/pdf/2306.03646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04285v3","updated":"2023-06-06T12:38:45Z","published":"2022-06-09T05:33:02Z","title":"A Unification Framework for Euclidean and Hyperbolic Graph Neural\n  Networks","summary":"  Hyperbolic neural networks can effectively capture the inherent hierarchy of\ngraph datasets, and consequently a powerful choice of GNNs. However, they\nentangle multiple incongruent (gyro-)vector spaces within a layer, which makes\nthem limited in terms of generalization and scalability. In this work, we\npropose the Poincare disk model as our search space, and apply all\napproximations on the disk (as if the disk is a tangent space derived from the\norigin), thus getting rid of all inter-space transformations. Such an approach\nenables us to propose a hyperbolic normalization layer and to further simplify\nthe entire hyperbolic model to a Euclidean model cascaded with our hyperbolic\nnormalization layer. We applied our proposed nonlinear hyperbolic normalization\nto the current state-of-the-art homogeneous and multi-relational graph\nnetworks. We demonstrate that our model not only leverages the power of\nEuclidean networks such as interpretability and efficient execution of various\nmodel components, but also outperforms both Euclidean and hyperbolic\ncounterparts on various benchmarks. Our code is made publicly available at\nhttps://github.com/oom-debugger/ijcai23.\n","authors":["Mehrdad Khatir","Nurendra Choudhary","Sutanay Choudhury","Khushbu Agarwal","Chandan K. Reddy"],"pdf_url":"https://arxiv.org/pdf/2206.04285v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03626v1","updated":"2023-06-06T12:27:54Z","published":"2023-06-06T12:27:54Z","title":"Understanding Progressive Training Through the Framework of Randomized\n  Coordinate Descent","summary":"  We propose a Randomized Progressive Training algorithm (RPT) -- a stochastic\nproxy for the well-known Progressive Training method (PT) (Karras et al.,\n2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was\nproposed as a heuristic, with no convergence analysis even for the simplest\nobjective functions. On the contrary, to the best of our knowledge, RPT is the\nfirst PT-type algorithm with rigorous and sound theoretical guarantees for\ngeneral smooth objective functions. We cast our method into the established\nframework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richt\\'arik &\nTak\\'a\\v{c}, 2014), for which (as a by-product of our investigations) we also\npropose a novel, simple and general convergence analysis encapsulating\nstrongly-convex, convex and nonconvex objectives. We then use this framework to\nestablish a convergence theory for RPT. Finally, we validate the effectiveness\nof our method through extensive computational experiments.\n","authors":["Rafał Szlendak","Elnur Gasanov","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2306.03626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03625v1","updated":"2023-06-06T12:22:20Z","published":"2023-06-06T12:22:20Z","title":"Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy\n  Learning","summary":"  We propose a simple and general framework for nonparametric estimation of\nheterogeneous treatment effects under fairness constraints. Under standard\nregularity conditions, we show that the resulting estimators possess the double\nrobustness property. We use this framework to characterize the trade-off\nbetween fairness and the maximum welfare achievable by the optimal policy. We\nevaluate the methods in a simulation study and illustrate them in a real-world\ncase study.\n","authors":["Kwangho Kim","José R. Zubizarreta"],"pdf_url":"https://arxiv.org/pdf/2306.03625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.00169v2","updated":"2023-06-06T12:20:23Z","published":"2023-04-29T04:42:44Z","title":"An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on\n  Broad Learning System","summary":"  Fault diagnosis is a crucial area of research in industry. Industrial\nprocesses exhibit diverse operating conditions, where data often have\nnon-Gaussian, multi-mode, and center-drift characteristics. Data-driven\napproaches are currently the main focus in the field, but continuous fault\nclassification and parameter updates of fault classifiers pose challenges for\nmultiple operating modes and real-time settings. Thus, a pressing issue is to\nachieve real-time multi-mode fault diagnosis in industrial systems. In this\npaper, a novel approach to achieve real-time multi-mode fault diagnosis is\nproposed for industrial applications, which addresses this critical research\nproblem. Our approach uses an extended evidence reasoning (ER) algorithm to\nfuse information and merge outputs from different base classifiers. These base\nclassifiers based on broad learning system (BLS) are trained to ensure maximum\nfault diagnosis accuracy. Furthermore, pseudo-label learning is used to update\nmodel parameters in real-time. The effectiveness of the proposed approach is\ndemonstrated on the multi-mode Tennessee Eastman process dataset.\n","authors":["Chen Li","Zeyi Liu","Limin Wang","Minyue Li","Xiao He"],"pdf_url":"https://arxiv.org/pdf/2305.00169v2.pdf","comment":"6 pages, 11 figures, Accepted by the 34th Chinese Process Control\n  Conference"},{"id":"http://arxiv.org/abs/2306.03623v1","updated":"2023-06-06T12:19:12Z","published":"2023-06-06T12:19:12Z","title":"Spike-based computation using classical recurrent neural networks","summary":"  Spiking neural networks are a type of artificial neural networks in which\ncommunication between neurons is only made of events, also called spikes. This\nproperty allows neural networks to make asynchronous and sparse computations\nand therefore to drastically decrease energy consumption when run on\nspecialized hardware. However, training such networks is known to be difficult,\nmainly due to the non-differentiability of the spike activation, which prevents\nthe use of classical backpropagation. This is because state-of-the-art spiking\nneural networks are usually derived from biologically-inspired neuron models,\nto which are applied machine learning methods for training. Nowadays, research\nabout spiking neural networks focuses on the design of training algorithms\nwhose goal is to obtain networks that compete with their non-spiking version on\nspecific tasks. In this paper, we attempt the symmetrical approach: we modify\nthe dynamics of a well-known, easily trainable type of recurrent neural network\nto make it event-based. This new RNN cell, called the Spiking Recurrent Cell,\ntherefore communicates using events, i.e. spikes, while being completely\ndifferentiable. Vanilla backpropagation can thus be used to train any network\nmade of such RNN cell. We show that this new network can achieve performance\ncomparable to other types of spiking networks in the MNIST benchmark and its\nvariants, the Fashion-MNIST and the Neuromorphic-MNIST. Moreover, we show that\nthis new cell makes the training of deep spiking networks achievable.\n","authors":["Florent De Geeter","Damien Ernst","Guillaume Drion"],"pdf_url":"https://arxiv.org/pdf/2306.03623v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.11355v3","updated":"2023-06-06T12:13:33Z","published":"2023-01-26T19:07:40Z","title":"Rigid body flows for sampling molecular crystal structures","summary":"  Normalizing flows (NF) are a class of powerful generative models that have\ngained popularity in recent years due to their ability to model complex\ndistributions with high flexibility and expressiveness. In this work, we\nintroduce a new type of normalizing flow that is tailored for modeling\npositions and orientations of multiple objects in three-dimensional space, such\nas molecules in a crystal. Our approach is based on two key ideas: first, we\ndefine smooth and expressive flows on the group of unit quaternions, which\nallows us to capture the continuous rotational motion of rigid bodies; second,\nwe use the double cover property of unit quaternions to define a proper density\non the rotation group. This ensures that our model can be trained using\nstandard likelihood-based methods or variational inference with respect to a\nthermodynamic target density. We evaluate the method by training Boltzmann\ngenerators for two molecular examples, namely the multi-modal density of a\ntetrahedral system in an external field and the ice XI phase in the TIP4P water\nmodel. Our flows can be combined with flows operating on the internal degrees\nof freedom of molecules, and constitute an important step towards the modeling\nof distributions of many interacting molecules.\n","authors":["Jonas Köhler","Michele Invernizzi","Pim de Haan","Frank Noé"],"pdf_url":"https://arxiv.org/pdf/2301.11355v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01692v3","updated":"2023-06-06T12:09:47Z","published":"2022-12-03T21:14:32Z","title":"Can In-context Learners Learn a Reasoning Concept from Demonstrations?","summary":"  Large language models show an emergent ability to learn a new task from a\nsmall number of input-output demonstrations. However, recent work shows that\nin-context learners largely rely on their pre-trained knowledge, such as the\nsentiment of the labels, instead of finding new associations in the input.\nHowever, the commonly-used few-shot evaluation settings using a random\nselection of in-context demonstrations can not disentangle models' ability to\nlearn a new skill from demonstrations, as most of the randomly-selected\ndemonstrations do not present relations informative for prediction beyond\nexposing the new task distribution.\n  To disentangle models' in-context learning ability independent of models'\nmemory, we introduce a Conceptual few-shot learning method selecting the\ndemonstrations sharing a possibly-informative concept with the predicted\nsample. We extract a set of such concepts from annotated explanations and\nmeasure how much can models benefit from presenting these concepts in few-shot\ndemonstrations.\n  We find that smaller models are more sensitive to the presented concepts.\nWhile some of the models are able to benefit from concept-presenting\ndemonstrations for each assessed concept, we find that none of the assessed\nin-context learners can benefit from all presented reasoning concepts\nconsistently, leaving the in-context concept learning an open challenge.\n","authors":["Michal Štefánik","Marek Kadlčík"],"pdf_url":"https://arxiv.org/pdf/2212.01692v3.pdf","comment":"Accepted at ACL 2023 Natural Language Reasoning workshop"},{"id":"http://arxiv.org/abs/2306.03615v1","updated":"2023-06-06T12:07:50Z","published":"2023-06-06T12:07:50Z","title":"Zero-shot Preference Learning for Offline RL via Optimal Transport","summary":"  Preference-based Reinforcement Learning (PbRL) has demonstrated remarkable\nefficacy in aligning rewards with human intentions. However, a significant\nchallenge lies in the need of substantial human labels, which is costly and\ntime-consuming. Additionally, the expensive preference data obtained from prior\ntasks is not typically reusable for subsequent task learning, leading to\nextensive labeling for each new task. In this paper, we propose a novel\nzero-shot preference-based RL algorithm that leverages labeled preference data\nfrom source tasks to infer labels for target tasks, eliminating the requirement\nfor human queries. Our approach utilizes Gromov-Wasserstein distance to align\ntrajectory distributions between source and target tasks. The solved optimal\ntransport matrix serves as a correspondence between trajectories of two tasks,\nmaking it possible to identify corresponding trajectory pairs between tasks and\ntransfer the preference labels. However, learning directly from inferred labels\nthat contains a fraction of noisy labels will result in an inaccurate reward\nfunction, subsequently affecting policy performance. To this end, we introduce\nRobust Preference Transformer, which models the rewards as Gaussian\ndistributions and incorporates reward uncertainty in addition to reward mean.\nThe empirical results on robotic manipulation tasks of Meta-World and Robomimic\nshow that our method has strong capabilities of transferring preferences\nbetween tasks and learns reward functions from noisy labels robustly.\nFurthermore, we reveal that our method attains near-oracle performance with a\nsmall proportion of scripted labels.\n","authors":["Runze Liu","Yali Du","Fengshuo Bai","Jiafei Lyu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2306.03615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02685v2","updated":"2023-06-06T12:06:03Z","published":"2023-06-05T08:22:18Z","title":"Predicting malaria dynamics in Burundi using deep Learning Models","summary":"  Malaria continues to be a major public health problem on the African\ncontinent, particularly in Sub-Saharan Africa. Nonetheless, efforts are\nongoing, and significant progress has been made. In Burundi, malaria is among\nthe main public health concerns. In the literature, there are limited\nprediction models for Burundi. We know that such tools are much needed for\ninterventions design. In our study, we built machine-learning based models to\nestimates malaria cases in Burundi. The forecast of malaria cases was carried\nout at province level and national scale as well. Long short term memory (LSTM)\nmodel, a type of deep learning model has been used to achieve best results\nusing climate-change related factors such as temperature, rainfal, and relative\nhumidity, together with malaria historical data and human population. With this\nmodel, the results showed that at country level different tuning of parameters\ncan be used in order to determine the minimum and maximum expected malaria\ncases. The univariate version of that model (LSTM) which learns from previous\ndynamics of malaria cases give more precise estimates at province-level, but\nboth models have same trends overall at provnce-level and country-level\n","authors":["Daxelle Sakubu","Kelly Joelle Gatore Sinigirira","David Niyukuri"],"pdf_url":"https://arxiv.org/pdf/2306.02685v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01513v3","updated":"2023-06-06T12:02:18Z","published":"2023-03-02T17:27:45Z","title":"Safe AI for health and beyond -- Monitoring to transform a health\n  service","summary":"  Machine learning techniques are effective for building predictive models\nbecause they identify patterns in large datasets. Development of a model for\ncomplex real-life problems often stop at the point of publication, proof of\nconcept or when made accessible through some mode of deployment. However, a\nmodel in the medical domain risks becoming obsolete as patient demographics,\nsystems and clinical practices change. The maintenance and monitoring of\npredictive model performance post-publication is crucial to enable their safe\nand effective long-term use. We will assess the infrastructure required to\nmonitor the outputs of a machine learning algorithm, and present two scenarios\nwith examples of monitoring and updates of models, firstly on a breast cancer\nprognosis model trained on public longitudinal data, and secondly on a\nneurodegenerative stratification algorithm that is currently being developed\nand tested in clinic.\n","authors":["Mahed Abroshan","Michael Burkhart","Oscar Giles","Sam Greenbury","Zoe Kourtzi","Jack Roberts","Mihaela van der Schaar","Jannetta S Steyn","Alan Wilson","May Yong"],"pdf_url":"https://arxiv.org/pdf/2303.01513v3.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2304.06653v3","updated":"2023-06-06T11:56:27Z","published":"2023-04-13T16:28:07Z","title":"Graph2topic: an opensource topic modeling framework based on sentence\n  embedding and community detection","summary":"  It has been reported that clustering-based topic models, which cluster\nhigh-quality sentence embeddings with an appropriate word selection method, can\ngenerate better topics than generative probabilistic topic models. However,\nthese approaches suffer from the inability to select appropriate parameters and\nincomplete models that overlook the quantitative relation between words with\ntopics and topics with text. To solve these issues, we propose graph to topic\n(G2T), a simple but effective framework for topic modelling. The framework is\ncomposed of four modules. First, document representation is acquired using\npretrained language models. Second, a semantic graph is constructed according\nto the similarity between document representations. Third, communities in\ndocument semantic graphs are identified, and the relationship between topics\nand documents is quantified accordingly. Fourth, the word--topic distribution\nis computed based on a variant of TFIDF. Automatic evaluation suggests that G2T\nachieved state-of-the-art performance on both English and Chinese documents\nwith different lengths.\n","authors":["Leihang Zhang","Jiapeng Liu","Qiang Yan"],"pdf_url":"https://arxiv.org/pdf/2304.06653v3.pdf","comment":"11pages"},{"id":"http://arxiv.org/abs/2302.10586v2","updated":"2023-06-06T11:53:03Z","published":"2023-02-21T10:24:53Z","title":"Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few\n  Labels","summary":"  In an effort to further advance semi-supervised generative and classification\ntasks, we propose a simple yet effective training strategy called dual pseudo\ntraining (DPT), built upon strong semi-supervised learners and diffusion\nmodels. DPT operates in three stages: training a classifier on partially\nlabeled data to predict pseudo-labels; training a conditional generative model\nusing these pseudo-labels to generate pseudo images; and retraining the\nclassifier with a mix of real and pseudo images. Empirically, DPT consistently\nachieves SOTA performance of semi-supervised generation and classification\nacross various settings. In particular, with one or two labels per class, DPT\nachieves a Fr\\'echet Inception Distance (FID) score of 3.08 or 2.52 on ImageNet\n256x256, surpassing strong diffusion models with full labels, such as IDDPM,\nCDM, ADM, and LDM. Besides, DPT outperforms competitive semi-supervised\nbaselines substantially on ImageNet classification tasks, achieving top-1\naccuracies of 59.0 (+2.8), 69.5 (+3.0), and 74.4 (+2.0) with one, two, or five\nlabels per class, respectively. Notably, our results demonstrate that diffusion\ncan generate realistic images with only a few labels (e.g., <0.1%) and\ngenerative augmentation remains viable for semi-supervised classification.\n","authors":["Zebin You","Yong Zhong","Fan Bao","Jiacheng Sun","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.10586v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03607v1","updated":"2023-06-06T11:50:09Z","published":"2023-06-06T11:50:09Z","title":"Buying Information for Stochastic Optimization","summary":"  Stochastic optimization is one of the central problems in Machine Learning\nand Theoretical Computer Science. In the standard model, the algorithm is given\na fixed distribution known in advance. In practice though, one may acquire at a\ncost extra information to make better decisions. In this paper, we study how to\nbuy information for stochastic optimization and formulate this question as an\nonline learning problem. Assuming the learner has an oracle for the original\noptimization problem, we design a $2$-competitive deterministic algorithm and a\n$e/(e-1)$-competitive randomized algorithm for buying information. We show that\nthis ratio is tight as the problem is equivalent to a robust generalization of\nthe ski-rental problem, which we call super-martingale stopping.\n  We also consider an adaptive setting where the learner can choose to buy\ninformation after taking some actions for the underlying optimization problem.\nWe focus on the classic optimization problem, Min-Sum Set Cover, where the goal\nis to quickly find an action that covers a given request drawn from a known\ndistribution. We provide an $8$-competitive algorithm running in polynomial\ntime that chooses actions and decides when to buy information about the\nunderlying request.\n","authors":["Mingchen Ma","Christos Tzamos"],"pdf_url":"https://arxiv.org/pdf/2306.03607v1.pdf","comment":"To appear in ICML 2023"},{"id":"http://arxiv.org/abs/2306.03600v1","updated":"2023-06-06T11:44:42Z","published":"2023-06-06T11:44:42Z","title":"Avoid Adversarial Adaption in Federated Learning by Multi-Metric\n  Investigations","summary":"  Federated Learning (FL) trains machine learning models on data distributed\nacross multiple devices, avoiding data transfer to a central location. This\nimproves privacy, reduces communication costs, and enhances model performance.\nHowever, FL is prone to poisoning attacks, which can be untargeted aiming to\nreduce the model performance, or targeted, so-called backdoors, which add\nadversarial behavior that can be triggered with appropriately crafted inputs.\nStriving for stealthiness, backdoor attacks are harder to deal with.\n  Mitigation techniques against poisoning attacks rely on monitoring certain\nmetrics and filtering malicious model updates. However, previous works didn't\nconsider real-world adversaries and data distributions. To support our\nstatement, we define a new notion of strong adaptive adversaries that can\nsimultaneously adapt to multiple objectives and demonstrate through extensive\ntests, that existing defense methods can be circumvented in this adversary\nmodel. We also demonstrate, that existing defenses have limited effectiveness\nwhen no assumptions are made about underlying data distributions.\n  To address realistic scenarios and adversary models, we propose\nMetric-Cascades (MESAS) a new defense that leverages multiple detection metrics\nsimultaneously for the filtering of poisoned model updates. This approach\nforces adaptive attackers into a heavy multi-objective optimization problem,\nand our evaluation with nine backdoors and three datasets shows that even our\nstrong adaptive attacker cannot evade MESAS's detection. We show that MESAS\noutperforms existing defenses in distinguishing backdoors from distortions\noriginating from different data distributions within and across the clients.\nOverall, MESAS is the first defense that is robust against strong adaptive\nadversaries and is effective in real-world data scenarios while introducing a\nlow overhead of 24.37s on average.\n","authors":["Torsten Krauß","Alexandra Dmitrienko"],"pdf_url":"https://arxiv.org/pdf/2306.03600v1.pdf","comment":"23 pages, 12 figures, 27 tables, 11 equations"},{"id":"http://arxiv.org/abs/2211.17223v3","updated":"2023-06-06T11:25:34Z","published":"2022-11-30T18:22:37Z","title":"Topological Data Analysis for Speech Processing","summary":"  We apply topological data analysis (TDA) to speech classification problems\nand to the introspection of a pretrained speech model, HuBERT. To this end, we\nintroduce a number of topological and algebraic features derived from\nTransformer attention maps and embeddings. We show that a simple linear\nclassifier built on top of such features outperforms a fine-tuned\nclassification head. In particular, we achieve an improvement of about $9\\%$\naccuracy and $5\\%$ ERR on four common datasets; on CREMA-D, the proposed\nfeature set reaches a new state of the art performance with accuracy $80.155$.\nWe also show that topological features are able to reveal functional roles of\nspeech Transformer heads; e.g., we find the heads capable to distinguish\nbetween pairs of sample sources (natural/synthetic) or voices without any\ndownstream fine-tuning. Our results demonstrate that TDA is a promising new\napproach for speech analysis, especially for tasks that require structural\nprediction. Appendices, an introduction to TDA, and other additional materials\nare available here - https://topohubert.github.io/speech-topology-webpages/\n","authors":["Eduard Tulchinskii","Kristian Kuznetsov","Laida Kushnareva","Daniil Cherniavskii","Serguei Barannikov","Irina Piontkovskaya","Sergey Nikolenko","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2211.17223v3.pdf","comment":"Accepted to INTERSPEECH 2023 conference"},{"id":"http://arxiv.org/abs/2306.03589v1","updated":"2023-06-06T11:15:53Z","published":"2023-06-06T11:15:53Z","title":"How does over-squashing affect the power of GNNs?","summary":"  Graph Neural Networks (GNNs) are the state-of-the-art model for machine\nlearning on graph-structured data. The most popular class of GNNs operate by\nexchanging information between adjacent nodes, and are known as Message Passing\nNeural Networks (MPNNs). Given their widespread use, understanding the\nexpressive power of MPNNs is a key question. However, existing results\ntypically consider settings with uninformative node features. In this paper, we\nprovide a rigorous analysis to determine which function classes of node\nfeatures can be learned by an MPNN of a given capacity. We do so by measuring\nthe level of pairwise interactions between nodes that MPNNs allow for. This\nmeasure provides a novel quantitative characterization of the so-called\nover-squashing effect, which is observed to occur when a large volume of\nmessages is aggregated into fixed-size vectors. Using our measure, we prove\nthat, to guarantee sufficient communication between pairs of nodes, the\ncapacity of the MPNN must be large enough, depending on properties of the input\ngraph structure, such as commute times. For many relevant scenarios, our\nanalysis results in impossibility statements in practice, showing that\nover-squashing hinders the expressive power of MPNNs. We validate our\ntheoretical findings through extensive controlled experiments and ablation\nstudies.\n","authors":["Francesco Di Giovanni","T. Konstantin Rusch","Michael M. Bronstein","Andreea Deac","Marc Lackenby","Siddhartha Mishra","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2306.03589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.05098v2","updated":"2023-06-06T11:02:06Z","published":"2022-09-12T09:02:00Z","title":"SELTO: Sample-Efficient Learned Topology Optimization","summary":"  Recent developments in Deep Learning (DL) suggest a vast potential for\nTopology Optimization (TO). However, while there are some promising attempts,\nthe subfield still lacks a firm footing regarding basic methods and datasets.\nWe aim to address both points. First, we explore physics-based preprocessing\nand equivariant networks to create sample-efficient components for TO DL\npipelines. We evaluate them in a large-scale ablation study using end-to-end\nsupervised training. The results demonstrate a drastic improvement in sample\nefficiency and the predictions' physical correctness. Second, to improve\ncomparability and future progress, we publish the two first TO datasets\ncontaining problems and corresponding ground truth solutions.\n","authors":["Sören Dittmer","David Erzmann","Henrik Harms","Peter Maass"],"pdf_url":"https://arxiv.org/pdf/2209.05098v2.pdf","comment":"25 pages, 10 figures, submitted to the International Journal for\n  Numerical Methods in Engineering"},{"id":"http://arxiv.org/abs/2306.03580v1","updated":"2023-06-06T10:53:26Z","published":"2023-06-06T10:53:26Z","title":"L-C2ST: Local Diagnostics for Posterior Approximations in\n  Simulation-Based Inference","summary":"  Many recent works in simulation-based inference (SBI) rely on deep generative\nmodels to approximate complex, high-dimensional posterior distributions.\nHowever, evaluating whether or not these approximations can be trusted remains\na challenge. Most approaches evaluate the posterior estimator only in\nexpectation over the observation space. This limits their interpretability and\nis not sufficient to identify for which observations the approximation can be\ntrusted or should be improved. Building upon the well-known classifier\ntwo-sample test (C2ST), we introduce L-C2ST, a new method that allows for a\nlocal evaluation of the posterior estimator at any given observation. It offers\ntheoretically grounded and easy to interpret - e.g. graphical - diagnostics,\nand unlike C2ST, does not require access to samples from the true posterior. In\nthe case of normalizing flow-based posterior estimators, L-C2ST can be\nspecialized to offer better statistical power, while being computationally more\nefficient. On standard SBI benchmarks, L-C2ST provides comparable results to\nC2ST and outperforms alternative local approaches such as coverage tests based\non highest predictive density (HPD). We further highlight the importance of\nlocal evaluation and the benefit of interpretability of L-C2ST on a challenging\napplication from computational neuroscience.\n","authors":["Julia Linhart","Alexandre Gramfort","Pedro L. C. Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2306.03580v1.pdf","comment":"20 pages, 4 figures, 7 appendices, in proceedings"},{"id":"http://arxiv.org/abs/2306.03570v1","updated":"2023-06-06T10:37:11Z","published":"2023-06-06T10:37:11Z","title":"Personalization Disentanglement for Federated Learning","summary":"  Personalized federated learning (PFL) jointly trains a variety of local\nmodels through balancing between knowledge sharing across clients and model\npersonalization per client. This paper addresses PFL via explicit disentangling\nlatent representations into two parts to capture the shared knowledge and\nclient-specific personalization, which leads to more reliable and effective\nPFL. The disentanglement is achieved by a novel Federated Dual Variational\nAutoencoder (FedDVA), which employs two encoders to infer the two types of\nrepresentations. FedDVA can produce a better understanding of the trade-off\nbetween global knowledge sharing and local personalization in PFL. Moreover, it\ncan be integrated with existing FL methods and turn them into personalized\nmodels for heterogeneous downstream tasks. Extensive experiments validate the\nadvantages caused by disentanglement and show that models trained with\ndisentangled representations substantially outperform those vanilla methods.\n","authors":["Peng Yan","Guodong Long"],"pdf_url":"https://arxiv.org/pdf/2306.03570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03566v1","updated":"2023-06-06T10:34:03Z","published":"2023-06-06T10:34:03Z","title":"Memory-Based Dual Gaussian Processes for Sequential Learning","summary":"  Sequential learning with Gaussian processes (GPs) is challenging when access\nto past data is limited, for example, in continual and active learning. In such\ncases, errors can accumulate over time due to inaccuracies in the posterior,\nhyperparameters, and inducing points, making accurate learning challenging.\nHere, we present a method to keep all such errors in check using the recently\nproposed dual sparse variational GP. Our method enables accurate inference for\ngeneric likelihoods and improves learning by actively building and updating a\nmemory of past data. We demonstrate its effectiveness in several applications\ninvolving Bayesian optimization, active learning, and continual learning.\n","authors":["Paul E. Chang","Prakhar Verma","S. T. John","Arno Solin","Mohammad Emtiyaz Khan"],"pdf_url":"https://arxiv.org/pdf/2306.03566v1.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2306.03561v1","updated":"2023-06-06T10:25:10Z","published":"2023-06-06T10:25:10Z","title":"CIN++: Enhancing Topological Message Passing","summary":"  Graph Neural Networks (GNNs) have demonstrated remarkable success in learning\nfrom graph-structured data. However, they face significant limitations in\nexpressive power, struggling with long-range interactions and lacking a\nprincipled approach to modeling higher-order structures and group interactions.\nCellular Isomorphism Networks (CINs) recently addressed most of these\nchallenges with a message passing scheme based on cell complexes. Despite their\nadvantages, CINs make use only of boundary and upper messages which do not\nconsider a direct interaction between the rings present in the underlying\ncomplex. Accounting for these interactions might be crucial for learning\nrepresentations of many real-world complex phenomena such as the dynamics of\nsupramolecular assemblies, neural activity within the brain, and gene\nregulation processes. In this work, we propose CIN++, an enhancement of the\ntopological message passing scheme introduced in CINs. Our message passing\nscheme accounts for the aforementioned limitations by letting the cells to\nreceive also lower messages within each layer. By providing a more\ncomprehensive representation of higher-order and long-range interactions, our\nenhanced topological message passing scheme achieves state-of-the-art results\non large-scale and long-range chemistry benchmarks.\n","authors":["Lorenzo Giusti","Teodora Reu","Francesco Ceccarelli","Cristian Bodnar","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2306.03561v1.pdf","comment":"21 pages, 9 figures"},{"id":"http://arxiv.org/abs/2304.12680v2","updated":"2023-06-06T10:22:56Z","published":"2023-04-25T09:31:20Z","title":"Communication-Constrained Bandits under Additive Gaussian Noise","summary":"  We study a distributed stochastic multi-armed bandit where a client supplies\nthe learner with communication-constrained feedback based on the rewards for\nthe corresponding arm pulls. In our setup, the client must encode the rewards\nsuch that the second moment of the encoded rewards is no more than $P$, and\nthis encoded reward is further corrupted by additive Gaussian noise of variance\n$\\sigma^2$; the learner only has access to this corrupted reward. For this\nsetting, we derive an information-theoretic lower bound of\n$\\Omega\\left(\\sqrt{\\frac{KT}{\\mathtt{SNR} \\wedge1}} \\right)$ on the minimax\nregret of any scheme, where $ \\mathtt{SNR} := \\frac{P}{\\sigma^2}$, and $K$ and\n$T$ are the number of arms and time horizon, respectively. Furthermore, we\npropose a multi-phase bandit algorithm, $\\mathtt{UE\\text{-}UCB++}$, which\nmatches this lower bound to a minor additive factor. $\\mathtt{UE\\text{-}UCB++}$\nperforms uniform exploration in its initial phases and then utilizes the {\\em\nupper confidence bound }(UCB) bandit algorithm in its final phase. An\ninteresting feature of $\\mathtt{UE\\text{-}UCB++}$ is that the coarser estimates\nof the mean rewards formed during a uniform exploration phase help to refine\nthe encoding protocol in the next phase, leading to more accurate mean\nestimates of the rewards in the subsequent phase. This positive reinforcement\ncycle is critical to reducing the number of uniform exploration rounds and\nclosely matching our lower bound.\n","authors":["Prathamesh Mayekar","Jonathan Scarlett","Vincent Y. F. Tan"],"pdf_url":"https://arxiv.org/pdf/2304.12680v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03558v1","updated":"2023-06-06T10:18:36Z","published":"2023-06-06T10:18:36Z","title":"Machine Unlearning: A Survey","summary":"  Machine learning has attracted widespread attention and evolved into an\nenabling technology for a wide range of highly successful applications, such as\nintelligent computer vision, speech recognition, medical diagnosis, and more.\nYet a special need has arisen where, due to privacy, usability, and/or the\nright to be forgotten, information about some specific samples needs to be\nremoved from a model, called machine unlearning. This emerging technology has\ndrawn significant interest from both academics and industry due to its\ninnovation and practicality. At the same time, this ambitious problem has led\nto numerous research efforts aimed at confronting its challenges. To the best\nof our knowledge, no study has analyzed this complex topic or compared the\nfeasibility of existing unlearning solutions in different kinds of scenarios.\nAccordingly, with this survey, we aim to capture the key concepts of unlearning\ntechniques. The existing solutions are classified and summarized based on their\ncharacteristics within an up-to-date and comprehensive review of each\ncategory's advantages and limitations. The survey concludes by highlighting\nsome of the outstanding issues with unlearning techniques, along with some\nfeasible directions for new research opportunities.\n","authors":["Heng Xu","Tianqing Zhu","Lefeng Zhang","Wanlei Zhou","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2306.03558v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.05924v3","updated":"2023-06-06T10:10:51Z","published":"2023-03-09T00:47:30Z","title":"Variational formulations of ODE-Net as a mean-field optimal control\n  problem and existence results","summary":"  This paper presents a mathematical analysis of ODE-Net, a continuum model of\ndeep neural networks (DNNs). In recent years, Machine Learning researchers have\nintroduced ideas of replacing the deep structure of DNNs with ODEs as a\ncontinuum limit. These studies regard the \"learning\" of ODE-Net as the\nminimization of a \"loss\" constrained by a parametric ODE. Although the\nexistence of a minimizer for this minimization problem needs to be assumed,\nonly a few studies have investigated its existence analytically in detail. In\nthe present paper, the existence of a minimizer is discussed based on a\nformulation of ODE-Net as a measure-theoretic mean-field optimal control\nproblem. The existence result is proved when a neural network, which describes\na vector field of ODE-Net, is linear with respect to learnable parameters. The\nproof employs the measure-theoretic formulation combined with the direct method\nof Calculus of Variations. Secondly, an idealized minimization problem is\nproposed to remove the above linearity assumption. Such a problem is inspired\nby a kinetic regularization associated with the Benamou--Brenier formula and\nuniversal approximation theorems for neural networks. The proofs of these\nexistence results use variational methods, differential equations, and\nmean-field optimal control theory. They will stand for a new analytic way to\ninvestigate the learning process of deep neural networks.\n","authors":["Noboru Isobe","Mizuho Okumura"],"pdf_url":"https://arxiv.org/pdf/2303.05924v3.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2306.03552v1","updated":"2023-06-06T10:06:09Z","published":"2023-06-06T10:06:09Z","title":"State Regularized Policy Optimization on Data with Dynamics Shift","summary":"  In many real-world scenarios, Reinforcement Learning (RL) algorithms are\ntrained on data with dynamics shift, i.e., with different underlying\nenvironment dynamics. A majority of current methods address such issue by\ntraining context encoders to identify environment parameters. Data with\ndynamics shift are separated according to their environment parameters to train\nthe corresponding policy. However, these methods can be sample inefficient as\ndata are used \\textit{ad hoc}, and policies trained for one dynamics cannot\nbenefit from data collected in all other environments with different dynamics.\nIn this paper, we find that in many environments with similar structures and\ndifferent dynamics, optimal policies have similar stationary state\ndistributions. We exploit such property and learn the stationary state\ndistribution from data with dynamics shift for efficient data reuse. Such\ndistribution is used to regularize the policy trained in a new environment,\nleading to the SRPO (\\textbf{S}tate \\textbf{R}egularized \\textbf{P}olicy\n\\textbf{O}ptimization) algorithm. To conduct theoretical analyses, the\nintuition of similar environment structures is characterized by the notion of\nhomomorphous MDPs. We then demonstrate a lower-bound performance guarantee on\npolicies regularized by the stationary state distribution. In practice, SRPO\ncan be an add-on module to context-based algorithms in both online and offline\nRL settings. Experimental results show that SRPO can make several context-based\nalgorithms far more data efficient and significantly improve their overall\nperformance.\n","authors":["Zhenghai Xue","Qingpeng Cai","Shuchang Liu","Dong Zheng","Peng Jiang","Kun Gai","Bo An"],"pdf_url":"https://arxiv.org/pdf/2306.03552v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2305.16914v3","updated":"2023-06-06T10:01:48Z","published":"2023-05-26T13:26:46Z","title":"PlaNeRF: SVD Unsupervised 3D Plane Regularization for NeRF Large-Scale\n  Scene Reconstruction","summary":"  Neural Radiance Fields (NeRF) enable 3D scene reconstruction from 2D images\nand camera poses for Novel View Synthesis (NVS). Although NeRF can produce\nphotorealistic results, it often suffers from overfitting to training views,\nleading to poor geometry reconstruction, especially in low-texture areas. This\nlimitation restricts many important applications which require accurate\ngeometry, such as extrapolated NVS, HD mapping and scene editing. To address\nthis limitation, we propose a new method to improve NeRF's 3D structure using\nonly RGB images and semantic maps. Our approach introduces a novel plane\nregularization based on Singular Value Decomposition (SVD), that does not rely\non any geometric prior. In addition, we leverage the Structural Similarity\nIndex Measure (SSIM) in our loss design to properly initialize the volumetric\nrepresentation of NeRF. Quantitative and qualitative results show that our\nmethod outperforms popular regularization approaches in accurate geometry\nreconstruction for large-scale outdoor scenes and achieves SoTA rendering\nquality on the KITTI-360 NVS benchmark.\n","authors":["Fusang Wang","Arnaud Louys","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou"],"pdf_url":"https://arxiv.org/pdf/2305.16914v3.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.03551v1","updated":"2023-06-06T09:57:04Z","published":"2023-06-06T09:57:04Z","title":"Scalable Concept Extraction in Industry 4.0","summary":"  The industry 4.0 is leveraging digital technologies and machine learning\ntechniques to connect and optimize manufacturing processes. Central to this\nidea is the ability to transform raw data into human understandable knowledge\nfor reliable data-driven decision-making. Convolutional Neural Networks (CNNs)\nhave been instrumental in processing image data, yet, their ``black box''\nnature complicates the understanding of their prediction process. In this\ncontext, recent advances in the field of eXplainable Artificial Intelligence\n(XAI) have proposed the extraction and localization of concepts, or which\nvisual cues intervene on the prediction process of CNNs. This paper tackles the\napplication of concept extraction (CE) methods to industry 4.0 scenarios. To\nthis end, we modify a recently developed technique, ``Extracting Concepts with\nLocal Aggregated Descriptors'' (ECLAD), improving its scalability.\nSpecifically, we propose a novel procedure for calculating concept importance,\nutilizing a wrapper function designed for CNNs. This process is aimed at\ndecreasing the number of times each image needs to be evaluated. Subsequently,\nwe demonstrate the potential of CE methods, by applying them in three\nindustrial use cases. We selected three representative use cases in the context\nof quality control for material design (tailored textiles), manufacturing\n(carbon fiber reinforcement), and maintenance (photovoltaic module inspection).\nIn these examples, CE was able to successfully extract and locate concepts\ndirectly related to each task. This is, the visual cues related to each\nconcept, coincided with what human experts would use to perform the task\nthemselves, even when the visual cues were entangled between multiple classes.\nThrough empirical results, we show that CE can be applied for understanding\nCNNs in an industrial context, giving useful insights that can relate to domain\nknowledge.\n","authors":["Andrés Felipe Posada-Moreno","Kai Müller","Florian Brillowski","Friedrich Solowjow","Thomas Gries","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2306.03551v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08451v2","updated":"2023-06-06T09:52:41Z","published":"2022-06-16T21:16:41Z","title":"I Know What You Trained Last Summer: A Survey on Stealing Machine\n  Learning Models and Defences","summary":"  Machine Learning-as-a-Service (MLaaS) has become a widespread paradigm,\nmaking even the most complex machine learning models available for clients via\ne.g. a pay-per-query principle. This allows users to avoid time-consuming\nprocesses of data collection, hyperparameter tuning, and model training.\nHowever, by giving their customers access to the (predictions of their) models,\nMLaaS providers endanger their intellectual property, such as sensitive\ntraining data, optimised hyperparameters, or learned model parameters.\nAdversaries can create a copy of the model with (almost) identical behavior\nusing the the prediction labels only. While many variants of this attack have\nbeen described, only scattered defence strategies have been proposed,\naddressing isolated threats. This raises the necessity for a thorough\nsystematisation of the field of model stealing, to arrive at a comprehensive\nunderstanding why these attacks are successful, and how they could be\nholistically defended against. We address this by categorising and comparing\nmodel stealing attacks, assessing their performance, and exploring\ncorresponding defence techniques in different settings. We propose a taxonomy\nfor attack and defence approaches, and provide guidelines on how to select the\nright attack or defence strategy based on the goal and available resources.\nFinally, we analyse which defences are rendered less effective by current\nattack strategies.\n","authors":["Daryna Oliynyk","Rudolf Mayer","Andreas Rauber"],"pdf_url":"https://arxiv.org/pdf/2206.08451v2.pdf","comment":"Accepted at ACM Computing Surveys, 2023:\n  https://doi.org/10.1145/3595292"},{"id":"http://arxiv.org/abs/2306.02865v2","updated":"2023-06-06T09:52:29Z","published":"2023-06-05T13:38:14Z","title":"Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy\n  Actor-Critic","summary":"  Learning high-quality Q-value functions plays a key role in the success of\nmany modern off-policy deep reinforcement learning (RL) algorithms. Previous\nworks focus on addressing the value overestimation issue, an outcome of\nadopting function approximators and off-policy learning. Deviating from the\ncommon viewpoint, we observe that Q-values are indeed underestimated in the\nlatter stage of the RL training process, primarily related to the use of\ninferior actions from the current policy in Bellman updates as compared to the\nmore optimal action samples in the replay buffer. We hypothesize that this\nlong-neglected phenomenon potentially hinders policy learning and reduces\nsample efficiency. Our insight to address this issue is to incorporate\nsufficient exploitation of past successes while maintaining exploration\noptimism. We propose the Blended Exploitation and Exploration (BEE) operator, a\nsimple yet effective approach that updates Q-value using both historical\nbest-performing actions and the current policy. The instantiations of our\nmethod in both model-free and model-based settings outperform state-of-the-art\nmethods in various continuous control tasks and achieve strong performance in\nfailure-prone scenarios and real-world robot tasks.\n","authors":["Tianying Ji","Yu Luo","Fuchun Sun","Xianyuan Zhan","Jianwei Zhang","Huazhe Xu"],"pdf_url":"https://arxiv.org/pdf/2306.02865v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03548v1","updated":"2023-06-06T09:50:38Z","published":"2023-06-06T09:50:38Z","title":"Learning Dynamical Systems from Noisy Data with Inverse-Explicit\n  Integrators","summary":"  We introduce the mean inverse integrator (MII), a novel approach to increase\nthe accuracy when training neural networks to approximate vector fields of\ndynamical systems from noisy data. This method can be used to average multiple\ntrajectories obtained by numerical integrators such as Runge-Kutta methods. We\nshow that the class of mono-implicit Runge-Kutta methods (MIRK) has particular\nadvantages when used in connection with MII. When training vector field\napproximations, explicit expressions for the loss functions are obtained when\ninserting the training data in the MIRK formulae, unlocking symmetric and\nhigh-order integrators that would otherwise be implicit for initial value\nproblems. The combined approach of applying MIRK within MII yields a\nsignificantly lower error compared to the plain use of the numerical integrator\nwithout averaging the trajectories. This is demonstrated with experiments using\ndata from several (chaotic) Hamiltonian systems. Additionally, we perform a\nsensitivity analysis of the loss functions under normally distributed\nperturbations, supporting the favorable performance of MII.\n","authors":["Håkon Noren","Sølve Eidnes","Elena Celledoni"],"pdf_url":"https://arxiv.org/pdf/2306.03548v1.pdf","comment":"23 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.03543v1","updated":"2023-06-06T09:44:56Z","published":"2023-06-06T09:44:56Z","title":"How to Select Which Active Learning Strategy is Best Suited for Your\n  Specific Problem and Budget","summary":"  In Active Learning (AL), a learner actively chooses which unlabeled examples\nto query for labels from an oracle, under some budget constraints. Different AL\nquery strategies are more suited to different problems and budgets. Therefore,\nin practice, knowing in advance which AL strategy is most suited for the\nproblem at hand remains an open problem. To tackle this challenge, we propose a\npractical derivative-based method that dynamically identifies the best strategy\nfor each budget. We provide theoretical analysis of a simplified case to\nmotivate our approach and build intuition. We then introduce a method to\ndynamically select an AL strategy based on the specific problem and budget.\nEmpirical results showcase the effectiveness of our approach across diverse\nbudgets and computer vision tasks.\n","authors":["Guy Hacohen","Daphna Weinshall"],"pdf_url":"https://arxiv.org/pdf/2306.03543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03542v1","updated":"2023-06-06T09:38:57Z","published":"2023-06-06T09:38:57Z","title":"Masked Autoencoders are Efficient Continual Federated Learners","summary":"  Machine learning is typically framed from a perspective of i.i.d., and more\nimportantly, isolated data. In parts, federated learning lifts this assumption,\nas it sets out to solve the real-world challenge of collaboratively learning a\nshared model from data distributed across clients. However, motivated primarily\nby privacy and computational constraints, the fact that data may change,\ndistributions drift, or even tasks advance individually on clients, is seldom\ntaken into account. The field of continual learning addresses this separate\nchallenge and first steps have recently been taken to leverage synergies in\ndistributed supervised settings, in which several clients learn to solve\nchanging classification tasks over time without forgetting previously seen\nones. Motivated by these prior works, we posit that such federated continual\nlearning should be grounded in unsupervised learning of representations that\nare shared across clients; in the loose spirit of how humans can indirectly\nleverage others' experience without exposure to a specific task. For this\npurpose, we demonstrate that masked autoencoders for distribution estimation\nare particularly amenable to this setup. Specifically, their masking strategy\ncan be seamlessly integrated with task attention mechanisms to enable selective\nknowledge transfer between clients. We empirically corroborate the latter\nstatement through several continual federated scenarios on both image and\nbinary datasets.\n","authors":["Subarnaduti Paul","Lars-Joel Frey","Roshni Kamath","Kristian Kersting","Martin Mundt"],"pdf_url":"https://arxiv.org/pdf/2306.03542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2004.13612v4","updated":"2023-06-06T09:37:37Z","published":"2020-04-28T15:45:21Z","title":"Denise: Deep Robust Principal Component Analysis for Positive\n  Semidefinite Matrices","summary":"  The robust PCA of covariance matrices plays an essential role when isolating\nkey explanatory features. The currently available methods for performing such a\nlow-rank plus sparse decomposition are matrix specific, meaning, those\nalgorithms must re-run for every new matrix. Since these algorithms are\ncomputationally expensive, it is preferable to learn and store a function that\nnearly instantaneously performs this decomposition when evaluated. Therefore,\nwe introduce Denise, a deep learning-based algorithm for robust PCA of\ncovariance matrices, or more generally, of symmetric positive semidefinite\nmatrices, which learns precisely such a function. Theoretical guarantees for\nDenise are provided. These include a novel universal approximation theorem\nadapted to our geometric deep learning problem and convergence to an optimal\nsolution to the learning problem. Our experiments show that Denise matches\nstate-of-the-art performance in terms of decomposition quality, while being\napproximately $2000\\times$ faster than the state-of-the-art, principal\ncomponent pursuit (PCP), and $200 \\times$ faster than the current\nspeed-optimized method, fast PCP.\n","authors":["Calypso Herrera","Florian Krach","Anastasis Kratsios","Pierre Ruyssen","Josef Teichmann"],"pdf_url":"https://arxiv.org/pdf/2004.13612v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03536v1","updated":"2023-06-06T09:35:29Z","published":"2023-06-06T09:35:29Z","title":"On Pitfalls of Test-Time Adaptation","summary":"  Test-Time Adaptation (TTA) has recently emerged as a promising approach for\ntackling the robustness challenge under distribution shifts. However, the lack\nof consistent settings and systematic studies in prior literature hinders\nthorough assessments of existing methods. To address this issue, we present\nTTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art\nalgorithms, a diverse array of distribution shifts, and two evaluation\nprotocols. Through extensive experiments, our benchmark reveals three common\npitfalls in prior efforts. First, selecting appropriate hyper-parameters,\nespecially for model selection, is exceedingly difficult due to online batch\ndependency. Second, the effectiveness of TTA varies greatly depending on the\nquality and properties of the model being adapted. Third, even under optimal\nalgorithmic conditions, none of the existing methods are capable of addressing\nall common types of distribution shifts. Our findings underscore the need for\nfuture research in the field to conduct rigorous evaluations on a broader set\nof models and shifts, and to re-examine the assumptions behind the empirical\nsuccess of TTA. Our code is available at\n\\url{https://github.com/lins-lab/ttab}.\n","authors":["Hao Zhao","Yuejiang Liu","Alexandre Alahi","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2306.03536v1.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.03534v1","updated":"2023-06-06T09:34:11Z","published":"2023-06-06T09:34:11Z","title":"Continual Learning in Linear Classification on Separable Data","summary":"  We analyze continual learning on a sequence of separable linear\nclassification tasks with binary labels. We show theoretically that learning\nwith weak regularization reduces to solving a sequential max-margin problem,\ncorresponding to a special case of the Projection Onto Convex Sets (POCS)\nframework. We then develop upper bounds on the forgetting and other quantities\nof interest under various settings with recurring tasks, including cyclic and\nrandom orderings of tasks. We discuss several practical implications to popular\ntraining practices like regularization scheduling and weighting. We point out\nseveral theoretical differences between our continual classification setting\nand a recently studied continual regression setting.\n","authors":["Itay Evron","Edward Moroshko","Gon Buzaglo","Maroun Khriesh","Badea Marjieh","Nathan Srebro","Daniel Soudry"],"pdf_url":"https://arxiv.org/pdf/2306.03534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12600v2","updated":"2023-06-06T09:33:37Z","published":"2022-11-22T21:56:38Z","title":"ArrayFlex: A Systolic Array Architecture with Configurable Transparent\n  Pipelining","summary":"  Convolutional Neural Networks (CNNs) are the state-of-the-art solution for\nmany deep learning applications. For maximum scalability, their computation\nshould combine high performance and energy efficiency. In practice, the\nconvolutions of each CNN layer are mapped to a matrix multiplication that\nincludes all input features and kernels of each layer and is computed using a\nsystolic array. In this work, we focus on the design of a systolic array with\nconfigurable pipeline with the goal to select an optimal pipeline configuration\nfor each CNN layer. The proposed systolic array, called ArrayFlex, can operate\nin normal, or in shallow pipeline mode, thus balancing the execution time in\ncycles and the operating clock frequency. By selecting the appropriate pipeline\nconfiguration per CNN layer, ArrayFlex reduces the inference latency of\nstate-of-the-art CNNs by 11%, on average, as compared to a traditional\nfixed-pipeline systolic array. Most importantly, this result is achieved while\nusing 13%-23% less power, for the same applications, thus offering a combined\nenergy-delay-product efficiency between 1.4x and 1.8x.\n","authors":["C. Peltekis","D. Filippas","G. Dimitrakopoulos","C. Nicopoulos","D. Pnevmatikatos"],"pdf_url":"https://arxiv.org/pdf/2211.12600v2.pdf","comment":"DATE 2023"},{"id":"http://arxiv.org/abs/2306.03530v1","updated":"2023-06-06T09:26:43Z","published":"2023-06-06T09:26:43Z","title":"BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for\n  Continuous Control","summary":"  Deep Reinforcement Learning (RL) has been demonstrated to yield capable\nagents and control policies in several domains but is commonly plagued by\nprohibitively long training times. Additionally, in the case of continuous\ncontrol problems, the applicability of learned policies on real-world embedded\ndevices is limited due to the lack of real-time guarantees and portability of\nexisting deep learning libraries. To address these challenges, we present\nBackpropTools, a dependency-free, header-only, pure C++ library for deep\nsupervised and reinforcement learning. Leveraging the template meta-programming\ncapabilities of recent C++ standards, we provide composable components that can\nbe tightly integrated by the compiler. Its novel architecture allows\nBackpropTools to be used seamlessly on a heterogeneous set of platforms, from\nHPC clusters over workstations and laptops to smartphones, smartwatches, and\nmicrocontrollers. Specifically, due to the tight integration of the RL\nalgorithms with simulation environments, BackpropTools can solve popular RL\nproblems like the Pendulum-v1 swing-up about 7 to 15 times faster in terms of\nwall-clock training time compared to other popular RL frameworks when using\nTD3. We also provide a low-overhead and parallelized interface to the MuJoCo\nsimulator, showing that our PPO implementation achieves state of the art\nreturns in the Ant-v4 environment while achieving a 25 to 30 percent faster\nwall-clock training time. Finally, we also benchmark the policy inference on a\ndiverse set of microcontrollers and show that in most cases our optimized\ninference implementation is much faster than even the manufacturer's DSP\nlibraries. To the best of our knowledge, BackpropTools enables the first-ever\ndemonstration of training a deep RL algorithm directly on a microcontroller,\ngiving rise to the field of Tiny Reinforcement Learning (TinyRL). Project page:\nhttps://backprop.tools\n","authors":["Jonas Eschmann","Dario Albani","Giuseppe Loianno"],"pdf_url":"https://arxiv.org/pdf/2306.03530v1.pdf","comment":"Project page: https://backprop.tools"},{"id":"http://arxiv.org/abs/2306.03527v1","updated":"2023-06-06T09:22:52Z","published":"2023-06-06T09:22:52Z","title":"Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR\n  Prediction in Taobao","summary":"  Click-Through Rate (CTR) prediction serves as a fundamental component in\nonline advertising. A common practice is to train a CTR model on advertisement\n(ad) impressions with user feedback. Since ad impressions are purposely\nselected by the model itself, their distribution differs from the inference\ndistribution and thus exhibits sample selection bias (SSB) that affects model\nperformance. Existing studies on SSB mainly employ sample re-weighting\ntechniques which suffer from high variance and poor model calibration. Another\nline of work relies on costly uniform data that is inadequate to train\nindustrial models. Thus mitigating SSB in industrial models with a\nuniform-data-free framework is worth exploring. Fortunately, many platforms\ndisplay mixed results of organic items (i.e., recommendations) and sponsored\nitems (i.e., ads) to users, where impressions of ads and recommendations are\nselected by different systems but share the same user decision rationales.\nBased on the above characteristics, we propose to leverage recommendations\nsamples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After\nelaborating data augmentation, Rec4Ad learns disentangled representations with\nalignment and decorrelation modules for enhancement. When deployed in Taobao\ndisplay advertising system, Rec4Ad achieves substantial gains in key business\nmetrics, with a lift of up to +6.6\\% CTR and +2.9\\% RPM.\n","authors":["Jingyue Gao","Shuguang Han","Han Zhu","Siran Yang","Yuning Jiang","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.03527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02923v2","updated":"2023-06-06T09:17:12Z","published":"2023-02-06T16:55:37Z","title":"In Search of Insights, Not Magic Bullets: Towards Demystification of the\n  Model Selection Dilemma in Heterogeneous Treatment Effect Estimation","summary":"  Personalized treatment effect estimates are often of interest in high-stakes\napplications -- thus, before deploying a model estimating such effects in\npractice, one needs to be sure that the best candidate from the ever-growing\nmachine learning toolbox for this task was chosen. Unfortunately, due to the\nabsence of counterfactual information in practice, it is usually not possible\nto rely on standard validation metrics for doing so, leading to a well-known\nmodel selection dilemma in the treatment effect estimation literature. While\nsome solutions have recently been investigated, systematic understanding of the\nstrengths and weaknesses of different model selection criteria is still\nlacking. In this paper, instead of attempting to declare a global `winner', we\ntherefore empirically investigate success- and failure modes of different\nselection criteria. We highlight that there is a complex interplay between\nselection strategies, candidate estimators and the data used for comparing\nthem, and provide interesting insights into the relative (dis)advantages of\ndifferent criteria alongside desiderata for the design of further illuminating\nempirical studies in this context.\n","authors":["Alicia Curth","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2302.02923v2.pdf","comment":"To appear in the Proceedings of the 40th International Conference on\n  Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023"},{"id":"http://arxiv.org/abs/2306.03522v1","updated":"2023-06-06T09:14:05Z","published":"2023-06-06T09:14:05Z","title":"A Functional Data Perspective and Baseline On Multi-Layer\n  Out-of-Distribution Detection","summary":"  A key feature of out-of-distribution (OOD) detection is to exploit a trained\nneural network by extracting statistical patterns and relationships through the\nmulti-layer classifier to detect shifts in the expected input data\ndistribution. Despite achieving solid results, several state-of-the-art methods\nrely on the penultimate or last layer outputs only, leaving behind valuable\ninformation for OOD detection. Methods that explore the multiple layers either\nrequire a special architecture or a supervised objective to do so. This work\nadopts an original approach based on a functional view of the network that\nexploits the sample's trajectories through the various layers and their\nstatistical dependencies. It goes beyond multivariate features aggregation and\nintroduces a baseline rooted in functional anomaly detection. In this new\nframework, OOD detection translates into detecting samples whose trajectories\ndiffer from the typical behavior characterized by the training set. We validate\nour method and empirically demonstrate its effectiveness in OOD detection\ncompared to strong state-of-the-art baselines on computer vision benchmarks.\n","authors":["Eduardo Dadalto","Pierre Colombo","Guillaume Staerman","Nathan Noiry","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2306.03522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03521v1","updated":"2023-06-06T09:12:49Z","published":"2023-06-06T09:12:49Z","title":"Machine learning in and out of equilibrium","summary":"  The algorithms used to train neural networks, like stochastic gradient\ndescent (SGD), have close parallels to natural processes that navigate a\nhigh-dimensional parameter space -- for example protein folding or evolution.\nOur study uses a Fokker-Planck approach, adapted from statistical physics, to\nexplore these parallels in a single, unified framework. We focus in particular\non the stationary state of the system in the long-time limit, which in\nconventional SGD is out of equilibrium, exhibiting persistent currents in the\nspace of network parameters. As in its physical analogues, the current is\nassociated with an entropy production rate for any given training trajectory.\nThe stationary distribution of these rates obeys the integral and detailed\nfluctuation theorems -- nonequilibrium generalizations of the second law of\nthermodynamics. We validate these relations in two numerical examples, a\nnonlinear regression network and MNIST digit classification. While the\nfluctuation theorems are universal, there are other aspects of the stationary\nstate that are highly sensitive to the training details. Surprisingly, the\neffective loss landscape and diffusion matrix that determine the shape of the\nstationary distribution vary depending on the simple choice of minibatching\ndone with or without replacement. We can take advantage of this nonequilibrium\nsensitivity to engineer an equilibrium stationary state for a particular\napplication: sampling from a posterior distribution of network weights in\nBayesian machine learning. We propose a new variation of stochastic gradient\nLangevin dynamics (SGLD) that harnesses without replacement minibatching. In an\nexample system where the posterior is exactly known, this SGWORLD algorithm\noutperforms SGLD, converging to the posterior orders of magnitude faster as a\nfunction of the learning rate.\n","authors":["Shishir Adhikari","Alkan Kabakçıoğlu","Alexander Strang","Deniz Yuret","Michael Hinczewski"],"pdf_url":"https://arxiv.org/pdf/2306.03521v1.pdf","comment":"24 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.03516v1","updated":"2023-06-06T09:08:40Z","published":"2023-06-06T09:08:40Z","title":"COPR: Consistency-Oriented Pre-Ranking for Online Advertising","summary":"  Cascading architecture has been widely adopted in large-scale advertising\nsystems to balance efficiency and effectiveness. In this architecture, the\npre-ranking model is expected to be a lightweight approximation of the ranking\nmodel, which handles more candidates with strict latency requirements. Due to\nthe gap in model capacity, the pre-ranking and ranking models usually generate\ninconsistent ranked results, thus hurting the overall system effectiveness. The\nparadigm of score alignment is proposed to regularize their raw scores to be\nconsistent. However, it suffers from inevitable alignment errors and error\namplification by bids when applied in online advertising. To this end, we\nintroduce a consistency-oriented pre-ranking framework for online advertising,\nwhich employs a chunk-based sampling module and a plug-and-play rank alignment\nmodule to explicitly optimize consistency of ECPM-ranked results. A $\\Delta\nNDCG$-based weighting mechanism is adopted to better distinguish the importance\nof inter-chunk samples in optimization. Both online and offline experiments\nhave validated the superiority of our framework. When deployed in Taobao\ndisplay advertising system, it achieves an improvement of up to +12.3\\% CTR and\n+5.6\\% RPM.\n","authors":["Zhishan Zhao","Jingyue Gao","Yu Zhang","Shuguang Han","Siyuan Lou","Xiang-Rong Sheng","Zhe Wang","Han Zhu","Yuning Jiang","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.03516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05643v4","updated":"2023-06-06T09:06:42Z","published":"2022-10-11T17:34:32Z","title":"A Kernel-Based View of Language Model Fine-Tuning","summary":"  It has become standard to solve NLP tasks by fine-tuning pre-trained language\nmodels (LMs), especially in low-data settings. There is minimal theoretical\nunderstanding of empirical success, e.g., why fine-tuning a model with $10^8$\nor more parameters on a couple dozen training points does not result in\noverfitting. We investigate whether the Neural Tangent Kernel (NTK) - which\noriginated as a model to study the gradient descent dynamics of infinitely wide\nnetworks with suitable random initialization - describes fine-tuning of\npre-trained LMs. This study was inspired by the decent performance of NTK for\ncomputer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam\nand use Tensor Programs (Yang, 2020) to characterize conditions under which the\nNTK lens may describe fine-tuning updates to pre-trained language models.\nExtensive experiments on 14 NLP tasks validate our theory and show that\nformulating the downstream task as a masked word prediction problem through\nprompting often induces kernel-based dynamics during fine-tuning. Finally, we\nuse this kernel view to propose an explanation for the success of\nparameter-efficient subspace-based fine-tuning methods.\n","authors":["Sadhika Malladi","Alexander Wettig","Dingli Yu","Danqi Chen","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2210.05643v4.pdf","comment":"Accepted at ICML 2023. Code and pre-computed kernels are publicly\n  available at https://github.com/princeton-nlp/LM-Kernel-FT"},{"id":"http://arxiv.org/abs/2305.07598v3","updated":"2023-06-06T09:06:28Z","published":"2023-05-12T16:42:54Z","title":"RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for\n  Oriented Object Detection","summary":"  With the publication of DINO, a variant of the Detection Transformer (DETR),\nDetection Transformers are breaking the record in the object detection\nbenchmark with the merits of their end-to-end design and scalability. However,\nthe extension of DETR to oriented object detection has not been thoroughly\nstudied although more benefits from its end-to-end architecture are expected\nsuch as removing NMS and anchor-related costs. In this paper, we propose a\nfirst strong DINO-based baseline for oriented object detection. We found that\nstraightforward employment of DETRs for oriented object detection does not\nguarantee non-duplicate prediction, and propose a simple cost to mitigate this.\nFurthermore, we introduce a $\\textit{dynamic denoising}$ strategy that uses\nHungarian matching to filter redundant noised queries and $\\textit{query\nalignment}$ to preserve matching consistency between Transformer decoder\nlayers. Our proposed model outperforms previous rotated DETRs and other\ncounterparts, achieving state-of-the-art performance in DOTA-v1.0/v1.5/v2.0,\nand DIOR-R benchmarks.\n","authors":["Hakjin Lee","Minki Song","Jamyoung Koo","Junghoon Seo"],"pdf_url":"https://arxiv.org/pdf/2305.07598v3.pdf","comment":"State-of-the-art rotated object detector in DOTA v1.0/v1.5/v2.0 and\n  DIOR-R at the time of publication"},{"id":"http://arxiv.org/abs/2306.03515v1","updated":"2023-06-06T09:01:17Z","published":"2023-06-06T09:01:17Z","title":"Logic Diffusion for Knowledge Graph Reasoning","summary":"  Most recent works focus on answering first order logical queries to explore\nthe knowledge graph reasoning via multi-hop logic predictions. However,\nexisting reasoning models are limited by the circumscribed logical paradigms of\ntraining samples, which leads to a weak generalization of unseen logic. To\naddress these issues, we propose a plug-in module called Logic Diffusion (LoD)\nto discover unseen queries from surroundings and achieves dynamical equilibrium\nbetween different kinds of patterns. The basic idea of LoD is relation\ndiffusion and sampling sub-logic by random walking as well as a special\ntraining mechanism called gradient adaption. Besides, LoD is accompanied by a\nnovel loss function to further achieve the robust logical diffusion when facing\nnoisy data in training or testing sets. Extensive experiments on four public\ndatasets demonstrate the superiority of mainstream knowledge graph reasoning\nmodels with LoD over state-of-the-art. Moreover, our ablation study proves the\ngeneral effectiveness of LoD on the noise-rich knowledge graph.\n","authors":["Xiaoying Xie","Biao Gong","Yiliang Lv","Zhen Han","Guoshuai Zhao","Xueming Qian"],"pdf_url":"https://arxiv.org/pdf/2306.03515v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.14471v4","updated":"2023-06-06T09:01:04Z","published":"2023-02-28T10:29:42Z","title":"Safe Peeling for L0-Regularized Least-Squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of L0-regularized least-squares problems via a Branch-and-Bound\n(BnB) algorithm. Our procedure enables to tighten the convex relaxation\nconsidered at each node of the BnB decision tree and therefore potentially\nallows for more aggressive pruning. Numerical simulations show that our\nproposed methodology leads to significant gains in terms of number of nodes\nexplored and overall solving time.s show that our proposed methodology leads to\nsignificant gains in terms of number of nodes explored and overall solving\ntime.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03506v1","updated":"2023-06-06T08:52:44Z","published":"2023-06-06T08:52:44Z","title":"Subgraph Networks Based Contrastive Learning","summary":"  Graph contrastive learning (GCL), as a self-supervised learning method, can\nsolve the problem of annotated data scarcity. It mines explicit features in\nunannotated graphs to generate favorable graph representations for downstream\ntasks. Most existing GCL methods focus on the design of graph augmentation\nstrategies and mutual information estimation operations. Graph augmentation\nproduces augmented views by graph perturbations. These views preserve a locally\nsimilar structure and exploit explicit features. However, these methods have\nnot considered the interaction existing in subgraphs. To explore the impact of\nsubstructure interactions on graph representations, we propose a novel\nframework called subgraph network-based contrastive learning (SGNCL). SGNCL\napplies a subgraph network generation strategy to produce augmented views. This\nstrategy converts the original graph into an Edge-to-Node mapping network with\nboth topological and attribute features. The single-shot augmented view is a\nfirst-order subgraph network that mines the interaction between nodes,\nnode-edge, and edges. In addition, we also investigate the impact of the\nsecond-order subgraph augmentation on mining graph structure interactions, and\nfurther, propose a contrastive objective that fuses the first-order and\nsecond-order subgraph information. We compare SGNCL with classical and\nstate-of-the-art graph contrastive learning methods on multiple benchmark\ndatasets of different domains. Extensive experiments show that SGNCL achieves\ncompetitive or better performance (top three) on all datasets in unsupervised\nlearning settings. Furthermore, SGNCL achieves the best average gain of 6.9\\%\nin transfer learning compared to the best method. Finally, experiments also\ndemonstrate that mining substructure interactions have positive implications\nfor graph contrastive learning.\n","authors":["Jinhuan Wang","Jiafei Shao","Zeyu Wang","Shanqing Yu","Qi Xuan","Xiaoniu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03506v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.03502v1","updated":"2023-06-06T08:41:02Z","published":"2023-06-06T08:41:02Z","title":"Russo-Ukrainian War: Prediction and explanation of Twitter suspension","summary":"  On 24 February 2022, Russia invaded Ukraine, starting what is now known as\nthe Russo-Ukrainian War, initiating an online discourse on social media.\nTwitter as one of the most popular SNs, with an open and democratic character,\nenables a transparent discussion among its large user base. Unfortunately, this\noften leads to Twitter's policy violations, propaganda, abusive actions, civil\nintegrity violation, and consequently to user accounts' suspension and\ndeletion. This study focuses on the Twitter suspension mechanism and the\nanalysis of shared content and features of the user accounts that may lead to\nthis. Toward this goal, we have obtained a dataset containing 107.7M tweets,\noriginating from 9.8 million users, using Twitter API. We extract the\ncategories of shared content of the suspended accounts and explain their\ncharacteristics, through the extraction of text embeddings in junction with\ncosine similarity clustering. Our results reveal scam campaigns taking\nadvantage of trending topics regarding the Russia-Ukrainian conflict for\nBitcoin and Ethereum fraud, spam, and advertisement campaigns. Additionally, we\napply a machine learning methodology including a SHapley Additive\nexplainability model to understand and explain how user accounts get suspended.\n","authors":["Alexander Shevtsov","Despoina Antonakaki","Ioannis Lamprou","Ioannis Kontogiorgakis","Polyvios Pratikakis","Sotiris Ioannidis"],"pdf_url":"https://arxiv.org/pdf/2306.03502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13954v4","updated":"2023-06-06T08:37:56Z","published":"2022-10-25T12:16:03Z","title":"I Prefer not to Say: Protecting User Consent in Models with Optional\n  Personal Data","summary":"  We examine machine learning models in a setup where individuals have the\nchoice to share optional personal information with a decision-making system, as\nseen in modern insurance pricing models. Some users consent to their data being\nused whereas others object and keep their data undisclosed. In this work, we\nshow that the decision not to share data can be considered as information in\nitself that should be protected to respect users' privacy. This observation\nraises the overlooked problem of how to ensure that users who protect their\npersonal data do not suffer any disadvantages as a result. To address this\nproblem, we formalize protection requirements for models which only use the\ninformation for which active user consent was obtained. This excludes implicit\ninformation contained in the decision to share data or not. We offer the first\nsolution to this problem by proposing the notion of Protected User Consent\n(PUC), which we prove to be loss-optimal under our protection requirement. To\nlearn PUC-compliant models, we devise a model-agnostic data augmentation\nstrategy with finite sample convergence guarantees. Finally, we analyze the\nimplications of PUC on a variety of challenging real-world datasets, tasks, and\nmodels.\n","authors":["Tobias Leemann","Martin Pawelczyk","Christian Thomas Eberle","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2210.13954v4.pdf","comment":"Updated Version. v1 accepted at NeurIPS 2022 Workshop on Algorithmic\n  Fairness through the Lens of Causality and Privacy (AFCP)"},{"id":"http://arxiv.org/abs/2212.01953v2","updated":"2023-06-06T08:29:28Z","published":"2022-12-04T23:40:14Z","title":"Context-aware multi-head self-attentional neural network model for next\n  location prediction","summary":"  Accurate activity location prediction is a crucial component of many mobility\napplications and is particularly required to develop personalized, sustainable\ntransportation systems. Despite the widespread adoption of deep learning\nmodels, next location prediction models lack a comprehensive discussion and\nintegration of mobility-related spatio-temporal contexts. Here, we utilize a\nmulti-head self-attentional (MHSA) neural network that learns location\ntransition patterns from historical location visits, their visit time and\nactivity duration, as well as their surrounding land use functions, to infer an\nindividual's next location. Specifically, we adopt point-of-interest data and\nlatent Dirichlet allocation for representing locations' land use contexts at\nmultiple spatial scales, generate embedding vectors of the spatio-temporal\nfeatures, and learn to predict the next location with an MHSA network. Through\nexperiments on two large-scale GNSS tracking datasets, we demonstrate that the\nproposed model outperforms other state-of-the-art prediction models, and reveal\nthe contribution of various spatio-temporal contexts to the model's\nperformance. Moreover, we find that the model trained on population data\nachieves higher prediction performance with fewer parameters than\nindividual-level models due to learning from collective movement patterns. We\nalso reveal mobility conducted in the recent past and one week before has the\nlargest influence on the current prediction, showing that learning from a\nsubset of the historical mobility is sufficient to obtain an accurate location\nprediction result. We believe that the proposed model is vital for\ncontext-aware mobility prediction. The gained insights will help to understand\nlocation prediction models and promote their implementation for mobility\napplications.\n","authors":["Ye Hong","Yatao Zhang","Konrad Schindler","Martin Raubal"],"pdf_url":"https://arxiv.org/pdf/2212.01953v2.pdf","comment":"Updated figures and added more descriptions in Appendix"},{"id":"http://arxiv.org/abs/2206.09959v5","updated":"2023-06-06T08:17:18Z","published":"2022-06-20T18:42:44Z","title":"Global Context Vision Transformers","summary":"  We propose global context vision transformer (GC ViT), a novel architecture\nthat enhances parameter and compute utilization for computer vision. Our method\nleverages global context self-attention modules, joint with standard local\nself-attention, to effectively and efficiently model both long and short-range\nspatial interactions, without the need for expensive operations such as\ncomputing attention masks or shifting local windows. In addition, we address\nthe lack of the inductive bias in ViTs, and propose to leverage a modified\nfused inverted residual blocks in our architecture. Our proposed GC ViT\nachieves state-of-the-art results across image classification, object detection\nand semantic segmentation tasks. On ImageNet-1K dataset for classification, the\nvariants of GC ViT with 51M, 90M and 201M parameters achieve 84.3%, 85.0% and\n85.7% Top-1 accuracy, respectively, at 224 image resolution and without any\npre-training, hence surpassing comparably-sized prior art such as CNN-based\nConvNeXt and ViT-based MaxViT and Swin Transformer by a large margin.\nPre-trained GC ViT backbones in downstream tasks of object detection, instance\nsegmentation, and semantic segmentation using MS COCO and ADE20K datasets\noutperform prior work consistently. Specifically, GC ViT with a 4-scale DINO\ndetection head achieves a box AP of 58.3 on MS COCO dataset.\n","authors":["Ali Hatamizadeh","Hongxu Yin","Greg Heinrich","Jan Kautz","Pavlo Molchanov"],"pdf_url":"https://arxiv.org/pdf/2206.09959v5.pdf","comment":"Accepted to ICML 2023"},{"id":"http://arxiv.org/abs/2303.10909v2","updated":"2023-06-06T08:11:51Z","published":"2023-03-20T06:57:10Z","title":"Graph Neural Rough Differential Equations for Traffic Forecasting","summary":"  Traffic forecasting is one of the most popular spatio-temporal tasks in the\nfield of machine learning. A prevalent approach in the field is to combine\ngraph convolutional networks and recurrent neural networks for the\nspatio-temporal processing. There has been fierce competition and many novel\nmethods have been proposed. In this paper, we present the method of\nspatio-temporal graph neural rough differential equation (STG-NRDE). Neural\nrough differential equations (NRDEs) are a breakthrough concept for processing\ntime-series data. Their main concept is to use the log-signature transform to\nconvert a time-series sample into a relatively shorter series of feature\nvectors. We extend the concept and design two NRDEs: one for the temporal\nprocessing and the other for the spatial processing. After that, we combine\nthem into a single framework. We conduct experiments with 6 benchmark datasets\nand 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming\nall those 27 baselines by non-trivial margins.\n","authors":["Jeongwhan Choi","Noseong Park"],"pdf_url":"https://arxiv.org/pdf/2303.10909v2.pdf","comment":"Accepted to ACM Transactions on Intelligent Systems and Technology\n  (ACM TIST). arXiv admin note: substantial text overlap with arXiv:2112.03558"},{"id":"http://arxiv.org/abs/2306.03481v1","updated":"2023-06-06T08:06:43Z","published":"2023-06-06T08:06:43Z","title":"Transition role of entangled data in quantum machine learning","summary":"  Entanglement serves as the resource to empower quantum computing. Recent\nprogress has highlighted its positive impact on learning quantum dynamics,\nwherein the integration of entanglement into quantum operations or measurements\nof quantum machine learning (QML) models leads to substantial reductions in\ntraining data size, surpassing a specified prediction error threshold. However,\nan analytical understanding of how the entanglement degree in data affects\nmodel performance remains elusive. In this study, we address this knowledge gap\nby establishing a quantum no-free-lunch (NFL) theorem for learning quantum\ndynamics using entangled data. Contrary to previous findings, we prove that the\nimpact of entangled data on prediction error exhibits a dual effect, depending\non the number of permitted measurements. With a sufficient number of\nmeasurements, increasing the entanglement of training data consistently reduces\nthe prediction error or decreases the required size of the training data to\nachieve the same prediction error. Conversely, when few measurements are\nallowed, employing highly entangled data could lead to an increased prediction\nerror. The achieved results provide critical guidance for designing advanced\nQML protocols, especially for those tailored for execution on early-stage\nquantum computers with limited access to quantum resources.\n","authors":["Xinbiao Wang","Yuxuan Du","Zhuozhuo Tu","Yong Luo","Xiao Yuan","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.03481v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03480v1","updated":"2023-06-06T08:03:18Z","published":"2023-06-06T08:03:18Z","title":"GSHOT: Few-shot Generative Modeling of Labeled Graphs","summary":"  Deep graph generative modeling has gained enormous attraction in recent years\ndue to its impressive ability to directly learn the underlying hidden graph\ndistribution. Despite their initial success, these techniques, like much of the\nexisting deep generative methods, require a large number of training samples to\nlearn a good model. Unfortunately, large number of training samples may not\nalways be available in scenarios such as drug discovery for rare diseases. At\nthe same time, recent advances in few-shot learning have opened door to\napplications where available training data is limited. In this work, we\nintroduce the hitherto unexplored paradigm of few-shot graph generative\nmodeling. Towards this, we develop GSHOT, a meta-learning based framework for\nfew-shot labeled graph generative modeling. GSHOT learns to transfer\nmeta-knowledge from similar auxiliary graph datasets. Utilizing these prior\nexperiences, GSHOT quickly adapts to an unseen graph dataset through self-paced\nfine-tuning. Through extensive experiments on datasets from diverse domains\nhaving limited training samples, we establish that GSHOT generates graphs of\nsuperior fidelity compared to existing baselines.\n","authors":["Sahil Manchanda","Shubham Gupta","Sayan Ranu","Srikanta Bedathur"],"pdf_url":"https://arxiv.org/pdf/2306.03480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02447v3","updated":"2023-06-06T07:45:31Z","published":"2022-08-04T04:35:53Z","title":"DL-DRL: A double-level deep reinforcement learning approach for\n  large-scale task scheduling of multi-UAV","summary":"  Exploiting unmanned aerial vehicles (UAVs) to execute tasks is gaining\ngrowing popularity recently. To solve the underlying task scheduling problem,\nthe deep reinforcement learning (DRL) based methods demonstrate notable\nadvantage over the conventional heuristics as they rely less on hand-engineered\nrules. However, their decision space will become prohibitively huge as the\nproblem scales up, thus deteriorating the computation efficiency. To alleviate\nthis issue, we propose a double-level deep reinforcement learning (DL-DRL)\napproach based on a divide and conquer framework (DCF), where we decompose the\ntask scheduling of multi-UAV into task allocation and route planning.\nParticularly, we design an encoder-decoder structured policy network in our\nupper-level DRL model to allocate the tasks to different UAVs, and we exploit\nanother attention based policy network in our lower-level DRL model to\nconstruct the route for each UAV, with the objective to maximize the number of\nexecuted tasks given the maximum flight distance of the UAV. To effectively\ntrain the two models, we design an interactive training strategy (ITS), which\nincludes pre-training, intensive training and alternate training. Experimental\nresults show that our DL-DRL performs favorably against the learning-based and\nconventional baselines including the OR-Tools, in terms of solution quality and\ncomputation efficiency. We also verify the generalization performance of our\napproach by applying it to larger sizes of up to 1000 tasks. Moreover, we also\nshow via an ablation study that our ITS can help achieve a balance between the\nperformance and training efficiency.\n","authors":["Xiao Mao","Zhiguang Cao","Mingfeng Fan","Guohua Wu","Witold Pedrycz"],"pdf_url":"https://arxiv.org/pdf/2208.02447v3.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.03466v1","updated":"2023-06-06T07:36:47Z","published":"2023-06-06T07:36:47Z","title":"Convergent Bregman Plug-and-Play Image Restoration for Poisson Inverse\n  Problems","summary":"  Plug-and-Play (PnP) methods are efficient iterative algorithms for solving\nill-posed image inverse problems. PnP methods are obtained by using deep\nGaussian denoisers instead of the proximal operator or the gradient-descent\nstep within proximal algorithms. Current PnP schemes rely on data-fidelity\nterms that have either Lipschitz gradients or closed-form proximal operators,\nwhich is not applicable to Poisson inverse problems. Based on the observation\nthat the Gaussian noise is not the adequate noise model in this setting, we\npropose to generalize PnP using theBregman Proximal Gradient (BPG) method. BPG\nreplaces the Euclidean distance with a Bregman divergence that can better\ncapture the smoothness properties of the problem. We introduce the Bregman\nScore Denoiser specifically parametrized and trained for the new Bregman\ngeometry and prove that it corresponds to the proximal operator of a nonconvex\npotential. We propose two PnP algorithms based on the Bregman Score Denoiser\nfor solving Poisson inverse problems. Extending the convergence results of BPG\nin the nonconvex settings, we show that the proposed methods converge,\ntargeting stationary points of an explicit global functional. Experimental\nevaluations conducted on various Poisson inverse problems validate the\nconvergence results and showcase effective restoration performance.\n","authors":["Samuel Hurault","Ulugbek Kamilov","Arthur Leclaire","Nicolas Papadakis"],"pdf_url":"https://arxiv.org/pdf/2306.03466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10071v2","updated":"2023-06-06T07:31:15Z","published":"2023-05-17T09:17:59Z","title":"Cold PAWS: Unsupervised class discovery and addressing the cold-start\n  problem for semi-supervised learning","summary":"  In many machine learning applications, labeling datasets can be an arduous\nand time-consuming task. Although research has shown that semi-supervised\nlearning techniques can achieve high accuracy with very few labels within the\nfield of computer vision, little attention has been given to how images within\na dataset should be selected for labeling. In this paper, we propose a novel\napproach based on well-established self-supervised learning, clustering, and\nmanifold learning techniques that address this challenge of selecting an\ninformative image subset to label in the first instance, which is known as the\ncold-start or unsupervised selective labelling problem. We test our approach\nusing several publicly available datasets, namely CIFAR10, Imagenette,\nDeepWeeds, and EuroSAT, and observe improved performance with both supervised\nand semi-supervised learning strategies when our label selection strategy is\nused, in comparison to random sampling. We also obtain superior performance for\nthe datasets considered with a much simpler approach compared to other methods\nin the literature.\n","authors":["Evelyn J. Mannix","Howard D. Bondell"],"pdf_url":"https://arxiv.org/pdf/2305.10071v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03460v1","updated":"2023-06-06T07:28:49Z","published":"2023-06-06T07:28:49Z","title":"Natural Language Commanding via Program Synthesis","summary":"  We present Semantic Interpreter, a natural language-friendly AI system for\nproductivity software such as Microsoft Office that leverages large language\nmodels (LLMs) to execute user intent across application features. While LLMs\nare excellent at understanding user intent expressed as natural language, they\nare not sufficient for fulfilling application-specific user intent that\nrequires more than text-to-text transformations. We therefore introduce the\nOffice Domain Specific Language (ODSL), a concise, high-level language\nspecialized for performing actions in and interacting with entities in Office\napplications. Semantic Interpreter leverages an Analysis-Retrieval prompt\nconstruction method with LLMs for program synthesis, translating natural\nlanguage user utterances to ODSL programs that can be transpiled to application\nAPIs and then executed. We focus our discussion primarily on a research\nexploration for Microsoft PowerPoint.\n","authors":["Apurva Gandhi","Thong Q. Nguyen","Huitian Jiao","Robert Steen","Ameya Bhatawdekar"],"pdf_url":"https://arxiv.org/pdf/2306.03460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.02104v2","updated":"2023-06-06T07:27:32Z","published":"2023-04-04T20:17:44Z","title":"Deep learning for diffusion in porous media","summary":"  We adopt convolutional neural networks (CNN) to predict the basic properties\nof the porous media. Two different media types are considered: one mimics the\nsand packings, and the other mimics the systems derived from the extracellular\nspace of biological tissues. The Lattice Boltzmann Method is used to obtain the\nlabeled data necessary for performing supervised learning. We distinguish two\ntasks. In the first, networks based on the analysis of the system's geometry\npredict porosity and effective diffusion coefficient. In the second, networks\nreconstruct the concentration map. In the first task, we propose two types of\nCNN models: the C-Net and the encoder part of the U-Net. Both networks are\nmodified by adding a self-normalization module [Graczyk \\textit{et al.}, Sci\nRep 12, 10583 (2022)]. The models predict with reasonable accuracy but only\nwithin the data type, they are trained on. For instance, the model trained on\nsand packings-like samples overshoots or undershoots for biological-like\nsamples. In the second task, we propose the usage of the U-Net architecture. It\naccurately reconstructs the concentration fields. In contrast to the first\ntask, the network trained on one data type works well for the other. For\ninstance, the model trained on sand packings-like samples works perfectly on\nbiological-like samples. Eventually, for both types of the data, we fit\nexponents in the Archie's law to find tortuosity that is used to describe the\ndependence of the effective diffusion on porosity.\n","authors":["Krzysztof M. Graczyk","Dawid Strzelczyk","Maciej Matyka"],"pdf_url":"https://arxiv.org/pdf/2304.02104v2.pdf","comment":"15 pages, 17 figures, to appear in Sci. Rep"},{"id":"http://arxiv.org/abs/2209.15404v2","updated":"2023-06-06T07:23:21Z","published":"2022-09-30T12:03:52Z","title":"Entropy-driven Unsupervised Keypoint Representation Learning in Videos","summary":"  Extracting informative representations from videos is fundamental for\neffectively learning various downstream tasks. We present a novel approach for\nunsupervised learning of meaningful representations from videos, leveraging the\nconcept of image spatial entropy (ISE) that quantifies the per-pixel\ninformation in an image. We argue that \\textit{local entropy} of pixel\nneighborhoods and their temporal evolution create valuable intrinsic\nsupervisory signals for learning prominent features. Building on this idea, we\nabstract visual features into a concise representation of keypoints that act as\ndynamic information transmitters, and design a deep learning model that learns,\npurely unsupervised, spatially and temporally consistent representations\n\\textit{directly} from video frames. Two original information-theoretic losses,\ncomputed from local entropy, guide our model to discover consistent keypoint\nrepresentations; a loss that maximizes the spatial information covered by the\nkeypoints and a loss that optimizes the keypoints' information transportation\nover time. We compare our keypoint representation to strong baselines for\nvarious downstream tasks, \\eg, learning object dynamics. Our empirical results\nshow superior performance for our information-driven keypoints that resolve\nchallenges like attendance to static and dynamic objects or objects abruptly\nentering and leaving the scene.\n","authors":["Ali Younes","Simone Schaub-Meyer","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2209.15404v2.pdf","comment":"29 pages, 14 figures, Accepted at ICML 2023"}]},"2023-06-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.04640v1","updated":"2023-06-07T17:59:57Z","published":"2023-06-07T17:59:57Z","title":"ModuleFormer: Learning Modular Large Language Models From Uncurated Data","summary":"  Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.\n","authors":["Yikang Shen","Zheyu Zhang","Tianyou Cao","Shawn Tan","Zhenfang Chen","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2306.04640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04637v1","updated":"2023-06-07T17:59:31Z","published":"2023-06-07T17:59:31Z","title":"Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection","summary":"  Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.\n","authors":["Yu Bai","Fan Chen","Huan Wang","Caiming Xiong","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2306.04637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04634v1","updated":"2023-06-07T17:58:48Z","published":"2023-06-07T17:58:48Z","title":"On the Reliability of Watermarks for Large Language Models","summary":"  Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Manli Shu","Khalid Saifullah","Kezhi Kong","Kasun Fernando","Aniruddha Saha","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2306.04634v1.pdf","comment":"14 pages in the main body. Code is available at\n  https://github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2305.07622v3","updated":"2023-06-07T17:55:58Z","published":"2023-05-12T17:21:33Z","title":"PALR: Personalization Aware LLMs for Recommendation","summary":"  Large language models (LLMs) have recently received significant attention for\ntheir exceptional capabilities. Despite extensive efforts in developing\ngeneral-purpose LLMs that can be utilized in various natural language\nprocessing (NLP) tasks, there has been less research exploring their potential\nin recommender systems. In this paper, we propose a novel framework, named\nPALR, which aiming to combine user history behaviors (such as clicks,\npurchases, ratings, etc.) with LLMs to generate user preferred items.\nSpecifically, we first use user/item interactions as guidance for candidate\nretrieval. Then we adopt a LLM-based ranking model to generate recommended\nitems. Unlike existing approaches that typically adopt general-purpose LLMs for\nzero/few-shot recommendation testing or training on small-sized language models\n(with less than 1 billion parameters), which cannot fully elicit LLMs'\nreasoning abilities and leverage rich item side parametric knowledge, we\nfine-tune a 7 billion parameters LLM for the ranking purpose. This model takes\nretrieval candidates in natural language format as input, with instruction\nwhich explicitly asking to select results from input candidates during\ninference. Our experimental results demonstrate that our solution outperforms\nstate-of-the-art models on various sequential recommendation tasks.\n","authors":["Fan Yang","Zheng Chen","Ziyan Jiang","Eunah Cho","Xiaojiang Huang","Yanbin Lu"],"pdf_url":"https://arxiv.org/pdf/2305.07622v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17491v2","updated":"2023-06-07T17:50:44Z","published":"2023-03-30T16:01:52Z","title":"Language Models can Solve Computer Tasks","summary":"  Agents capable of carrying out general tasks on a computer can improve\nefficiency and productivity by automating repetitive tasks and assisting in\ncomplex problem-solving. Ideally, such agents should be able to solve new\ncomputer tasks presented to them through natural language commands. However,\nprevious approaches to this problem require large amounts of expert\ndemonstrations and task-specific reward functions, both of which are\nimpractical for new tasks. In this work, we show that a pre-trained large\nlanguage model (LLM) agent can execute computer tasks guided by natural\nlanguage using a simple prompting scheme where the agent Recursively Criticizes\nand Improves its output (RCI). The RCI approach significantly outperforms\nexisting LLM methods for automating computer tasks and surpasses supervised\nlearning (SL) and reinforcement learning (RL) approaches on the MiniWoB++\nbenchmark. We compare multiple LLMs and find that RCI with the\nInstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful\nof demonstrations per task rather than tens of thousands, and without a\ntask-specific reward function. Furthermore, we demonstrate RCI prompting's\neffectiveness in enhancing LLMs' reasoning abilities on a suite of natural\nlanguage reasoning tasks, outperforming chain of thought (CoT) prompting. We\nfind that RCI combined with CoT performs better than either separately. Our\ncode can be found here: https://github.com/posgnu/rci-agent.\n","authors":["Geunwoo Kim","Pierre Baldi","Stephen McAleer"],"pdf_url":"https://arxiv.org/pdf/2303.17491v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04618v1","updated":"2023-06-07T17:47:03Z","published":"2023-06-07T17:47:03Z","title":"Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations","summary":"  This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.\n","authors":["Lifan Yuan","Yangyi Chen","Ganqu Cui","Hongcheng Gao","Fangyuan Zou","Xingyi Cheng","Heng Ji","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2306.04618v1.pdf","comment":"Code is available at \\url{https://github.com/lifan-yuan/OOD_NLP}"},{"id":"http://arxiv.org/abs/2306.03901v2","updated":"2023-06-07T17:22:22Z","published":"2023-06-06T17:58:24Z","title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory","summary":"  Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .\n","authors":["Chenxu Hu","Jie Fu","Chenzhuang Du","Simian Luo","Junbo Zhao","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.03901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04610v1","updated":"2023-06-07T17:22:03Z","published":"2023-06-07T17:22:03Z","title":"The Two Word Test: A Semantic Benchmark for Large Language Models","summary":"  Large Language Models (LLMs) have shown remarkable abilities recently,\nincluding passing advanced professional exams and demanding benchmark tests.\nThis performance has led many to suggest that they are close to achieving\nhumanlike or 'true' understanding of language, and even Artificial General\nIntelligence (AGI). Here, we provide a new open-source benchmark that can\nassess semantic abilities of LLMs using two-word phrases using a task that can\nbe performed relatively easily by humans without advanced training. Combining\nmultiple words into a single concept is a fundamental aspect of human language\nand intelligence. The test requires meaningfulness judgments of 1768 noun-noun\ncombinations that have been rated as meaningful (e.g., baby boy) or not\nmeaningful (e.g., goat sky). by 150 human raters. We provide versions of the\ntask that probe meaningfulness ratings on a 0-4 scale as well as binary\njudgments. We conducted a series of experiments using the TWT on GPT-4,\nGPT-3.5, and Bard, with both versions. Results demonstrated that, compared to\nhumans, all models perform poorly at rating meaningfulness of these phrases.\nGPT-3.5 and Bard are also unable to make binary discriminations between\nsensible and nonsense phrases as making sense. GPT-4 makes a substantial\nimprovement in binary discrimination of combinatorial phrases but is still\nsignificantly worse than human performance. The TWT can be used to understand\nthe limitations and weaknesses of current LLMs, and potentially improve them.\nThe test also reminds us that caution is warranted in attributing 'true\nunderstanding' or AGI to LLMs. TWT is available at:\nhttps://github.com/NickRiccardi/two-word-test\n","authors":["Nicholas Riccardi","Rutvik H. Desai"],"pdf_url":"https://arxiv.org/pdf/2306.04610v1.pdf","comment":"12 pages, 5 figures, 3 tables, submitted to NeurIPS 2023 Datasets and\n  Benchmarks Track"},{"id":"http://arxiv.org/abs/2208.09770v2","updated":"2023-06-07T17:13:29Z","published":"2022-08-21T01:00:54Z","title":"Z-Code++: A Pre-trained Language Model Optimized for Abstractive\n  Summarization","summary":"  This paper presents Z-Code++, a new pre-trained language model optimized for\nabstractive text summarization. The model extends the state of the art\nencoder-decoder model using three techniques. First, we use a two-phase\npre-training process to improve model's performance on low-resource\nsummarization tasks. The model is first pre-trained using text corpora for\nlanguage understanding, and then is continually pre-trained on summarization\ncorpora for grounded text generation. Second, we replace self-attention layers\nin the encoder with disentangled attention layers, where each word is\nrepresented using two vectors that encode its content and position,\nrespectively. Third, we use fusion-in-encoder, a simple yet effective method of\nencoding long sequences in a hierarchical manner. Z-Code++ creates new state of\nthe art on 9 out of 13 text summarization tasks across 5 languages. Our model\nis parameter-efficient in that it outperforms the 600x larger PaLM-540B on\nXSum, and the finetuned 200x larger GPT3-175B on SAMSum. In zero-shot and\nfew-shot settings, our model substantially outperforms the competing models.\n","authors":["Pengcheng He","Baolin Peng","Liyang Lu","Song Wang","Jie Mei","Yang Liu","Ruochen Xu","Hany Hassan Awadalla","Yu Shi","Chenguang Zhu","Wayne Xiong","Michael Zeng","Jianfeng Gao","Xuedong Huang"],"pdf_url":"https://arxiv.org/pdf/2208.09770v2.pdf","comment":"16 pages, 3 figures. Accepted as long paper in main conference of ACL\n  2023"},{"id":"http://arxiv.org/abs/2306.04597v1","updated":"2023-06-07T16:50:03Z","published":"2023-06-07T16:50:03Z","title":"Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions","summary":"  Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.\n","authors":["Himanshu Thakur","Atishay Jain","Praneetha Vaddamanu","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2306.04597v1.pdf","comment":"Accepted to ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2211.03759v2","updated":"2023-06-07T16:36:13Z","published":"2022-11-07T18:31:07Z","title":"Easily Accessible Text-to-Image Generation Amplifies Demographic\n  Stereotypes at Large Scale","summary":"  Machine learning models that convert user-written text descriptions into\nimages are now widely available online and used by millions of users to\ngenerate millions of images a day. We investigate the potential for these\nmodels to amplify dangerous and complex stereotypes. We find a broad range of\nordinary prompts produce stereotypes, including prompts simply mentioning\ntraits, descriptors, occupations, or objects. For example, we find cases of\nprompting for basic traits or social roles resulting in images reinforcing\nwhiteness as ideal, prompting for occupations resulting in amplification of\nracial and gender disparities, and prompting for objects resulting in\nreification of American norms. Stereotypes are present regardless of whether\nprompts explicitly mention identity and demographic language or avoid such\nlanguage. Moreover, stereotypes persist despite mitigation strategies; neither\nuser attempts to counter stereotypes by requesting images with specific\ncounter-stereotypes nor institutional attempts to add system ``guardrails''\nhave prevented the perpetuation of stereotypes. Our analysis justifies concerns\nregarding the impacts of today's models, presenting striking exemplars, and\nconnecting these findings with deep insights into harms drawn from social\nscientific and humanist disciplines. This work contributes to the effort to\nshed light on the uniquely complex biases in language-vision models and\ndemonstrates the ways that the mass deployment of text-to-image generation\nmodels results in mass dissemination of stereotypes and resulting harms.\n","authors":["Federico Bianchi","Pratyusha Kalluri","Esin Durmus","Faisal Ladhak","Myra Cheng","Debora Nozza","Tatsunori Hashimoto","Dan Jurafsky","James Zou","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2211.03759v2.pdf","comment":"FAccT 2023 paper. The published version is available at\n  10.1145/3593013.3594095"},{"id":"http://arxiv.org/abs/2306.04573v1","updated":"2023-06-07T16:21:59Z","published":"2023-06-07T16:21:59Z","title":"Gender, names and other mysteries: Towards the ambiguous for\n  gender-inclusive translation","summary":"  The vast majority of work on gender in MT focuses on 'unambiguous' inputs,\nwhere gender markers in the source language are expected to be resolved in the\noutput. Conversely, this paper explores the widespread case where the source\nsentence lacks explicit gender markers, but the target sentence contains them\ndue to richer grammatical gender. We particularly focus on inputs containing\nperson names.\n  Investigating such sentence pairs casts a new light on research into MT\ngender bias and its mitigation. We find that many name-gender co-occurrences in\nMT data are not resolvable with 'unambiguous gender' in the source language,\nand that gender-ambiguous examples can make up a large proportion of training\nexamples. From this, we discuss potential steps toward gender-inclusive\ntranslation which accepts the ambiguity in both gender and translation.\n","authors":["Danielle Saunders","Katrina Olsen"],"pdf_url":"https://arxiv.org/pdf/2306.04573v1.pdf","comment":"GITT workshop at EAMT 2023"},{"id":"http://arxiv.org/abs/2306.04563v1","updated":"2023-06-07T16:10:21Z","published":"2023-06-07T16:10:21Z","title":"ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models","summary":"  Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.\n","authors":["Sophie Jentzsch","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.04563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13040v2","updated":"2023-06-07T16:04:30Z","published":"2023-05-22T13:47:51Z","title":"SpokenWOZ: A Large-Scale Speech-Text Dataset for Spoken Task-Oriented\n  Dialogue in Multiple Domains","summary":"  Task-oriented dialogue (TOD) models have made significant progress in recent\nyears. However, previous studies primarily focus on datasets written by\nannotators, which has resulted in a gap between academic research and\nreal-world spoken conversation scenarios. While several small-scale spoken TOD\ndatasets are proposed to address robustness issues such as ASR errors, they\nignore the unique challenges in spoken conversation. To tackle the limitations,\nwe introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD,\ncontaining 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from\nhuman-to-human spoken conversations. SpokenWOZ further incorporates common\nspoken characteristics such as word-by-word processing and reasoning in spoken\nlanguage. Based on these characteristics, we present cross-turn slot and\nreasoning slot detection as new challenges. We conduct experiments on various\nbaselines, including text-modal models, newly proposed dual-modal models, and\nLLMs, e.g., ChatGPT. The results show that the current models still have\nsubstantial room for improvement in spoken conversation, where the most\nadvanced dialogue state tracker only achieves 25.65% in joint goal accuracy and\nthe SOTA end-to-end model only correctly completes the user request in 52.1% of\ndialogues. The dataset, code, and leaderboard are available:\nhttps://spokenwoz.github.io/SpokenWOZ-github.io/.\n","authors":["Shuzheng Si","Wentao Ma","Haoyu Gao","Yuchuan Wu","Ting-En Lin","Yinpei Dai","Hangyu Li","Rui Yan","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2305.13040v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04551v1","updated":"2023-06-07T15:55:34Z","published":"2023-06-07T15:55:34Z","title":"Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning","summary":"  Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.\n","authors":["Brihat Sharma","Yanjun Gao","Timothy Miller","Matthew M. Churpek","Majid Afshar","Dmitriy Dligach"],"pdf_url":"https://arxiv.org/pdf/2306.04551v1.pdf","comment":"Accepted to 2023 ClinicalNLP Workshop"},{"id":"http://arxiv.org/abs/2306.04544v1","updated":"2023-06-07T15:49:04Z","published":"2023-06-07T15:49:04Z","title":"Contrastive Bootstrapping for Label Refinement","summary":"  Traditional text classification typically categorizes texts into pre-defined\ncoarse-grained classes, from which the produced models cannot handle the\nreal-world scenario where finer categories emerge periodically for accurate\nservices. In this work, we investigate the setting where fine-grained\nclassification is done only using the annotation of coarse-grained categories\nand the coarse-to-fine mapping. We propose a lightweight contrastive\nclustering-based bootstrapping method to iteratively refine the labels of\npassages. During clustering, it pulls away negative passage-prototype pairs\nunder the guidance of the mapping from both global and local perspectives.\nExperiments on NYT and 20News show that our method outperforms the\nstate-of-the-art methods by a large margin.\n","authors":["Shudi Hou","Yu Xia","Muhao Chen","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2306.04544v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.04539v1","updated":"2023-06-07T15:44:53Z","published":"2023-06-07T15:44:53Z","title":"Multimodal Learning Without Labeled Multimodal Data: Guarantees and\n  Applications","summary":"  In many machine learning systems that jointly learn from multiple modalities,\na core research question is to understand the nature of multimodal\ninteractions: the emergence of new task-relevant information during learning\nfrom both modalities that was not present in either alone. We study this\nchallenge of interaction quantification in a semi-supervised setting with only\nlabeled unimodal data and naturally co-occurring multimodal data (e.g.,\nunlabeled images and captions, video and corresponding audio) but when labeling\nthem is time-consuming. Using a precise information-theoretic definition of\ninteractions, our key contributions are the derivations of lower and upper\nbounds to quantify the amount of multimodal interactions in this\nsemi-supervised setting. We propose two lower bounds based on the amount of\nshared information between modalities and the disagreement between separately\ntrained unimodal classifiers, and derive an upper bound through connections to\napproximate algorithms for min-entropy couplings. We validate these estimated\nbounds and show how they accurately track true interactions. Finally, two\nsemi-supervised multimodal applications are explored based on these theoretical\nresults: (1) analyzing the relationship between multimodal performance and\nestimated interactions, and (2) self-supervised learning that embraces\ndisagreement between modalities beyond agreement as is typically done.\n","authors":["Paul Pu Liang","Chun Kai Ling","Yun Cheng","Alex Obolenskiy","Yudong Liu","Rohan Pandey","Alex Wilf","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2306.04539v1.pdf","comment":"Code available at: https://github.com/pliang279/PID"},{"id":"http://arxiv.org/abs/2306.04537v1","updated":"2023-06-07T15:42:31Z","published":"2023-06-07T15:42:31Z","title":"Long-form analogies generated by chatGPT lack human-like\n  psycholinguistic properties","summary":"  Psycholinguistic analyses provide a means of evaluating large language model\n(LLM) output and making systematic comparisons to human-generated text. These\nmethods can be used to characterize the psycholinguistic properties of LLM\noutput and illustrate areas where LLMs fall short in comparison to\nhuman-generated text. In this work, we apply psycholinguistic methods to\nevaluate individual sentences from long-form analogies about biochemical\nconcepts. We compare analogies generated by human subjects enrolled in\nintroductory biochemistry courses to analogies generated by chatGPT. We perform\na supervised classification analysis using 78 features extracted from\nCoh-metrix that analyze text cohesion, language, and readability (Graesser et.\nal., 2004). Results illustrate high performance for classifying\nstudent-generated and chatGPT-generated analogies. To evaluate which features\ncontribute most to model performance, we use a hierarchical clustering\napproach. Results from this analysis illustrate several linguistic differences\nbetween the two sources.\n","authors":["S. M. Seals","Valerie L. Shalin"],"pdf_url":"https://arxiv.org/pdf/2306.04537v1.pdf","comment":"arxiv version of conference paper to appear at CogSci 2023 conference"},{"id":"http://arxiv.org/abs/2306.04535v1","updated":"2023-06-07T15:41:40Z","published":"2023-06-07T15:41:40Z","title":"PromptAttack: Probing Dialogue State Trackers with Adversarial Prompts","summary":"  A key component of modern conversational systems is the Dialogue State\nTracker (or DST), which models a user's goals and needs. Toward building more\nrobust and reliable DSTs, we introduce a prompt-based learning approach to\nautomatically generate effective adversarial examples to probe DST models. Two\nkey characteristics of this approach are: (i) it only needs the output of the\nDST with no need for model parameters, and (ii) it can learn to generate\nnatural language utterances that can target any DST. Through experiments over\nstate-of-the-art DSTs, the proposed framework leads to the greatest reduction\nin accuracy and the best attack success rate while maintaining good fluency and\na low perturbation ratio. We also show how much the generated adversarial\nexamples can bolster a DST through adversarial training. These results indicate\nthe strength of prompt-based attacks on DSTs and leave open avenues for\ncontinued refinement.\n","authors":["Xiangjue Dong","Yun He","Ziwei Zhu","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2306.04535v1.pdf","comment":"To appear in Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.04530v1","updated":"2023-06-07T15:39:02Z","published":"2023-06-07T15:39:02Z","title":"Lenient Evaluation of Japanese Speech Recognition: Modeling Naturally\n  Occurring Spelling Inconsistency","summary":"  Word error rate (WER) and character error rate (CER) are standard metrics in\nSpeech Recognition (ASR), but one problem has always been alternative\nspellings: If one's system transcribes adviser whereas the ground truth has\nadvisor, this will count as an error even though the two spellings really\nrepresent the same word.\n  Japanese is notorious for ``lacking orthography'': most words can be spelled\nin multiple ways, presenting a problem for accurate ASR evaluation. In this\npaper we propose a new lenient evaluation metric as a more defensible CER\nmeasure for Japanese ASR. We create a lattice of plausible respellings of the\nreference transcription, using a combination of lexical resources, a Japanese\ntext-processing system, and a neural machine translation model for\nreconstructing kanji from hiragana or katakana. In a manual evaluation, raters\nrated 95.4% of the proposed spelling variants as plausible. ASR results show\nthat our method, which does not penalize the system for choosing a valid\nalternate spelling of a word, affords a 2.4%-3.1% absolute reduction in CER\ndepending on the task.\n","authors":["Shigeki Karita","Richard Sproat","Haruko Ishikawa"],"pdf_url":"https://arxiv.org/pdf/2306.04530v1.pdf","comment":"ACL Workshop on Computation and Written Language (CAWL) 2023"},{"id":"http://arxiv.org/abs/2303.04562v3","updated":"2023-06-07T15:34:38Z","published":"2023-03-08T13:21:27Z","title":"Extrapolative Controlled Sequence Generation via Iterative Refinement","summary":"  We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.\n","authors":["Vishakh Padmakumar","Richard Yuanzhe Pang","He He","Ankur P. Parikh"],"pdf_url":"https://arxiv.org/pdf/2303.04562v3.pdf","comment":"ICML 2023 - Camera Ready Version"},{"id":"http://arxiv.org/abs/2306.04523v1","updated":"2023-06-07T15:33:07Z","published":"2023-06-07T15:33:07Z","title":"Can current NLI systems handle German word order? Investigating language\n  model performance on a new German challenge set of minimal pairs","summary":"  Compared to English, German word order is freer and therefore poses\nadditional challenges for natural language inference (NLI). We create WOGLI\n(Word Order in German Language Inference), the first adversarial NLI dataset\nfor German word order that has the following properties: (i) each premise has\nan entailed and a non-entailed hypothesis; (ii) premise and hypotheses differ\nonly in word order and necessary morphological changes to mark case and number.\nIn particular, each premise andits two hypotheses contain exactly the same\nlemmata. Our adversarial examples require the model to use morphological\nmarkers in order to recognise or reject entailment. We show that current German\nautoencoding models fine-tuned on translated NLI data can struggle on this\nchallenge set, reflecting the fact that translated NLI datasets will not mirror\nall necessary language phenomena in the target language. We also examine\nperformance after data augmentation as well as on related word order phenomena\nderived from WOGLI. Our datasets are publically available at\nhttps://github.com/ireinig/wogli.\n","authors":["Ines Reinig","Katja Markert"],"pdf_url":"https://arxiv.org/pdf/2306.04523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04508v1","updated":"2023-06-07T15:20:24Z","published":"2023-06-07T15:20:24Z","title":"Enhancing In-Context Learning with Answer Feedback for Multi-Span\n  Question Answering","summary":"  Whereas the recent emergence of large language models (LLMs) like ChatGPT has\nexhibited impressive general performance, it still has a large gap with\nfully-supervised models on specific tasks such as multi-span question\nanswering. Previous researches found that in-context learning is an effective\napproach to exploiting LLM, by using a few task-related labeled data as\ndemonstration examples to construct a few-shot prompt for answering new\nquestions. A popular implementation is to concatenate a few questions and their\ncorrect answers through simple templates, informing LLM of the desired output.\nIn this paper, we propose a novel way of employing labeled data such that it\nalso informs LLM of some undesired output, by extending demonstration examples\nwith feedback about answers predicted by an off-the-shelf model, e.g., correct,\nincorrect, or incomplete. Experiments on three multi-span question answering\ndatasets as well as a keyphrase extraction dataset show that our new prompting\nstrategy consistently improves LLM's in-context learning performance.\n","authors":["Zixian Huang","Jiaying Zhou","Gengyang Xiao","Gong Cheng"],"pdf_url":"https://arxiv.org/pdf/2306.04508v1.pdf","comment":"12 pages, submitted to NLPCC 2023"},{"id":"http://arxiv.org/abs/2306.04504v1","updated":"2023-06-07T15:11:26Z","published":"2023-06-07T15:11:26Z","title":"Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with\n  Fine-Tuned Generative Transformers","summary":"  ChatGPT is a large language model developed by OpenAI. Despite its impressive\nperformance across various tasks, no prior work has investigated its capability\nin the biomedical domain yet. To this end, this paper aims to evaluate the\nperformance of ChatGPT on various benchmark biomedical tasks, such as relation\nextraction, document classification, question answering, and summarization. To\nthe best of our knowledge, this is the first work that conducts an extensive\nevaluation of ChatGPT in the biomedical domain. Interestingly, we find based on\nour evaluation that in biomedical datasets that have smaller training sets,\nzero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative\ntransformer models, such as BioGPT and BioBART. This suggests that ChatGPT's\npre-training on large text corpora makes it quite specialized even in the\nbiomedical domain. Our findings demonstrate that ChatGPT has the potential to\nbe a valuable tool for various tasks in the biomedical domain that lack large\nannotated data.\n","authors":["Israt Jahan","Md Tahmid Rahman Laskar","Chun Peng","Jimmy Huang"],"pdf_url":"https://arxiv.org/pdf/2306.04504v1.pdf","comment":"Accepted by BioNLP@ACL 2023"},{"id":"http://arxiv.org/abs/2302.08950v3","updated":"2023-06-07T15:04:41Z","published":"2023-02-17T15:33:47Z","title":"Handling the Alignment for Wake Word Detection: A Comparison Between\n  Alignment-Based, Alignment-Free and Hybrid Approaches","summary":"  Wake word detection exists in most intelligent homes and portable devices. It\noffers these devices the ability to \"wake up\" when summoned at a low cost of\npower and computing. This paper focuses on understanding alignment's role in\ndeveloping a wake-word system that answers a generic phrase. We discuss three\napproaches. The first is alignment-based, where the model is trained with\nframe-wise cross-entropy. The second is alignment-free, where the model is\ntrained with CTC. The third, proposed by us, is a hybrid solution in which the\nmodel is trained with a small set of aligned data and then tuned with a\nsizeable unaligned dataset. We compare the three approaches and evaluate the\nimpact of the different aligned-to-unaligned ratios for hybrid training. Our\nresults show that the alignment-free system performs better than the\nalignment-based for the target operating point, and with a small fraction of\nthe data (20%), we can train a model that complies with our initial\nconstraints.\n","authors":["Vinicius Ribeiro","Yiteng Huang","Yuan Shangguan","Zhaojun Yang","Li Wan","Ming Sun"],"pdf_url":"https://arxiv.org/pdf/2302.08950v3.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2304.13835v2","updated":"2023-06-07T14:53:55Z","published":"2023-04-26T21:41:17Z","title":"Multi-Party Chat: Conversational Agents in Group Settings with Humans\n  and Models","summary":"  Current dialogue research primarily studies pairwise (two-party)\nconversations, and does not address the everyday setting where more than two\nspeakers converse together. In this work, we both collect and evaluate\nmulti-party conversations to study this more general case. We use the LIGHT\nenvironment to construct grounded conversations, where each participant has an\nassigned character to role-play. We thus evaluate the ability of language\nmodels to act as one or more characters in such conversations. Models require\ntwo skills that pairwise-trained models appear to lack: (1) being able to\ndecide when to talk; (2) producing coherent utterances grounded on multiple\ncharacters. We compare models trained on our new dataset to existing\npairwise-trained dialogue models, as well as large language models with\nfew-shot prompting. We find that our new dataset, MultiLIGHT, which we will\npublicly release, can help bring significant improvements in the group setting.\n","authors":["Jimmy Wei","Kurt Shuster","Arthur Szlam","Jason Weston","Jack Urbanek","Mojtaba Komeili"],"pdf_url":"https://arxiv.org/pdf/2304.13835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04441v1","updated":"2023-06-07T13:58:55Z","published":"2023-06-07T13:58:55Z","title":"STEPS: A Benchmark for Order Reasoning in Sequential Tasks","summary":"  Various human activities can be abstracted into a sequence of actions in\nnatural text, i.e. cooking, repairing, manufacturing, etc. Such action\nsequences heavily depend on the executing order, while disorder in action\nsequences leads to failure of further task execution by robots or AI agents.\nTherefore, to verify the order reasoning capability of current neural models in\nsequential tasks, we propose a challenging benchmark , named STEPS. STEPS\ninvolves two subtask settings, focusing on determining the rationality of given\nnext step in recipes and selecting the reasonable step from the multi-choice\nquestion, respectively. We describe the data construction and task\nformulations, and benchmark most of significant Large Language Models (LLMs).\nThe experimental results demonstrate 1) The commonsense reasoning of action\norders in sequential tasks are challenging to resolve via zero-shot prompting\nor few-shot in-context learning for LLMs; 2) Prompting method still\nsignificantly lags behind tuning-based method on STEPS.\n","authors":["Weizhi Wang","Hong Wang","Xifeng Yan"],"pdf_url":"https://arxiv.org/pdf/2306.04441v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2305.19926v2","updated":"2023-06-07T13:45:30Z","published":"2023-05-31T15:03:28Z","title":"ChatGPT an ENFJ, Bard an ISTJ: Empirical Study on Personalities of Large\n  Language Models","summary":"  Large Language Models (LLMs) have made remarkable advancements in the field\nof artificial intelligence, significantly reshaping the human-computer\ninteraction. We not only focus on the performance of LLMs, but also explore\ntheir features from a psychological perspective, acknowledging the importance\nof understanding their behavioral characteristics. Our study examines the\nbehavioral patterns displayed by LLMs by employing trait theory, a\npsychological framework. We first focus on evaluating the consistency of\npersonality types exhibited by ChatGPT. Furthermore, experiments include\ncross-lingual effects on seven additional languages, and the investigation of\nsix other LLMs. Moreover, the study investigates whether ChatGPT can exhibit\npersonality changes in response to instructions or contextual cues. The\nfindings show that ChatGPT consistently maintains its ENFJ personality\nregardless of instructions or contexts. By shedding light on the\npersonalization of LLMs, we anticipate that our study will serve as a catalyst\nfor further research in this field.\n","authors":["Jen-tse Huang","Wenxuan Wang","Man Ho Lam","Eric John Li","Wenxiang Jiao","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2305.19926v2.pdf","comment":"Added robustness analysis against fine-tuning (results of\n  text-davinci-003); Added results of ChatGLM; Added limitations"},{"id":"http://arxiv.org/abs/2306.04428v1","updated":"2023-06-07T13:36:37Z","published":"2023-06-07T13:36:37Z","title":"Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages","summary":"  This work introduces Zambezi Voice, an open-source multilingual speech\nresource for Zambian languages. It contains two collections of datasets:\nunlabelled audio recordings of radio news and talk shows programs (160 hours)\nand labelled data (over 80 hours) consisting of read speech recorded from text\nsourced from publicly available literature books. The dataset is created for\nspeech recognition but can be extended to multilingual speech processing\nresearch for both supervised and unsupervised learning approaches. To our\nknowledge, this is the first multilingual speech dataset created for Zambian\nlanguages. We exploit pretraining and cross-lingual transfer learning by\nfinetuning the Wav2Vec2.0 large-scale multilingual pre-trained model to build\nend-to-end (E2E) speech recognition models for our baseline models. The dataset\nis released publicly under a Creative Commons BY-NC-ND 4.0 license and can be\naccessed through the project repository. See\nhttps://github.com/unza-speech-lab/zambezi-voice\n","authors":["Claytone Sikasote","Kalinda Siaminwe","Stanly Mwape","Bangiwe Zulu","Mofya Phiri","Martin Phiri","David Zulu","Mayumbo Nyirenda","Antonios Anastasopoulos"],"pdf_url":"https://arxiv.org/pdf/2306.04428v1.pdf","comment":"Accepted at INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.04424v1","updated":"2023-06-07T13:31:02Z","published":"2023-06-07T13:31:02Z","title":"Examining Bias in Opinion Summarisation Through the Perspective of\n  Opinion Diversity","summary":"  Opinion summarisation is a task that aims to condense the information\npresented in the source documents while retaining the core message and\nopinions. A summary that only represents the majority opinions will leave the\nminority opinions unrepresented in the summary. In this paper, we use the\nstance towards a certain target as an opinion. We study bias in opinion\nsummarisation from the perspective of opinion diversity, which measures whether\nthe model generated summary can cover a diverse set of opinions. In addition,\nwe examine opinion similarity, a measure of how closely related two opinions\nare in terms of their stance on a given topic, and its relationship with\nopinion diversity. Through the lens of stances towards a topic, we examine\nopinion diversity and similarity using three debatable topics under COVID-19.\nExperimental results on these topics revealed that a higher degree of\nsimilarity of opinions did not indicate good diversity or fairly cover the\nvarious opinions originally presented in the source documents. We found that\nBART and ChatGPT can better capture diverse opinions presented in the source\ndocuments.\n","authors":["Nannan Huang","Lin Tian","Haytham Fayek","Xiuzhen Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04424v1.pdf","comment":"9 pages, 3 figures, accepted at WASSA, ACL 2023"},{"id":"http://arxiv.org/abs/2305.16253v2","updated":"2023-06-07T13:30:39Z","published":"2023-05-25T17:08:56Z","title":"Uncovering and Categorizing Social Biases in Text-to-SQL","summary":"  Content Warning: This work contains examples that potentially implicate\nstereotypes, associations, and other harms that could be offensive to\nindividuals in certain social groups.} Large pre-trained language models are\nacknowledged to carry social biases towards different demographics, which can\nfurther amplify existing stereotypes in our society and cause even more harm.\nText-to-SQL is an important task, models of which are mainly adopted by\nadministrative industries, where unfair decisions may lead to catastrophic\nconsequences. However, existing Text-to-SQL models are trained on clean,\nneutral datasets, such as Spider and WikiSQL. This, to some extent, cover up\nsocial bias in models under ideal conditions, which nevertheless may emerge in\nreal application scenarios. In this work, we aim to uncover and categorize\nsocial biases in Text-to-SQL models. We summarize the categories of social\nbiases that may occur in structured data for Text-to-SQL models. We build test\nbenchmarks and reveal that models with similar task accuracy can contain social\nbiases at very different rates. We show how to take advantage of our\nmethodology to uncover and assess social biases in the downstream Text-to-SQL\ntask. We will release our code and data.\n","authors":["Yan Liu","Yan Gao","Zhe Su","Xiaokang Chen","Elliott Ash","Jian-Guang Lou"],"pdf_url":"https://arxiv.org/pdf/2305.16253v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03882v2","updated":"2023-06-07T13:17:04Z","published":"2023-06-06T17:36:43Z","title":"Causal interventions expose implicit situation models for commonsense\n  language understanding","summary":"  Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.\n","authors":["Takateru Yamakoshi","James L. McClelland","Adele E. Goldberg","Robert D. Hawkins"],"pdf_url":"https://arxiv.org/pdf/2306.03882v2.pdf","comment":"Findings of ACL"},{"id":"http://arxiv.org/abs/2306.04399v1","updated":"2023-06-07T12:58:46Z","published":"2023-06-07T12:58:46Z","title":"Transfer Learning of Transformer-based Speech Recognition Models from\n  Czech to Slovak","summary":"  In this paper, we are comparing several methods of training the Slovak speech\nrecognition models based on the Transformers architecture. Specifically, we are\nexploring the approach of transfer learning from the existing Czech pre-trained\nWav2Vec 2.0 model into Slovak. We are demonstrating the benefits of the\nproposed approach on three Slovak datasets. Our Slovak models scored the best\nresults when initializing the weights from the Czech model at the beginning of\nthe pre-training phase. Our results show that the knowledge stored in the Cezch\npre-trained model can be successfully reused to solve tasks in Slovak while\noutperforming even much larger public multilingual models.\n","authors":["Jan Lehečka","Josef V. Psutka","Josef Psutka"],"pdf_url":"https://arxiv.org/pdf/2306.04399v1.pdf","comment":"Accepted to TSD 2023"},{"id":"http://arxiv.org/abs/2306.00458v2","updated":"2023-06-07T12:55:49Z","published":"2023-06-01T09:01:48Z","title":"Exploring Anisotropy and Outliers in Multilingual Language Models for\n  Cross-Lingual Semantic Sentence Similarity","summary":"  Previous work has shown that the representations output by contextual\nlanguage models are more anisotropic than static type embeddings, and typically\ndisplay outlier dimensions. This seems to be true for both monolingual and\nmultilingual models, although much less work has been done on the multilingual\ncontext. Why these outliers occur and how they affect the representations is\nstill an active area of research. We investigate outlier dimensions and their\nrelationship to anisotropy in multiple pre-trained multilingual language\nmodels. We focus on cross-lingual semantic similarity tasks, as these are\nnatural tasks for evaluating multilingual representations. Specifically, we\nexamine sentence representations. Sentence transformers which are fine-tuned on\nparallel resources (that are not always available) perform better on this task,\nand we show that their representations are more isotropic. However, we aim to\nimprove multilingual representations in general. We investigate how much of the\nperformance difference can be made up by only transforming the embedding space\nwithout fine-tuning, and visualise the resulting spaces. We test different\noperations: Removing individual outlier dimensions, cluster-based isotropy\nenhancement, and ZCA whitening. We publish our code for reproducibility.\n","authors":["Katharina Hämmerl","Alina Fastowski","Jindřich Libovický","Alexander Fraser"],"pdf_url":"https://arxiv.org/pdf/2306.00458v2.pdf","comment":"To appear in ACL Findings 2023. Fixed a citation in this version"},{"id":"http://arxiv.org/abs/2306.04387v1","updated":"2023-06-07T12:35:37Z","published":"2023-06-07T12:35:37Z","title":"M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual\n  Instruction Tuning","summary":"  Instruction tuning has significantly advanced large language models (LLMs)\nsuch as ChatGPT, enabling them to align with human instructions across diverse\ntasks. However, progress in open vision-language models (VLMs) has been limited\ndue to the scarcity of high-quality instruction datasets. To tackle this\nchallenge and promote research in the vision-language field, we introduce the\nMulti-Modal, Multilingual Instruction Tuning (M$^3$IT) dataset, designed to\noptimize VLM alignment with human instructions. Our M$^3$IT dataset comprises\n40 carefully curated datasets, including 2.4 million instances and 400 manually\nwritten task instructions, reformatted into a vision-to-text structure. Key\ntasks are translated into 80 languages with an advanced translation system,\nensuring broader accessibility. M$^3$IT surpasses previous datasets regarding\ntask coverage, instruction number and instance scale. Moreover, we develop\nYing-VLM, a VLM model trained on our M$^3$IT dataset, showcasing its potential\nto answer complex questions requiring world knowledge, generalize to unseen\nvideo tasks, and comprehend unseen instructions in Chinese. To encourage\nfurther research, we have open-sourced both the dataset and trained models.\n","authors":["Lei Li","Yuwei Yin","Shicheng Li","Liang Chen","Peiyi Wang","Shuhuai Ren","Mukai Li","Yazheng Yang","Jingjing Xu","Xu Sun","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2306.04387v1.pdf","comment":"Dataset available at: https://huggingface.co/MMInstruction/M3IT"},{"id":"http://arxiv.org/abs/2306.04384v1","updated":"2023-06-07T12:31:07Z","published":"2023-06-07T12:31:07Z","title":"Multilingual Clinical NER: Translation or Cross-lingual Transfer?","summary":"  Natural language tasks like Named Entity Recognition (NER) in the clinical\ndomain on non-English texts can be very time-consuming and expensive due to the\nlack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent\nthis issue thanks to the ability of multilingual large language models to be\nfine-tuned on a specific task in one language and to provide high accuracy for\nthe same task in another language. However, other methods leveraging\ntranslation models can be used to perform NER without annotated data in the\ntarget language, by either translating the training set or test set. This paper\ncompares cross-lingual transfer with these two alternative methods, to perform\nclinical NER in French and in German without any training data in those\nlanguages. To this end, we release MedNERF a medical NER test set extracted\nfrom French drug prescriptions and annotated with the same guidelines as an\nEnglish dataset. Through extensive experiments on this dataset and on a German\nmedical dataset (Frei and Kramer, 2021), we show that translation-based methods\ncan achieve similar performance to CLT but require more care in their design.\nAnd while they can take advantage of monolingual clinical language models,\nthose do not guarantee better results than large general-purpose multilingual\nmodels, whether with cross-lingual transfer or translation.\n","authors":["Xavier Fontaine","Félix Gaschi","Parisa Rastin","Yannick Toussaint"],"pdf_url":"https://arxiv.org/pdf/2306.04384v1.pdf","comment":"23 pages, Proceedings of the 5th Clinical Natural Language Processing\n  Workshop"},{"id":"http://arxiv.org/abs/2207.08230v4","updated":"2023-06-07T12:25:00Z","published":"2022-07-17T17:12:16Z","title":"A Context-Sensitive Word Embedding Approach for The Detection of Troll\n  Tweets","summary":"  In this study, we aimed to address the growing concern of trolling behavior\non social media by developing and evaluating a set of model architectures for\nthe automatic detection of troll tweets. Utilizing deep learning techniques and\npre-trained word embedding methods such as BERT, ELMo, and GloVe, we evaluated\nthe performance of each architecture using metrics such as classification\naccuracy, F1 score, AUC, and precision. Our results indicate that BERT and ELMo\nembedding methods performed better than the GloVe method, likely due to their\nability to provide contextualized word embeddings that better capture the\nnuances and subtleties of language use in online social media. Additionally, we\nfound that CNN and GRU encoders performed similarly in terms of F1 score and\nAUC, suggesting their effectiveness in extracting relevant information from\ninput text. The best-performing method was found to be an ELMo-based\narchitecture that employed a GRU classifier, with an AUC score of 0.929. This\nresearch highlights the importance of utilizing contextualized word embeddings\nand appropriate encoder methods in the task of troll tweet detection, which can\nassist social-based systems in improving their performance in identifying and\naddressing trolling behavior on their platforms.\n","authors":["Seyhmus Yilmaz","Sultan Zavrak"],"pdf_url":"https://arxiv.org/pdf/2207.08230v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03501v2","updated":"2023-06-07T12:23:08Z","published":"2023-05-02T09:57:54Z","title":"Improving Cancer Hallmark Classification with BERT-based Deep Learning\n  Approach","summary":"  This paper presents a novel approach to accurately classify the hallmarks of\ncancer, which is a crucial task in cancer research. Our proposed method\nutilizes the Bidirectional Encoder Representations from Transformers (BERT)\narchitecture, which has shown exceptional performance in various downstream\napplications. By applying transfer learning, we fine-tuned the pre-trained BERT\nmodel on a small corpus of biomedical text documents related to cancer. The\noutcomes of our experimental investigations demonstrate that our approach\nattains a noteworthy accuracy of 94.45%, surpassing almost all prior findings\nwith a substantial increase of at least 8.04% as reported in the literature.\nThese findings highlight the effectiveness of our proposed model in accurately\nclassifying and comprehending text documents for cancer research, thus\ncontributing significantly to the field. As cancer remains one of the top ten\nleading causes of death globally, our approach holds great promise in advancing\ncancer research and improving patient outcomes.\n","authors":["Sultan Zavrak","Seyhmus Yilmaz"],"pdf_url":"https://arxiv.org/pdf/2305.03501v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04374v1","updated":"2023-06-07T12:14:16Z","published":"2023-06-07T12:14:16Z","title":"Label Aware Speech Representation Learning For Language Identification","summary":"  Speech representation learning approaches for non-semantic tasks such as\nlanguage recognition have either explored supervised embedding extraction\nmethods using a classifier model or self-supervised representation learning\napproaches using raw data. In this paper, we propose a novel framework of\ncombining self-supervised representation learning with the language label\ninformation for the pre-training task. This framework, termed as Label Aware\nSpeech Representation (LASR) learning, uses a triplet based objective function\nto incorporate language labels along with the self-supervised loss function.\nThe speech representations are further fine-tuned for the downstream task. The\nlanguage recognition experiments are performed on two public datasets - FLEURS\nand Dhwani. In these experiments, we illustrate that the proposed LASR\nframework improves over the state-of-the-art systems on language\nidentification. We also report an analysis of the robustness of LASR approach\nto noisy/missing labels as well as its application to multi-lingual speech\nrecognition tasks.\n","authors":["Shikhar Vashishth","Shikhar Bharadwaj","Sriram Ganapathy","Ankur Bapna","Min Ma","Wei Han","Vera Axelrod","Partha Talukdar"],"pdf_url":"https://arxiv.org/pdf/2306.04374v1.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.04368v1","updated":"2023-06-07T12:01:46Z","published":"2023-06-07T12:01:46Z","title":"Arabic Dysarthric Speech Recognition Using Adversarial and Signal-Based\n  Augmentation","summary":"  Despite major advancements in Automatic Speech Recognition (ASR), the\nstate-of-the-art ASR systems struggle to deal with impaired speech even with\nhigh-resource languages. In Arabic, this challenge gets amplified, with added\ncomplexities in collecting data from dysarthric speakers. In this paper, we aim\nto improve the performance of Arabic dysarthric automatic speech recognition\nthrough a multi-stage augmentation approach. To this effect, we first propose a\nsignal-based approach to generate dysarthric Arabic speech from healthy Arabic\nspeech by modifying its speed and tempo. We also propose a second stage\nParallel Wave Generative (PWG) adversarial model that is trained on an English\ndysarthric dataset to capture language-independant dysarthric speech patterns\nand further augment the signal-adjusted speech samples. Furthermore, we propose\na fine-tuning and text-correction strategies for Arabic Conformer at different\ndysarthric speech severity levels. Our fine-tuned Conformer achieved 18% Word\nError Rate (WER) and 17.2% Character Error Rate (CER) on synthetically\ngenerated dysarthric speech from the Arabic commonvoice speech dataset. This\nshows significant WER improvement of 81.8% compared to the baseline model\ntrained solely on healthy data. We perform further validation on real English\ndysarthric speech showing a WER improvement of 124% compared to the baseline\ntrained only on healthy English LJSpeech dataset.\n","authors":["Massa Baali","Ibrahim Almakky","Shady Shehata","Fakhri Karray"],"pdf_url":"https://arxiv.org/pdf/2306.04368v1.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.04362v1","updated":"2023-06-07T11:52:36Z","published":"2023-06-07T11:52:36Z","title":"Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for\n  Pre-training and Benchmarks","summary":"  To promote the development of Vision-Language Pre-training (VLP) and\nmultimodal Large Language Model (LLM) in the Chinese community, we firstly\nrelease the largest public Chinese high-quality video-language dataset named\nYouku-mPLUG, which is collected from Youku, a well-known Chinese video-sharing\nwebsite, with strict criteria of safety, diversity, and quality. Youku-mPLUG\ncontains 10 million Chinese video-text pairs filtered from 400 million raw\nvideos across a wide range of 45 diverse categories for large-scale\npre-training. In addition, to facilitate a comprehensive evaluation of\nvideo-language models, we carefully build the largest human-annotated Chinese\nbenchmarks covering three popular video-language tasks of cross-modal\nretrieval, video captioning, and video category classification. Youku-mPLUG can\nenable researchers to conduct more in-depth multimodal research and develop\nbetter applications in the future. Furthermore, we release popular\nvideo-language pre-training models, ALPRO and mPLUG-2, and our proposed\nmodularized decoder-only model mPLUG-video pre-trained on Youku-mPLUG.\nExperiments show that models pre-trained on Youku-mPLUG gain up to 23.1%\nimprovement in video category classification. Besides, mPLUG-video achieves a\nnew state-of-the-art result on these benchmarks with 80.5% top-1 accuracy in\nvideo category classification and 68.9 CIDEr score in video captioning,\nrespectively. Finally, we scale up mPLUG-video based on the frozen Bloomz with\nonly 1.7% trainable parameters as Chinese multimodal LLM, and demonstrate\nimpressive instruction and video understanding ability. The zero-shot\ninstruction understanding experiment indicates that pretraining with\nYouku-mPLUG can enhance the ability to comprehend overall and detailed visual\nsemantics, recognize scene text, and leverage open-domain knowledge.\n","authors":["Haiyang Xu","Qinghao Ye","Xuan Wu","Ming Yan","Yuan Miao","Jiabo Ye","Guohai Xu","Anwen Hu","Yaya Shi","Guangwei Xu","Chenliang Li","Qi Qian","Maofei Que","Ji Zhang","Xiao Zeng","Fei Huang"],"pdf_url":"https://arxiv.org/pdf/2306.04362v1.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2305.18226v2","updated":"2023-06-07T11:43:44Z","published":"2023-05-26T11:07:25Z","title":"HowkGPT: Investigating the Detection of ChatGPT-generated University\n  Student Homework through Context-Aware Perplexity Analysis","summary":"  As the use of Large Language Models (LLMs) in text generation tasks\nproliferates, concerns arise over their potential to compromise academic\nintegrity. The education sector currently tussles with distinguishing\nstudent-authored homework assignments from AI-generated ones. This paper\naddresses the challenge by introducing HowkGPT, designed to identify homework\nassignments generated by AI. HowkGPT is built upon a dataset of academic\nassignments and accompanying metadata [17] and employs a pretrained LLM to\ncompute perplexity scores for student-authored and ChatGPT-generated responses.\nThese scores then assist in establishing a threshold for discerning the origin\nof a submitted assignment. Given the specificity and contextual nature of\nacademic work, HowkGPT further refines its analysis by defining\ncategory-specific thresholds derived from the metadata, enhancing the precision\nof the detection. This study emphasizes the critical need for effective\nstrategies to uphold academic integrity amidst the growing influence of LLMs\nand provides an approach to ensuring fair and accurate grading in educational\ninstitutions.\n","authors":["Christoforos Vasilatos","Manaar Alam","Talal Rahwan","Yasir Zaki","Michail Maniatakos"],"pdf_url":"https://arxiv.org/pdf/2305.18226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04357v1","updated":"2023-06-07T11:40:07Z","published":"2023-06-07T11:40:07Z","title":"ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems","summary":"  Dialogue response selection aims to select an appropriate response from\nseveral candidates based on a given user and system utterance history. Recent\nstudies have been improving the accuracy of dialogue response selection through\npost-training, mostly relying on naive masked language modeling methods.\nHowever, the recently developed generative methods have shown promising text\nrepresentation capabilities in IR community, which could potentially lead to\nbetter dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE\n(Dialogue Contextual Masking Auto-encoder), a straightforward yet effective\npost-training technique tailored for dialogue response selection. Dial-MAE uses\nan asymmetric encoder-decoder architecture that learns to better compress the\nsemantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE\ninvolves a deep encoder creating a dialogue embedding with the masked dialogue\ncontext, followed by a shallow decoder that uses this embedding along with the\nhighly masked response to restore the original response. Our experiments have\ndemonstrated that Dial-MAE is highly effective, achieving state-of-the-art\nperformance on two commonly evaluated benchmarks.\n","authors":["Zhenpeng Su","Xing Wu","Wei Zhou","Guangyuan Ma"," Songlin"],"pdf_url":"https://arxiv.org/pdf/2306.04357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04349v1","updated":"2023-06-07T11:33:14Z","published":"2023-06-07T11:33:14Z","title":"GPT Self-Supervision for a Better Data Annotator","summary":"  The task of annotating data into concise summaries poses a significant\nchallenge across various domains, frequently requiring the allocation of\nsignificant time and specialized knowledge by human experts. Despite existing\nefforts to use large language models for annotation tasks, significant problems\nsuch as limited applicability to unlabeled data, the absence of self-supervised\nmethods, and the lack of focus on complex structured data still persist. In\nthis work, we propose a GPT self-supervision annotation method. This method\nembodies a generating-recovering paradigm that leverages the capabilities of\none-shot learning capabilities in Generative Pretrained Transformer (GPT). The\nproposed approach comprises a one-shot tuning phase followed by a generation\nphase. In the one-shot tuning phase, we sample a data from the support set as\npart of the prompt for GPT to generate a textual summary, which is then used to\nrecover the original data. The alignment score between the recovered and\noriginal data serves as a self-supervision navigator to refine the process. In\nthe generation stage, the optimally selected one-shot sample serves as a\ntemplate in the prompt and is applied to generating summaries from challenging\ndatasets. The annotation performance is evaluated by tuning several human\nfeedback reward networks and by calculating alignment scores between original\nand recovered data at both sentence and structure levels. Our self-supervised\nannotation method consistently achieves competitive scores, convincingly\ndemonstrating its robust strength in various data-to-summary annotation tasks.\n","authors":["Xiaohuan Pei","Yanxi Li","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2306.04349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04347v1","updated":"2023-06-07T11:25:20Z","published":"2023-06-07T11:25:20Z","title":"World Models for Math Story Problems","summary":"  Solving math story problems is a complex task for students and NLP models\nalike, requiring them to understand the world as described in the story and\nreason over it to compute an answer. Recent years have seen impressive\nperformance on automatically solving these problems with large pre-trained\nlanguage models and innovative techniques to prompt them. However, it remains\nunclear if these models possess accurate representations of mathematical\nconcepts. This leads to lack of interpretability and trustworthiness which\nimpedes their usefulness in various applications. In this paper, we consolidate\nprevious work on categorizing and representing math story problems and develop\nMathWorld, which is a graph-based semantic formalism specific for the domain of\nmath story problems. With MathWorld, we can assign world models to math story\nproblems which represent the situations and actions introduced in the text and\ntheir mathematical relationships. We combine math story problems from several\nexisting datasets and annotate a corpus of 1,019 problems and 3,204 logical\nforms with MathWorld. Using this data, we demonstrate the following use cases\nof MathWorld: (1) prompting language models with synthetically generated\nquestion-answer pairs to probe their reasoning and world modeling abilities,\nand (2) generating new problems by using the world models as a design space.\n","authors":["Andreas Opedal","Niklas Stoehr","Abulhair Saparov","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2306.04347v1.pdf","comment":"ACL Findings 2023"},{"id":"http://arxiv.org/abs/2306.04340v1","updated":"2023-06-07T11:11:12Z","published":"2023-06-07T11:11:12Z","title":"Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction","summary":"  Emotion-Cause Pair Extraction (ECPE) aims to extract all emotion clauses and\ntheir corresponding cause clauses from a document. Existing approaches tackle\nthis task through multi-task learning (MTL) framework in which the two subtasks\nprovide indicative clues for ECPE. However, the previous MTL framework\nconsiders only one round of multi-task reasoning and ignores the reverse\nfeedbacks from ECPE to the subtasks. Besides, its multi-task reasoning only\nrelies on semantics-level interactions, which cannot capture the explicit\ndependencies, and both the encoder sharing and multi-task hidden states\nconcatenations can hardly capture the causalities. To solve these issues, we\nfirst put forward a new MTL framework based on Co-evolving Reasoning. It (1)\nmodels the bidirectional feedbacks between ECPE and its subtasks; (2) allows\nthe three tasks to evolve together and prompt each other recurrently; (3)\nintegrates prediction-level interactions to capture explicit dependencies. Then\nwe propose a novel multi-task relational graph (MRG) to sufficiently exploit\nthe causal relations. Finally, we propose a Co-evolving Graph Reasoning Network\n(CGR-Net) that implements our MTL framework and conducts Co-evolving Reasoning\non MRG. Experimental results show that our model achieves new state-of-the-art\nperformance, and further analysis confirms the advantages of our method.\n","authors":["Bowen Xing","Ivor W. Tsang"],"pdf_url":"https://arxiv.org/pdf/2306.04340v1.pdf","comment":"Accepted by ECML-PKDD 2023"},{"id":"http://arxiv.org/abs/2306.04337v1","updated":"2023-06-07T11:04:02Z","published":"2023-06-07T11:04:02Z","title":"A Study on the Reliability of Automatic Dysarthric Speech Assessments","summary":"  Automating dysarthria assessments offers the opportunity to develop\neffective, low-cost tools that address the current limitations of manual and\nsubjective assessments. Nonetheless, it is unclear whether current approaches\nrely on dysarthria-related speech patterns or external factors. We aim toward\nobtaining a clearer understanding of dysarthria patterns. To this extent, we\nstudy the effects of noise in recordings, both through addition and reduction.\nWe design and implement a new method for visualizing and comparing feature\nextractors and models, at a patient level, in a more interpretable way. We use\nthe UA-Speech dataset with a speaker-based split of the dataset. Results\nreported in the literature appear to have been done irrespective of such split,\nleading to models that may be overconfident due to data-leakage. We hope that\nthese results raise awareness in the research community regarding the\nrequirements for establishing reliable automatic dysarthria assessment systems.\n","authors":["Xavier F. Cadet","Ranya Aloufi","Sara Ahmadi-Abhari","Hamed Haddadi"],"pdf_url":"https://arxiv.org/pdf/2306.04337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04334v1","updated":"2023-06-07T11:01:39Z","published":"2023-06-07T11:01:39Z","title":"Echoes from Alexandria: A Large Resource for Multilingual Book\n  Summarization","summary":"  In recent years, research in text summarization has mainly focused on the\nnews domain, where texts are typically short and have strong layout features.\nThe task of full-book summarization presents additional challenges which are\nhard to tackle with current resources, due to their limited size and\navailability in English only. To overcome these limitations, we present \"Echoes\nfrom Alexandria\", or in shortened form, \"Echoes\", a large resource for\nmultilingual book summarization. Echoes features three novel datasets: i)\nEcho-Wiki, for multilingual book summarization, ii) Echo-XSum, for\nextremely-compressive multilingual book summarization, and iii) Echo-FairySum,\nfor extractive book summarization. To the best of our knowledge, Echoes, with\nits thousands of books and summaries, is the largest resource, and the first to\nbe multilingual, featuring 5 languages and 25 language pairs. In addition to\nEchoes, we also introduce a new extractive-then-abstractive baseline, and,\nsupported by our experimental results and manual analysis of the summaries\ngenerated, we argue that this baseline is more suitable for book summarization\nthan purely-abstractive approaches. We release our resource and software at\nhttps://github.com/Babelscape/echoes-from-alexandria in the hope of fostering\ninnovative research in multilingual book summarization.\n","authors":["Alessandro Scirè","Simone Conia","Simone Ciciliano","Roberto Navigli"],"pdf_url":"https://arxiv.org/pdf/2306.04334v1.pdf","comment":"9 pages, long paper at ACL 2023"},{"id":"http://arxiv.org/abs/2306.04328v1","updated":"2023-06-07T10:47:33Z","published":"2023-06-07T10:47:33Z","title":"IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for\n  multilayer summarization of clinical conversations?","summary":"  Clinical conversation summarization has become an important application of\nNatural language Processing. In this work, we intend to analyze summarization\nmodel ensembling approaches, that can be utilized to improve the overall\naccuracy of the generated medical report called chart note. The work starts\nwith a single summarization model creating the baseline. Then leads to an\nensemble of summarization models trained on a separate section of the chart\nnote. This leads to the final approach of passing the generated results to\nanother summarization model in a multi-layer/stage fashion for better coherency\nof the generated text. Our results indicate that although an ensemble of models\nspecialized in each section produces better results, the multi-layer/stage\napproach does not improve accuracy. The code for the above paper is available\nat https://github.com/dhananjay-srivastava/MEDIQA-Chat-2023-iuteam1.git\n","authors":["Dhananjay Srivastava"],"pdf_url":"https://arxiv.org/pdf/2306.04328v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2306.04314v1","updated":"2023-06-07T10:19:50Z","published":"2023-06-07T10:19:50Z","title":"Cross-Genre Argument Mining: Can Language Models Automatically Fill in\n  Missing Discourse Markers?","summary":"  Available corpora for Argument Mining differ along several axes, and one of\nthe key differences is the presence (or absence) of discourse markers to signal\nargumentative content. Exploring effective ways to use discourse markers has\nreceived wide attention in various discourse parsing tasks, from which it is\nwell-known that discourse markers are strong indicators of discourse relations.\nTo improve the robustness of Argument Mining systems across different genres,\nwe propose to automatically augment a given text with discourse markers such\nthat all relations are explicitly signaled. Our analysis unveils that popular\nlanguage models taken out-of-the-box fail on this task; however, when\nfine-tuned on a new heterogeneous dataset that we construct (including\nsynthetic and real examples), they perform considerably better. We demonstrate\nthe impact of our approach on an Argument Mining downstream task, evaluated on\ndifferent corpora, showing that language models can be trained to automatically\nfill in discourse markers across different corpora, improving the performance\nof a downstream model in some, but not all, cases. Our proposed approach can\nfurther be employed as an assistive tool for better discourse understanding.\n","authors":["Gil Rocha","Henrique Lopes Cardoso","Jonas Belouadi","Steffen Eger"],"pdf_url":"https://arxiv.org/pdf/2306.04314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09440v2","updated":"2023-06-07T10:18:44Z","published":"2022-10-17T21:22:23Z","title":"Using Bottleneck Adapters to Identify Cancer in Clinical Notes under\n  Low-Resource Constraints","summary":"  Processing information locked within clinical health records is a challenging\ntask that remains an active area of research in biomedical NLP. In this work,\nwe evaluate a broad set of machine learning techniques ranging from simple RNNs\nto specialised transformers such as BioBERT on a dataset containing clinical\nnotes along with a set of annotations indicating whether a sample is\ncancer-related or not.\n  Furthermore, we specifically employ efficient fine-tuning methods from NLP,\nnamely, bottleneck adapters and prompt tuning, to adapt the models to our\nspecialised task. Our evaluations suggest that fine-tuning a frozen BERT model\npre-trained on natural language and with bottleneck adapters outperforms all\nother strategies, including full fine-tuning of the specialised BioBERT model.\nBased on our findings, we suggest that using bottleneck adapters in\nlow-resource situations with limited access to labelled data or processing\ncapacity could be a viable strategy in biomedical text mining. The code used in\nthe experiments are going to be made available at\nhttps://github.com/omidrohanian/bottleneck-adapters.\n","authors":["Omid Rohanian","Hannah Jauncey","Mohammadmahdi Nouriborji","Vinod Kumar Chauhan","Bronner P. Gonçalves","Christiana Kartsonaki","ISARIC Clinical Characterisation Group","Laura Merson","David Clifton"],"pdf_url":"https://arxiv.org/pdf/2210.09440v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04308v1","updated":"2023-06-07T10:14:17Z","published":"2023-06-07T10:14:17Z","title":"Personality testing of GPT-3: Limited temporal reliability, but\n  highlighted social desirability of GPT-3's personality instruments results","summary":"  To assess the potential applications and limitations of chatbot GPT-3\nDavinci-003, this study explored the temporal reliability of personality\nquestionnaires applied to the chatbot and its personality profile.\nPsychological questionnaires were administered to the chatbot on two separate\noccasions, followed by a comparison of the responses to human normative data.\nThe findings revealed varying levels of agreement in the chatbot's responses\nover time, with some scales displaying excellent while others demonstrated poor\nagreement. Overall, Davinci-003 displayed a socially desirable and pro-social\npersonality profile, particularly in the domain of communion. However, the\nunderlying basis of the chatbot's responses, whether driven by conscious\nself-reflection or predetermined algorithms, remains uncertain.\n","authors":["Bojana Bodroza","Bojana M. Dinic","Ljubisa Bojic"],"pdf_url":"https://arxiv.org/pdf/2306.04308v1.pdf","comment":"18 pages, 1 table"},{"id":"http://arxiv.org/abs/2306.04306v1","updated":"2023-06-07T10:11:09Z","published":"2023-06-07T10:11:09Z","title":"Allophant: Cross-lingual Phoneme Recognition with Articulatory\n  Attributes","summary":"  This paper proposes Allophant, a multilingual phoneme recognizer. It requires\nonly a phoneme inventory for cross-lingual transfer to a target language,\nallowing for low-resource recognition. The architecture combines a\ncompositional phone embedding approach with individually supervised phonetic\nattribute classifiers in a multi-task architecture. We also introduce\nAllophoible, an extension of the PHOIBLE database. When combined with a\ndistance based mapping approach for grapheme-to-phoneme outputs, it allows us\nto train on PHOIBLE inventories directly. By training and evaluating on 34\nlanguages, we found that the addition of multi-task learning improves the\nmodel's capability of being applied to unseen phonemes and phoneme inventories.\nOn supervised languages we achieve phoneme error rate improvements of 11\npercentage points (pp.) compared to a baseline without multi-task learning.\nEvaluation of zero-shot transfer on 84 languages yielded a decrease in PER of\n2.63 pp. over the baseline.\n","authors":["Kevin Glocker","Aaricia Herygers","Munir Georges"],"pdf_url":"https://arxiv.org/pdf/2306.04306v1.pdf","comment":"5 pages, 2 figures, 2 tables, accepted to INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.04293v1","updated":"2023-06-07T09:46:38Z","published":"2023-06-07T09:46:38Z","title":"Phrase Retrieval for Open-Domain Conversational Question Answering with\n  Conversational Dependency Modeling via Contrastive Learning","summary":"  Open-Domain Conversational Question Answering (ODConvQA) aims at answering\nquestions through a multi-turn conversation based on a retriever-reader\npipeline, which retrieves passages and then predicts answers with them.\nHowever, such a pipeline approach not only makes the reader vulnerable to the\nerrors propagated from the retriever, but also demands additional effort to\ndevelop both the retriever and the reader, which further makes it slower since\nthey are not runnable in parallel. In this work, we propose a method to\ndirectly predict answers with a phrase retrieval scheme for a sequence of\nwords, reducing the conventional two distinct subtasks into a single one. Also,\nfor the first time, we study its capability for ODConvQA tasks. However, simply\nadopting it is largely problematic, due to the dependencies between previous\nand current turns in a conversation. To address this problem, we further\nintroduce a novel contrastive learning strategy, making sure to reflect\nprevious turns when retrieving the phrase for the current context, by\nmaximizing representational similarities of consecutive turns in a conversation\nwhile minimizing irrelevant conversational contexts. We validate our model on\ntwo ODConvQA datasets, whose experimental results show that it substantially\noutperforms the relevant baselines with the retriever-reader. Code is available\nat: https://github.com/starsuzi/PRO-ConvQA.\n","authors":["Soyeong Jeong","Jinheon Baek","Sung Ju Hwang","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2306.04293v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2210.07222v3","updated":"2023-06-07T09:29:04Z","published":"2022-10-13T17:48:15Z","title":"Saliency Map Verbalization: Comparing Feature Importance Representations\n  from Model-free and Instruction-based Methods","summary":"  Saliency maps can explain a neural model's predictions by identifying\nimportant input features. They are difficult to interpret for laypeople,\nespecially for instances with many features. In order to make them more\naccessible, we formalize the underexplored task of translating saliency maps\ninto natural language and compare methods that address two key challenges of\nthis approach -- what and how to verbalize. In both automatic and human\nevaluation setups, using token-level attributions from text classification\ntasks, we compare two novel methods (search-based and instruction-based\nverbalizations) against conventional feature importance representations\n(heatmap visualizations and extractive rationales), measuring simulatability,\nfaithfulness, helpfulness and ease of understanding. Instructing GPT-3.5 to\ngenerate saliency map verbalizations yields plausible explanations which\ninclude associations, abstractive summarization and commonsense reasoning,\nachieving by far the highest human ratings, but they are not faithfully\ncapturing numeric information and are inconsistent in their interpretation of\nthe task. In comparison, our search-based, model-free verbalization approach\nefficiently completes templated verbalizations, is faithful by design, but\nfalls short in helpfulness and simulatability. Our results suggest that\nsaliency map verbalization makes feature attribution explanations more\ncomprehensible and less cognitively challenging to humans than conventional\nrepresentations.\n","authors":["Nils Feldhus","Leonhard Hennig","Maximilian Dustin Nasert","Christopher Ebert","Robert Schwarzenberg","Sebastian Möller"],"pdf_url":"https://arxiv.org/pdf/2210.07222v3.pdf","comment":"ACL 2023 Workshop on Natural Language Reasoning and Structured\n  Explanations (NLRSE)"},{"id":"http://arxiv.org/abs/2306.04277v1","updated":"2023-06-07T09:23:26Z","published":"2023-06-07T09:23:26Z","title":"Analysis of the Fed's communication by using textual entailment model of\n  Zero-Shot classification","summary":"  In this study, we analyze documents published by central banks using text\nmining techniques and propose a method to evaluate the policy tone of central\nbanks. Since the monetary policies of major central banks have a broad impact\non financial market trends, the pricing of risky assets, and the real economy,\nmarket participants are attempting to more accurately capture changes in the\noutlook for central banks' future monetary policies. Since the published\ndocuments are also an important tool for the central bank to communicate with\nthe market, they are meticulously elaborated on grammatical syntax and wording,\nand investors are urged to read more accurately about the central bank's policy\nstance. Sentiment analysis on central bank documents has long been carried out,\nbut it has been difficult to interpret the meaning of the documents accurately\nand to explicitly capture even the intentional change in nuance. This study\nattempts to evaluate the implication of the zero-shot text classification\nmethod for an unknown economic environment using the same model. We compare the\ntone of the statements, minutes, press conference transcripts of FOMC meetings,\nand the Fed officials' (chair, vice chair, and Governors) speeches. In\naddition, the minutes of the FOMC meetings were subjected to a phase analysis\nof changes in each policy stance since 1971.\n","authors":["Yasuhiro Nakayama","Tomochika Sawaki"],"pdf_url":"https://arxiv.org/pdf/2306.04277v1.pdf","comment":"6 pages, 4 figures, 2 Tables"},{"id":"http://arxiv.org/abs/2306.04268v1","updated":"2023-06-07T09:09:00Z","published":"2023-06-07T09:09:00Z","title":"Multi-microphone Automatic Speech Segmentation in Meetings Based on\n  Circular Harmonics Features","summary":"  Speaker diarization is the task of answering Who spoke and when? in an audio\nstream. Pipeline systems rely on speech segmentation to extract speakers'\nsegments and achieve robust speaker diarization. This paper proposes a common\nframework to solve three segmentation tasks in the distant speech scenario:\nVoice Activity Detection (VAD), Overlapped Speech Detection (OSD), and Speaker\nChange Detection (SCD). In the literature, a few studies investigate the\nmulti-microphone distant speech scenario. In this work, we propose a new set of\nspatial features based on direction-of-arrival estimations in the circular\nharmonic domain (CH-DOA). These spatial features are extracted from\nmulti-microphone audio data and combined with standard acoustic features.\nExperiments on the AMI meeting corpus show that CH-DOA can improve the\nsegmentation while being robust in the case of deactivated microphones.\n","authors":["Théo Mariotte","Anthony Larcher","Silvio Montrésor","Jean-Hugh Thomas"],"pdf_url":"https://arxiv.org/pdf/2306.04268v1.pdf","comment":"Interspeech 2023, international Speech Communication Association\n  (ISCA), Aug 2023, Dublin, Ireland"},{"id":"http://arxiv.org/abs/2305.14070v2","updated":"2023-06-07T08:53:08Z","published":"2023-05-23T13:49:14Z","title":"Assessing Linguistic Generalisation in Language Models: A Dataset for\n  Brazilian Portuguese","summary":"  Much recent effort has been devoted to creating large-scale language models.\nNowadays, the most prominent approaches are based on deep neural networks, such\nas BERT. However, they lack transparency and interpretability, and are often\nseen as black boxes. This affects not only their applicability in downstream\ntasks but also the comparability of different architectures or even of the same\nmodel trained using different corpora or hyperparameters. In this paper, we\npropose a set of intrinsic evaluation tasks that inspect the linguistic\ninformation encoded in models developed for Brazilian Portuguese. These tasks\nare designed to evaluate how different language models generalise information\nrelated to grammatical structures and multiword expressions (MWEs), thus\nallowing for an assessment of whether the model has learned different\nlinguistic phenomena. The dataset that was developed for these tasks is\ncomposed of a series of sentences with a single masked word and a cue phrase\nthat helps in narrowing down the context. This dataset is divided into MWEs and\ngrammatical structures, and the latter is subdivided into 6 tasks: impersonal\nverbs, subject agreement, verb agreement, nominal agreement, passive and\nconnectors. The subset for MWEs was used to test BERTimbau Large, BERTimbau\nBase and mBERT. For the grammatical structures, we used only BERTimbau Large,\nbecause it yielded the best results in the MWE task.\n","authors":["Rodrigo Wilkens","Leonardo Zilio","Aline Villavicencio"],"pdf_url":"https://arxiv.org/pdf/2305.14070v2.pdf","comment":"This is the original manuscript that was submitted to LREV. The final\n  version was published recently and can be found at: https://rdcu.be/ddEa6.\n  Language Resources and Evaluation, https://doi.org/10.1007/s10579-023-09664-1"},{"id":"http://arxiv.org/abs/2306.04233v1","updated":"2023-06-07T08:23:58Z","published":"2023-06-07T08:23:58Z","title":"Transfer Learning from Pre-trained Language Models Improves End-to-End\n  Speech Summarization","summary":"  End-to-end speech summarization (E2E SSum) directly summarizes input speech\ninto easy-to-read short sentences with a single model. This approach is\npromising because it, in contrast to the conventional cascade approach, can\nutilize full acoustical information and mitigate to the propagation of\ntranscription errors. However, due to the high cost of collecting\nspeech-summary pairs, an E2E SSum model tends to suffer from training data\nscarcity and output unnatural sentences. To overcome this drawback, we propose\nfor the first time to integrate a pre-trained language model (LM), which is\nhighly capable of generating natural sentences, into the E2E SSum decoder via\ntransfer learning. In addition, to reduce the gap between the independently\npre-trained encoder and decoder, we also propose to transfer the baseline E2E\nSSum encoder instead of the commonly used automatic speech recognition encoder.\nExperimental results show that the proposed model outperforms baseline and data\naugmented models.\n","authors":["Kohei Matsuura","Takanori Ashihara","Takafumi Moriya","Tomohiro Tanaka","Takatomo Kano","Atsunori Ogawa","Marc Delcroix"],"pdf_url":"https://arxiv.org/pdf/2306.04233v1.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2304.07438v3","updated":"2023-06-07T08:23:55Z","published":"2023-04-15T00:19:44Z","title":"Tractable Control for Autoregressive Language Generation","summary":"  Despite the success of autoregressive large language models in text\ngeneration, it remains a major challenge to generate text that satisfies\ncomplex constraints: sampling from the conditional distribution\n${\\Pr}(\\text{text} | \\alpha)$ is intractable for even the simplest lexical\nconstraints $\\alpha$. To overcome this challenge, we propose to use tractable\nprobabilistic models (TPMs) to impose lexical constraints in autoregressive\ntext generation models, which we refer to as GeLaTo (Generating Language with\nTractable Constraints). To demonstrate the effectiveness of this framework, we\nuse distilled hidden Markov models, where we can efficiently compute\n${\\Pr}(\\text{text} | \\alpha)$, to guide autoregressive generation from GPT2.\nGeLaTo achieves state-of-the-art performance on challenging benchmarks for\nconstrained text generation (e.g., CommonGen), beating various strong baselines\nby a large margin. Our work not only opens up new avenues for controlling large\nlanguage models but also motivates the development of more expressive TPMs.\n","authors":["Honghua Zhang","Meihua Dang","Nanyun Peng","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2304.07438v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04217v1","updated":"2023-06-07T07:45:38Z","published":"2023-06-07T07:45:38Z","title":"Effective Neural Topic Modeling with Embedding Clustering Regularization","summary":"  Topic models have been prevalent for decades with various applications.\nHowever, existing topic models commonly suffer from the notorious topic\ncollapsing: discovered topics semantically collapse towards each other, leading\nto highly repetitive topics, insufficient topic discovery, and damaged model\ninterpretability. In this paper, we propose a new neural topic model, Embedding\nClustering Regularization Topic Model (ECRTM). Besides the existing\nreconstruction error, we propose a novel Embedding Clustering Regularization\n(ECR), which forces each topic embedding to be the center of a separately\naggregated word embedding cluster in the semantic space. This enables each\nproduced topic to contain distinct word semantics, which alleviates topic\ncollapsing. Regularized by ECR, our ECRTM generates diverse and coherent topics\ntogether with high-quality topic distributions of documents. Extensive\nexperiments on benchmark datasets demonstrate that ECRTM effectively addresses\nthe topic collapsing issue and consistently surpasses state-of-the-art\nbaselines in terms of topic quality, topic distributions of documents, and\ndownstream classification tasks.\n","authors":["Xiaobao Wu","Xinshuai Dong","Thong Nguyen","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2306.04217v1.pdf","comment":"Accepted to ICML 2023 conference"},{"id":"http://arxiv.org/abs/2306.00739v2","updated":"2023-06-07T07:23:56Z","published":"2023-05-26T21:39:05Z","title":"SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL","summary":"  One impressive emergent capability of large language models (LLMs) is\ngeneration of code, including Structured Query Language (SQL) for databases.\nFor the task of converting natural language text to SQL queries, Text-to-SQL,\nadaptation of LLMs is of paramount importance, both in in-context learning and\nfine-tuning settings, depending on the amount of adaptation data used. In this\npaper, we propose an LLM-based Text-to-SQL model SQL-PaLM, leveraging on\nPaLM-2, that pushes the state-of-the-art in both settings. Few-shot SQL-PaLM is\nbased on an execution-based self-consistency prompting approach designed for\nText-to-SQL, and achieves 77.3% in test-suite accuracy on Spider, which to our\nbest knowledge is the first to outperform previous state-of-the-art with\nfine-tuning by a significant margin, 4%. Furthermore, we demonstrate that the\nfine-tuned SQL-PALM outperforms it further by another 1%. Towards applying\nSQL-PaLM to real-world scenarios we further evaluate its robustness on other\nchallenging variants of Spider and demonstrate the superior generalization\ncapability of SQL-PaLM. In addition, via extensive case studies, we demonstrate\nthe impressive intelligent capabilities and various success enablers of\nLLM-based Text-to-SQL.\n","authors":["Ruoxi Sun","Sercan O. Arik","Hootan Nakhost","Hanjun Dai","Rajarishi Sinha","Pengcheng Yin","Tomas Pfister"],"pdf_url":"https://arxiv.org/pdf/2306.00739v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2306.04203v1","updated":"2023-06-07T07:15:20Z","published":"2023-06-07T07:15:20Z","title":"Leveraging Knowledge Graph Embeddings to Enhance Contextual\n  Representations for Relation Extraction","summary":"  Relation extraction task is a crucial and challenging aspect of Natural\nLanguage Processing. Several methods have surfaced as of late, exhibiting\nnotable performance in addressing the task; however, most of these approaches\nrely on vast amounts of data from large-scale knowledge graphs or language\nmodels pretrained on voluminous corpora. In this paper, we hone in on the\neffective utilization of solely the knowledge supplied by a corpus to create a\nhigh-performing model. Our objective is to showcase that by leveraging the\nhierarchical structure and relational distribution of entities within a corpus\nwithout introducing external knowledge, a relation extraction model can achieve\nsignificantly enhanced performance. We therefore proposed a relation extraction\napproach based on the incorporation of pretrained knowledge graph embeddings at\nthe corpus scale into the sentence-level contextual representation. We\nconducted a series of experiments which revealed promising and very interesting\nresults for our proposed approach.The obtained results demonstrated an\noutperformance of our method compared to context-based relation extraction\nmodels.\n","authors":["Fréjus A. A. Laleye","Loïc Rakotoson","Sylvain Massip"],"pdf_url":"https://arxiv.org/pdf/2306.04203v1.pdf","comment":"15 pages, 1 figures, The 17th International Conference on Document\n  Analysis and Recognition"},{"id":"http://arxiv.org/abs/2306.04190v1","updated":"2023-06-07T06:58:38Z","published":"2023-06-07T06:58:38Z","title":"An ASR-Based Tutor for Learning to Read: How to Optimize Feedback to\n  First Graders","summary":"  The interest in employing automatic speech recognition (ASR) in applications\nfor reading practice has been growing in recent years. In a previous study, we\npresented an ASR-based Dutch reading tutor application that was developed to\nprovide instantaneous feedback to first-graders learning to read. We saw that\nASR has potential at this stage of the reading process, as the results\nsuggested that pupils made progress in reading accuracy and fluency by using\nthe software. In the current study, we used children's speech from an existing\ncorpus (JASMIN) to develop two new ASR systems, and compared the results to\nthose of the previous study. We analyze correct/incorrect classification of the\nASR systems using human transcripts at word level, by means of evaluation\nmeasures such as Cohen's Kappa, Matthews Correlation Coefficient (MCC),\nprecision, recall and F-measures. We observe improvements for the newly\ndeveloped ASR systems regarding the agreement with human-based judgment and\ncorrect rejection (CR). The accuracy of the ASR systems varies for different\nreading tasks and word types. Our results suggest that, in the current\nconfiguration, it is difficult to classify isolated words. We discuss these\nresults, possible ways to improve our systems and avenues for future research.\n","authors":["Yu Bai","Cristian Tejedor-Garcia","Ferdy Hubers","Catia Cucchiarini","Helmer Strik"],"pdf_url":"https://arxiv.org/pdf/2306.04190v1.pdf","comment":"Published (double-blind peer-reviewed) on SPECOM 2021"},{"id":"http://arxiv.org/abs/2306.04188v1","updated":"2023-06-07T06:47:34Z","published":"2023-06-07T06:47:34Z","title":"A New Dataset and Empirical Study for Sentence Simplification in Chinese","summary":"  Sentence Simplification is a valuable technique that can benefit language\nlearners and children a lot. However, current research focuses more on English\nsentence simplification. The development of Chinese sentence simplification is\nrelatively slow due to the lack of data. To alleviate this limitation, this\npaper introduces CSS, a new dataset for assessing sentence simplification in\nChinese. We collect manual simplifications from human annotators and perform\ndata analysis to show the difference between English and Chinese sentence\nsimplifications. Furthermore, we test several unsupervised and zero/few-shot\nlearning methods on CSS and analyze the automatic evaluation and human\nevaluation results. In the end, we explore whether Large Language Models can\nserve as high-quality Chinese sentence simplification systems by evaluating\nthem on CSS.\n","authors":["Shiping Yang","Renliang Sun","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2306.04188v1.pdf","comment":"Accepted by ACL2023 main conference"},{"id":"http://arxiv.org/abs/2306.04187v1","updated":"2023-06-07T06:46:56Z","published":"2023-06-07T06:46:56Z","title":"Knowing-how & Knowing-that: A New Task for Machine Reading Comprehension\n  of User Manuals","summary":"  The machine reading comprehension (MRC) of user manuals has huge potential in\ncustomer service. However,current methods have trouble answering complex\nquestions. Therefore, we introduce the Knowing-how & Knowing-that task that\nrequires the model to answer factoid-style, procedure-style, and inconsistent\nquestions about user manuals. We resolve this task by jointly representing the\nsteps and facts in a graph (TARA), which supports a unified inference of\nvarious questions. Towards a systematical benchmarking study, we design a\nheuristic method to automatically parse user manuals into TARAs and build an\nannotated dataset to test the model's ability in answering real-world\nquestions. Empirical results demonstrate that representing user manuals as\nTARAs is a desired solution for the MRC of user manuals. An in-depth\ninvestigation of TARA further sheds light on the issues and broader impacts of\nfuture representations of user manuals. We hope our work can move the MRC of\nuser manuals to a more complex and realistic stage.\n","authors":["Hongru Liang","Jia Liu","Weihong Du","dingnan jin","Wenqiang Lei","Zujie Wen","Jiancheng Lv"],"pdf_url":"https://arxiv.org/pdf/2306.04187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04181v1","updated":"2023-06-07T06:29:58Z","published":"2023-06-07T06:29:58Z","title":"Benchmarking Foundation Models with Language-Model-as-an-Examiner","summary":"  Numerous benchmarks have been established to assess the performance of\nfoundation models on open-ended question answering, which serves as a\ncomprehensive test of a model's ability to understand and generate language in\na manner similar to humans. Most of these works focus on proposing new\ndatasets, however, we see two main issues within previous benchmarking\npipelines, namely testing leakage and evaluation automation. In this paper, we\npropose a novel benchmarking framework, Language-Model-as-an-Examiner, where\nthe LM serves as a knowledgeable examiner that formulates questions based on\nits knowledge and evaluates responses in a reference-free manner. Our framework\nallows for effortless extensibility as various LMs can be adopted as the\nexaminer, and the questions can be constantly updated given more diverse\ntrigger topics. For a more comprehensive and equitable evaluation, we devise\nthree strategies: (1) We instruct the LM examiner to generate questions across\na multitude of domains to probe for a broad acquisition, and raise follow-up\nquestions to engage in a more in-depth assessment. (2) Upon evaluation, the\nexaminer combines both scoring and ranking measurements, providing a reliable\nresult as it aligns closely with human annotations. (3) We additionally propose\na decentralized Peer-examination method to address the biases in a single\nexaminer. Our data and benchmarking results are available at:\nhttps://lmexam.com.\n","authors":["Yushi Bai","Jiahao Ying","Yixin Cao","Xin Lv","Yuze He","Xiaozhi Wang","Jifan Yu","Kaisheng Zeng","Yijia Xiao","Haozhe Lyu","Jiayin Zhang","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2306.04181v1.pdf","comment":"23 pages, 8 figures"},{"id":"http://arxiv.org/abs/2305.18466v2","updated":"2023-06-07T06:21:30Z","published":"2023-05-29T08:03:28Z","title":"Test-Time Training on Nearest Neighbors for Large Language Models","summary":"  Many recent efforts aim to augment language models with relevant information\nretrieved from a database at test time. We avoid the need for prompt\nengineering by directly fine-tuning the model on data retrieved at test time\nusing its standard training setup. For this purpose, we build a large-scale\ndistributed nearest neighbor index based on text embeddings of the Pile\ndataset. Given a query to a language model, our system retrieves the neighbors\nof the query and fine-tunes the model on the text data corresponding to those\nneighbors. Surprisingly, retrieving and training on as few as 20 neighbors,\neach for only one gradient iteration, drastically improves performance across\nmore than twenty language modeling tasks in the Pile benchmark. For example,\ntest-time training significantly narrows the performance gap between a small\nGPT2 model and a GPTNeo model, more than ten times larger, that was\nspecifically trained to convergence on the Pile. Sufficient index quality and\nsize, however, are important. Our work establishes a valuable first baseline\nfor implementing test-time training in the context of large language models,\nopening the door to numerous promising research avenues.\n","authors":["Moritz Hardt","Yu Sun"],"pdf_url":"https://arxiv.org/pdf/2305.18466v2.pdf","comment":"Corrected Figure 8. Code repository here:\n  https://github.com/socialfoundations/tttlm"},{"id":"http://arxiv.org/abs/2305.16259v4","updated":"2023-06-07T06:03:49Z","published":"2023-05-25T17:13:44Z","title":"Neural Natural Language Processing for Long Texts: A Survey of the\n  State-of-the-Art","summary":"  The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural\nLanguage Processing (NLP) during the past decade. However, the demands of long\ndocument analysis are quite different from those of shorter texts, while the\never increasing size of documents uploaded on-line renders automated\nunderstanding of long texts a critical area of research. This article has two\ngoals: a) it overviews the relevant neural building blocks, thus serving as a\nshort tutorial, and b) it surveys the state-of-the-art in long document NLP,\nmainly focusing on two central tasks: document classification and document\nsummarization. Sentiment analysis for long texts is also covered, since it is\ntypically treated as a particular case of document classification. Thus, this\narticle concerns document-level analysis. It discusses the main challenges and\nissues of long document NLP, along with the current solutions. Finally, the\nrelevant, publicly available, annotated datasets are presented, in order to\nfacilitate further research.\n","authors":["Dimitrios Tsirmpas","Ioannis Gkionis","Ioannis Mademlis"],"pdf_url":"https://arxiv.org/pdf/2305.16259v4.pdf","comment":"51 pages, 2 figures, 168 citations"},{"id":"http://arxiv.org/abs/2306.04176v1","updated":"2023-06-07T06:03:39Z","published":"2023-06-07T06:03:39Z","title":"When to Read Documents or QA History: On Unified and Selective\n  Open-domain QA","summary":"  This paper studies the problem of open-domain question answering, with the\naim of answering a diverse range of questions leveraging knowledge resources.\nTwo types of sources, QA-pair and document corpora, have been actively\nleveraged with the following complementary strength. The former is highly\nprecise when the paraphrase of given question $q$ was seen and answered during\ntraining, often posed as a retrieval problem, while the latter generalizes\nbetter for unseen questions. A natural follow-up is thus leveraging both\nmodels, while a naive pipelining or integration approaches have failed to bring\nadditional gains over either model alone. Our distinction is interpreting the\nproblem as calibration, which estimates the confidence of predicted answers as\nan indicator to decide when to use a document or QA-pair corpus. The\neffectiveness of our method was validated on widely adopted benchmarks such as\nNatural Questions and TriviaQA.\n","authors":["Kyungjae Lee","Sang-eun Han","Seung-won Hwang","Moontae Lee"],"pdf_url":"https://arxiv.org/pdf/2306.04176v1.pdf","comment":"Findings of ACL 2023 camera ready"},{"id":"http://arxiv.org/abs/2306.04170v1","updated":"2023-06-07T05:46:19Z","published":"2023-06-07T05:46:19Z","title":"From the One, Judge of the Whole: Typed Entailment Graph Construction\n  with Predicate Generation","summary":"  Entailment Graphs (EGs) have been constructed based on extracted corpora as a\nstrong and explainable form to indicate context-independent entailment\nrelations in natural languages. However, EGs built by previous methods often\nsuffer from the severe sparsity issues, due to limited corpora available and\nthe long-tail phenomenon of predicate distributions. In this paper, we propose\na multi-stage method, Typed Predicate-Entailment Graph Generator (TP-EGG), to\ntackle this problem. Given several seed predicates, TP-EGG builds the graphs by\ngenerating new predicates and detecting entailment relations among them. The\ngenerative nature of TP-EGG helps us leverage the recent advances from large\npretrained language models (PLMs), while avoiding the reliance on carefully\nprepared corpora. Experiments on benchmark datasets show that TP-EGG can\ngenerate high-quality and scale-controllable entailment graphs, achieving\nsignificant in-domain improvement over state-of-the-art EGs and boosting the\nperformance of down-stream inference tasks.\n","authors":["Zhibin Chen","Yansong Feng","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.04170v1.pdf","comment":"9 pages, 3 figures, accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2305.06294v2","updated":"2023-06-07T05:33:07Z","published":"2023-05-10T16:31:35Z","title":"CADGE: Context-Aware Dialogue Generation Enhanced with Graph-Structured\n  Knowledge Aggregation","summary":"  Commonsense knowledge is crucial to many natural language processing tasks.\nExisting works usually incorporate graph knowledge with conventional graph\nneural networks (GNNs), leading to the text and graph knowledge encoding\nprocesses being separated in a serial pipeline. We argue that these separate\nrepresentation learning stages may be suboptimal for neural networks to learn\nthe overall context contained in both types of input knowledge. In this paper,\nwe propose a novel context-aware graph-attention model (Context-aware GAT),\nwhich can effectively incorporate global features of relevant knowledge graphs\nbased on a context-enhanced knowledge aggregation process. Specifically, our\nframework leverages a novel representation learning approach to process\nheterogeneous features - combining flattened graph knowledge with text. To the\nbest of our knowledge, this is the first attempt at hierarchically applying\ngraph knowledge aggregation on a connected subgraph in addition to contextual\ninformation to support commonsense dialogue generation. This framework shows\nsuperior performance compared to conventional GNN-based language frameworks.\nBoth automatic and human evaluation demonstrates that our proposed model has\nsignificant performance uplifts over state-of-the-art baselines.\n","authors":["Hongbo Zhang","Chen Tang","Tyler Loakman","Chenghua Lin","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2305.06294v2.pdf","comment":"Submitted to KBS"},{"id":"http://arxiv.org/abs/2306.03457v2","updated":"2023-06-07T05:24:25Z","published":"2023-06-06T07:20:51Z","title":"TwistList: Resources and Baselines for Tongue Twister Generation","summary":"  Previous work in phonetically-grounded language generation has mainly focused\non domains such as lyrics and poetry. In this paper, we present work on the\ngeneration of tongue twisters - a form of language that is required to be\nphonetically conditioned to maximise sound overlap, whilst maintaining semantic\nconsistency with an input topic, and still being grammatically correct. We\npresent \\textbf{TwistList}, a large annotated dataset of tongue twisters,\nconsisting of 2.1K+ human-authored examples. We additionally present several\nbenchmark systems (referred to as TwisterMisters) for the proposed task of\ntongue twister generation, including models that both do and do not require\ntraining on in-domain data. We present the results of automatic and human\nevaluation to demonstrate the performance of existing mainstream pre-trained\nmodels in this task with limited (or no) task specific training and data, and\nno explicit phonetic knowledge. We find that the task of tongue twister\ngeneration is challenging for models under these conditions, yet some models\nare still capable of generating acceptable examples of this language type.\n","authors":["Tyler Loakman","Chen Tang","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2306.03457v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.02434v2","updated":"2023-06-07T04:51:48Z","published":"2022-07-06T04:46:07Z","title":"Early Discovery of Emerging Entities in Persian Twitter with Semantic\n  Similarity","summary":"  Discovering emerging entities (EEs) is the problem of finding entities before\ntheir establishment. These entities can be critical for individuals, companies,\nand governments. Many of these entities can be discovered on social media\nplatforms, e.g. Twitter. These identities have been the spot of research in\nacademia and industry in recent years. Similar to any machine learning problem,\ndata availability is one of the major challenges in this problem. This paper\nproposes EEPT. That is an online clustering method able to discover EEs without\nany need for training on a dataset. Additionally, due to the lack of a proper\nevaluation metric, this paper uses a new metric to evaluate the results. The\nresults show that EEPT is promising and finds significant entities before their\nestablishment.\n","authors":["Shahin Yousefi","Mohsen Hooshmand","Mohsen Afsharchi"],"pdf_url":"https://arxiv.org/pdf/2207.02434v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12874v4","updated":"2023-06-07T04:38:19Z","published":"2022-10-23T22:35:02Z","title":"Global Contrastive Batch Sampling via Optimization on Sample\n  Permutations","summary":"  Contrastive Learning has recently achieved state-of-the-art performance in a\nwide range of tasks. Many contrastive learning approaches use mined hard\nnegatives to make batches more informative during training but these approaches\nare inefficient as they increase epoch length proportional to the number of\nmined negatives and require frequent updates of nearest neighbor indices or\nmining from recent batches. In this work, we provide an alternative to hard\nnegative mining, Global Contrastive Batch Sampling (GCBS), an efficient\napproximation to the batch assignment problem that upper bounds the gap between\nthe global and training losses, $\\mathcal{L}^{Global} - \\mathcal{L}^{Train}$,\nin contrastive learning settings. Through experimentation we find GCBS improves\nstate-of-the-art performance in sentence embedding and code-search tasks.\nAdditionally, GCBS is easy to implement as it requires only a few additional\nlines of code, does not maintain external data structures such as nearest\nneighbor indices, is more computationally efficient than the most minimal hard\nnegative mining approaches, and makes no changes to the model being trained.\n","authors":["Vin Sachidananda","Ziyi Yang","Chenguang Zhu"],"pdf_url":"https://arxiv.org/pdf/2210.12874v4.pdf","comment":"ICML 2023; 21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.04140v1","updated":"2023-06-07T04:27:09Z","published":"2023-06-07T04:27:09Z","title":"Increasing Diversity While Maintaining Accuracy: Text Data Generation\n  with Large Language Models and Human Interventions","summary":"  Large language models (LLMs) can be used to generate text data for training\nand evaluating other models. However, creating high-quality datasets with LLMs\ncan be challenging. In this work, we explore human-AI partnerships to\nfacilitate high diversity and accuracy in LLM-based text data generation. We\nfirst examine two approaches to diversify text generation: 1) logit\nsuppression, which minimizes the generation of languages that have already been\nfrequently generated, and 2) temperature sampling, which flattens the token\nsampling probability. We found that diversification approaches can increase\ndata diversity but often at the cost of data accuracy (i.e., text and labels\nbeing appropriate for the target domain). To address this issue, we examined\ntwo human interventions, 1) label replacement (LR), correcting misaligned\nlabels, and 2) out-of-scope filtering (OOSF), removing instances that are out\nof the user's domain of interest or to which no considered label applies. With\noracle studies, we found that LR increases the absolute accuracy of models\ntrained with diversified datasets by 14.4%. Moreover, we found that some models\ntrained with data generated with LR interventions outperformed LLM-based\nfew-shot classification. In contrast, OOSF was not effective in increasing\nmodel accuracy, implying the need for future work in human-in-the-loop text\ndata generation.\n","authors":["John Joon Young Chung","Ece Kamar","Saleema Amershi"],"pdf_url":"https://arxiv.org/pdf/2306.04140v1.pdf","comment":"Accepted as a long paper at ACL 2023"},{"id":"http://arxiv.org/abs/2306.04136v1","updated":"2023-06-07T04:15:21Z","published":"2023-06-07T04:15:21Z","title":"Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge\n  Graph Question Answering","summary":"  Large Language Models (LLMs) are capable of performing zero-shot closed-book\nquestion answering tasks, based on their internal knowledge stored in\nparameters during pre-training. However, such internalized knowledge might be\ninsufficient and incorrect, which could lead LLMs to generate factually wrong\nanswers. Furthermore, fine-tuning LLMs to update their knowledge is expensive.\nTo this end, we propose to augment the knowledge directly in the input of LLMs.\nSpecifically, we first retrieve the relevant facts to the input question from\nthe knowledge graph based on semantic similarities between the question and its\nassociated facts. After that, we prepend the retrieved facts to the input\nquestion in the form of the prompt, which is then forwarded to LLMs to generate\nthe answer. Our framework, Knowledge-Augmented language model PromptING\n(KAPING), requires no model training, thus completely zero-shot. We validate\nthe performance of our KAPING framework on the knowledge graph question\nanswering task, that aims to answer the user's question based on facts over a\nknowledge graph, on which ours outperforms relevant zero-shot baselines by up\nto 48% in average, across multiple LLMs of various sizes.\n","authors":["Jinheon Baek","Alham Fikri Aji","Amir Saffari"],"pdf_url":"https://arxiv.org/pdf/2306.04136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02349v2","updated":"2023-06-07T03:57:51Z","published":"2023-06-04T12:54:00Z","title":"bgGLUE: A Bulgarian General Language Understanding Evaluation Benchmark","summary":"  We present bgGLUE(Bulgarian General Language Understanding Evaluation), a\nbenchmark for evaluating language models on Natural Language Understanding\n(NLU) tasks in Bulgarian. Our benchmark includes NLU tasks targeting a variety\nof NLP problems (e.g., natural language inference, fact-checking, named entity\nrecognition, sentiment analysis, question answering, etc.) and machine learning\ntasks (sequence labeling, document-level classification, and regression). We\nrun the first systematic evaluation of pre-trained language models for\nBulgarian, comparing and contrasting results across the nine tasks in the\nbenchmark. The evaluation results show strong performance on sequence labeling\ntasks, but there is a lot of room for improvement for tasks that require more\ncomplex reasoning. We make bgGLUE publicly available together with the\nfine-tuning and the evaluation code, as well as a public leaderboard at\nhttps://bgglue.github.io/, and we hope that it will enable further advancements\nin developing NLU models for Bulgarian.\n","authors":["Momchil Hardalov","Pepa Atanasova","Todor Mihaylov","Galia Angelova","Kiril Simov","Petya Osenova","Ves Stoyanov","Ivan Koychev","Preslav Nakov","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2306.02349v2.pdf","comment":"Accepted to ACL 2023 (Main Conference)"},{"id":"http://arxiv.org/abs/2306.01707v3","updated":"2023-06-07T03:45:15Z","published":"2023-06-02T17:29:22Z","title":"Learning Multi-Step Reasoning by Solving Arithmetic Tasks","summary":"  Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT which is composed of Multi-step Arithmetic Tasks. Our experiments on four\nmath word problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.\n","authors":["Tianduo Wang","Wei Lu"],"pdf_url":"https://arxiv.org/pdf/2306.01707v3.pdf","comment":"ACL 2023. Code and data are available at\n  https://github.com/TianduoWang/MsAT"},{"id":"http://arxiv.org/abs/2306.04125v1","updated":"2023-06-07T03:44:50Z","published":"2023-06-07T03:44:50Z","title":"Multimodal Fusion Interactions: A Study of Human and Automatic\n  Quantification","summary":"  Multimodal fusion of multiple heterogeneous and interconnected signals is a\nfundamental challenge in almost all multimodal problems and applications. In\norder to perform multimodal fusion, we need to understand the types of\ninteractions that modalities can exhibit: how each modality individually\nprovides information useful for a task and how this information changes in the\npresence of other modalities. In this paper, we perform a comparative study of\nhow human annotators can be leveraged to annotate two categorizations of\nmultimodal interactions: (1) partial labels, where different randomly assigned\nannotators annotate the label given the first, second, and both modalities, and\n(2) counterfactual labels, where the same annotator is tasked to annotate the\nlabel given the first modality before giving them the second modality and\nasking them to explicitly reason about how their answer changes, before\nproposing an alternative taxonomy based on (3) information decomposition, where\nannotators annotate the degrees of redundancy: the extent to which modalities\nindividually and together give the same predictions on the task, uniqueness:\nthe extent to which one modality enables a task prediction that the other does\nnot, and synergy: the extent to which only both modalities enable one to make a\nprediction about the task that one would not otherwise make using either\nmodality individually. Through extensive experiments and annotations, we\nhighlight several opportunities and limitations of each approach and propose a\nmethod to automatically convert annotations of partial and counterfactual\nlabels to information decomposition, yielding an accurate and efficient method\nfor quantifying interactions in multimodal datasets.\n","authors":["Paul Pu Liang","Yun Cheng","Ruslan Salakhutdinov","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2306.04125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16636v2","updated":"2023-06-07T03:08:27Z","published":"2023-05-26T05:22:36Z","title":"DataFinder: Scientific Dataset Recommendation from Natural Language\n  Descriptions","summary":"  Modern machine learning relies on datasets to develop and validate research\nideas. Given the growth of publicly available data, finding the right dataset\nto use is increasingly difficult. Any research question imposes explicit and\nimplicit constraints on how well a given dataset will enable researchers to\nanswer this question, such as dataset size, modality, and domain. We\noperationalize the task of recommending datasets given a short natural language\ndescription of a research idea, to help people find relevant datasets for their\nneeds. Dataset recommendation poses unique challenges as an information\nretrieval problem; datasets are hard to directly index for search and there are\nno corpora readily available for this task. To facilitate this task, we build\nthe DataFinder Dataset which consists of a larger automatically-constructed\ntraining set (17.5K queries) and a smaller expert-annotated evaluation set (392\nqueries). Using this data, we compare various information retrieval algorithms\non our test set and present a superior bi-encoder retriever for text-based\ndataset recommendation. This system, trained on the DataFinder Dataset, finds\nmore relevant search results than existing third-party dataset search engines.\nTo encourage progress on dataset recommendation, we release our dataset and\nmodels to the public.\n","authors":["Vijay Viswanathan","Luyu Gao","Tongshuang Wu","Pengfei Liu","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2305.16636v2.pdf","comment":"To appear at ACL 2023. Code published at\n  https://github.com/viswavi/datafinder"},{"id":"http://arxiv.org/abs/2306.04116v1","updated":"2023-06-07T03:03:41Z","published":"2023-06-07T03:03:41Z","title":"Unbalanced Optimal Transport for Unbalanced Word Alignment","summary":"  Monolingual word alignment is crucial to model semantic interactions between\nsentences. In particular, null alignment, a phenomenon in which words have no\ncorresponding counterparts, is pervasive and critical in handling semantically\ndivergent sentences. Identification of null alignment is useful on its own to\nreason about the semantic similarity of sentences by indicating there exists\ninformation inequality. To achieve unbalanced word alignment that values both\nalignment and null alignment, this study shows that the family of optimal\ntransport (OT), i.e., balanced, partial, and unbalanced OT, are natural and\npowerful approaches even without tailor-made techniques. Our extensive\nexperiments covering unsupervised and supervised settings indicate that our\ngeneric OT-based alignment methods are competitive against the\nstate-of-the-arts specially designed for word alignment, remarkably on\nchallenging datasets with high null alignment frequencies.\n","authors":["Yuki Arase","Han Bao","Sho Yokoi"],"pdf_url":"https://arxiv.org/pdf/2306.04116v1.pdf","comment":"Accepted for the Annual Meeting of the Association for Computational\n  Linguistics (ACL 2023)"},{"id":"http://arxiv.org/abs/2211.05041v2","updated":"2023-06-07T02:02:51Z","published":"2022-11-09T17:17:37Z","title":"MACSum: Controllable Summarization with Mixed Attributes","summary":"  Controllable summarization allows users to generate customized summaries with\nspecified attributes. However, due to the lack of designated annotations of\ncontrolled summaries, existing works have to craft pseudo datasets by adapting\ngeneric summarization benchmarks. Furthermore, most research focuses on\ncontrolling single attributes individually (e.g., a short summary or a highly\nabstractive summary) rather than controlling a mix of attributes together\n(e.g., a short and highly abstractive summary). In this paper, we propose\nMACSum, the first human-annotated summarization dataset for controlling mixed\nattributes. It contains source texts from two domains, news articles and\ndialogues, with human-annotated summaries controlled by five designed\nattributes (Length, Extractiveness, Specificity, Topic, and Speaker). We\npropose two simple and effective parameter-efficient approaches for the new\ntask of mixed controllable summarization based on hard prompt tuning and soft\nprefix tuning. Results and analysis demonstrate that hard prompt models yield\nthe best performance on all metrics and human evaluations. However,\nmixed-attribute control is still challenging for summarization tasks. Our\ndataset and code are available at https://github.com/psunlpgroup/MACSum.\n","authors":["Yusen Zhang","Yang Liu","Ziyi Yang","Yuwei Fang","Yulong Chen","Dragomir Radev","Chenguang Zhu","Michael Zeng","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.05041v2.pdf","comment":"TACL 2023"},{"id":"http://arxiv.org/abs/2306.03763v2","updated":"2023-06-07T01:50:14Z","published":"2023-05-28T21:11:59Z","title":"ChatGPT Informed Graph Neural Network for Stock Movement Prediction","summary":"  ChatGPT has demonstrated remarkable capabilities across various natural\nlanguage processing (NLP) tasks. However, its potential for inferring dynamic\nnetwork structures from temporal textual data, specifically financial news,\nremains an unexplored frontier. In this research, we introduce a novel\nframework that leverages ChatGPT's graph inference capabilities to enhance\nGraph Neural Networks (GNN). Our framework adeptly extracts evolving network\nstructures from textual data, and incorporates these networks into graph neural\nnetworks for subsequent predictive tasks. The experimental results from stock\nmovement forecasting indicate our model has consistently outperformed the\nstate-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios\nconstructed based on our model's outputs demonstrate higher annualized\ncumulative returns, alongside reduced volatility and maximum drawdown. This\nsuperior performance highlights the potential of ChatGPT for text-based network\ninferences and underscores its promising implications for the financial sector.\n","authors":["Zihan Chen","Lei Nico Zheng","Cheng Lu","Jialu Yuan","Di Zhu"],"pdf_url":"https://arxiv.org/pdf/2306.03763v2.pdf","comment":"Under Review. 10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.04101v1","updated":"2023-06-07T01:44:43Z","published":"2023-06-07T01:44:43Z","title":"Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data\n  Augmentation","summary":"  Few-shot question answering (QA) aims at precisely discovering answers to a\nset of questions from context passages while only a few training samples are\navailable. Although existing studies have made some progress and can usually\nachieve proper results, they suffer from understanding deep semantics for\nreasoning out the questions. In this paper, we develop Gotta, a Generative\nprOmpT-based daTa Augmentation framework to mitigate the challenge above.\nInspired by the human reasoning process, we propose to integrate the cloze task\nto enhance few-shot QA learning. Following the recent success of prompt-tuning,\nwe present the cloze task in the same format as the main QA task, allowing the\nmodel to learn both tasks seamlessly together to fully take advantage of the\npower of prompt-tuning. Extensive experiments on widely used benchmarks\ndemonstrate that Gotta consistently outperforms competitive baselines,\nvalidating the effectiveness of our proposed prompt-tuning-based cloze task,\nwhich not only fine-tunes language models but also learns to guide reasoning in\nQA tasks. Further analysis shows that the prompt-based loss incorporates the\nauxiliary task better than the multi-task loss, highlighting the strength of\nprompt-tuning on the few-shot QA task.\n","authors":["Xiusi Chen","Yu Zhang","Jinliang Deng","Jyun-Yu Jiang","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.04101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04085v1","updated":"2023-06-07T01:09:37Z","published":"2023-06-07T01:09:37Z","title":"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages\n  and Meaning Representations","summary":"  Cross-Lingual Semantic Parsing (CLSP) aims to translate queries in multiple\nnatural languages (NLs) into meaning representations (MRs) such as SQL, lambda\ncalculus, and logic forms. However, existing CLSP models are separately\nproposed and evaluated on datasets of limited tasks and applications, impeding\na comprehensive and unified evaluation of CLSP on a diverse range of NLs and\nMRs. To this end, we present XSemPLR, a unified benchmark for cross-lingual\nsemantic parsing featured with 22 natural languages and 8 meaning\nrepresentations by examining and selecting 9 existing datasets to cover 5 tasks\nand 164 domains. We use XSemPLR to conduct a comprehensive benchmark study on a\nwide range of multilingual language models including encoder-based models\n(mBERT, XLM-R), encoder-decoder models (mBART, mT5), and decoder-based models\n(Codex, BLOOM). We design 6 experiment settings covering various lingual\ncombinations (monolingual, multilingual, cross-lingual) and numbers of learning\nsamples (full dataset, few-shot, and zero-shot). Our experiments show that\nencoder-decoder models (mT5) achieve the highest performance compared with\nother popular models, and multilingual training can further improve the average\nperformance. Notably, multilingual large language models (e.g., BLOOM) are\nstill inadequate to perform CLSP tasks. We also find that the performance gap\nbetween monolingual training and cross-lingual transfer learning is still\nsignificant for multilingual models, though it can be mitigated by\ncross-lingual few-shot training. Our dataset and code are available at\nhttps://github.com/psunlpgroup/XSemPLR.\n","authors":["Yusen Zhang","Jun Wang","Zhiguo Wang","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04085v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.03872v2","updated":"2023-06-07T00:37:34Z","published":"2023-06-06T17:18:56Z","title":"Deductive Verification of Chain-of-Thought Reasoning","summary":"  Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.\n","authors":["Zhan Ling","Yunhao Fang","Xuanlin Li","Zhiao Huang","Mingu Lee","Roland Memisevic","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2306.03872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04076v1","updated":"2023-06-07T00:33:02Z","published":"2023-06-07T00:33:02Z","title":"Text-only Domain Adaptation using Unified Speech-Text Representation in\n  Transducer","summary":"  Domain adaptation using text-only corpus is challenging in end-to-end(E2E)\nspeech recognition. Adaptation by synthesizing audio from text through TTS is\nresource-consuming. We present a method to learn Unified Speech-Text\nRepresentation in Conformer Transducer(USTR-CT) to enable fast domain\nadaptation using the text-only corpus. Different from the previous textogram\nmethod, an extra text encoder is introduced in our work to learn text\nrepresentation and is removed during inference, so there is no modification for\nonline deployment. To improve the efficiency of adaptation, single-step and\nmulti-step adaptations are also explored. The experiments on adapting\nLibriSpeech to SPGISpeech show the proposed method reduces the word error\nrate(WER) by relatively 44% on the target domain, which is better than those of\nTTS method and textogram method. Also, it is shown the proposed method can be\ncombined with internal language model estimation(ILME) to further improve the\nperformance.\n","authors":["Lu Huang","Boyu Li","Jun Zhang","Lu Lu","Zejun Ma"],"pdf_url":"https://arxiv.org/pdf/2306.04076v1.pdf","comment":"Submitted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.03341v2","updated":"2023-06-07T00:27:45Z","published":"2023-06-06T01:26:53Z","title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language\n  Model","summary":"  We introduce Inference-Time Intervention (ITI), a technique designed to\nenhance the truthfulness of large language models (LLMs). ITI operates by\nshifting model activations during inference, following a set of directions\nacross a limited number of attention heads. This intervention significantly\nimproves the performance of LLaMA models on the TruthfulQA benchmark. On an\ninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from\n32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and\ndemonstrate how to balance it by tuning the intervention strength. ITI is\nminimally invasive and computationally inexpensive. Moreover, the technique is\ndata efficient: while approaches like RLHF require extensive annotations, ITI\nlocates truthful directions using only few hundred examples. Our findings\nsuggest that LLMs may have an internal representation of the likelihood of\nsomething being true, even as they produce falsehoods on the surface.\n","authors":["Kenneth Li","Oam Patel","Fernanda Viégas","Hanspeter Pfister","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2306.03341v2.pdf","comment":"code: https://github.com/likenneth/honest_llama"},{"id":"http://arxiv.org/abs/2210.03251v2","updated":"2023-06-07T23:15:30Z","published":"2022-10-06T23:29:59Z","title":"Small Character Models Match Large Word Models for Autocomplete Under\n  Memory Constraints","summary":"  Autocomplete is a task where the user inputs a piece of text, termed prompt,\nwhich is conditioned by the model to generate semantically coherent\ncontinuation. Existing works for this task have primarily focused on datasets\n(e.g., email, chat) with high frequency user prompt patterns (or focused\nprompts) where word-based language models have been quite effective. In this\nwork, we study the more challenging open-domain setting consisting of low\nfrequency user prompt patterns (or broad prompts, e.g., prompt about 93rd\nacademy awards) and demonstrate the effectiveness of character-based language\nmodels. We study this problem under memory-constrained settings (e.g., edge\ndevices and smartphones), where character-based representation is effective in\nreducing the overall model size (in terms of parameters). We use WikiText-103\nbenchmark to simulate broad prompts and demonstrate that character models rival\nword models in exact match accuracy for the autocomplete task, when controlled\nfor the model size. For instance, we show that a 20M parameter character model\nperforms similar to an 80M parameter word model in the vanilla setting. We\nfurther propose novel methods to improve character models by incorporating\ninductive bias in the form of compositional information and representation\ntransfer from large word models. Datasets and code used in this work are\navailable at https://github.com/UBC-NLP/char_autocomplete.\n","authors":["Ganesh Jawahar","Subhabrata Mukherjee","Debadeepta Dey","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan","Caio Cesar Teodoro Mendes","Gustavo Henrique de Rosa","Shital Shah"],"pdf_url":"https://arxiv.org/pdf/2210.03251v2.pdf","comment":"SustaiNLP 2023"},{"id":"http://arxiv.org/abs/2306.02827v2","updated":"2023-06-07T23:07:26Z","published":"2023-06-05T12:23:04Z","title":"UNIDECOR: A Unified Deception Corpus for Cross-Corpus Deception\n  Detection","summary":"  Verbal deception has been studied in psychology, forensics, and computational\nlinguistics for a variety of reasons, like understanding behaviour patterns,\nidentifying false testimonies, and detecting deception in online communication.\nVarying motivations across research fields lead to differences in the domain\nchoices to study and in the conceptualization of deception, making it hard to\ncompare models and build robust deception detection systems for a given\nlanguage. With this paper, we improve this situation by surveying available\nEnglish deception datasets which include domains like social media reviews,\ncourt testimonials, opinion statements on specific topics, and deceptive\ndialogues from online strategy games. We consolidate these datasets into a\nsingle unified corpus. Based on this resource, we conduct a correlation\nanalysis of linguistic cues of deception across datasets to understand the\ndifferences and perform cross-corpus modeling experiments which show that a\ncross-domain generalization is challenging to achieve. The unified deception\ncorpus (UNIDECOR) can be obtained from\nhttps://www.ims.uni-stuttgart.de/data/unidecor.\n","authors":["Aswathy Velutharambath","Roman Klinger"],"pdf_url":"https://arxiv.org/pdf/2306.02827v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04823v1","updated":"2023-06-07T23:07:23Z","published":"2023-06-07T23:07:23Z","title":"Data Augmentation for Improving Tail-traffic Robustness in Skill-routing\n  for Dialogue Systems","summary":"  Large-scale conversational systems typically rely on a skill-routing\ncomponent to route a user request to an appropriate skill and interpretation to\nserve the request. In such system, the agent is responsible for serving\nthousands of skills and interpretations which create a long-tail distribution\ndue to the natural frequency of requests. For example, the samples related to\nplay music might be a thousand times more frequent than those asking for\ntheatre show times. Moreover, inputs used for ML-based skill routing are often\na heterogeneous mix of strings, embedding vectors, categorical and scalar\nfeatures which makes employing augmentation-based long-tail learning approaches\nchallenging. To improve the skill-routing robustness, we propose an\naugmentation of heterogeneous skill-routing data and training targeted for\nrobust operation in long-tail data regimes. We explore a variety of conditional\nencoder-decoder generative frameworks to perturb original data fields and\ncreate synthetic training data. To demonstrate the effectiveness of the\nproposed method, we conduct extensive experiments using real-world data from a\ncommercial conversational system. Based on the experiment results, the proposed\napproach improves more than 80% (51 out of 63) of intents with less than 10K of\ntraffic instances in the skill-routing replication task.\n","authors":["Ting-Wei Wu","Fatemeh Sheikholeslami","Mohammad Kachuee","Jaeyoung Do","Sungjin Lee"],"pdf_url":"https://arxiv.org/pdf/2306.04823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10773v2","updated":"2023-06-07T23:05:26Z","published":"2022-12-21T05:17:06Z","title":"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction\n  Tuning","summary":"  Instruction tuning, a new learning paradigm that fine-tunes pre-trained\nlanguage models on tasks specified through instructions, has shown promising\nzero-shot performance on various natural language processing tasks. However,\nit's still not explored for vision and multimodal tasks. In this work, we\nintroduce MultiInstruct, the first multimodal instruction tuning benchmark\ndataset that consists of 47 diverse multimodal tasks covering 11 broad\ncategories. Each task is designed at least with 5,000 instances (input-out\npairs) from existing open-source datasets and 5 expert-written instructions. We\ntake OFA as the base pre-trained model for multimodal instruction tuning, and\nto improve its performance, we explore multiple transfer learning strategies to\nleverage the large-scale Natural Instructions dataset. Experimental results\ndemonstrate its strong zero-shot performance on various unseen multimodal tasks\nand the benefit of transfer learning from text-only instructions. We also\ndesign a new evaluation metric: Sensitivity, to evaluate how sensitive the\nmodel is to the variety of instructions. Our results indicate that the model is\nless sensitive to the varying instructions after finetuning on a diverse set of\ntasks and instructions for each task.\n","authors":["Zhiyang Xu","Ying Shen","Lifu Huang"],"pdf_url":"https://arxiv.org/pdf/2212.10773v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.04820v1","updated":"2023-06-07T22:56:53Z","published":"2023-06-07T22:56:53Z","title":"Good Data, Large Data, or No Data? Comparing Three Approaches in\n  Developing Research Aspect Classifiers for Biomedical Papers","summary":"  The rapid growth of scientific publications, particularly during the COVID-19\npandemic, emphasizes the need for tools to help researchers efficiently\ncomprehend the latest advancements. One essential part of understanding\nscientific literature is research aspect classification, which categorizes\nsentences in abstracts to Background, Purpose, Method, and Finding. In this\nstudy, we investigate the impact of different datasets on model performance for\nthe crowd-annotated CODA-19 research aspect classification task. Specifically,\nwe explore the potential benefits of using the large, automatically curated\nPubMed 200K RCT dataset and evaluate the effectiveness of large language models\n(LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4. Our results indicate that\nusing the PubMed 200K RCT dataset does not improve performance for the CODA-19\ntask. We also observe that while GPT-4 performs well, it does not outperform\nthe SciBERT model fine-tuned on the CODA-19 dataset, emphasizing the importance\nof a dedicated and task-aligned datasets dataset for the target task. Our code\nis available at https://github.com/Crowd-AI-Lab/CODA-19-exp.\n","authors":["Shreya Chandrasekhar","Chieh-Yang Huang","Ting-Hao 'Kenneth' Huang"],"pdf_url":"https://arxiv.org/pdf/2306.04820v1.pdf","comment":"BioNLP workshop 2023"},{"id":"http://arxiv.org/abs/2210.07535v2","updated":"2023-06-07T22:41:40Z","published":"2022-10-14T05:32:17Z","title":"AutoMoE: Heterogeneous Mixture-of-Experts with Adaptive Computation for\n  Efficient Neural Machine Translation","summary":"  Mixture-of-Expert (MoE) models have obtained state-of-the-art performance in\nNeural Machine Translation (NMT) tasks. Existing works in MoE mostly consider a\nhomogeneous design where the same number of experts of the same size are placed\nuniformly throughout the network. Furthermore, existing MoE works do not\nconsider computational constraints (e.g., FLOPs, latency) to guide their\ndesign. To this end, we develop AutoMoE -- a framework for designing\nheterogeneous MoE's under computational constraints. AutoMoE leverages Neural\nArchitecture Search (NAS) to obtain efficient sparse MoE sub-transformers with\n4x inference speedup (CPU) and FLOPs reduction over manually designed\nTransformers, with parity in BLEU score over dense Transformer and within 1\nBLEU point of MoE SwitchTransformer, on aggregate over benchmark datasets for\nNMT. Heterogeneous search space with dense and sparsely activated Transformer\nmodules (e.g., how many experts? where to place them? what should be their\nsizes?) allows for adaptive compute -- where different amounts of computations\nare used for different tokens in the input. Adaptivity comes naturally from\nrouting decisions which send tokens to experts of different sizes. AutoMoE\ncode, data, and trained models are available at https://aka.ms/AutoMoE.\n","authors":["Ganesh Jawahar","Subhabrata Mukherjee","Xiaodong Liu","Young Jin Kim","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan","Ahmed Hassan Awadallah","Sebastien Bubeck","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2210.07535v2.pdf","comment":"ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2210.12023v3","updated":"2023-06-07T22:03:16Z","published":"2022-10-21T15:12:37Z","title":"A Causal Framework to Quantify the Robustness of Mathematical Reasoning\n  with Language Models","summary":"  We have recently witnessed a number of impressive results on hard\nmathematical reasoning problems with language models. At the same time, the\nrobustness of these models has also been called into question; recent works\nhave shown that models can rely on shallow patterns in the problem description\nwhen generating a solution. Building on the idea of behavioral testing, we\npropose a novel framework, which pins down the causal effect of various factors\nin the input, e.g., the surface form of the problem text, the operands, and\nmath operators on the output solution. By grounding the behavioral analysis in\na causal graph describing an intuitive reasoning process, we study the behavior\nof language models in terms of robustness and sensitivity to direct\ninterventions in the input space. We apply our framework on a test bed of math\nword problems. Our analysis shows that robustness does not appear to\ncontinuously improve as a function of size, but the GPT-3 Davinci models (175B)\nachieve a dramatic improvement in both robustness and sensitivity compared to\nall other GPT variants.\n","authors":["Alessandro Stolfo","Zhijing Jin","Kumar Shridhar","Bernhard Schölkopf","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2210.12023v3.pdf","comment":"ACL 2023. A shorter version of the paper was accepted at the MATH-AI\n  Workshop at NeurIPS 2022. 15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.04803v1","updated":"2023-06-07T21:53:14Z","published":"2023-06-07T21:53:14Z","title":"Privately generating tabular data using language models","summary":"  Privately generating synthetic data from a table is an important brick of a\nprivacy-first world. We propose and investigate a simple approach of treating\neach row in a table as a sentence and training a language model with\ndifferential privacy. We show this approach obtains competitive results in\nmodelling tabular data across multiple datasets, even at small scales that\nfavor alternative methods based on marginal distributions.\n","authors":["Alexandre Sablayrolles","Yue Wang","Brian Karrer"],"pdf_url":"https://arxiv.org/pdf/2306.04803v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.04802v1","updated":"2023-06-07T21:51:56Z","published":"2023-06-07T21:51:56Z","title":"A Survey on Knowledge Graphs for Healthcare: Resources, Applications,\n  and Promises","summary":"  Healthcare knowledge graphs (HKGs) have emerged as a promising tool for\norganizing medical knowledge in a structured and interpretable way, which\nprovides a comprehensive view of medical concepts and their relationships.\nHowever, challenges such as data heterogeneity and limited coverage remain,\nemphasizing the need for further research in the field of HKGs. This survey\npaper serves as the first comprehensive overview of HKGs. We summarize the\npipeline and key techniques for HKG construction (i.e., from scratch and\nthrough integration), as well as the common utilization approaches (i.e.,\nmodel-free and model-based). To provide researchers with valuable resources, we\norganize existing HKGs (The resource is available at\nhttps://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase) based on the\ndata types they capture and application domains, supplemented with pertinent\nstatistical information. In the application section, we delve into the\ntransformative impact of HKGs across various healthcare domains, spanning from\nfine-grained basic science research to high-level clinical decision support.\nLastly, we shed light on the opportunities for creating comprehensive and\naccurate HKGs in the era of large language models, presenting the potential to\nrevolutionize healthcare delivery and enhance the interpretability and\nreliability of clinical prediction.\n","authors":["Hejie Cui","Jiaying Lu","Shiyu Wang","Ran Xu","Wenjing Ma","Shaojun Yu","Yue Yu","Xuan Kan","Chen Ling","Joyce Ho","Fei Wang","Carl Yang"],"pdf_url":"https://arxiv.org/pdf/2306.04802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04787v1","updated":"2023-06-07T21:18:23Z","published":"2023-06-07T21:18:23Z","title":"Absformer: Transformer-based Model for Unsupervised Multi-Document\n  Abstractive Summarization","summary":"  Multi-document summarization (MDS) refers to the task of summarizing the text\nin multiple documents into a concise summary. The generated summary can save\nthe time of reading many documents by providing the important content in the\nform of a few sentences. Abstractive MDS aims to generate a coherent and fluent\nsummary for multiple documents using natural language generation techniques. In\nthis paper, we consider the unsupervised abstractive MDS setting where there\nare only documents with no groundtruh summaries provided, and we propose\nAbsformer, a new Transformer-based method for unsupervised abstractive summary\ngeneration. Our method consists of a first step where we pretrain a\nTransformer-based encoder using the masked language modeling (MLM) objective as\nthe pretraining task in order to cluster the documents into semantically\nsimilar groups; and a second step where we train a Transformer-based decoder to\ngenerate abstractive summaries for the clusters of documents. To our knowledge,\nwe are the first to successfully incorporate a Transformer-based model to solve\nthe unsupervised abstractive MDS task. We evaluate our approach using three\nreal-world datasets from different domains, and we demonstrate both substantial\nimprovements in terms of evaluation metrics over state-of-the-art\nabstractive-based methods, and generalization to datasets from different\ndomains.\n","authors":["Mohamed Trabelsi","Huseyin Uzunalioglu"],"pdf_url":"https://arxiv.org/pdf/2306.04787v1.pdf","comment":"ICDAR 2023 International Workshop on Machine Learning (WML)"},{"id":"http://arxiv.org/abs/2305.15932v2","updated":"2023-06-07T20:33:09Z","published":"2023-05-25T10:59:47Z","title":"BUCA: A Binary Classification Approach to Unsupervised Commonsense\n  Question Answering","summary":"  Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as\nthe construction of commonsense reasoning datasets is expensive, and they are\ninevitably limited in their scope. A popular approach to UCR is to fine-tune\nlanguage models with external knowledge (e.g., knowledge graphs), but this\nusually requires a large number of training examples. In this paper, we propose\nto transform the downstream multiple choice question answering task into a\nsimpler binary classification task by ranking all candidate answers according\nto their reasonableness. To this end, for training the model, we convert the\nknowledge graph triples into reasonable and unreasonable texts. Extensive\nexperimental results show the effectiveness of our approach on various multiple\nchoice question answering benchmarks. Furthermore, compared with existing UCR\napproaches using KGs, ours is less data hungry. Our code is available at\nhttps://github.com/probe2/BUCA.\n","authors":["Jie He","Simon Chi Lok U","Víctor Gutiérrez-Basulto","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2305.15932v2.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.04765v1","updated":"2023-06-07T20:24:43Z","published":"2023-06-07T20:24:43Z","title":"The HCI Aspects of Public Deployment of Research Chatbots: A User Study,\n  Design Recommendations, and Open Challenges","summary":"  Publicly deploying research chatbots is a nuanced topic involving necessary\nrisk-benefit analyses. While there have recently been frequent discussions on\nwhether it is responsible to deploy such models, there has been far less focus\non the interaction paradigms and design approaches that the resulting\ninterfaces should adopt, in order to achieve their goals more effectively. We\naim to pose, ground, and attempt to answer HCI questions involved in this\nscope, by reporting on a mixed-methods user study conducted on a recent\nresearch chatbot. We find that abstract anthropomorphic representation for the\nagent has a significant effect on user's perception, that offering AI\nexplainability may have an impact on feedback rates, and that two (diegetic and\nextradiegetic) levels of the chat experience should be intentionally designed.\nWe offer design recommendations and areas of further focus for the research\ncommunity.\n","authors":["Morteza Behrooz","William Ngan","Joshua Lane","Giuliano Morse","Benjamin Babcock","Kurt Shuster","Mojtaba Komeili","Moya Chen","Melanie Kambadur","Y-Lan Boureau","Jason Weston"],"pdf_url":"https://arxiv.org/pdf/2306.04765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04757v1","updated":"2023-06-07T20:12:29Z","published":"2023-06-07T20:12:29Z","title":"INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large\n  Language Models","summary":"  Instruction-tuned large language models have revolutionized natural language\nprocessing and have shown great potential in applications such as\nconversational agents. These models, such as GPT-4, can not only master\nlanguage but also solve complex tasks in areas like mathematics, coding,\nmedicine, and law. Despite their impressive capabilities, there is still a lack\nof comprehensive understanding regarding their full potential, primarily due to\nthe black-box nature of many models and the absence of holistic evaluation\nstudies. To address these challenges, we present INSTRUCTEVAL, a more\ncomprehensive evaluation suite designed specifically for instruction-tuned\nlarge language models. Unlike previous works, our evaluation involves a\nrigorous assessment of models based on problem-solving, writing ability, and\nalignment to human values. We take a holistic approach to analyze various\nfactors affecting model performance, including the pretraining foundation,\ninstruction-tuning data, and training methods. Our findings reveal that the\nquality of instruction data is the most crucial factor in scaling model\nperformance. While open-source models demonstrate impressive writing abilities,\nthere is substantial room for improvement in problem-solving and alignment. We\nare encouraged by the rapid development of models by the open-source community,\nbut we also highlight the need for rigorous evaluation to support claims made\nabout these models. Through INSTRUCTEVAL, we aim to foster a deeper\nunderstanding of instruction-tuned models and advancements in their\ncapabilities. INSTRUCTEVAL is publicly available at\nhttps://github.com/declare-lab/instruct-eval.\n","authors":["Yew Ken Chia","Pengfei Hong","Lidong Bing","Soujanya Poria"],"pdf_url":"https://arxiv.org/pdf/2306.04757v1.pdf","comment":"https://github.com/declare-lab/instruct-eval"},{"id":"http://arxiv.org/abs/2306.04751v1","updated":"2023-06-07T19:59:23Z","published":"2023-06-07T19:59:23Z","title":"How Far Can Camels Go? Exploring the State of Instruction Tuning on Open\n  Resources","summary":"  In this work we explore recent advances in instruction-tuning language models\non a range of open instruction-following datasets. Despite recent claims that\nopen models can be on par with state-of-the-art proprietary models, these\nclaims are often accompanied by limited evaluation, making it difficult to\ncompare models across the board and determine the utility of various resources.\nWe provide a large set of instruction-tuned models from 6.7B to 65B parameters\nin size, trained on 12 instruction datasets ranging from manually curated\n(e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and\nsystematically evaluate them on their factual knowledge, reasoning,\nmultilinguality, coding, and open-ended instruction following abilities through\na collection of automatic, model-based, and human-based metrics. We further\nintroduce T\\\"ulu, our best performing instruction-tuned model suite finetuned\non a combination of high-quality open resources.\n  Our experiments show that different instruction-tuning datasets can uncover\nor enhance specific skills, while no single dataset (or combination) provides\nthe best performance across all evaluations. Interestingly, we find that model\nand human preference-based evaluations fail to reflect differences in model\ncapabilities exposed by benchmark-based evaluations, suggesting the need for\nthe type of systemic evaluation performed in this work. Our evaluations show\nthat the best model in any given evaluation reaches on average 83% of ChatGPT\nperformance, and 68% of GPT-4 performance, suggesting that further investment\nin building better base models and instruction-tuning data is required to close\nthe gap. We release our instruction-tuned models, including a fully finetuned\n65B T\\\"ulu, along with our code, data, and evaluation framework at\nhttps://github.com/allenai/open-instruct to facilitate future research.\n","authors":["Yizhong Wang","Hamish Ivison","Pradeep Dasigi","Jack Hessel","Tushar Khot","Khyathi Raghavi Chandu","David Wadden","Kelsey MacMillan","Noah A. Smith","Iz Beltagy","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2306.04751v1.pdf","comment":"18 pages, 5 figure, 7 tables. Under the review of NeurIPS 2023\n  Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2306.04746v1","updated":"2023-06-07T19:49:41Z","published":"2023-06-07T19:49:41Z","title":"Using Large Language Model Annotations for Valid Downstream Statistical\n  Inference in Social Science: Design-Based Semi-Supervised Learning","summary":"  In computational social science (CSS), researchers analyze documents to\nexplain social and political phenomena. In most scenarios, CSS researchers\nfirst obtain labels for documents and then explain labels using interpretable\nregression analyses in the second step. The recent advancements in large\nlanguage models (LLMs) can lower costs for CSS research by annotating documents\ncheaply at scale, but such surrogate labels are often imperfect and biased. We\npresent a new algorithm for using outputs from LLMs for downstream statistical\nanalyses while guaranteeing statistical properties -- like asymptotic\nunbiasedness and proper uncertainty quantification -- which are fundamental to\nCSS research. We show that direct use of LLM-predicted surrogate labels in\ndownstream statistical analyses leads to substantial bias and invalid\nconfidence intervals, even with high surrogate accuracy of 80--90\\%. To address\nthis, we build on debiased machine learning to propose the design-based\nsemi-supervised learning (DSL) estimator. DSL employs a doubly-robust procedure\nto combine surrogate labels with a smaller number of gold-standard labels. Our\napproach guarantees valid inference for downstream statistical analyses, even\nwhen surrogates are arbitrarily biased, without requiring stringent\nassumptions, by controlling the probability of sampling documents for\ngold-standard labeling. Both our theoretical analysis and experimental results\nshow that DSL provides valid statistical inference while achieving root mean\nsquared errors comparable to existing alternatives that focus only on\nprediction without statistical guarantees.\n","authors":["Naoki Egami","Musashi Jacobs-Harukawa","Brandon M. Stewart","Hanying Wei"],"pdf_url":"https://arxiv.org/pdf/2306.04746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04743v1","updated":"2023-06-07T19:37:55Z","published":"2023-06-07T19:37:55Z","title":"ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural\n  Language to SQL Systems","summary":"  Natural Language to SQL systems (NL-to-SQL) have recently shown a significant\nincrease in accuracy for natural language to SQL query translation. This\nimprovement is due to the emergence of transformer-based language models, and\nthe popularity of the Spider benchmark - the de-facto standard for evaluating\nNL-to-SQL systems. The top NL-to-SQL systems reach accuracies of up to 85\\%.\nHowever, Spider mainly contains simple databases with few tables, columns, and\nentries, which does not reflect a realistic setting. Moreover, complex\nreal-world databases with domain-specific content have little to no training\ndata available in the form of NL/SQL-pairs leading to poor performance of\nexisting NL-to-SQL systems.\n  In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL\nbenchmark for three real-world, highly domain-specific databases. For this new\nbenchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for\neach domain. To garner more data, we extended the small amount of\nhuman-generated data with synthetic data generated using GPT-3. We show that\nour benchmark is highly challenging, as the top performing systems on Spider\nachieve a very low performance on our benchmark. Thus, the challenge is\nmany-fold: creating NL-to-SQL systems for highly complex domains with a small\namount of hand-made training data augmented with synthetic data. To our\nknowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with\ncomplex real-world scientific databases, containing challenging training and\ntest data carefully validated by domain experts.\n","authors":["Yi Zhang","Jan Deriu","George Katsogiannis-Meimarakis","Catherine Kosten","Georgia Koutrika","Kurt Stockinger"],"pdf_url":"https://arxiv.org/pdf/2306.04743v1.pdf","comment":"12 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2306.04735v1","updated":"2023-06-07T19:11:25Z","published":"2023-06-07T19:11:25Z","title":"Soft-prompt Tuning for Large Language Models to Evaluate Bias","summary":"  Prompting large language models has gained immense popularity in recent years\ndue to the advantage of producing good results even without the need for\nlabelled data. However, this requires prompt tuning to get optimal prompts that\nlead to better model performances. In this paper, we explore the use of\nsoft-prompt tuning on sentiment classification task to quantify the biases of\nlarge language models (LLMs) such as Open Pre-trained Transformers (OPT) and\nGalactica language model. Since these models are trained on real-world data\nthat could be prone to bias toward certain groups of populations, it is\nimportant to identify these underlying issues. Using soft-prompts to evaluate\nbias gives us the extra advantage of avoiding the human-bias injection that can\nbe caused by manually designed prompts. We check the model biases on different\nsensitive attributes using the group fairness (bias) and find interesting bias\npatterns. Since LLMs have been used in the industry in various applications, it\nis crucial to identify the biases before deploying these models in practice. We\nopen-source our pipeline and encourage industry researchers to adapt our work\nto their use cases.\n","authors":["Jacob-Junqi Tian","David Emerson","Sevil Zanjani Miyandoab","Deval Pandya","Laleh Seyyed-Kalantari","Faiza Khan Khattak"],"pdf_url":"https://arxiv.org/pdf/2306.04735v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04724v1","updated":"2023-06-07T18:39:57Z","published":"2023-06-07T18:39:57Z","title":"Prompter: Zero-shot Adaptive Prefixes for Dialogue State Tracking Domain\n  Adaptation","summary":"  A challenge in the Dialogue State Tracking (DST) field is adapting models to\nnew domains without using any supervised data, zero-shot domain adaptation.\nParameter-Efficient Transfer Learning (PETL) has the potential to address this\nproblem due to its robustness. However, it has yet to be applied to the\nzero-shot scenarios, as it is not clear how to apply it unsupervisedly.\n  Our method, Prompter, uses descriptions of target domain slots to generate\ndynamic prefixes that are concatenated to the key and values at each layer's\nself-attention mechanism. This allows for the use of prefix-tuning in\nzero-shot. Prompter outperforms previous methods on both the MultiWOZ and SGD\nbenchmarks. In generating prefixes, our analyses find that Prompter not only\nutilizes the semantics of slot descriptions but also how often the slots appear\ntogether in conversation. Moreover, Prompter's gains are due to its improved\nability to distinguish \"none\"-valued dialogue slots, compared against\nbaselines.\n","authors":["Taha Aksu","Min-Yen Kan","Nancy F. Chen"],"pdf_url":"https://arxiv.org/pdf/2306.04724v1.pdf","comment":"Accepted to ACL 2023"},{"id":"http://arxiv.org/abs/2306.04723v1","updated":"2023-06-07T18:38:04Z","published":"2023-06-07T18:38:04Z","title":"Intrinsic Dimension Estimation for Robust Detection of AI-Generated\n  Texts","summary":"  Rapidly increasing quality of AI-generated content makes it difficult to\ndistinguish between human and AI-generated texts, which may lead to undesirable\nconsequences for society. Therefore, it becomes increasingly important to study\nthe properties of human texts that are invariant over text domains and various\nproficiency of human writers, can be easily calculated for any language, and\ncan robustly separate natural and AI-generated texts regardless of the\ngeneration model and sampling method. In this work, we propose such an\ninvariant of human texts, namely the intrinsic dimensionality of the manifold\nunderlying the set of embeddings of a given text sample. We show that the\naverage intrinsic dimensionality of fluent texts in natural language is\nhovering around the value $9$ for several alphabet-based languages and around\n$7$ for Chinese, while the average intrinsic dimensionality of AI-generated\ntexts for each language is $\\approx 1.5$ lower, with a clear statistical\nseparation between human-generated and AI-generated distributions. This\nproperty allows us to build a score-based artificial text detector. The\nproposed detector's accuracy is stable over text domains, generator models, and\nhuman writer proficiency levels, outperforming SOTA detectors in model-agnostic\nand cross-domain scenarios by a significant margin.\n","authors":["Eduard Tulchinskii","Kristian Kuznetsov","Laida Kushnareva","Daniil Cherniavskii","Serguei Barannikov","Irina Piontkovskaya","Sergey Nikolenko","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2306.04723v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04707v1","updated":"2023-06-07T18:19:46Z","published":"2023-06-07T18:19:46Z","title":"Improving Open Language Models by Learning from Organic Interactions","summary":"  We present BlenderBot 3x, an update on the conversational model BlenderBot 3,\nwhich is now trained using organic conversation and feedback data from\nparticipating users of the system in order to improve both its skills and\nsafety. We are publicly releasing the participating de-identified interaction\ndata for use by the research community, in order to spur further progress.\nTraining models with organic data is challenging because interactions with\npeople \"in the wild\" include both high quality conversations and feedback, as\nwell as adversarial and toxic behavior. We study techniques that enable\nlearning from helpful teachers while avoiding learning from people who are\ntrying to trick the model into unhelpful or toxic responses. BlenderBot 3x is\nboth preferred in conversation to BlenderBot 3, and is shown to produce safer\nresponses in challenging situations. While our current models are still far\nfrom perfect, we believe further improvement can be achieved by continued use\nof the techniques explored in this work.\n","authors":["Jing Xu","Da Ju","Joshua Lane","Mojtaba Komeili","Eric Michael Smith","Megan Ung","Morteza Behrooz","William Ngan","Rashel Moritz","Sainbayar Sukhbaatar","Y-Lan Boureau","Jason Weston","Kurt Shuster"],"pdf_url":"https://arxiv.org/pdf/2306.04707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16740v3","updated":"2023-06-07T18:01:11Z","published":"2022-11-30T04:51:26Z","title":"Explicit Knowledge Transfer for Weakly-Supervised Code Generation","summary":"  Large language models (LLMs) can acquire strong code-generation capabilities\nthrough few-shot learning. In contrast, supervised fine-tuning is still needed\nfor smaller models to achieve good performance. Such fine-tuning demands a\nlarge number of task-specific NL-code pairs, which are expensive to obtain. In\nthis paper, we attempt to transfer the code generation ability of an LLM to a\nsmaller model with the aid of weakly-supervised data. More specifically, we\npropose explicit knowledge transfer (EKT), which uses the few-shot capabilities\nof a teacher LLM to create NL-code pairs that we then filter for correctness\nand fine-tune the student on. We evaluate EKT on the task of generating code\nsolutions to math word problems from the GSM8k dataset. We find that EKT not\nonly yields better performance than training with expert iteration, but also\noutperforms knowledge distillation, another form of knowledge transfer. A\nGPT-Neo 1.3B model trained using EKT with a GPT-J teacher achieves a 12.4%\npass@100 on GSM8k, while the same student and teacher trained with knowledge\ndistillation yield only a 3.7% pass@100. We also show that it is possible for a\nstudent model to outperform the teacher using EKT.\n","authors":["Zhangir Azerbayev","Ansong Ni","Hailey Schoelkopf","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2211.16740v3.pdf","comment":"Updated on Jun 7. 2023 with ICLR workshop header"},{"id":"http://arxiv.org/abs/2306.04695v1","updated":"2023-06-07T18:00:38Z","published":"2023-06-07T18:00:38Z","title":"ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image\n  Diffusion Models","summary":"  The ability to understand visual concepts and replicate and compose these\nconcepts from images is a central goal for computer vision. Recent advances in\ntext-to-image (T2I) models have lead to high definition and realistic image\nquality generation by learning from large databases of images and their\ndescriptions. However, the evaluation of T2I models has focused on photorealism\nand limited qualitative measures of visual understanding. To quantify the\nability of T2I models in learning and synthesizing novel visual concepts, we\nintroduce ConceptBed, a large-scale dataset that consists of 284 unique visual\nconcepts, 5K unique concept compositions, and 33K composite text prompts. Along\nwith the dataset, we propose an evaluation metric, Concept Confidence Deviation\n(CCD), that uses the confidence of oracle concept classifiers to measure the\nalignment between concepts generated by T2I generators and concepts contained\nin ground truth images. We evaluate visual concepts that are either objects,\nattributes, or styles, and also evaluate four dimensions of compositionality:\ncounting, attributes, relations, and actions. Our human study shows that CCD is\nhighly correlated with human understanding of concepts. Our results point to a\ntrade-off between learning the concepts and preserving the compositionality\nwhich existing approaches struggle to overcome.\n","authors":["Maitreya Patel","Tejas Gokhale","Chitta Baral","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2306.04695v1.pdf","comment":"Project page: https://conceptbed.github.io"},{"id":"http://arxiv.org/abs/2306.04528v1","updated":"2023-06-07T15:37:00Z","published":"2023-06-07T15:37:00Z","title":"PromptBench: Towards Evaluating the Robustness of Large Language Models\n  on Adversarial Prompts","summary":"  The increasing reliance on Large Language Models (LLMs) across academia and\nindustry necessitates a comprehensive understanding of their robustness to\nprompts. In response to this vital need, we introduce PromptBench, a robustness\nbenchmark designed to measure LLMs' resilience to adversarial prompts. This\nstudy uses a plethora of adversarial textual attacks targeting prompts across\nmultiple levels: character, word, sentence, and semantic. These prompts are\nthen employed in diverse tasks, such as sentiment analysis, natural language\ninference, reading comprehension, machine translation, and math\nproblem-solving. Our study generates 4,032 adversarial prompts, meticulously\nevaluated over 8 tasks and 13 datasets, with 567,084 test samples in total. Our\nfindings demonstrate that contemporary LLMs are vulnerable to adversarial\nprompts. Furthermore, we present comprehensive analysis to understand the\nmystery behind prompt robustness and its transferability. We then offer\ninsightful robustness analysis and pragmatic recommendations for prompt\ncomposition, beneficial to both researchers and everyday users. We make our\ncode, prompts, and methodologies to generate adversarial prompts publicly\naccessible, thereby enabling and encouraging collaborative exploration in this\npivotal field: https://github.com/microsoft/promptbench.\n","authors":["Kaijie Zhu","Jindong Wang","Jiaheng Zhou","Zichen Wang","Hao Chen","Yidong Wang","Linyi Yang","Wei Ye","Neil Zhenqiang Gong","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2306.04528v1.pdf","comment":"Technical report; 23 pages"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2301.12366v2","updated":"2023-06-07T17:32:00Z","published":"2023-01-29T06:03:20Z","title":"Smooth Non-Stationary Bandits","summary":"  In many applications of online decision making, the environment is\nnon-stationary and it is therefore crucial to use bandit algorithms that handle\nchanges. Most existing approaches are designed to protect against non-smooth\nchanges, constrained only by total variation or Lipschitzness over time, where\nthey guarantee $\\tilde \\Theta(T^{2/3})$ regret. However, in practice\nenvironments are often changing {\\bf smoothly}, so such algorithms may incur\nhigher-than-necessary regret in these settings and do not leverage information\non the rate of change. We study a non-stationary two-armed bandits problem\nwhere we assume that an arm's mean reward is a $\\beta$-H\\\"older function over\n(normalized) time, meaning it is $(\\beta-1)$-times Lipschitz-continuously\ndifferentiable. We show the first separation between the smooth and non-smooth\nregimes by presenting a policy with $\\tilde O(T^{3/5})$ regret for $\\beta=2$.\nWe complement this result by an $\\Omg(T^{(\\beta+1)/(2\\beta+1)})$ lower bound\nfor any integer $\\beta\\ge 1$, which matches our upper bound for $\\beta=2$.\n","authors":["Su Jia","Qian Xie","Nathan Kallus","Peter I. Frazier"],"pdf_url":"https://arxiv.org/pdf/2301.12366v2.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2209.10051v3","updated":"2023-06-07T16:56:08Z","published":"2022-09-21T00:12:52Z","title":"An Unregularized Third Order Newton Method","summary":"  In this paper, we propose a third-order Newton's method which in each\niteration solves a semidefinite program as a subproblem. Our approach is based\non moving to the local minimum of the third-order Taylor expansion at each\niteration, rather than that of the second order. We show that this scheme has\nlocal cubic convergence. We then provide numerical experiments comparing this\nscheme to some standard algorithms.\n","authors":["Olha Silina","Jeffrey Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.10051v3.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2204.06895v2","updated":"2023-06-07T16:12:41Z","published":"2022-04-14T11:47:19Z","title":"Gradient boosting for convex cone predict and optimize problems","summary":"  Prediction models are typically optimized independently from decision\noptimization. A smart predict then optimize (SPO) framework optimizes\nprediction models to minimize downstream decision regret. In this paper we\npresent dboost, the first general purpose implementation of smart gradient\nboosting for `predict, then optimize' problems. The framework supports convex\nquadratic cone programming and gradient boosting is performed by implicit\ndifferentiation of a custom fixed-point mapping. Experiments comparing with\nstate-of-the-art SPO methods show that dboost can further reduce out-of-sample\ndecision regret.\n","authors":["Andrew Butler","Roy H. Kwon"],"pdf_url":"https://arxiv.org/pdf/2204.06895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04560v1","updated":"2023-06-07T16:07:21Z","published":"2023-06-07T16:07:21Z","title":"The lifted functional approach to mean field games with common noise","summary":"  We introduce a new path-by-path approach to mean field games with common\nnoise that recovers duality at the pathwise level. We verify this perspective\nby explicitly solving some difficult examples with linear-quadratic data,\nincluding control in the volatility coefficient of the common noise as well as\nthe constraint of partial information. As an application, we establish the\ncelebrated separation principle in the latter context. In pursuing this\nprogram, we believe we have made a crucial contribution to clarifying the\nnotion of regular solution in the path dependent PDE literature.\n","authors":["Mark Cerenzia","Aaron Palmer"],"pdf_url":"https://arxiv.org/pdf/2306.04560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04531v1","updated":"2023-06-07T15:40:15Z","published":"2023-06-07T15:40:15Z","title":"Comparison of SeDuMi and SDPT3 Solvers for Stability of Continuous-time\n  Linear System","summary":"  SeDuMi and SDPT3 are two solvers for solving Semi-definite Programming (SDP)\nor Linear Matrix Inequality (LMI) problems. A computational performance\ncomparison of these two are undertaken in this paper regarding the Stability of\nContinuous-time Linear Systems. The comparison mainly focuses on computational\ntimes and memory requirements for different scales of problems. To implement\nand compare the two solvers on a set of well-posed problems, we employ YALMIP,\na widely used toolbox for modeling and optimization in MATLAB. The primary goal\nof this study is to provide an empirical assessment of the relative\ncomputational efficiency of SeDuMi and SDPT3 under varying problem conditions.\nOur evaluation indicates that SDPT3 performs much better in large-scale,\nhigh-precision calculations.\n","authors":["Guangda Xu"],"pdf_url":"https://arxiv.org/pdf/2306.04531v1.pdf","comment":"13 pages, 12 figures"},{"id":"http://arxiv.org/abs/2306.04492v1","updated":"2023-06-07T15:02:10Z","published":"2023-06-07T15:02:10Z","title":"A Mirror Descent Perspective on Classical and Quantum Blahut-Arimoto\n  Algorithms","summary":"  The Blahut-Arimoto algorithm is a well known method to compute classical\nchannel capacities and rate-distortion functions. Recent works have extended\nthis algorithm to compute various quantum analogs of these quantities. In this\npaper, we show how these Blahut-Arimoto algorithms are special instances of\nmirror descent, which is a well-studied generalization of gradient descent for\nconstrained convex optimization. Using new convex analysis tools, we show how\nrelative smoothness and strong convexity analysis recovers known sublinear and\nlinear convergence rates for Blahut-Arimoto algorithms. This mirror descent\nviewpoint allows us to derive related algorithms with similar convergence\nguarantees to solve problems in information theory for which\nBlahut-Arimoto-type algorithms are not directly applicable. We apply this\nframework to compute energy-constrained classical and quantum channel\ncapacities, classical and quantum rate-distortion functions, and approximations\nof the relative entropy of entanglement, all with provable convergence\nguarantees.\n","authors":["Kerry He","James Saunderson","Hamza Fawzi"],"pdf_url":"https://arxiv.org/pdf/2306.04492v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2303.17310v2","updated":"2023-06-07T14:48:17Z","published":"2023-03-30T11:55:33Z","title":"Perfect Copositive Matrices","summary":"  In this paper we give a first study of perfect copositive $n \\times n$\nmatrices. They can be used to find rational certificates for completely\npositive matrices. We describe similarities and differences to classical\nperfect, positive definite matrices. Most of the differences occur only for $n\n\\geq 3$, where we find for instance lower rank and indefinite perfect matrices.\nNevertheless, we find for all $n$ that for every classical perfect matrix there\nis an arithmetically equivalent one which is also perfect copositive.\nFurthermore we study the neighborhood graph and polyhedral structure of perfect\ncopositive matrices. As an application we obtain a new characterization of the\ncone of completely positive matrices: It is equal to the set of nonnegative\nmatrices having a nonnegative inner product with all perfect copositive\nmatrices.\n","authors":["Valentin Dannenberg","Achill Schürmann"],"pdf_url":"https://arxiv.org/pdf/2303.17310v2.pdf","comment":"20 pages, 1 figure"},{"id":"http://arxiv.org/abs/2301.11974v2","updated":"2023-06-07T14:00:08Z","published":"2023-01-27T20:17:49Z","title":"Augmenting Bi-objective Branch and Bound by Scalarization-Based\n  Information","summary":"  While Branch and Bound based algorithms are a standard approach to solve\nsingle-objective (mixed-)integer optimization problems, multi-objective Branch\nand Bound methods are only rarely applied compared to the predominant objective\nspace methods. In this paper we propose modifications to increase the\nperformance of multi-objective Branch and Bound algorithms by utilizing\nscalarization-based information. We use the hypervolume indicator as a measure\nfor the gap between lower and upper bound set to implement a multi-objective\nbest-first strategy. By adaptively solving scalarizations in the root node to\ninteger optimality we improve both, upper and lower bound set. The obtained\nlower bound can then be integrated into the lower bounds of all active nodes,\nwhile the determined solution is added to the upper bound set. Numerical\nexperiments show that the number of investigated nodes can be significantly\nreduced by up to 83% and the total computation time can be reduced by up to\n80%.\n","authors":["Julius Bauß","Michael Stiglmayr"],"pdf_url":"https://arxiv.org/pdf/2301.11974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.01028v2","updated":"2023-06-07T12:27:16Z","published":"2022-07-03T12:57:13Z","title":"Myopic Quantal Response Policy: Thompson Sampling Meets Behavioral\n  Economics","summary":"  We study a novel family of behavioral policies for the multi-armed bandit\n(MAB) problem, which we have termed Myopic Quantal Response (MQR). MQR\nprescribes a simple way to randomize over arms according to historical rewards\nand a \"coefficient of exploitation,\" which explicitly manages the\nexploration-exploitation trade-off. MQR is a dynamic adaptation of quantal\nresponse models where the anticipated utilities are directly derived from past\nrewards. Furthermore, it can be viewed as a generalization of the Thompson\nSampling (TS) algorithm. We develop an asymptotic theory for MQR and show how\nit can help understand not only asymptotically optimal policies like TS, but\nalso those that are suboptimal due to \"under\" or \"over\" exploring. In the\nnon-asymptotic setup, we demonstrate how MQR can be used as a structural\nestimation tool: Given observed data (i.e., realized actions and rewards), we\ncan estimate the implied coefficient of exploitation of any given policy\n(either generated by human beings or algorithms). This allows us to diagnose\nwhether and to what extent the policy underexplores or overexplores.\n","authors":["Jingying Ding","Yifan Feng","Ying Rong"],"pdf_url":"https://arxiv.org/pdf/2207.01028v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07960v3","updated":"2023-06-07T12:18:33Z","published":"2022-02-16T10:10:53Z","title":"Temporal Difference Learning with Continuous Time and State in the\n  Stochastic Setting","summary":"  We consider the problem of continuous-time policy evaluation. This consists\nin learning through observations the value function associated with an\nuncontrolled continuous-time stochastic dynamic and a reward function. We\npropose two original variants of the well-known TD(0) method using vanishing\ntime steps. One is model-free and the other is model-based. For both methods,\nwe prove theoretical convergence rates that we subsequently verify through\nnumerical simulations. Alternatively, those methods can be interpreted as novel\nreinforcement learning approaches for approximating solutions of linear PDEs\n(partial differential equations) or linear BSDEs (backward stochastic\ndifferential equations).\n","authors":["Ziad Kobeissi","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2202.07960v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03542v3","updated":"2023-06-07T11:51:35Z","published":"2023-02-07T15:50:49Z","title":"Two Losses Are Better Than One: Faster Optimization Using a Cheaper\n  Proxy","summary":"  We present an algorithm for minimizing an objective with hard-to-compute\ngradients by using a related, easier-to-access function as a proxy. Our\nalgorithm is based on approximate proximal point iterations on the proxy\ncombined with relatively few stochastic gradients from the objective. When the\ndifference between the objective and the proxy is $\\delta$-smooth, our\nalgorithm guarantees convergence at a rate matching stochastic gradient descent\non a $\\delta$-smooth objective, which can lead to substantially better sample\nefficiency. Our algorithm has many potential applications in machine learning,\nand provides a principled means of leveraging synthetic data, physics\nsimulators, mixed public and private data, and more.\n","authors":["Blake Woodworth","Konstantin Mishchenko","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03542v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04350v1","updated":"2023-06-07T11:34:09Z","published":"2023-06-07T11:34:09Z","title":"A Hierarchical OPF Algorithm with Improved Gradient Evaluation in\n  Three-Phase Networks","summary":"  Linear approximation commonly used in solving alternating-current optimal\npower flow (AC-OPF) simplifies the system models but incurs accumulated voltage\nerrors in large power networks. Such errors will make the primal-dual type\ngradient algorithms converge to the solutions at which the power networks may\nbe exposed to the risk of voltage violation. In this paper, we improve a recent\nhierarchical OPF algorithm that rested on primal-dual gradients evaluated with\na linearized distribution power flow model. Specifically, we propose a more\naccurate gradient evaluation method based on a three-phase unbalanced nonlinear\ndistribution power flow model to mitigate the errors arising from model\nlinearization. The resultant gradients feature a blocked structure that enables\nus to further develop an improved hierarchical primal-dual algorithm to solve\nthe OPF problem. Numerical results on the IEEE $123$-bus test feeder and a\n$4,518$-node test feeder show that the proposed method can enhance the overall\nvoltage safety while achieving comparable computational efficiency with the\nlinearized algorithm.\n","authors":["Heng Liang","Xinyang Zhou","Changhong Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.04350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.15989v3","updated":"2023-06-07T10:53:53Z","published":"2021-03-29T23:43:44Z","title":"Complexity of a Projected Newton-CG Method for Optimization with Bounds","summary":"  This paper describes a method for solving smooth nonconvex minimization\nproblems subject to bound constraints with good worst-case complexity\nguarantees and practical performance. The method contains elements of two\nexisting methods: the classical gradient projection approach for\nbound-constrained optimization and a recently proposed Newton-conjugate\ngradient algorithm for unconstrained nonconvex optimization. Using a new\ndefinition of approximate second-order optimality parametrized by some\ntolerance $\\epsilon$ (which is compared with related definitions from previous\nworks), we derive complexity bounds in terms of $\\epsilon$ for both the number\nof iterations required and the total amount of computation. The latter is\nmeasured by the number of gradient evaluations or Hessian-vector products. We\nalso describe illustrative computational results on several test problems from\nlow-rank matrix optimization.\n","authors":["Yue Xie","Stephen J. Wright"],"pdf_url":"https://arxiv.org/pdf/2103.15989v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17112v2","updated":"2023-06-07T10:45:22Z","published":"2023-05-26T17:28:15Z","title":"Optimal control for sampling the transition path process and estimating\n  rates","summary":"  Many processes in nature such as conformal changes in biomolecules and\nclusters of interacting particles, genetic switches, noisy mechanical or\nelectromechanical oscillators, and many others are modeled using stochastic\ndifferential equations with small white noise. The study of rare transitions\nbetween metastable states in such systems is of great interest and importance,\nbut direct simulations are difficult due to long waiting times. Transition path\ntheory is a mathematical framework for the quantitative description of rare\nevents. Its direct implementation the key component of which is the solution of\nthe committor problem, a boundary value problem for the backward Kolmogorov\nequation, is often challenging due to high dimensionality or other numerical\nissues. This work exploits the key fact that the optimal controller constructed\nfrom the committor leads to generation of transition trajectories exclusively.\n","authors":["Jiaxin Yuan","Amar Shah","Channing Bentz","Maria Cameron"],"pdf_url":"https://arxiv.org/pdf/2305.17112v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04283v1","updated":"2023-06-07T09:37:58Z","published":"2023-06-07T09:37:58Z","title":"Stochastic optimal transport and Hamilton-Jacobi-Bellman equations on\n  the set of probability measures","summary":"  We introduce a stochastic version of the optimal transport problem. We\nprovide an analysis by means of the study of the associated\nHamilton-Jacobi-Bellman equation, which is set on the set of probability\nmeasures. We introduce a new definition of viscosity solutions of this\nequation, which yields general comparison principles, in particular for cases\ninvolving terms modeling stochasticity in the optimal control problem. We are\nthen able to establish results of existence and uniqueness of viscosity\nsolutions of the Hamilton-Jacobi-Bellman equation. These results rely on\ncontrollability results for stochastic optimal transport that we also\nestablish.\n","authors":["Charles Bertucci"],"pdf_url":"https://arxiv.org/pdf/2306.04283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04264v1","updated":"2023-06-07T09:04:33Z","published":"2023-06-07T09:04:33Z","title":"Integer Carathéodory results with bounded multiplicity","summary":"  The integer Carath\\'eodory rank of a pointed rational cone $C$ is the\nsmallest number $k$ such that every integer vector contained in $C$ is an\nintegral non-negative combination of at most $k$ Hilbert basis elements. We\ninvestigate the integer Carath\\'eodory rank of simplicial cones with respect to\ntheir multiplicity, i.e., the determinant of the integral generators of the\ncone. One of the main results states that simplicial cones with multiplicity\nbounded by five have the integral Carath\\'eodory property, that is, the integer\nCarath\\'eodory rank equals the dimension. Furthermore, we present a novel upper\nbound on the integer Carath\\'eodory rank which depends on the dimension and the\nmultiplicity. This bound improves upon the best known upper bound on the\ninteger Carath\\'eodory rank if the dimension exceeds the multiplicity. At last,\nwe present special cones which have the integral Carath\\'eodory property such\nas certain dual cones of Gorenstein cones.\n","authors":["Stefan Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2306.04264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2007.07731v3","updated":"2023-06-07T08:13:58Z","published":"2020-07-15T14:53:13Z","title":"A posteriori error estimates for fully coupled McKean-Vlasov\n  forward-backward SDEs","summary":"  Fully coupled McKean-Vlasov forward-backward stochastic differential\nequations (MV-FBSDEs) arise naturally from large population optimization\nproblems. Judging the quality of given numerical solutions for MV-FBSDEs, which\nusually require Picard iterations and approximations of nested conditional\nexpectations, is typically difficult. This paper proposes an a posteriori error\nestimator to quantify the $L^2$-approximation error of an arbitrarily generated\napproximation on a time grid. We establish that the error estimator is\nequivalent to the global approximation error between the given numerical\nsolution and the solution of a forward Euler discretized MV-FBSDE. A crucial\nand challenging step in the analysis is the proof of stability of this Euler\napproximation to the MV-FBSDE, which is of independent interest. We further\ndemonstrate that, for sufficiently fine time grids, the accuracy of numerical\nsolutions for solving the continuous MV-FBSDE can also be measured by the error\nestimator. The error estimates justify the use of residual-based algorithms for\nsolving MV-FBSDEs. Numerical experiments for MV-FBSDEs arising from mean field\ncontrol and games confirm the effectiveness and practical applicability of the\nerror estimator.\n","authors":["Christoph Reisinger","Wolfgang Stockinger","Yufei Zhang"],"pdf_url":"https://arxiv.org/pdf/2007.07731v3.pdf","comment":"The effectiveness of the error estimator is demonstrated in\n  high-dimensional and nonlinear examples"},{"id":"http://arxiv.org/abs/2306.04230v1","updated":"2023-06-07T08:13:35Z","published":"2023-06-07T08:13:35Z","title":"Distributed accelerated proximal conjugate gradient methods for\n  multi-agent constrained optimization problems","summary":"  The purpose of this paper is to introduce two new classes of accelerated\ndistributed proximal conjugate gradient algorithms for multi-agent constrained\noptimization problems; given as minimization of a function decomposed as a sum\nof M number of smooth and M number of nonsmooth functions over the common fixed\npoints of M number of nonlinear mappings. Exploiting the special properties of\nthe cost component function of the objective function and the nonlinear mapping\nof the constraint problem of each agent, a new inertial accelerated incremental\nand parallel computing distributed algorithms will be presented based on the\ncombinations of computations of proximal, conjugate gradient and Halpern\nmethods. Some numerical experiments and comparisons are given to illustrate our\nresults.\n","authors":["Anteneh Getachew Gebrie"],"pdf_url":"https://arxiv.org/pdf/2306.04230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04219v1","updated":"2023-06-07T07:48:50Z","published":"2023-06-07T07:48:50Z","title":"A Decomposition Approach to Last Mile Delivery Using Public\n  Transportation Systems","summary":"  This study explores the potential of using public transportation systems for\nfreight delivery, where we intend to utilize the spare capacities of public\nvehicles like buses, trams, metros, and trains, particularly during off-peak\nhours, to transport packages within the city instead of using dedicated\ndelivery vehicles. The study contributes {to the growing} literature on\ninnovative strategies for performing sustainable last mile deliveries. We study\nan operational level problem called the Three-Tier Delivery Problem on Public\nTransportation, where packages are first transported from the Consolidation and\nDistribution Center (CDC) to nearby public vehicle stations by delivery trucks.\nFrom there, public vehicles transport them into the city area. The last leg of\nthe delivery is performed to deliver the packages to their respective customers\nusing green vehicles or eco-friendly systems. We propose mixed-integer linear\nprogramming formulations to study the transport of packages from the CDC to the\ncustomers, use decomposition approaches to solve them, and provide numerical\nexperiments to demonstrate the efficiency and effectiveness of the system. Our\nresults show that this system has the potential to drastically reduce the\nlength of trips performed by dedicated delivery vehicles, thereby reducing the\nnegative social and environmental impacts of existing last mile delivery\nsystems.\n","authors":["Minakshi Punam Mandal","Claudia Archetti"],"pdf_url":"https://arxiv.org/pdf/2306.04219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04218v1","updated":"2023-06-07T07:46:47Z","published":"2023-06-07T07:46:47Z","title":"Input Rate Control in Stochastic Road Traffic Networks: Effective\n  Bandwidths","summary":"  In road traffic networks, large traffic volumes may lead to extreme delays.\nThese severe delays are caused by the fact that, whenever the maximum capacity\nof a road is approached, speeds drop rapidly. Therefore, the focus in this\npaper is on real-time control of traffic input rates, thereby aiming to prevent\nsuch detrimental capacity drops. To account for the fact that, by the\nheterogeneity within and between traffic streams, the available capacity of a\nroad suffers from randomness, we introduce a stochastic flow model that\ndescribes the impact of traffic input streams on the available road capacities.\nThen, exploiting similarities with traffic control of telecommunication\nnetworks, in which the available bandwidth is a stochastic function of the\ninput rate, and in which the use of effective bandwidths have proven an\neffective input rate control framework, we propose a similar traffic rate\ncontrol policy based on the concept of effective bandwidths. This policy allows\nfor increased waiting times at the access boundaries of the network, so as to\nlimit the probability of large delays within the network. Numerical examples\nshow that, by applying such a control policy capacity violations are indeed\nrare, and that the increased waiting at the boundaries of the network is of\nmuch smaller scale, compared to uncontrolled delays in the network.\n","authors":["Nikki Levering","Rudesindo Núñez-Queija"],"pdf_url":"https://arxiv.org/pdf/2306.04218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04208v1","updated":"2023-06-07T07:30:33Z","published":"2023-06-07T07:30:33Z","title":"Two-step inertial Bregman alternating structure-adapted proximal\n  gradient descent algorithm for nonconvex and nonsmooth problems","summary":"  In the paper, we introduce several accelerate iterative algorithms for\nsolving the multiple-set split common fixed-point problem of quasi-nonexpansive\noperators in real Hilbert space. Based on primal-dual method, we construct\nseveral iterative algorithms in a way that combines inertial technology and the\nself-adaptive stepsize such that the implementation of the algorithms doesn't\nneed any prior information about bounded linear operator norm. Under suitable\nassumptions, weak convergence of the proposed algorithms is established. As\napplications, we obtain relative iterative algorithms to solve the multiple-set\nsplit feasibility problem. Finally, the performance of the proposed algorithms\nis illustrated by numerical experiments.\n","authors":["Chenzheng Guo","Jing Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.04208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04174v1","updated":"2023-06-07T05:55:45Z","published":"2023-06-07T05:55:45Z","title":"End-to-End Learning for Stochastic Optimization: A Bayesian Perspective","summary":"  We develop a principled approach to end-to-end learning in stochastic\noptimization. First, we show that the standard end-to-end learning algorithm\nadmits a Bayesian interpretation and trains a posterior Bayes action map.\nBuilding on the insights of this analysis, we then propose new end-to-end\nlearning algorithms for training decision maps that output solutions of\nempirical risk minimization and distributionally robust optimization problems,\ntwo dominant modeling paradigms in optimization under uncertainty. Numerical\nresults for a synthetic newsvendor problem illustrate the key differences\nbetween alternative training schemes. We also investigate an economic dispatch\nproblem based on real data to showcase the impact of the neural network\narchitecture of the decision maps on their test performance.\n","authors":["Yves Rychener","Daniel Kuhn Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2306.04174v1.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2203.05312v2","updated":"2023-06-07T05:55:40Z","published":"2022-03-10T11:55:37Z","title":"Explicit representations for Banach subspaces of Lizorkin distributions","summary":"  The Lizorkin space is well-suited for studying various operators; e.g.,\nfractional Laplacians and the Radon transform. In this paper, we show that the\nspace is unfortunately not complemented in the Schwartz space. However, we can\nshow that it is dense in $C_0(\\mathbb R^d)$, a property that is shared by the\nlarger Schwartz space and that turns out to be useful for applications. Based\non this result, we investigate subspaces of Lizorkin distributions that are\nBanach spaces and for which a continuous representation operator exists. Then,\nwe introduce a variational framework involving these spaces and that makes use\nof the constructed operator. By investigating two particular cases of this\nframework, we are able to strengthen existing results for fractional splines\nand 2-layer ReLU networks.\n","authors":["Sebastian Neumayer","Michael Unser"],"pdf_url":"https://arxiv.org/pdf/2203.05312v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.12994v2","updated":"2023-06-07T05:48:51Z","published":"2023-04-25T17:05:01Z","title":"Deep Reinforcement Learning in Finite-Horizon to Explore the Most\n  Probable Transition Pathway","summary":"  In many scientific and engineering problems, noise and nonlinearity are\nunavoidable, which could induce interesting mathematical problem such as\ntransition phenomena. This paper focuses on efficiently discovering the most\nprobable transition pathway for stochastic dynamical systems employing\nreinforcement learning. With the Onsager-Machlup action functional theory to\nquantify rare events in stochastic dynamical systems, finding the most probable\npathway is equivalent to solving a variational problem on the action\nfunctional. When the action function cannot be explicitly expressed by paths\nnear the reference orbit, the variational problem needs to be converted into an\noptimal control problem. First, by integrating terminal prediction into the\nreinforcement learning framework, we develop a Terminal Prediction Deep\nDeterministic Policy Gradient (TP-DDPG) algorithm to deal with the\nfinite-horizon optimal control issue in a forward way. Next, we present the\nconvergence analysis of our algorithm for the value function in terms of the\nneural network's approximation error and estimation error. Finally, we conduct\nvarious experiments in different dimensions for the transition problems in\napplications to illustrate the effectiveness of our algorithm.\n","authors":["Jin Guo","Ting Gao","Peng Zhang","Jiequn Han","Jinqiao Duan"],"pdf_url":"https://arxiv.org/pdf/2304.12994v2.pdf","comment":"33 pages, 24 figures"},{"id":"http://arxiv.org/abs/2306.02689v2","updated":"2023-06-07T05:34:34Z","published":"2023-06-05T08:29:55Z","title":"Solving NP-hard Min-max Routing Problems as Sequential Generation with\n  Equity Context","summary":"  Min-max routing problems aim to minimize the maximum tour length among agents\nas they collaboratively visit all cities, i.e., the completion time. These\nproblems include impactful real-world applications but are known as NP-hard.\nExisting methods are facing challenges, particularly in large-scale problems\nthat require the coordination of numerous agents to cover thousands of cities.\nThis paper proposes a new deep-learning framework to solve large-scale min-max\nrouting problems. We model the simultaneous decision-making of multiple agents\nas a sequential generation process, allowing the utilization of scalable\ndeep-learning models for sequential decision-making. In the sequentially\napproximated problem, we propose a scalable contextual Transformer model,\nEquity-Transformer, which generates sequential actions considering an equitable\nworkload among other agents. The effectiveness of Equity-Transformer is\ndemonstrated through its superior performance in two representative min-max\nrouting tasks: the min-max multiple traveling salesman problem (min-max mTSP)\nand the min-max multiple pick-up and delivery problem (min-max mPDP). Notably,\nour method achieves significant reductions of runtime, approximately 335 times,\nand cost values of about 53% compared to a competitive heuristic (LKH3) in the\ncase of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source\ncode: https://github.com/kaist-silab/equity-transformer\n","authors":["Jiwoo Son","Minsu Kim","Sanghyeok Choi","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02689v2.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2212.02457v2","updated":"2023-06-07T05:00:40Z","published":"2022-12-05T18:00:31Z","title":"Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,\n  Directional Convergence, and Equilibria","summary":"  Covariate distribution shifts and adversarial perturbations present\nrobustness challenges to the conventional statistical learning framework: mild\nshifts in the test covariate distribution can significantly affect the\nperformance of the statistical model learned based on the training\ndistribution. The model performance typically deteriorates when extrapolation\nhappens: namely, covariates shift to a region where the training distribution\nis scarce, and naturally, the learned model has little information. For\nrobustness and regularization considerations, adversarial perturbation\ntechniques are proposed as a remedy; however, careful study needs to be carried\nout about what extrapolation region adversarial covariate shift will focus on,\ngiven a learned model. This paper precisely characterizes the extrapolation\nregion, examining both regression and classification in an infinite-dimensional\nsetting. We study the implications of adversarial covariate shifts to\nsubsequent learning of the equilibrium -- the Bayes optimal model -- in a\nsequential game framework. We exploit the dynamics of the adversarial learning\ngame and reveal the curious effects of the covariate shift to equilibrium\nlearning and experimental design. In particular, we establish two directional\nconvergence results that exhibit distinctive phenomena: (1) a blessing in\nregression, the adversarial covariate shifts in an exponential rate to an\noptimal experimental design for rapid subsequent learning, (2) a curse in\nclassification, the adversarial covariate shifts in a subquadratic rate fast to\nthe hardest experimental design trapping subsequent learning.\n","authors":["Tengyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2212.02457v2.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.04087v1","updated":"2023-06-07T01:16:50Z","published":"2023-06-07T01:16:50Z","title":"Accelerating 128-bit Floating-Point Matrix Multiplication on FPGAs","summary":"  General Matrix Multiplication (GEMM) is a fundamental operation widely used\nin scientific computations. Its performance and accuracy significantly impact\nthe performance and accuracy of applications that depend on it. One such\napplication is semidefinite programming (SDP), and it often requires binary128\nor higher precision arithmetic to solve problems involving SDP stably. However,\nonly some processors support binary128 arithmetic, which makes SDP solvers\ngenerally slow. In this study, we focused on accelerating GEMM with binary128\narithmetic on field-programmable gate arrays (FPGAs) to enable the flexible\ndesign of accelerators for the desired computations. Our binary128 GEMM designs\non a recent high-performance FPGA achieved approximately 90GFlops, 147x faster\nthan the computation executed on a recent CPU with 20 threads for large\nmatrices. Using our binary128 GEMM design on the FPGA, we successfully\naccelerated two numerical applications: LU decomposition and SDP problems, for\nthe first time.\n","authors":["Fumiya Kono","Naohito Nakasato","Maho Nakata"],"pdf_url":"https://arxiv.org/pdf/2306.04087v1.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.04084v1","updated":"2023-06-07T01:06:06Z","published":"2023-06-07T01:06:06Z","title":"Modelling the discretization error of initial value problems using the\n  Wishart distribution","summary":"  This paper presents a new discretization error quantification method for the\nnumerical integration of ordinary differential equations. The error is modelled\nby using the Wishart distribution, which enables us to capture the correlation\nbetween variables. Error quantification is achieved by solving an optimization\nproblem under the order constraints for the covariance matrices. An algorithm\nfor the optimization problem is also established in a slightly broader context.\n","authors":["Naoki Marumo","Takeru Matsuda","Yuto Miyatake"],"pdf_url":"https://arxiv.org/pdf/2306.04084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04836v1","updated":"2023-06-07T23:55:12Z","published":"2023-06-07T23:55:12Z","title":"$K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic\n  Control","summary":"  We propose a novel $K$-nearest neighbor resampling procedure for estimating\nthe performance of a policy from historical data containing realized episodes\nof a decision process generated under a different policy. We focus on feedback\npolicies that depend deterministically on the current state in environments\nwith continuous state-action spaces and system-inherent stochasticity effected\nby chosen actions. Such settings are common in a wide range of high-stake\napplications and are actively investigated in the context of stochastic\ncontrol. Our procedure exploits that similar state/action pairs (in a metric\nsense) are associated with similar rewards and state transitions. This enables\nour resampling procedure to tackle the counterfactual estimation problem\nunderlying off-policy evaluation (OPE) by simulating trajectories similarly to\nMonte Carlo methods. Compared to other OPE methods, our algorithm does not\nrequire optimization, can be efficiently implemented via tree-based nearest\nneighbor search and parallelization and does not explicitly assume a parametric\nmodel for the environment's dynamics. These properties make the proposed\nresampling algorithm particularly useful for stochastic control environments.\nWe prove that our method is statistically consistent in estimating the\nperformance of a policy in the OPE setting under weak assumptions and for data\nsets containing entire episodes rather than independent transitions. To\nestablish the consistency, we generalize Stone's Theorem, a well-known result\nin nonparametric statistics on local averaging, to include episodic data and\nthe counterfactual estimation underlying OPE. Numerical experiments demonstrate\nthe effectiveness of the algorithm in a variety of stochastic control settings\nincluding a linear quadratic regulator, trade execution in limit order books\nand online stochastic bin packing.\n","authors":["Michael Giegrich","Roel Oomen","Christoph Reisinger"],"pdf_url":"https://arxiv.org/pdf/2306.04836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04686v2","updated":"2023-06-07T21:44:19Z","published":"2023-02-09T15:04:35Z","title":"Global and Preference-based Optimization with Mixed Variables using\n  Piecewise Affine Surrogates","summary":"  Optimization problems involving mixed variables, i.e., variables of numerical\nand categorical nature, can be challenging to solve, especially in the presence\nof complex constraints. Moreover, when the objective function is the result of\na complicated simulation or experiment, it may be expensive to evaluate. This\npaper proposes a novel surrogate-based global optimization algorithm to solve\nlinearly constrained mixed-variable problems up to medium-large size (around\n100 variables after encoding and 20 constraints) based on constructing a\npiecewise affine surrogate of the objective function over feasible samples. We\nintroduce two types of exploration functions to efficiently search the feasible\ndomain via mixed-integer linear programming solvers. We also provide a\npreference-based version of the algorithm, which can be used when only pairwise\ncomparisons between samples can be acquired while the underlying objective\nfunction to minimize remains unquantified. The two algorithms are tested on\nmixed-variable benchmark problems with and without constraints. The results\nshow that, within a small number of acquisitions, the proposed algorithms can\noften achieve better or comparable results than other existing methods.\n","authors":["Mengjia Zhu","Alberto Bemporad"],"pdf_url":"https://arxiv.org/pdf/2302.04686v2.pdf","comment":"code available at https://github.com/mjzhu-p/PWAS"},{"id":"http://arxiv.org/abs/2306.04788v1","updated":"2023-06-07T21:20:00Z","published":"2023-06-07T21:20:00Z","title":"Deep Learning for Population-Dependent Controls in Mean Field Control\n  Problems","summary":"  In this paper, we propose several approaches to learn optimal\npopulation-dependent controls, in order to solve mean field control problems\n(MFC). Such policies enable us to solve MFC problems with generic common noise.\nWe analyze the convergence of the proposed approximation algorithms,\nparticularly the N-particle approximation. The effectiveness of our algorithms\nis supported by three different experiments, including systemic risk, price\nimpact and crowd motion. We first show that our algorithms converge to the\ncorrect solution in an explicitly solvable MFC problem. Then, we conclude by\nshowing that population-dependent controls outperform state-dependent controls.\nAlong the way, we show that specific neural network architectures can improve\nthe learning further.\n","authors":["Gokce Dayanikli","Mathieu Lauriere","Jiacheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04788v1.pdf","comment":"21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.04769v1","updated":"2023-06-07T20:33:56Z","published":"2023-06-07T20:33:56Z","title":"Achieving Consensus over Compact Submanifolds","summary":"  We consider the consensus problem in a decentralized network, focusing on a\ncompact submanifold that acts as a nonconvex constraint set. By leveraging the\nproximal smoothness of the compact submanifold, which encompasses the local\nsingleton property and the local Lipschitz continuity of the projection\noperator on the manifold, and establishing the connection between the\nprojection operator and general retraction, we show that the Riemannian\ngradient descent with a unit step size has locally linear convergence if the\nnetwork has a satisfactory level of connectivity. Moreover, based on the\ngeometry of the compact submanifold, we prove that a convexity-like regularity\ncondition, referred to as the restricted secant inequality, always holds in an\nexplicitly characterized neighborhood around the solution set of the nonconvex\nconsensus problem. By leveraging this restricted secant inequality and imposing\na weaker connectivity requirement on the decentralized network, we present a\ncomprehensive analysis of the linear convergence of the Riemannian gradient\ndescent, taking into consideration appropriate initialization and step size.\nFurthermore, if the network is well connected, we demonstrate that the local\nLipschitz continuity endowed by proximal smoothness is a sufficient condition\nfor the restricted secant inequality, thus contributing to the local error\nbound. We believe that our established results will find more application in\nthe consensus problems over a more general proximally smooth set. Numerical\nexperiments are conducted to validate our theoretical findings.\n","authors":["Jiang Hu","Jiaojiao Zhang","Kangkang Deng"],"pdf_url":"https://arxiv.org/pdf/2306.04769v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2304.07716v4","updated":"2023-06-07T19:26:58Z","published":"2023-04-16T07:56:26Z","title":"On modeling NP-Complete problems as polynomial-sized linear programs:\n  Escaping/Side-stepping the \"barriers\"","summary":"  In view of the extended formulations (EFs) developments (e.g. \"Fiorini, S.,\nS. Massar, S. Pokutta, H.R. Tiwary, and R. de Wolf [2015]. Exponential Lower\nBounds for Polytopes in Combinatorial Optimization. Journal of the ACM 62:2\"),\nwe focus in this paper on the question of whether it is possible to model an\nNP-Complete problem as a polynomial-sized linear program. For the sake of\nsimplicity of exposition, the discussions are focused on the TSP. We show that\na finding that there exists no polynomial-sized extended formulation of \"the\nTSP polytope\" does not (necessarily) imply that it is \"impossible\" for a\npolynomial-sized linear program to solve the TSP optimization problem. We show\nthat under appropriate conditions the TSP optimization problem can be solved\nwithout recourse to the traditional city-to-city (\"travel leg\") variables,\nthereby side-stepping/\"escaping from\" \"the TSP polytope\" and hence, the\nbarriers. Some illustrative examples are discussed.\n","authors":["Moustapha Diaby","Mark Karwan","Lei Sun"],"pdf_url":"https://arxiv.org/pdf/2304.07716v4.pdf","comment":"24 pages; 4 figures; 2 tables; Version 2: Minor typos corrected;\n  Version 3: Discussion/editorial clarification in section 2.2.1 (last\n  paragraph); This version (4): Further clarification in last paragraph of\n  section 2.2.1"},{"id":"http://arxiv.org/abs/2212.03923v2","updated":"2023-06-07T19:06:37Z","published":"2022-12-07T19:38:34Z","title":"Designing System Level Synthesis Controllers for Nonlinear Systems with\n  Stability Guarantees","summary":"  We introduce a method for controlling systems with nonlinear dynamics and\nfull actuation by approximating the dynamics with polynomials and applying a\nsystem level synthesis controller. We show how to optimize over this class of\ncontrollers using a neural network while maintaining stability guarantees,\nwithout requiring a Lyapunov function. We give bounds for the domain over which\nthe use of the class of controllers preserves stability and gives bounds on the\ncontrol costs incurred by optimized controllers. We then numerically validate\nour approach and show improved performance compared with feedback linearization\n-- suggesting that the SLS controllers are able to take advantage of\nnonlinearities in the dynamics while guaranteeing stability.\n","authors":["Lauren Conger","Syndey Vernon","Eric Mazumdar"],"pdf_url":"https://arxiv.org/pdf/2212.03923v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04730v1","updated":"2023-06-07T18:49:19Z","published":"2023-06-07T18:49:19Z","title":"Stochastic Natural Thresholding Algorithms","summary":"  Sparse signal recovery is one of the most fundamental problems in various\napplications, including medical imaging and remote sensing. Many greedy\nalgorithms based on the family of hard thresholding operators have been\ndeveloped to solve the sparse signal recovery problem. More recently, Natural\nThresholding (NT) has been proposed with improved computational efficiency.\nThis paper proposes and discusses convergence guarantees for stochastic natural\nthresholding algorithms by extending the NT from the deterministic version with\nlinear measurements to the stochastic version with a general objective\nfunction. We also conduct various numerical experiments on linear and nonlinear\nmeasurements to demonstrate the performance of StoNT.\n","authors":["Rachel Grotheer","Shuang Li","Anna Ma","Deanna Needell","Jing Qin"],"pdf_url":"https://arxiv.org/pdf/2306.04730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2011.11788v6","updated":"2023-06-07T18:02:56Z","published":"2020-11-23T23:16:06Z","title":"Stabilizing Queuing Networks with Model Data-Independent Control","summary":"  Classical queuing network control strategies typically rely on accurate\nknowledge of model data, i.e., arrival and service rates. However, such data\nare not always available and may be time-variant. To address this challenge, we\nconsider a class of model data-independent (MDI) control policies that only\nrely on traffic state observation and network topology. Specifically, we focus\non the MDI control policies that can stabilize multi-class Markovian queuing\nnetworks under centralized and decentralized policies. Control actions include\nrouting, sequencing, and holding. By expanding the routes and constructing\npiecewise-linear test functions, we derive an easy-to-use criterion to check\nthe stability of a multi-class network under a given MDI policy. For\nstabilizable multi-class networks, we show that a centralized, stabilizing MDI\npolicy exists. For stabilizable single-class networks, we further show that a\ndecentralized, stabilizing MDI policy exists. In addition, for both settings,\nwe construct explicit policies that attain maximal throughput and present\nnumerical examples to illustrate the results.\n","authors":["Qian Xie","Li Jin"],"pdf_url":"https://arxiv.org/pdf/2011.11788v6.pdf","comment":"Accepted by IEEE Transactions on Control of Network Systems"},{"id":"http://arxiv.org/abs/2306.04169v1","updated":"2023-06-07T05:38:55Z","published":"2023-06-07T05:38:55Z","title":"Efficient Alternating Minimization with Applications to Weighted Low\n  Rank Approximation","summary":"  Weighted low rank approximation is a fundamental problem in numerical linear\nalgebra, and it has many applications in machine learning. Given a matrix $M\n\\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n\n\\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in\n\\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V) \\|_F$ is minimized,\nwhere $\\circ$ denotes the Hadamard product. Such a problem is known to be\nNP-hard and even hard to approximate [RSW16]. Meanwhile, alternating\nminimization is a good heuristic solution for approximating weighted low rank\napproximation. The work [LLR16] shows that, under mild assumptions, alternating\nminimization does provide provable guarantees. In this work, we develop an\nefficient and robust framework for alternating minimization. For weighted low\nrank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to\n$n^2k$. At the heart of our work framework is a high-accuracy multiple response\nregression solver together with a robust analysis of alternating minimization.\n","authors":["Zhao Song","Mingquan Ye","Junze Yin","Lichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04169v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.11068"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.04640v1","updated":"2023-06-07T17:59:57Z","published":"2023-06-07T17:59:57Z","title":"ModuleFormer: Learning Modular Large Language Models From Uncurated Data","summary":"  Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.\n","authors":["Yikang Shen","Zheyu Zhang","Tianyou Cao","Shawn Tan","Zhenfang Chen","Chuang Gan"],"pdf_url":"https://arxiv.org/pdf/2306.04640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04637v1","updated":"2023-06-07T17:59:31Z","published":"2023-06-07T17:59:31Z","title":"Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection","summary":"  Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.\n","authors":["Yu Bai","Fan Chen","Huan Wang","Caiming Xiong","Song Mei"],"pdf_url":"https://arxiv.org/pdf/2306.04637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04636v1","updated":"2023-06-07T17:59:22Z","published":"2023-06-07T17:59:22Z","title":"GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image\n  Translation","summary":"  Recent advances in deep learning have witnessed many successful unsupervised\nimage-to-image translation models that learn correspondences between two visual\ndomains without paired data. However, it is still a great challenge to build\nrobust mappings between various domains especially for those with drastic\nvisual discrepancies. In this paper, we introduce a novel versatile framework,\nGenerative Prior-guided UNsupervised Image-to-image Translation (GP-UNIT), that\nimproves the quality, applicability and controllability of the existing\ntranslation models. The key idea of GP-UNIT is to distill the generative prior\nfrom pre-trained class-conditional GANs to build coarse-level cross-domain\ncorrespondences, and to apply the learned prior to adversarial translations to\nexcavate fine-level correspondences. With the learned multi-level content\ncorrespondences, GP-UNIT is able to perform valid translations between both\nclose domains and distant domains. For close domains, GP-UNIT can be\nconditioned on a parameter to determine the intensity of the content\ncorrespondences during translation, allowing users to balance between content\nand style consistency. For distant domains, semi-supervised learning is\nexplored to guide GP-UNIT to discover accurate semantic correspondences that\nare hard to learn solely from the appearance. We validate the superiority of\nGP-UNIT over state-of-the-art translation models in robust, high-quality and\ndiversified translations between various domains through extensive experiments.\n","authors":["Shuai Yang","Liming Jiang","Ziwei Liu","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2306.04636v1.pdf","comment":"Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). Code: https://github.com/williamyang1991/GP-UNIT\n  Project page: https://www.mmlab-ntu.com/project/gpunit/. arXiv admin note:\n  substantial text overlap with arXiv:2204.03641"},{"id":"http://arxiv.org/abs/2306.04634v1","updated":"2023-06-07T17:58:48Z","published":"2023-06-07T17:58:48Z","title":"On the Reliability of Watermarks for Large Language Models","summary":"  Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Manli Shu","Khalid Saifullah","Kezhi Kong","Kasun Fernando","Aniruddha Saha","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2306.04634v1.pdf","comment":"14 pages in the main body. Code is available at\n  https://github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2306.04633v1","updated":"2023-06-07T17:57:45Z","published":"2023-06-07T17:57:45Z","title":"Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast\n  Contrastive Fusion","summary":"  Instance segmentation in 3D is a challenging task due to the lack of\nlarge-scale annotated datasets. In this paper, we show that this task can be\naddressed effectively by leveraging instead 2D pre-trained models for instance\nsegmentation. We propose a novel approach to lift 2D segments to 3D and fuse\nthem by means of a neural field representation, which encourages multi-view\nconsistency across frames. The core of our approach is a slow-fast clustering\nobjective function, which is scalable and well-suited for scenes with a large\nnumber of objects. Unlike previous approaches, our method does not require an\nupper bound on the number of objects or object tracking across frames. To\ndemonstrate the scalability of the slow-fast clustering, we create a new\nsemi-realistic dataset called the Messy Rooms dataset, which features scenes\nwith up to 500 objects per scene. Our approach outperforms the state-of-the-art\non challenging scenes from the ScanNet, Hypersim, and Replica datasets, as well\nas on our newly created Messy Rooms dataset, demonstrating the effectiveness\nand scalability of our slow-fast clustering method.\n","authors":["Yash Bhalgat","Iro Laina","João F. Henriques","Andrew Zisserman","Andrea Vedaldi"],"pdf_url":"https://arxiv.org/pdf/2306.04633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04622v1","updated":"2023-06-07T17:52:29Z","published":"2023-06-07T17:52:29Z","title":"Yet Another Algorithm for Supervised Principal Component Analysis:\n  Supervised Linear Centroid-Encoder","summary":"  We propose a new supervised dimensionality reduction technique called\nSupervised Linear Centroid-Encoder (SLCE), a linear counterpart of the\nnonlinear Centroid-Encoder (CE) \\citep{ghosh2022supervised}. SLCE works by\nmapping the samples of a class to its class centroid using a linear\ntransformation. The transformation is a projection that reconstructs a point\nsuch that its distance from the corresponding class centroid, i.e.,\ncentroid-reconstruction loss, is minimized in the ambient space. We derive a\nclosed-form solution using an eigendecomposition of a symmetric matrix. We did\na detailed analysis and presented some crucial mathematical properties of the\nproposed approach. %We also provide an iterative solution approach based\nsolving the optimization problem using a descent method. We establish a\nconnection between the eigenvalues and the centroid-reconstruction loss. In\ncontrast to Principal Component Analysis (PCA) which reconstructs a sample in\nthe ambient space, the transformation of SLCE uses the instances of a class to\nrebuild the corresponding class centroid. Therefore the proposed method can be\nconsidered a form of supervised PCA. Experimental results show the performance\nadvantage of SLCE over other supervised methods.\n","authors":["Tomojit Ghosh","Michael Kirby"],"pdf_url":"https://arxiv.org/pdf/2306.04622v1.pdf","comment":"A novel algorithm for supervised PCA. 22 pages (including 2 reference\n  pages), 8 figures and mathematical analysis of the proposed algorithm. The\n  article is under review now"},{"id":"http://arxiv.org/abs/2206.05260v3","updated":"2023-06-07T17:52:01Z","published":"2022-06-10T17:59:02Z","title":"Balanced Product of Calibrated Experts for Long-Tailed Recognition","summary":"  Many real-world recognition problems are characterized by long-tailed label\ndistributions. These distributions make representation learning highly\nchallenging due to limited generalization over the tail classes. If the test\ndistribution differs from the training distribution, e.g. uniform versus\nlong-tailed, the problem of the distribution shift needs to be addressed. A\nrecent line of work proposes learning multiple diverse experts to tackle this\nissue. Ensemble diversity is encouraged by various techniques, e.g. by\nspecializing different experts in the head and the tail classes. In this work,\nwe take an analytical approach and extend the notion of logit adjustment to\nensembles to form a Balanced Product of Experts (BalPoE). BalPoE combines a\nfamily of experts with different test-time target distributions, generalizing\nseveral previous approaches. We show how to properly define these distributions\nand combine the experts in order to achieve unbiased predictions, by proving\nthat the ensemble is Fisher-consistent for minimizing the balanced error. Our\ntheoretical analysis shows that our balanced ensemble requires calibrated\nexperts, which we achieve in practice using mixup. We conduct extensive\nexperiments and our method obtains new state-of-the-art results on three\nlong-tailed datasets: CIFAR-100-LT, ImageNet-LT, and iNaturalist-2018. Our code\nis available at https://github.com/emasa/BalPoE-CalibratedLT.\n","authors":["Emanuel Sanchez Aimar","Arvi Jonnarth","Michael Felsberg","Marco Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2206.05260v3.pdf","comment":"Accepted at CVPR 2023, 19 pages"},{"id":"http://arxiv.org/abs/2306.04621v1","updated":"2023-06-07T17:50:59Z","published":"2023-06-07T17:50:59Z","title":"Align, Distill, and Augment Everything All at Once for Imbalanced\n  Semi-Supervised Learning","summary":"  Addressing the class imbalance in long-tailed semi-supervised learning (SSL)\nposes a few significant challenges stemming from differences between the\nmarginal distributions of unlabeled data and the labeled data, as the former is\noften unknown and potentially distinct from the latter. The first challenge is\nto avoid biasing the pseudo-labels towards an incorrect distribution, such as\nthat of the labeled data or a balanced distribution, during training. However,\nwe still wish to ensure a balanced unlabeled distribution during inference,\nwhich is the second challenge. To address both of these challenges, we propose\na three-faceted solution: a flexible distribution alignment that progressively\naligns the classifier from a dynamically estimated unlabeled prior towards a\nbalanced distribution, a soft consistency regularization that exploits\nunderconfident pseudo-labels discarded by threshold-based methods, and a schema\nfor expanding the unlabeled set with input data from the labeled partition.\nThis last facet comes in as a response to the commonly-overlooked fact that\ndisjoint partitions of labeled and unlabeled data prevent the benefits of\nstrong data augmentation on the labeled set. Our overall framework requires no\nadditional training cycles, so it will align, distill, and augment everything\nall at once (ADALLO). Our extensive evaluations of ADALLO on imbalanced SSL\nbenchmark datasets, including CIFAR10-LT, CIFAR100-LT, and STL10-LT with\nvarying degrees of class imbalance, amount of labeled data, and distribution\nmismatch, demonstrate significant improvements in the performance of imbalanced\nSSL under large distribution mismatch, as well as competitiveness with\nstate-of-the-art methods when the labeled and unlabeled data follow the same\nmarginal distribution. Our code will be released upon paper acceptance.\n","authors":["Emanuel Sanchez Aimar","Hannah Helgesen","Michael Felsberg","Marco Kuhlmann"],"pdf_url":"https://arxiv.org/pdf/2306.04621v1.pdf","comment":"Under review, 12 pages"},{"id":"http://arxiv.org/abs/2303.17491v2","updated":"2023-06-07T17:50:44Z","published":"2023-03-30T16:01:52Z","title":"Language Models can Solve Computer Tasks","summary":"  Agents capable of carrying out general tasks on a computer can improve\nefficiency and productivity by automating repetitive tasks and assisting in\ncomplex problem-solving. Ideally, such agents should be able to solve new\ncomputer tasks presented to them through natural language commands. However,\nprevious approaches to this problem require large amounts of expert\ndemonstrations and task-specific reward functions, both of which are\nimpractical for new tasks. In this work, we show that a pre-trained large\nlanguage model (LLM) agent can execute computer tasks guided by natural\nlanguage using a simple prompting scheme where the agent Recursively Criticizes\nand Improves its output (RCI). The RCI approach significantly outperforms\nexisting LLM methods for automating computer tasks and surpasses supervised\nlearning (SL) and reinforcement learning (RL) approaches on the MiniWoB++\nbenchmark. We compare multiple LLMs and find that RCI with the\nInstructGPT-3+RLHF LLM is state-of-the-art on MiniWoB++, using only a handful\nof demonstrations per task rather than tens of thousands, and without a\ntask-specific reward function. Furthermore, we demonstrate RCI prompting's\neffectiveness in enhancing LLMs' reasoning abilities on a suite of natural\nlanguage reasoning tasks, outperforming chain of thought (CoT) prompting. We\nfind that RCI combined with CoT performs better than either separately. Our\ncode can be found here: https://github.com/posgnu/rci-agent.\n","authors":["Geunwoo Kim","Pierre Baldi","Stephen McAleer"],"pdf_url":"https://arxiv.org/pdf/2303.17491v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04620v1","updated":"2023-06-07T17:48:29Z","published":"2023-06-07T17:48:29Z","title":"Goal-conditioned GFlowNets for Controllable Multi-Objective Molecular\n  Design","summary":"  In recent years, in-silico molecular design has received much attention from\nthe machine learning community. When designing a new compound for\npharmaceutical applications, there are usually multiple properties of such\nmolecules that need to be optimised: binding energy to the target,\nsynthesizability, toxicity, EC50, and so on. While previous approaches have\nemployed a scalarization scheme to turn the multi-objective problem into a\npreference-conditioned single objective, it has been established that this kind\nof reduction may produce solutions that tend to slide towards the extreme\npoints of the objective space when presented with a problem that exhibits a\nconcave Pareto front. In this work we experiment with an alternative\nformulation of goal-conditioned molecular generation to obtain a more\ncontrollable conditional model that can uniformly explore solutions along the\nentire Pareto front.\n","authors":["Julien Roy","Pierre-Luc Bacon","Christopher Pal","Emmanuel Bengio"],"pdf_url":"https://arxiv.org/pdf/2306.04620v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2306.04618v1","updated":"2023-06-07T17:47:03Z","published":"2023-06-07T17:47:03Z","title":"Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations","summary":"  This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.\n","authors":["Lifan Yuan","Yangyi Chen","Ganqu Cui","Hongcheng Gao","Fangyuan Zou","Xingyi Cheng","Heng Ji","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2306.04618v1.pdf","comment":"Code is available at \\url{https://github.com/lifan-yuan/OOD_NLP}"},{"id":"http://arxiv.org/abs/2301.12366v2","updated":"2023-06-07T17:32:00Z","published":"2023-01-29T06:03:20Z","title":"Smooth Non-Stationary Bandits","summary":"  In many applications of online decision making, the environment is\nnon-stationary and it is therefore crucial to use bandit algorithms that handle\nchanges. Most existing approaches are designed to protect against non-smooth\nchanges, constrained only by total variation or Lipschitzness over time, where\nthey guarantee $\\tilde \\Theta(T^{2/3})$ regret. However, in practice\nenvironments are often changing {\\bf smoothly}, so such algorithms may incur\nhigher-than-necessary regret in these settings and do not leverage information\non the rate of change. We study a non-stationary two-armed bandits problem\nwhere we assume that an arm's mean reward is a $\\beta$-H\\\"older function over\n(normalized) time, meaning it is $(\\beta-1)$-times Lipschitz-continuously\ndifferentiable. We show the first separation between the smooth and non-smooth\nregimes by presenting a policy with $\\tilde O(T^{3/5})$ regret for $\\beta=2$.\nWe complement this result by an $\\Omg(T^{(\\beta+1)/(2\\beta+1)})$ lower bound\nfor any integer $\\beta\\ge 1$, which matches our upper bound for $\\beta=2$.\n","authors":["Su Jia","Qian Xie","Nathan Kallus","Peter I. Frazier"],"pdf_url":"https://arxiv.org/pdf/2301.12366v2.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2303.17152v2","updated":"2023-06-07T17:27:03Z","published":"2023-03-30T05:19:43Z","title":"Mixed Autoencoder for Self-supervised Visual Representation Learning","summary":"  Masked Autoencoder (MAE) has demonstrated superior performance on various\nvision tasks via randomly masking image patches and reconstruction. However,\neffective data augmentation strategies for MAE still remain open questions,\ndifferent from those in contrastive learning that serve as the most important\npart. This paper studies the prevailing mixing augmentation for MAE. We first\ndemonstrate that naive mixing will in contrast degenerate model performance due\nto the increase of mutual information (MI). To address, we propose homologous\nrecognition, an auxiliary pretext task, not only to alleviate the MI\nincreasement by explicitly requiring each patch to recognize homologous\npatches, but also to perform object-aware self-supervised pre-training for\nbetter downstream dense perception performance. With extensive experiments, we\ndemonstrate that our proposed Mixed Autoencoder (MixedAE) achieves the\nstate-of-the-art transfer results among masked image modeling (MIM)\naugmentations on different downstream tasks with significant efficiency.\nSpecifically, our MixedAE outperforms MAE by +0.3% accuracy, +1.7 mIoU and +0.9\nAP on ImageNet-1K, ADE20K and COCO respectively with a standard ViT-Base.\nMoreover, MixedAE surpasses iBOT, a strong MIM method combined with instance\ndiscrimination, while accelerating training by 2x. To our best knowledge, this\nis the very first work to consider mixing for MIM from the perspective of\npretext task design. Code will be made available.\n","authors":["Kai Chen","Zhili Liu","Lanqing Hong","Hang Xu","Zhenguo Li","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2303.17152v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2306.03901v2","updated":"2023-06-07T17:22:22Z","published":"2023-06-06T17:58:24Z","title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory","summary":"  Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .\n","authors":["Chenxu Hu","Jie Fu","Chenzhuang Du","Simian Luo","Junbo Zhao","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.03901v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04600v1","updated":"2023-06-07T17:04:36Z","published":"2023-06-07T17:04:36Z","title":"Uncovering solutions from data corrupted by systematic errors: A\n  physics-constrained convolutional neural network approach","summary":"  Information on natural phenomena and engineering systems is typically\ncontained in data. Data can be corrupted by systematic errors in models and\nexperiments. In this paper, we propose a tool to uncover the spatiotemporal\nsolution of the underlying physical system by removing the systematic errors\nfrom data. The tool is the physics-constrained convolutional neural network\n(PC-CNN), which combines information from both the systems governing equations\nand data. We focus on fundamental phenomena that are modelled by partial\ndifferential equations, such as linear convection, Burgers equation, and\ntwo-dimensional turbulence. First, we formulate the problem, describe the\nphysics-constrained convolutional neural network, and parameterise the\nsystematic error. Second, we uncover the solutions from data corrupted by large\nmultimodal systematic errors. Third, we perform a parametric study for\ndifferent systematic errors. We show that the method is robust. Fourth, we\nanalyse the physical properties of the uncovered solutions. We show that the\nsolutions inferred from the PC-CNN are physical, in contrast to the data\ncorrupted by systematic errors that does not fulfil the governing equations.\nThis work opens opportunities for removing epistemic errors from models, and\nsystematic errors from measurements.\n","authors":["Daniel Kelshaw","Luca Magri"],"pdf_url":"https://arxiv.org/pdf/2306.04600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04597v1","updated":"2023-06-07T16:50:03Z","published":"2023-06-07T16:50:03Z","title":"Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions","summary":"  Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.\n","authors":["Himanshu Thakur","Atishay Jain","Praneetha Vaddamanu","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2306.04597v1.pdf","comment":"Accepted to ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2306.04595v1","updated":"2023-06-07T16:49:03Z","published":"2023-06-07T16:49:03Z","title":"Generalization Across Observation Shifts in Reinforcement Learning","summary":"  Learning policies which are robust to changes in the environment are critical\nfor real world deployment of Reinforcement Learning agents. They are also\nnecessary for achieving good generalization across environment shifts. We focus\non bisimulation metrics, which provide a powerful means for abstracting task\nrelevant components of the observation and learning a succinct representation\nspace for training the agent using reinforcement learning. In this work, we\nextend the bisimulation framework to also account for context dependent\nobservation shifts. Specifically, we focus on the simulator based learning\nsetting and use alternate observations to learn a representation space which is\ninvariant to observation shifts using a novel bisimulation based objective.\nThis allows us to deploy the agent to varying observation settings during test\ntime and generalize to unseen scenarios. We further provide novel theoretical\nbounds for simulator fidelity and performance transfer guarantees for using a\nlearnt policy to unseen shifts. Empirical analysis on the high-dimensional\nimage based control domains demonstrates the efficacy of our method.\n","authors":["Anuj Mahajan","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04590v1","updated":"2023-06-07T16:40:51Z","published":"2023-06-07T16:40:51Z","title":"Proximity-Informed Calibration for Deep Neural Networks","summary":"  Confidence calibration is central to providing accurate and interpretable\nuncertainty estimates, especially under safety-critical scenarios. However, we\nfind that existing calibration algorithms often overlook the issue of proximity\nbias, a phenomenon where models tend to be more overconfident in low proximity\ndata (i.e., lying in the sparse region of the data distribution) compared to\nhigh proximity samples, and thus suffer from inconsistent miscalibration across\ndifferent proximity samples. We examine the problem over pretrained ImageNet\nmodels and observe that: 1) Proximity bias exists across a wide variety of\nmodel architectures and sizes; 2) Transformer-based models are more susceptible\nto proximity bias than CNN-based models; 3) Proximity bias persists even after\nperforming popular calibration algorithms like temperature scaling; 4) Models\ntend to overfit more heavily on low proximity samples than on high proximity\nsamples. Motivated by the empirical findings, we propose ProCal, a\nplug-and-play algorithm with a theoretical guarantee to adjust sample\nconfidence based on proximity. To further quantify the effectiveness of\ncalibration algorithms in mitigating proximity bias, we introduce\nproximity-informed expected calibration error (PIECE) with theoretical\nanalysis. We show that ProCal is effective in addressing proximity bias and\nimproving calibration on balanced, long-tail, and distribution-shift settings\nunder four metrics over various model architectures.\n","authors":["Miao Xiong","Ailin Deng","Pang Wei Koh","Jiaying Wu","Shen Li","Jianqing Xu","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2306.04590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04581v1","updated":"2023-06-07T16:33:52Z","published":"2023-06-07T16:33:52Z","title":"Divide and Repair: Using Options to Improve Performance of Imitation\n  Learning Against Adversarial Demonstrations","summary":"  We consider the problem of learning to perform a task from demonstrations\ngiven by teachers or experts, when some of the experts' demonstrations might be\nadversarial and demonstrate an incorrect way to perform the task. We propose a\nnovel technique that can identify parts of demonstrated trajectories that have\nnot been significantly modified by the adversary and utilize them for learning,\nusing temporally extended policies or options. We first define a trajectory\ndivergence measure based on the spatial and temporal features of demonstrated\ntrajectories to detect and discard parts of the trajectories that have been\nsignificantly modified by an adversarial expert, and, could degrade the\nlearner's performance, if used for learning, We then use an options-based\nalgorithm that partitions trajectories and learns only from the parts of\ntrajectories that have been determined as admissible. We provide theoretical\nresults of our technique to show that repairing partial trajectories improves\nthe sample efficiency of the demonstrations without degrading the learner's\nperformance. We then evaluate the proposed algorithm for learning to play an\nAtari-like, computer-based game called LunarLander in the presence of different\ntypes and degrees of adversarial attacks of demonstrated trajectories. Our\nexperimental results show that our technique can identify adversarially\nmodified parts of the demonstrated trajectories and successfully prevent the\nlearning performance from degrading due to adversarial demonstrations.\n","authors":["Prithviraj Dasgupta"],"pdf_url":"https://arxiv.org/pdf/2306.04581v1.pdf","comment":"33 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.04566v1","updated":"2023-06-07T16:13:16Z","published":"2023-06-07T16:13:16Z","title":"Recent applications of machine learning, remote sensing, and iot\n  approaches in yield prediction: a critical review","summary":"  The integration of remote sensing and machine learning in agriculture is\ntransforming the industry by providing insights and predictions through data\nanalysis. This combination leads to improved yield prediction and water\nmanagement, resulting in increased efficiency, better yields, and more\nsustainable agricultural practices. Achieving the United Nations' Sustainable\nDevelopment Goals, especially \"zero hunger,\" requires the investigation of crop\nyield and precipitation gaps, which can be accomplished through, the usage of\nartificial intelligence (AI), machine learning (ML), remote sensing (RS), and\nthe internet of things (IoT). By integrating these technologies, a robust\nagricultural mobile or web application can be developed, providing farmers and\ndecision-makers with valuable information and tools for improving crop\nmanagement and increasing efficiency. Several studies have investigated these\nnew technologies and their potential for diverse tasks such as crop monitoring,\nyield prediction, irrigation management, etc. Through a critical review, this\npaper reviews relevant articles that have used RS, ML, cloud computing, and IoT\nin crop yield prediction. It reviews the current state-of-the-art in this field\nby critically evaluating different machine-learning approaches proposed in the\nliterature for crop yield prediction and water management. It provides insights\ninto how these methods can improve decision-making in agricultural production\nsystems. This work will serve as a compendium for those interested in yield\nprediction in terms of primary literature but, most importantly, what\napproaches can be used for real-time and robust prediction.\n","authors":["Fatima Zahra Bassine","Terence Epule Epule","Ayoub Kechchour","Abdelghani Chehbouni"],"pdf_url":"https://arxiv.org/pdf/2306.04566v1.pdf","comment":"35 pages, 12 figures, 14 tables"},{"id":"http://arxiv.org/abs/2204.06895v2","updated":"2023-06-07T16:12:41Z","published":"2022-04-14T11:47:19Z","title":"Gradient boosting for convex cone predict and optimize problems","summary":"  Prediction models are typically optimized independently from decision\noptimization. A smart predict then optimize (SPO) framework optimizes\nprediction models to minimize downstream decision regret. In this paper we\npresent dboost, the first general purpose implementation of smart gradient\nboosting for `predict, then optimize' problems. The framework supports convex\nquadratic cone programming and gradient boosting is performed by implicit\ndifferentiation of a custom fixed-point mapping. Experiments comparing with\nstate-of-the-art SPO methods show that dboost can further reduce out-of-sample\ndecision regret.\n","authors":["Andrew Butler","Roy H. Kwon"],"pdf_url":"https://arxiv.org/pdf/2204.06895v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01951v3","updated":"2023-06-07T16:12:13Z","published":"2023-06-02T23:23:34Z","title":"GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction","summary":"  Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes\nwithin graphs, finding applications in network security, fraud detection,\nsocial media spam detection, and various other domains. A common method for GAD\nis Graph Auto-Encoders (GAEs), which encode graph data into node\nrepresentations and identify anomalies by assessing the reconstruction quality\nof the graphs based on these representations. However, existing GAE models are\nprimarily optimized for direct link reconstruction, resulting in nodes\nconnected in the graph being clustered in the latent space. As a result, they\nexcel at detecting cluster-type structural anomalies but struggle with more\ncomplex structural anomalies that do not conform to clusters. To address this\nlimitation, we propose a novel solution called GAD-NR, a new variant of GAE\nthat incorporates neighborhood reconstruction for graph anomaly detection.\nGAD-NR aims to reconstruct the entire neighborhood of a node, encompassing the\nlocal structure, self-attributes, and neighbor attributes, based on the\ncorresponding node representation. By comparing the neighborhood reconstruction\nloss between anomalous nodes and normal nodes, GAD-NR can effectively detect\nany anomalies. Extensive experimentation conducted on six real-world datasets\nvalidates the effectiveness of GAD-NR, showcasing significant improvements (by\nup to 30% in AUC) over state-of-the-art competitors. The source code for GAD-NR\nis openly available. Importantly, the comparative analysis reveals that the\nexisting methods perform well only in detecting one or two types of anomalies\nout of the three types studied. In contrast, GAD-NR excels at detecting all\nthree types of anomalies across the datasets, demonstrating its comprehensive\nanomaly detection capabilities.\n","authors":["Amit Roy","Juan Shu","Jia Li","Carl Yang","Olivier Elshocht","Jeroen Smeets","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2306.01951v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04563v1","updated":"2023-06-07T16:10:21Z","published":"2023-06-07T16:10:21Z","title":"ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models","summary":"  Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.\n","authors":["Sophie Jentzsch","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2306.04563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13585v2","updated":"2023-06-07T16:06:18Z","published":"2022-11-24T13:14:29Z","title":"Learning to Suggest Breaks: Sustainable Optimization of Long-Term User\n  Engagement","summary":"  Optimizing user engagement is a key goal for modern recommendation systems,\nbut blindly pushing users towards increased consumption risks burn-out, churn,\nor even addictive habits. To promote digital well-being, most platforms now\noffer a service that periodically prompts users to take breaks. These, however,\nmust be set up manually, and so may be suboptimal for both users and the\nsystem. In this paper, we study the role of breaks in recommendation, and\npropose a framework for learning optimal breaking policies that promote and\nsustain long-term engagement. Based on the notion that recommendation dynamics\nare susceptible to both positive and negative feedback, we cast recommendation\nas a Lotka-Volterra dynamical system, where breaking reduces to a problem of\noptimal control. We then give an efficient learning algorithm, provide\ntheoretical guarantees, and empirically demonstrate the utility of our approach\non semi-synthetic data.\n","authors":["Eden Saig","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2211.13585v2.pdf","comment":"Accepted for publication in ICML 2023"},{"id":"http://arxiv.org/abs/2306.04556v1","updated":"2023-06-07T16:03:55Z","published":"2023-06-07T16:03:55Z","title":"StudentEval: A Benchmark of Student-Written Prompts for Large Language\n  Models of Code","summary":"  Code LLMs are being rapidly deployed and there is evidence that they can make\nprofessional programmers more productive. Current benchmarks for code\ngeneration measure whether models generate correct programs given an expert\nprompt. In this paper, we present a new benchmark containing multiple prompts\nper problem, written by a specific population of non-expert prompters:\nbeginning programmers. StudentEval contains 1,749 prompts for 48 problems,\nwritten by 80 students who have only completed one semester of Python\nprogramming. Our students wrote these prompts while working interactively with\na Code LLM, and we observed very mixed success rates. We use StudentEval to\nevaluate 5 Code LLMs and find that StudentEval is a better discriminator of\nmodel performance than existing benchmarks. We analyze the prompts and find\nsignificant variation in students' prompting techniques. We also find that\nnondeterministic LLM sampling could mislead students into thinking that their\nprompts are more (or less) effective than they actually are, which has\nimplications for how to teach with Code LLMs.\n","authors":["Hannah McLean Babe","Sydney Nguyen","Yangtian Zi","Arjun Guha","Molly Q Feldman","Carolyn Jane Anderson"],"pdf_url":"https://arxiv.org/pdf/2306.04556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04756v3","updated":"2023-06-07T15:57:30Z","published":"2023-03-08T17:45:48Z","title":"Meta-learning Control Variates: Variance Reduction with Limited Data","summary":"  Control variates can be a powerful tool to reduce the variance of Monte Carlo\nestimators, but constructing effective control variates can be challenging when\nthe number of samples is small. In this paper, we show that when a large number\nof related integrals need to be computed, it is possible to leverage the\nsimilarity between these integration tasks to improve performance even when the\nnumber of samples per task is very small. Our approach, called meta learning\nCVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our\nempirical assessment indicates that Meta-CVs can lead to significant variance\nreduction in such settings, and our theoretical analysis establishes general\nconditions under which Meta-CVs can be successfully trained.\n","authors":["Zhuo Sun","Chris J. Oates","François-Xavier Briol"],"pdf_url":"https://arxiv.org/pdf/2303.04756v3.pdf","comment":"Accepted for publication (with an oral presentation) at UAI 2023"},{"id":"http://arxiv.org/abs/2306.04551v1","updated":"2023-06-07T15:55:34Z","published":"2023-06-07T15:55:34Z","title":"Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning","summary":"  Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.\n","authors":["Brihat Sharma","Yanjun Gao","Timothy Miller","Matthew M. Churpek","Majid Afshar","Dmitriy Dligach"],"pdf_url":"https://arxiv.org/pdf/2306.04551v1.pdf","comment":"Accepted to 2023 ClinicalNLP Workshop"},{"id":"http://arxiv.org/abs/2301.08951v3","updated":"2023-06-07T15:54:03Z","published":"2023-01-21T13:39:39Z","title":"Time-Conditioned Generative Modeling of Object-Centric Representations\n  for Video Decomposition and Prediction","summary":"  When perceiving the world from multiple viewpoints, humans have the ability\nto reason about the complete objects in a compositional manner even when an\nobject is completely occluded from certain viewpoints. Meanwhile, humans are\nable to imagine novel views after observing multiple viewpoints. Recent\nremarkable advances in multi-view object-centric learning still leaves some\nunresolved problems: 1) The shapes of partially or completely occluded objects\ncan not be well reconstructed. 2) The novel viewpoint prediction depends on\nexpensive viewpoint annotations rather than implicit rules in view\nrepresentations. In this paper, we introduce a time-conditioned generative\nmodel for videos. To reconstruct the complete shape of an object accurately, we\nenhance the disentanglement between the latent representations of objects and\nviews, where the latent representations of time-conditioned views are jointly\ninferred with a Transformer and then are input to a sequential extension of\nSlot Attention to learn object-centric representations. In addition, Gaussian\nprocesses are employed as priors of view latent variables for video generation\nand novel-view prediction without viewpoint annotations. Experiments on\nmultiple datasets demonstrate that the proposed model can make object-centric\nvideo decomposition, reconstruct the complete shapes of occluded objects, and\nmake novel-view predictions.\n","authors":["Chengmin Gao","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2301.08951v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04548v1","updated":"2023-06-07T15:51:06Z","published":"2023-06-07T15:51:06Z","title":"Convergence of SARSA with linear function approximation: The random\n  horizon case","summary":"  The reinforcement learning algorithm SARSA combined with linear function\napproximation has been shown to converge for infinite horizon discounted Markov\ndecision problems (MDPs). In this paper, we investigate the convergence of the\nalgorithm for random horizon MDPs, which has not previously been shown. We\nshow, similar to earlier results for infinite horizon discounted MDPs, that if\nthe behaviour policy is $\\varepsilon$-soft and Lipschitz continuous with\nrespect to the weight vector of the linear function approximation, with small\nenough Lipschitz constant, then the algorithm will converge with probability\none when considering a random horizon MDP.\n","authors":["Lina Palmborg"],"pdf_url":"https://arxiv.org/pdf/2306.04548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04542v1","updated":"2023-06-07T15:46:47Z","published":"2023-06-07T15:46:47Z","title":"On the Design Fundamentals of Diffusion Models: A Survey","summary":"  Diffusion models are generative models, which gradually add and remove noise\nto learn the underlying distribution of training data for data generation. The\ncomponents of diffusion models have gained significant attention with many\ndesign choices proposed. Existing reviews have primarily focused on\nhigher-level solutions, thereby covering less on the design fundamentals of\ncomponents. This study seeks to address this gap by providing a comprehensive\nand coherent review on component-wise design choices in diffusion models.\nSpecifically, we organize this review according to their three key components,\nnamely the forward process, the reverse process, and the sampling procedure.\nThis allows us to provide a fine-grained perspective of diffusion models,\nbenefiting future studies in the analysis of individual components, the\napplicability of design choices, and the implementation of diffusion models.\n","authors":["Ziyi Chang","George A. Koulieris","Hubert P. H. Shum"],"pdf_url":"https://arxiv.org/pdf/2306.04542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02209v3","updated":"2023-06-07T15:46:12Z","published":"2023-02-04T17:40:03Z","title":"A Theory of Link Prediction via Relational Weisfeiler-Leman","summary":"  Graph neural networks are prominent models for representation learning over\ngraph-structured data. While the capabilities and limitations of these models\nare well-understood for simple graphs, our understanding remains incomplete in\nthe context of knowledge graphs. Our goal is to provide a systematic\nunderstanding of the landscape of graph neural networks for knowledge graphs\npertaining to the prominent task of link prediction. Our analysis entails a\nunifying perspective on seemingly unrelated models and unlocks a series of\nother models. The expressive power of various models is characterized via a\ncorresponding relational Weisfeiler-Leman algorithm. This analysis is extended\nto provide a precise logical characterization of the class of functions\ncaptured by a class of graph neural networks. The theoretical findings\npresented in this paper explain the benefits of some widely employed practical\ndesign choices, which are validated empirically.\n","authors":["Xingyue Huang","Miguel Romero Orth","İsmail İlkan Ceylan","Pablo Barceló"],"pdf_url":"https://arxiv.org/pdf/2302.02209v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04539v1","updated":"2023-06-07T15:44:53Z","published":"2023-06-07T15:44:53Z","title":"Multimodal Learning Without Labeled Multimodal Data: Guarantees and\n  Applications","summary":"  In many machine learning systems that jointly learn from multiple modalities,\na core research question is to understand the nature of multimodal\ninteractions: the emergence of new task-relevant information during learning\nfrom both modalities that was not present in either alone. We study this\nchallenge of interaction quantification in a semi-supervised setting with only\nlabeled unimodal data and naturally co-occurring multimodal data (e.g.,\nunlabeled images and captions, video and corresponding audio) but when labeling\nthem is time-consuming. Using a precise information-theoretic definition of\ninteractions, our key contributions are the derivations of lower and upper\nbounds to quantify the amount of multimodal interactions in this\nsemi-supervised setting. We propose two lower bounds based on the amount of\nshared information between modalities and the disagreement between separately\ntrained unimodal classifiers, and derive an upper bound through connections to\napproximate algorithms for min-entropy couplings. We validate these estimated\nbounds and show how they accurately track true interactions. Finally, two\nsemi-supervised multimodal applications are explored based on these theoretical\nresults: (1) analyzing the relationship between multimodal performance and\nestimated interactions, and (2) self-supervised learning that embraces\ndisagreement between modalities beyond agreement as is typically done.\n","authors":["Paul Pu Liang","Chun Kai Ling","Yun Cheng","Alex Obolenskiy","Yudong Liu","Rohan Pandey","Alex Wilf","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2306.04539v1.pdf","comment":"Code available at: https://github.com/pliang279/PID"},{"id":"http://arxiv.org/abs/2306.04529v1","updated":"2023-06-07T15:37:50Z","published":"2023-06-07T15:37:50Z","title":"Git-Theta: A Git Extension for Collaborative Development of Machine\n  Learning Models","summary":"  Currently, most machine learning models are trained by centralized teams and\nare rarely updated. In contrast, open-source software development involves the\niterative development of a shared artifact through distributed collaboration\nusing a version control system. In the interest of enabling collaborative and\ncontinual improvement of machine learning models, we introduce Git-Theta, a\nversion control system for machine learning models. Git-Theta is an extension\nto Git, the most widely used version control software, that allows fine-grained\ntracking of changes to model parameters alongside code and other artifacts.\nUnlike existing version control systems that treat a model checkpoint as a blob\nof data, Git-Theta leverages the structure of checkpoints to support\ncommunication-efficient updates, automatic model merges, and meaningful\nreporting about the difference between two versions of a model. In addition,\nGit-Theta includes a plug-in system that enables users to easily add support\nfor new functionality. In this paper, we introduce Git-Theta's design and\nfeatures and include an example use-case of Git-Theta where a pre-trained model\nis continually adapted and modified. We publicly release Git-Theta in hopes of\nkickstarting a new era of collaborative model development.\n","authors":["Nikhil Kandpal","Brian Lester","Mohammed Muqeeth","Anisha Mascarenhas","Monty Evans","Vishal Baskaran","Tenghao Huang","Haokun Liu","Colin Raffel"],"pdf_url":"https://arxiv.org/pdf/2306.04529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04528v1","updated":"2023-06-07T15:37:00Z","published":"2023-06-07T15:37:00Z","title":"PromptBench: Towards Evaluating the Robustness of Large Language Models\n  on Adversarial Prompts","summary":"  The increasing reliance on Large Language Models (LLMs) across academia and\nindustry necessitates a comprehensive understanding of their robustness to\nprompts. In response to this vital need, we introduce PromptBench, a robustness\nbenchmark designed to measure LLMs' resilience to adversarial prompts. This\nstudy uses a plethora of adversarial textual attacks targeting prompts across\nmultiple levels: character, word, sentence, and semantic. These prompts are\nthen employed in diverse tasks, such as sentiment analysis, natural language\ninference, reading comprehension, machine translation, and math\nproblem-solving. Our study generates 4,032 adversarial prompts, meticulously\nevaluated over 8 tasks and 13 datasets, with 567,084 test samples in total. Our\nfindings demonstrate that contemporary LLMs are vulnerable to adversarial\nprompts. Furthermore, we present comprehensive analysis to understand the\nmystery behind prompt robustness and its transferability. We then offer\ninsightful robustness analysis and pragmatic recommendations for prompt\ncomposition, beneficial to both researchers and everyday users. We make our\ncode, prompts, and methodologies to generate adversarial prompts publicly\naccessible, thereby enabling and encouraging collaborative exploration in this\npivotal field: https://github.com/microsoft/promptbench.\n","authors":["Kaijie Zhu","Jindong Wang","Jiaheng Zhou","Zichen Wang","Hao Chen","Yidong Wang","Linyi Yang","Wei Ye","Neil Zhenqiang Gong","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2306.04528v1.pdf","comment":"Technical report; 23 pages"},{"id":"http://arxiv.org/abs/2306.04527v1","updated":"2023-06-07T15:36:26Z","published":"2023-06-07T15:36:26Z","title":"ContriMix: Unsupervised disentanglement of content and attribute for\n  domain generalization in microscopy image analysis","summary":"  Domain generalization is critical for real-world applications of machine\nlearning models to microscopy images, including histopathology and fluorescence\nimaging. Artifacts in histopathology arise through a complex combination of\nfactors relating to tissue collection and laboratory processing, as well as\nfactors intrinsic to patient samples. In fluorescence imaging, these artifacts\nstem from variations across experimental batches. The complexity and subtlety\nof these artifacts make the enumeration of data domains intractable. Therefore,\naugmentation-based methods of domain generalization that require domain\nidentifiers and manual fine-tuning are inadequate in this setting. To overcome\nthis challenge, we introduce ContriMix, a domain generalization technique that\nlearns to generate synthetic images by disentangling and permuting the\nbiological content (\"content\") and technical variations (\"attributes\") in\nmicroscopy images. ContriMix does not rely on domain identifiers or handcrafted\naugmentations and makes no assumptions about the input characteristics of\nimages. We assess the performance of ContriMix on two pathology datasets\n(Camelyon17-WILDS and a prostate cell classification dataset) and one\nfluorescence microscopy dataset (RxRx1-WILDS). ContriMix outperforms current\nstate-of-the-art methods in all datasets, motivating its usage for microscopy\nimage analysis in real-world settings where domain information is hard to come\nby.\n","authors":["Tan H. Nguyen","Dinkar Juyal","Jin Li","Aaditya Prakash","Shima Nofallah","Chintan Shah","Sai Chowdary Gullapally","Michael Griffin","Anand Sampat","John Abel","Justin Lee","Amaro Taylor-Weiner"],"pdf_url":"https://arxiv.org/pdf/2306.04527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04562v3","updated":"2023-06-07T15:34:38Z","published":"2023-03-08T13:21:27Z","title":"Extrapolative Controlled Sequence Generation via Iterative Refinement","summary":"  We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.\n","authors":["Vishakh Padmakumar","Richard Yuanzhe Pang","He He","Ankur P. Parikh"],"pdf_url":"https://arxiv.org/pdf/2303.04562v3.pdf","comment":"ICML 2023 - Camera Ready Version"},{"id":"http://arxiv.org/abs/2306.04520v1","updated":"2023-06-07T15:30:03Z","published":"2023-06-07T15:30:03Z","title":"Estimating Koopman operators with sketching to provably learn large\n  scale dynamical systems","summary":"  The theory of Koopman operators allows to deploy non-parametric machine\nlearning algorithms to predict and analyze complex dynamical systems.\nEstimators such as principal component regression (PCR) or reduced rank\nregression (RRR) in kernel spaces can be shown to provably learn Koopman\noperators from finite empirical observations of the system's time evolution.\nScaling these approaches to very long trajectories is a challenge and requires\nintroducing suitable approximations to make computations feasible. In this\npaper, we boost the efficiency of different kernel-based Koopman operator\nestimators using random projections (sketching). We derive, implement and test\nthe new \"sketched\" estimators with extensive experiments on synthetic and\nlarge-scale molecular dynamics datasets. Further, we establish non asymptotic\nerror bounds giving a sharp characterization of the trade-offs between\nstatistical learning rates and computational efficiency. Our empirical and\ntheoretical analysis shows that the proposed estimators provide a sound and\nefficient way to learn large scale dynamical systems. In particular our\nexperiments indicate that the proposed estimators retain the same accuracy of\nPCR or RRR, while being much faster.\n","authors":["Giacomo Meanti","Antoine Chatalic","Vladimir R. Kostic","Pietro Novelli","Massimiliano Pontil","Lorenzo Rosasco"],"pdf_url":"https://arxiv.org/pdf/2306.04520v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2306.04519v1","updated":"2023-06-07T15:29:46Z","published":"2023-06-07T15:29:46Z","title":"Sample-Level Weighting for Multi-Task Learning with Auxiliary Tasks","summary":"  Multi-task learning (MTL) can improve the generalization performance of\nneural networks by sharing representations with related tasks. Nonetheless, MTL\ncan also degrade performance through harmful interference between tasks. Recent\nwork has pursued task-specific loss weighting as a solution for this\ninterference. However, existing algorithms treat tasks as atomic, lacking the\nability to explicitly separate harmful and helpful signals beyond the task\nlevel. To this end, we propose SLGrad, a sample-level weighting algorithm for\nmulti-task learning with auxiliary tasks. Through sample-specific task weights,\nSLGrad reshapes the task distributions during training to eliminate harmful\nauxiliary signals and augment useful task signals. Substantial generalization\nperformance gains are observed on (semi-) synthetic datasets and common\nsupervised multi-task problems.\n","authors":["Emilie Grégoire","Hafeez Chaudhary","Sam Verboven"],"pdf_url":"https://arxiv.org/pdf/2306.04519v1.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.04518v1","updated":"2023-06-07T15:29:12Z","published":"2023-06-07T15:29:12Z","title":"Optimal sensor placement for reconstructing wind pressure field around\n  buildings using compressed sensing","summary":"  Deciding how to optimally deploy sensors in a large, complex, and spatially\nextended structure is critical to ensure that the surface pressure field is\naccurately captured for subsequent analysis and design. In some cases,\nreconstruction of missing data is required in downstream tasks such as the\ndevelopment of digital twins. This paper presents a data-driven sparse sensor\nselection algorithm, aiming to provide the most information contents for\nreconstructing aerodynamic characteristics of wind pressures over tall building\nstructures parsimoniously. The algorithm first fits a set of basis functions to\nthe training data, then applies a computationally efficient QR algorithm that\nranks existing pressure sensors in order of importance based on the state\nreconstruction to this tailored basis. The findings of this study show that the\nproposed algorithm successfully reconstructs the aerodynamic characteristics of\ntall buildings from sparse measurement locations, generating stable and optimal\nsolutions across a range of conditions. As a result, this study serves as a\npromising first step toward leveraging the success of data-driven and machine\nlearning algorithms to supplement traditional genetic algorithms currently used\nin wind engineering.\n","authors":["Xihaier Luo","Ahsan Kareem","Shinjae Yoo"],"pdf_url":"https://arxiv.org/pdf/2306.04518v1.pdf","comment":"31 pages, 19 figures"},{"id":"http://arxiv.org/abs/2306.04507v1","updated":"2023-06-07T15:17:54Z","published":"2023-06-07T15:17:54Z","title":"Improving neural network representations using human similarity\n  judgments","summary":"  Deep neural networks have reached human-level performance on many computer\nvision tasks. However, the objectives used to train these networks enforce only\nthat similar images are embedded at similar locations in the representation\nspace, and do not directly constrain the global structure of the resulting\nspace. Here, we explore the impact of supervising this global structure by\nlinearly aligning it with human similarity judgments. We find that a naive\napproach leads to large changes in local representational structure that harm\ndownstream performance. Thus, we propose a novel method that aligns the global\nstructure of representations while preserving their local structure. This\nglobal-local transform considerably improves accuracy across a variety of\nfew-shot learning and anomaly detection tasks. Our results indicate that human\nvisual representations are globally organized in a way that facilitates\nlearning from few examples, and incorporating this global structure into neural\nnetwork representations improves performance on downstream tasks.\n","authors":["Lukas Muttenthaler","Lorenz Linhardt","Jonas Dippel","Robert A. Vandermeulen","Katherine Hermann","Andrew K. Lampinen","Simon Kornblith"],"pdf_url":"https://arxiv.org/pdf/2306.04507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02918v2","updated":"2023-06-07T15:13:33Z","published":"2022-11-05T14:24:46Z","title":"A Filtering-based General Approach to Learning Rational Constraints of\n  Epistemic Graphs","summary":"  Epistemic graphs are a generalization of the epistemic approach to\nprobabilistic argumentation. Hunter proposed a 2-way generalization framework\nto learn epistemic constraints from crowd-sourcing data. However, the learnt\nepistemic constraints only reflect users' beliefs from data, without\nconsidering the rationality encoded in epistemic graphs. Meanwhile, the current\nframework can only generate epistemic constraints that reflect whether an agent\nbelieves an argument, but not the degree to which it believes in it. The major\nchallenge to achieving this effect is that the computational complexity will\nincrease sharply when expanding the variety of constraints, which may lead to\nunacceptable time performance. To address these problems, we propose a\nfiltering-based approach using a multiple-way generalization step to generate a\nset of rational rules which are consistent with their epistemic graphs from a\ndataset. This approach is able to learn a wider variety of rational rules that\nreflect information in both the domain model and the user model. Moreover, to\nimprove computational efficiency, we introduce a new function to exclude\nmeaningless rules. The empirical results show that our approach significantly\noutperforms the existing framework when expanding the variety of rules.\n","authors":["Xiao Chi"],"pdf_url":"https://arxiv.org/pdf/2211.02918v2.pdf","comment":"18 pages, 6 figures, submitted to CLAR 2023"},{"id":"http://arxiv.org/abs/2306.04505v1","updated":"2023-06-07T15:12:16Z","published":"2023-06-07T15:12:16Z","title":"Hardness of Deceptive Certificate Selection","summary":"  Recent progress towards theoretical interpretability guarantees for AI has\nbeen made with classifiers that are based on interactive proof systems. A\nprover selects a certificate from the datapoint and sends it to a verifier who\ndecides the class. In the context of machine learning, such a certificate can\nbe a feature that is informative of the class. For a setup with high soundness\nand completeness, the exchanged certificates must have a high mutual\ninformation with the true class of the datapoint. However, this guarantee\nrelies on a bound on the Asymmetric Feature Correlation of the dataset, a\nproperty that so far is difficult to estimate for high-dimensional data. It was\nconjectured in W\\\"aldchen et al. that it is computationally hard to exploit the\nAFC, which is what we prove here.\n  We consider a malicious prover-verifier duo that aims to exploit the AFC to\nachieve high completeness and soundness while using uninformative certificates.\nWe show that this task is $\\mathsf{NP}$-hard and cannot be approximated better\nthan $\\mathcal{O}(m^{1/8 - \\epsilon})$, where $m$ is the number of possible\ncertificates, for $\\epsilon>0$ under the Dense-vs-Random conjecture. This is\nsome evidence that AFC should not prevent the use of interactive classification\nfor real-world tasks, as it is computationally hard to be exploited.\n","authors":["Stephan Wäldchen"],"pdf_url":"https://arxiv.org/pdf/2306.04505v1.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.04504v1","updated":"2023-06-07T15:11:26Z","published":"2023-06-07T15:11:26Z","title":"Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with\n  Fine-Tuned Generative Transformers","summary":"  ChatGPT is a large language model developed by OpenAI. Despite its impressive\nperformance across various tasks, no prior work has investigated its capability\nin the biomedical domain yet. To this end, this paper aims to evaluate the\nperformance of ChatGPT on various benchmark biomedical tasks, such as relation\nextraction, document classification, question answering, and summarization. To\nthe best of our knowledge, this is the first work that conducts an extensive\nevaluation of ChatGPT in the biomedical domain. Interestingly, we find based on\nour evaluation that in biomedical datasets that have smaller training sets,\nzero-shot ChatGPT even outperforms the state-of-the-art fine-tuned generative\ntransformer models, such as BioGPT and BioBART. This suggests that ChatGPT's\npre-training on large text corpora makes it quite specialized even in the\nbiomedical domain. Our findings demonstrate that ChatGPT has the potential to\nbe a valuable tool for various tasks in the biomedical domain that lack large\nannotated data.\n","authors":["Israt Jahan","Md Tahmid Rahman Laskar","Chun Peng","Jimmy Huang"],"pdf_url":"https://arxiv.org/pdf/2306.04504v1.pdf","comment":"Accepted by BioNLP@ACL 2023"},{"id":"http://arxiv.org/abs/2306.04502v1","updated":"2023-06-07T15:10:01Z","published":"2023-06-07T15:10:01Z","title":"Learning with Noisy Labels by Adaptive Gradient-Based Outlier Removal","summary":"  An accurate and substantial dataset is necessary to train a reliable and\nwell-performing model. However, even manually labeled datasets contain errors,\nnot to mention automatically labeled ones. The problem of data denoising was\naddressed in different existing research, most of which focuses on the\ndetection of outliers and their permanent removal - a process that is likely to\nover- or underfilter the dataset. In this work, we propose AGRA: a new method\nfor Adaptive GRAdient-based outlier removal. Instead of cleaning the dataset\nprior to model training, the dataset is adjusted during the training process.\nBy comparing the aggregated gradient of a batch of samples and an individual\nexample gradient, our method dynamically decides whether a corresponding\nexample is helpful for the model at this point or is counter-productive and\nshould be left out for the current update. Extensive evaluation on several\ndatasets demonstrates the AGRA effectiveness, while comprehensive results\nanalysis supports our initial hypothesis: permanent hard outlier removal is not\nalways what model benefits the most from.\n","authors":["Anastasiia Sedova","Lena Zellinger","Benjamin Roth"],"pdf_url":"https://arxiv.org/pdf/2306.04502v1.pdf","comment":"Accepted for ECML PKDD 2023"},{"id":"http://arxiv.org/abs/2206.12543v3","updated":"2023-06-07T15:07:14Z","published":"2022-06-25T03:02:35Z","title":"A Fast, Well-Founded Approximation to the Empirical Neural Tangent\n  Kernel","summary":"  Empirical neural tangent kernels (eNTKs) can provide a good understanding of\na given network's representation: they are often far less expensive to compute\nand applicable more broadly than infinite width NTKs. For networks with O\noutput units (e.g. an O-class classifier), however, the eNTK on N inputs is of\nsize $NO \\times NO$, taking $O((NO)^2)$ memory and up to $O((NO)^3)$\ncomputation. Most existing applications have therefore used one of a handful of\napproximations yielding $N \\times N$ kernel matrices, saving orders of\nmagnitude of computation, but with limited to no justification. We prove that\none such approximation, which we call \"sum of logits\", converges to the true\neNTK at initialization for any network with a wide final \"readout\" layer. Our\nexperiments demonstrate the quality of this approximation for various uses\nacross a range of settings.\n","authors":["Mohamad Amin Mohamadi","Wonho Bae","Danica J. Sutherland"],"pdf_url":"https://arxiv.org/pdf/2206.12543v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04498v1","updated":"2023-06-07T15:05:53Z","published":"2023-06-07T15:05:53Z","title":"Optimal Fair Multi-Agent Bandits","summary":"  In this paper, we study the problem of fair multi-agent multi-arm bandit\nlearning when agents do not communicate with each other, except collision\ninformation, provided to agents accessing the same arm simultaneously. We\nprovide an algorithm with regret $O\\left(N^3 \\log N \\log T \\right)$ (assuming\nbounded rewards, with unknown bound). This significantly improves previous\nresults which had regret of order $O(\\log T \\log\\log T)$ and exponential\ndependence on the number of agents. The result is attained by using a\ndistributed auction algorithm to learn the sample-optimal matching, a new type\nof exploitation phase whose length is derived from the observed samples, and a\nnovel order-statistics-based regret analysis. Simulation results present the\ndependence of the regret on $\\log T$.\n","authors":["Amir Leshem"],"pdf_url":"https://arxiv.org/pdf/2306.04498v1.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.04495v1","updated":"2023-06-07T15:04:58Z","published":"2023-06-07T15:04:58Z","title":"Limits, approximation and size transferability for GNNs on sparse graphs\n  via graphops","summary":"  Can graph neural networks generalize to graphs that are different from the\ngraphs they were trained on, e.g., in size? In this work, we study this\nquestion from a theoretical perspective. While recent work established such\ntransferability and approximation results via graph limits, e.g., via graphons,\nthese only apply non-trivially to dense graphs. To include frequently\nencountered sparse graphs such as bounded-degree or power law graphs, we take a\nperspective of taking limits of operators derived from graphs, such as the\naggregation operation that makes up GNNs. This leads to the recently introduced\nlimit notion of graphops (Backhausz and Szegedy, 2022). We demonstrate how the\noperator perspective allows us to develop quantitative bounds on the distance\nbetween a finite GNN and its limit on an infinite graph, as well as the\ndistance between the GNN on graphs of different sizes that share structural\nproperties, under a regularity assumption verified for various graph sequences.\nOur results hold for dense and sparse graphs, and various notions of graph\nlimits.\n","authors":["Thien Le","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2306.04495v1.pdf","comment":"NeurIPS 2023 submission, 34 pages"},{"id":"http://arxiv.org/abs/2306.04489v1","updated":"2023-06-07T15:00:38Z","published":"2023-06-07T15:00:38Z","title":"Fair Column Subset Selection","summary":"  We consider the problem of fair column subset selection. In particular, we\nassume that two groups are present in the data, and the chosen column subset\nmust provide a good approximation for both, relative to their respective best\nrank-k approximations. We show that this fair setting introduces significant\nchallenges: in order to extend known results, one cannot do better than the\ntrivial solution of simply picking twice as many columns as the original\nmethods. We adopt a known approach based on deterministic leverage-score\nsampling, and show that merely sampling a subset of appropriate size becomes\nNP-hard in the presence of two groups. Whereas finding a subset of two times\nthe desired size is trivial, we provide an efficient algorithm that achieves\nthe same guarantees with essentially 1.5 times that size. We validate our\nmethods through an extensive set of experiments on real-world data.\n","authors":["Antonis Matakos","Bruno Ordozgoiti","Suhas Thejaswi"],"pdf_url":"https://arxiv.org/pdf/2306.04489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04488v1","updated":"2023-06-07T14:58:15Z","published":"2023-06-07T14:58:15Z","title":"Rewarded soups: towards Pareto-optimal alignment by interpolating\n  weights fine-tuned on diverse rewards","summary":"  Foundation models are first pre-trained on vast unsupervised datasets and\nthen fine-tuned on labeled data. Reinforcement learning, notably from human\nfeedback (RLHF), can further align the network with the intended usage. Yet the\nimperfections in the proxy reward may hinder the training and lead to\nsuboptimal results; the diversity of objectives in real-world tasks and human\nopinions exacerbate the issue. This paper proposes embracing the heterogeneity\nof diverse rewards by following a multi-policy strategy. Rather than focusing\non a single a priori reward, we aim for Pareto-optimal generalization across\nthe entire space of preferences. To this end, we propose rewarded soup, first\nspecializing multiple networks independently (one for each proxy reward) and\nthen interpolating their weights linearly. This succeeds empirically because we\nshow that the weights remain linearly connected when fine-tuned on diverse\nrewards from a shared pre-trained initialization. We demonstrate the\neffectiveness of our approach for text-to-text (summarization, Q&A, helpful\nassistant, review), text-image (image captioning, text-to-image generation,\nvisual grounding, VQA), and control (locomotion) tasks. We hope to enhance the\nalignment of deep models, and how they interact with the world in all its\ndiversity.\n","authors":["Alexandre Rame","Guillaume Couairon","Mustafa Shukor","Corentin Dancette","Jean-Baptiste Gaya","Laure Soulier","Matthieu Cord"],"pdf_url":"https://arxiv.org/pdf/2306.04488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.07852v2","updated":"2023-06-07T14:56:10Z","published":"2023-03-14T12:46:48Z","title":"FPUS23: An Ultrasound Fetus Phantom Dataset with Deep Neural Network\n  Evaluations for Fetus Orientations, Fetal Planes, and Anatomical Features","summary":"  Ultrasound imaging is one of the most prominent technologies to evaluate the\ngrowth, progression, and overall health of a fetus during its gestation.\nHowever, the interpretation of the data obtained from such studies is best left\nto expert physicians and technicians who are trained and well-versed in\nanalyzing such images. To improve the clinical workflow and potentially develop\nan at-home ultrasound-based fetal monitoring platform, we present a novel fetus\nphantom ultrasound dataset, FPUS23, which can be used to identify (1) the\ncorrect diagnostic planes for estimating fetal biometric values, (2) fetus\norientation, (3) their anatomical features, and (4) bounding boxes of the fetus\nphantom anatomies at 23 weeks gestation. The entire dataset is composed of\n15,728 images, which are used to train four different Deep Neural Network\nmodels, built upon a ResNet34 backbone, for detecting aforementioned fetus\nfeatures and use-cases. We have also evaluated the models trained using our\nFPUS23 dataset, to show that the information learned by these models can be\nused to substantially increase the accuracy on real-world ultrasound fetus\ndatasets. We make the FPUS23 dataset and the pre-trained models publicly\naccessible at https://github.com/bharathprabakaran/FPUS23, which will further\nfacilitate future research on fetal ultrasound imaging and analysis.\n","authors":["Bharath Srinivas Prabakaran","Paul Hamelmann","Erik Ostrowski","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.07852v2.pdf","comment":"Accepted for Publication at IEEE Access"},{"id":"http://arxiv.org/abs/2304.13835v2","updated":"2023-06-07T14:53:55Z","published":"2023-04-26T21:41:17Z","title":"Multi-Party Chat: Conversational Agents in Group Settings with Humans\n  and Models","summary":"  Current dialogue research primarily studies pairwise (two-party)\nconversations, and does not address the everyday setting where more than two\nspeakers converse together. In this work, we both collect and evaluate\nmulti-party conversations to study this more general case. We use the LIGHT\nenvironment to construct grounded conversations, where each participant has an\nassigned character to role-play. We thus evaluate the ability of language\nmodels to act as one or more characters in such conversations. Models require\ntwo skills that pairwise-trained models appear to lack: (1) being able to\ndecide when to talk; (2) producing coherent utterances grounded on multiple\ncharacters. We compare models trained on our new dataset to existing\npairwise-trained dialogue models, as well as large language models with\nfew-shot prompting. We find that our new dataset, MultiLIGHT, which we will\npublicly release, can help bring significant improvements in the group setting.\n","authors":["Jimmy Wei","Kurt Shuster","Arthur Szlam","Jason Weston","Jack Urbanek","Mojtaba Komeili"],"pdf_url":"https://arxiv.org/pdf/2304.13835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.00421v2","updated":"2023-06-07T14:38:06Z","published":"2023-06-01T07:53:11Z","title":"Introduction to Medical Imaging Informatics","summary":"  Medical imaging informatics is a rapidly growing field that combines the\nprinciples of medical imaging and informatics to improve the acquisition,\nmanagement, and interpretation of medical images. This chapter introduces the\nbasic concepts of medical imaging informatics, including image processing,\nfeature engineering, and machine learning. It also discusses the recent\nadvancements in computer vision and deep learning technologies and how they are\nused to develop new quantitative image markers and prediction models for\ndisease detection, diagnosis, and prognosis prediction. By covering the basic\nknowledge of medical imaging informatics, this chapter provides a foundation\nfor understanding the role of informatics in medicine and its potential impact\non patient care.\n","authors":["Md. Zihad Bin Jahangir","Ruksat Hossain","Riadul Islam","MD Abdullah Al Nasim","Md. Mahim Anjum Haque","Md Jahangir Alam","Sajedul Talukder"],"pdf_url":"https://arxiv.org/pdf/2306.00421v2.pdf","comment":"18 pages, 11 figures, 2 tables; Acceptance of the chapter for the\n  Springer book \"Data-driven approaches to medical imaging\""},{"id":"http://arxiv.org/abs/2306.03833v2","updated":"2023-06-07T14:36:30Z","published":"2023-06-06T16:23:00Z","title":"Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic\n  Knowledge Graph and Text Mining Approach","summary":"  Virtual health has been acclaimed as a transformative force in healthcare\ndelivery. Yet, its dropout issue is critical that leads to poor health\noutcomes, increased health, societal, and economic costs. Timely prediction of\npatient dropout enables stakeholders to take proactive steps to address\npatients' concerns, potentially improving retention rates. In virtual health,\nthe information asymmetries inherent in its delivery format, between different\nstakeholders, and across different healthcare delivery systems hinder the\nperformance of existing predictive methods. To resolve those information\nasymmetries, we propose a Multimodal Dynamic Knowledge-driven Dropout\nPrediction (MDKDP) framework that learns implicit and explicit knowledge from\ndoctor-patient dialogues and the dynamic and complex networks of various\nstakeholders in both online and offline healthcare delivery systems. We\nevaluate MDKDP by partnering with one of the largest virtual health platforms\nin China. MDKDP improves the F1-score by 3.26 percentage points relative to the\nbest benchmark. Comprehensive robustness analyses show that integrating\nstakeholder attributes, knowledge dynamics, and compact bilinear pooling\nsignificantly improves the performance. Our work provides significant\nimplications for healthcare IT by revealing the value of mining relations and\nknowledge across different service modalities. Practically, MDKDP offers a\nnovel design artifact for virtual health platforms in patient dropout\nmanagement.\n","authors":["Shuang Geng","Wenli Zhang","Jiaheng Xie","Gemin Liang","Ben Niu"],"pdf_url":"https://arxiv.org/pdf/2306.03833v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04454v1","updated":"2023-06-07T14:28:42Z","published":"2023-06-07T14:28:42Z","title":"Training-Free Neural Active Learning with Initialization-Robustness\n  Guarantees","summary":"  Existing neural active learning algorithms have aimed to optimize the\npredictive performance of neural networks (NNs) by selecting data for\nlabelling. However, other than a good predictive performance, being robust\nagainst random parameter initializations is also a crucial requirement in\nsafety-critical applications. To this end, we introduce our expected variance\nwith Gaussian processes (EV-GP) criterion for neural active learning, which is\ntheoretically guaranteed to select data points which lead to trained NNs with\nboth (a) good predictive performances and (b) initialization robustness.\nImportantly, our EV-GP criterion is training-free, i.e., it does not require\nany training of the NN during data selection, which makes it computationally\nefficient. We empirically demonstrate that our EV-GP criterion is highly\ncorrelated with both initialization robustness and generalization performance,\nand show that it consistently outperforms baseline methods in terms of both\ndesiderata, especially in situations with limited initial data or large batch\nsizes.\n","authors":["Apivich Hemachandra","Zhongxiang Dai","Jasraj Singh","See-Kiong Ng","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2306.04454v1.pdf","comment":"Accepted to 40th International Conference on Machine Learning (ICML\n  2023), 41 pages"},{"id":"http://arxiv.org/abs/2305.11930v2","updated":"2023-06-07T14:25:19Z","published":"2023-05-19T17:47:50Z","title":"PyTorch Hyperparameter Tuning - A Tutorial for spotPython","summary":"  The goal of hyperparameter tuning (or hyperparameter optimization) is to\noptimize the hyperparameters to improve the performance of the machine or deep\nlearning model. spotPython (``Sequential Parameter Optimization Toolbox in\nPython'') is the Python version of the well-known hyperparameter tuner SPOT,\nwhich has been developed in the R programming environment for statistical\nanalysis for over a decade. PyTorch is an optimized tensor library for deep\nlearning using GPUs and CPUs. This document shows how to integrate the\nspotPython hyperparameter tuner into the PyTorch training workflow. As an\nexample, the results of the CIFAR10 image classifier are used. In addition to\nan introduction to spotPython, this tutorial also includes a brief comparison\nwith Ray Tune, a Python library for running experiments and tuning\nhyperparameters. This comparison is based on the PyTorch hyperparameter tuning\ntutorial. The advantages and disadvantages of both approaches are discussed. We\nshow that spotPython achieves similar or even better results while being more\nflexible and transparent than Ray Tune.\n","authors":["Thomas Bartz-Beielstein"],"pdf_url":"https://arxiv.org/pdf/2305.11930v2.pdf","comment":"Refers to spotPython version 0.2.15"},{"id":"http://arxiv.org/abs/2306.04445v1","updated":"2023-06-07T14:16:44Z","published":"2023-06-07T14:16:44Z","title":"Multi-modal Latent Diffusion","summary":"  Multi-modal data-sets are ubiquitous in modern applications, and multi-modal\nVariational Autoencoders are a popular family of models that aim to learn a\njoint representation of the different modalities. However, existing approaches\nsuffer from a coherence-quality tradeoff, where models with good generation\nquality lack generative coherence across modalities, and vice versa. We discuss\nthe limitations underlying the unsatisfactory performance of existing methods,\nto motivate the need for a different approach. We propose a novel method that\nuses a set of independently trained, uni-modal, deterministic autoencoders.\nIndividual latent variables are concatenated into a common latent space, which\nis fed to a masked diffusion model to enable generative modeling. We also\nintroduce a new multi-time training method to learn the conditional score\nnetwork for multi-modal diffusion. Our methodology substantially outperforms\ncompetitors in both generation quality and coherence, as shown through an\nextensive experimental campaign.\n","authors":["Mustapha Bounoua","Giulio Franzese","Pietro Michiardi"],"pdf_url":"https://arxiv.org/pdf/2306.04445v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04444v1","updated":"2023-06-07T14:07:35Z","published":"2023-06-07T14:07:35Z","title":"Fast Optimal Locally Private Mean Estimation via Random Projections","summary":"  We study the problem of locally private mean estimation of high-dimensional\nvectors in the Euclidean ball. Existing algorithms for this problem either\nincur sub-optimal error or have high communication and/or run-time complexity.\nWe propose a new algorithmic framework, ProjUnit, for private mean estimation\nthat yields algorithms that are computationally efficient, have low\ncommunication complexity, and incur optimal error up to a $1+o(1)$-factor. Our\nframework is deceptively simple: each randomizer projects its input to a random\nlow-dimensional subspace, normalizes the result, and then runs an optimal\nalgorithm such as PrivUnitG in the lower-dimensional space. In addition, we\nshow that, by appropriately correlating the random projection matrices across\ndevices, we can achieve fast server run-time. We mathematically analyze the\nerror of the algorithm in terms of properties of the random projections, and\nstudy two instantiations. Lastly, our experiments for private mean estimation\nand private federated learning demonstrate that our algorithms empirically\nobtain nearly the same utility as optimal ones while having significantly lower\ncommunication and computational cost.\n","authors":["Hilal Asi","Vitaly Feldman","Jelani Nelson","Huy L. Nguyen","Kunal Talwar"],"pdf_url":"https://arxiv.org/pdf/2306.04444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04440v1","updated":"2023-06-07T13:58:45Z","published":"2023-06-07T13:58:45Z","title":"Dual policy as self-model for planning","summary":"  Planning is a data efficient decision-making strategy where an agent selects\ncandidate actions by exploring possible future states. To simulate future\nstates when there is a high-dimensional action space, the knowledge of one's\ndecision making strategy must be used to limit the number of actions to be\nexplored. We refer to the model used to simulate one's decisions as the agent's\nself-model. While self-models are implicitly used widely in conjunction with\nworld models to plan actions, it remains unclear how self-models should be\ndesigned. Inspired by current reinforcement learning approaches and\nneuroscience, we explore the benefits and limitations of using a distilled\npolicy network as the self-model. In such dual-policy agents, a model-free\npolicy and a distilled policy are used for model-free actions and planned\nactions, respectively. Our results on a ecologically relevant, parametric\nenvironment indicate that distilled policy network for self-model stabilizes\ntraining, has faster inference than using model-free policy, promotes better\nexploration, and could learn a comprehensive understanding of its own\nbehaviors, at the cost of distilling a new network apart from the model-free\npolicy.\n","authors":["Jaesung Yoo","Fernanda de la Torre","Robert Guangyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.04440v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01633v2","updated":"2023-06-07T13:54:02Z","published":"2023-02-03T10:04:44Z","title":"Convergence Analysis of Sequencial Split Learning on Heterogeneous Data","summary":"  Federated Learning (FL) and Split Learning (SL) are two popular paradigms of\ndistributed machine learning. By offloading the computation-intensive portions\nto the server, SL is promising for deep model training on resource-constrained\ndevices, yet still lacking of rigorous convergence analysis. In this paper, we\nderive the convergence guarantees of Sequential SL (SSL, the vanilla case of SL\nthat conducts the model training in sequence) for strongly/general/non-convex\nobjectives on heterogeneous data. Notably, the derived guarantees suggest that\nSSL is better than Federated Averaging (FedAvg, the most popular algorithm in\nFL) on heterogeneous data. We validate the counterintuitive analysis result\nempirically on extremely heterogeneous data.\n","authors":["Yipeng Li","Xinchen Lyu"],"pdf_url":"https://arxiv.org/pdf/2302.01633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04431v1","updated":"2023-06-07T13:41:55Z","published":"2023-06-07T13:41:55Z","title":"Faithful Knowledge Distillation","summary":"  Knowledge distillation (KD) has received much attention due to its success in\ncompressing networks to allow for their deployment in resource-constrained\nsystems. While the problem of adversarial robustness has been studied before in\nthe KD setting, previous works overlook what we term the relative calibration\nof the student network with respect to its teacher in terms of soft\nconfidences. In particular, we focus on two crucial questions with regard to a\nteacher-student pair: (i) do the teacher and student disagree at points close\nto correctly classified dataset examples, and (ii) is the distilled student as\nconfident as the teacher around dataset examples? These are critical questions\nwhen considering the deployment of a smaller student network trained from a\nrobust teacher within a safety-critical setting. To address these questions, we\nintroduce a faithful imitation framework to discuss the relative calibration of\nconfidences, as well as provide empirical and certified methods to evaluate the\nrelative calibration of a student w.r.t. its teacher. Further, to verifiably\nalign the relative calibration incentives of the student to those of its\nteacher, we introduce faithful distillation. Our experiments on the MNIST and\nFashion-MNIST datasets demonstrate the need for such an analysis and the\nadvantages of the increased verifiability of faithful distillation over\nalternative adversarial distillation methods.\n","authors":["Tom A. Lamb","Rudy Brunel"," Krishnamurthy"," Dvijotham","M. Pawan Kumar","Philip H. S. Torr","Francisco Eiras"],"pdf_url":"https://arxiv.org/pdf/2306.04431v1.pdf","comment":"12pgs (main content), 3 figures"},{"id":"http://arxiv.org/abs/2306.04429v1","updated":"2023-06-07T13:40:20Z","published":"2023-06-07T13:40:20Z","title":"Balancing of competitive two-player Game Levels with Reinforcement\n  Learning","summary":"  The balancing process for game levels in a competitive two-player context\ninvolves a lot of manual work and testing, particularly in non-symmetrical game\nlevels. In this paper, we propose an architecture for automated balancing of\ntile-based levels within the recently introduced PCGRL framework (procedural\ncontent generation via reinforcement learning). Our architecture is divided\ninto three parts: (1) a level generator, (2) a balancing agent and, (3) a\nreward modeling simulation. By playing the level in a simulation repeatedly,\nthe balancing agent is rewarded for modifying it towards the same win rates for\nall players. To this end, we introduce a novel family of swap-based\nrepresentations to increase robustness towards playability. We show that this\napproach is capable to teach an agent how to alter a level for balancing better\nand faster than plain PCGRL. In addition, by analyzing the agent's swapping\nbehavior, we can draw conclusions about which tile types influence the\nbalancing most. We test and show our results using the Neural MMO (NMMO)\nenvironment in a competitive two-player setting.\n","authors":["Florian Rupp","Manuel Eberhardinger","Kai Eckert"],"pdf_url":"https://arxiv.org/pdf/2306.04429v1.pdf","comment":"8 pages, 8 figures, 1 table. Accepted at IEEE Conference on Games\n  2023"},{"id":"http://arxiv.org/abs/2111.10635v4","updated":"2023-06-07T13:33:11Z","published":"2021-11-20T17:09:15Z","title":"HeterPS: Distributed Deep Learning With Reinforcement Learning Based\n  Scheduling in Heterogeneous Environments","summary":"  Deep neural networks (DNNs) exploit many layers and a large number of\nparameters to achieve excellent performance. The training process of DNN models\ngenerally handles large-scale input data with many sparse features, which\nincurs high Input/Output (IO) cost, while some layers are compute-intensive.\nThe training process generally exploits distributed computing resources to\nreduce training time. In addition, heterogeneous computing resources, e.g.,\nCPUs, GPUs of multiple types, are available for the distributed training\nprocess. Thus, the scheduling of multiple layers to diverse computing resources\nis critical for the training process. To efficiently train a DNN model using\nthe heterogeneous computing resources, we propose a distributed framework,\ni.e., Paddle-Heterogeneous Parameter Server (Paddle-HeterPS), composed of a\ndistributed architecture and a Reinforcement Learning (RL)-based scheduling\nmethod. The advantages of Paddle-HeterPS are three-fold compared with existing\nframeworks. First, Paddle-HeterPS enables efficient training process of diverse\nworkloads with heterogeneous computing resources. Second, Paddle-HeterPS\nexploits an RL-based method to efficiently schedule the workload of each layer\nto appropriate computing resources to minimize the cost while satisfying\nthroughput constraints. Third, Paddle-HeterPS manages data storage and data\ncommunication among distributed computing resources. We carry out extensive\nexperiments to show that Paddle-HeterPS significantly outperforms\nstate-of-the-art approaches in terms of throughput (14.5 times higher) and\nmonetary cost (312.3% smaller). The codes of the framework are publicly\navailable at: https://github.com/PaddlePaddle/Paddle.\n","authors":["Ji Liu","Zhihua Wu","Dianhai Yu","Yanjun Ma","Danlei Feng","Minxu Zhang","Xinxuan Wu","Xuefeng Yao","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2111.10635v4.pdf","comment":"14 pages, 11 figures, 2 tables; To appear in Future Generation\n  Computer Systems (FGCS)"},{"id":"http://arxiv.org/abs/2306.04425v1","updated":"2023-06-07T13:31:57Z","published":"2023-06-07T13:31:57Z","title":"Towards High-Performance Exploratory Data Analysis (EDA) Via Stable\n  Equilibrium Point","summary":"  Exploratory data analysis (EDA) is a vital procedure for data science\nprojects. In this work, we introduce a stable equilibrium point (SEP) - based\nframework for improving the efficiency and solution quality of EDA. By\nexploiting the SEPs to be the representative points, our approach aims to\ngenerate high-quality clustering and data visualization for large-scale data\nsets. A very unique property of the proposed method is that the SEPs will\ndirectly encode the clustering properties of data sets. Compared with prior\nstate-of-the-art clustering and data visualization methods, the proposed\nmethods allow substantially improving computing efficiency and solution quality\nfor large-scale data analysis tasks.\n","authors":["Yuxuan Song","Yongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.04425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04423v1","updated":"2023-06-07T13:30:43Z","published":"2023-06-07T13:30:43Z","title":"On Computing Optimal Tree Ensembles","summary":"  Random forests and, more generally, (decision\\nobreakdash-)tree ensembles are\nwidely used methods for classification and regression. Recent algorithmic\nadvances allow to compute decision trees that are optimal for various measures\nsuch as their size or depth. We are not aware of such research for tree\nensembles and aim to contribute to this area. Mainly, we provide two novel\nalgorithms and corresponding lower bounds. First, we are able to carry over and\nsubstantially improve on tractability results for decision trees, obtaining a\n$(6\\delta D S)^S \\cdot poly$-time algorithm, where $S$ is the number of cuts in\nthe tree ensemble, $D$ the largest domain size, and $\\delta$ is the largest\nnumber of features in which two examples differ. To achieve this, we introduce\nthe witness-tree technique which also seems promising for practice. Second, we\nshow that dynamic programming, which has been successful for decision trees,\nmay also be viable for tree ensembles, providing an $\\ell^n \\cdot poly$-time\nalgorithm, where $\\ell$ is the number of trees and $n$ the number of examples.\nFinally, we compare the number of cuts necessary to classify training data sets\nfor decision trees and tree ensembles, showing that ensembles may need\nexponentially fewer cuts for increasing number of trees.\n","authors":["Christian Komusiewicz","Pascal Kunz","Frank Sommer","Manuel Sorge"],"pdf_url":"https://arxiv.org/pdf/2306.04423v1.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2206.12977v2","updated":"2023-06-07T13:27:57Z","published":"2022-06-26T21:27:23Z","title":"Adversarially Robust PAC Learnability of Real-Valued Functions","summary":"  We study robustness to test-time adversarial attacks in the regression\nsetting with $\\ell_p$ losses and arbitrary perturbation sets. We address the\nquestion of which function classes are PAC learnable in this setting. We show\nthat classes of finite fat-shattering dimension are learnable in both\nrealizable and agnostic settings. Moreover, for convex function classes, they\nare even properly learnable. In contrast, some non-convex function classes\nprovably require improper learning algorithms. Our main technique is based on a\nconstruction of an adversarially robust sample compression scheme of a size\ndetermined by the fat-shattering dimension. Along the way, we introduce a novel\nagnostic sample compression scheme for real-valued functions, which may be of\nindependent interest.\n","authors":["Idan Attias","Steve Hanneke"],"pdf_url":"https://arxiv.org/pdf/2206.12977v2.pdf","comment":"accepted to ICML2023"},{"id":"http://arxiv.org/abs/2301.05062v4","updated":"2023-06-07T13:21:51Z","published":"2023-01-12T14:59:19Z","title":"Tracr: Compiled Transformers as a Laboratory for Interpretability","summary":"  We show how to \"compile\" human-readable programs into standard decoder-only\ntransformer models. Our compiler, Tracr, generates models with known structure.\nThis structure can be used to design experiments. For example, we use it to\nstudy \"superposition\" in transformers that execute multi-step algorithms.\nAdditionally, the known structure of Tracr-compiled models can serve as\nground-truth for evaluating interpretability methods. Commonly, because the\n\"programs\" learned by transformers are unknown it is unclear whether an\ninterpretation succeeded. We demonstrate our approach by implementing and\nexamining programs including computing token frequencies, sorting, and\nparenthesis checking. We provide an open-source implementation of Tracr at\nhttps://github.com/deepmind/tracr.\n","authors":["David Lindner","János Kramár","Sebastian Farquhar","Matthew Rahtz","Thomas McGrath","Vladimir Mikulik"],"pdf_url":"https://arxiv.org/pdf/2301.05062v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19111v2","updated":"2023-06-07T13:14:23Z","published":"2023-05-30T15:15:30Z","title":"GAN-MPC: Training Model Predictive Controllers with Parameterized Cost\n  Functions using Demonstrations from Non-identical Experts","summary":"  Model predictive control (MPC) is a popular approach for trajectory\noptimization in practical robotics applications. MPC policies can optimize\ntrajectory parameters under kinodynamic and safety constraints and provide\nguarantees on safety, optimality, generalizability, interpretability, and\nexplainability. However, some behaviors are complex and it is difficult to\nhand-craft an MPC objective function. A special class of MPC policies called\nLearnable-MPC addresses this difficulty using imitation learning from expert\ndemonstrations. However, they require the demonstrator and the imitator agents\nto be identical which is hard to satisfy in many real world applications of\nrobotics. In this paper, we address the practical problem of training\nLearnable-MPC policies when the demonstrator and the imitator do not share the\nsame dynamics and their state spaces may have a partial overlap. We propose a\nnovel approach that uses a generative adversarial network (GAN) to minimize the\nJensen-Shannon divergence between the state-trajectory distributions of the\ndemonstrator and the imitator. We evaluate our approach on a variety of\nsimulated robotics tasks of DeepMind Control suite and demonstrate the efficacy\nof our approach at learning the demonstrator's behavior without having to copy\ntheir actions.\n","authors":["Returaj Burnwal","Anirban Santara","Nirav P. Bhatt","Balaraman Ravindran","Gaurav Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2305.19111v2.pdf","comment":"Recipient of the best paper award at RBCDSAI-DAI 2023, IIT Madras\n  (https://rbcdsai.iitm.ac.in/DAI-2023/)"},{"id":"http://arxiv.org/abs/2302.07221v2","updated":"2023-06-07T13:11:24Z","published":"2023-02-14T17:51:00Z","title":"On the Role of Randomization in Adversarially Robust Classification","summary":"  Deep neural networks are known to be vulnerable to small adversarial\nperturbations in test data. To defend against adversarial attacks,\nprobabilistic classifiers have been proposed as an alternative to deterministic\nones. However, literature has conflicting findings on the effectiveness of\nprobabilistic classifiers in comparison to deterministic ones. In this paper,\nwe clarify the role of randomization in building adversarially robust\nclassifiers. Given a base hypothesis set of deterministic classifiers, we show\nthe conditions under which a randomized ensemble outperforms the hypothesis set\nin adversarial risk, extending previous results. Additionally, we show that for\nany probabilistic classifier (including randomized ensembles), there exists a\ndeterministic classifier that outperforms it. Finally, we give an explicit\ndescription of the deterministic hypothesis set that contains such a\ndeterministic classifier for many types of commonly used probabilistic\nclassifiers, i.e. randomized ensembles and parametric/input noise injection.\n","authors":["Lucas Gnecco-Heredia","Yann Chevaleyre","Benjamin Negrevergne","Laurent Meunier","Muni Sreenivas Pydi"],"pdf_url":"https://arxiv.org/pdf/2302.07221v2.pdf","comment":"9 pages + bibliography and appendix, 2 figures. This is a replacement\n  with important changes, including a refinement of the main result in the last\n  paper and a new section on passing from deterministic to randomized"},{"id":"http://arxiv.org/abs/2305.19903v2","updated":"2023-06-07T13:07:52Z","published":"2023-05-31T14:37:31Z","title":"Improving Expressivity of GNNs with Subgraph-specific Factor Embedded\n  Normalization","summary":"  Graph Neural Networks~(GNNs) have emerged as a powerful category of learning\narchitecture for handling graph-structured data. However, existing GNNs\ntypically ignore crucial structural characteristics in node-induced subgraphs,\nwhich thus limits their expressiveness for various downstream tasks. In this\npaper, we strive to strengthen the representative capabilities of GNNs by\ndevising a dedicated plug-and-play normalization scheme, termed as\nSUbgraph-sPEcific FactoR Embedded Normalization (SuperNorm), that explicitly\nconsiders the intra-connection information within each node-induced subgraph.\nTo this end, we embed the subgraph-specific factor at the beginning and the end\nof the standard BatchNorm, as well as incorporate graph instance-specific\nstatistics for improved distinguishable capabilities. In the meantime, we\nprovide theoretical analysis to support that, with the elaborated SuperNorm, an\narbitrary GNN is at least as powerful as the 1-WL test in distinguishing\nnon-isomorphism graphs. Furthermore, the proposed SuperNorm scheme is also\ndemonstrated to alleviate the over-smoothing phenomenon. Experimental results\nrelated to predictions of graph, node, and link properties on the eight popular\ndatasets demonstrate the effectiveness of the proposed method. The code is\navailable at \\url{https://github.com/chenchkx/SuperNorm}.\n","authors":["Kaixuan Chen","Shunyu Liu","Tongtian Zhu","Tongya Zheng","Haofei Zhang","Zunlei Feng","Jingwen Ye","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2305.19903v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.00390v3","updated":"2023-06-07T13:07:38Z","published":"2023-06-01T06:50:47Z","title":"Learning Gaussian Mixture Representations for Tensor Time Series\n  Forecasting","summary":"  Tensor time series (TTS) data, a generalization of one-dimensional time\nseries on a high-dimensional space, is ubiquitous in real-world scenarios,\nespecially in monitoring systems involving multi-source spatio-temporal data\n(e.g., transportation demands and air pollutants). Compared to modeling time\nseries or multivariate time series, which has received much attention and\nachieved tremendous progress in recent years, tensor time series has been paid\nless effort. Properly coping with the tensor time series is a much more\nchallenging task, due to its high-dimensional and complex inner structure. In\nthis paper, we develop a novel TTS forecasting framework, which seeks to\nindividually model each heterogeneity component implied in the time, the\nlocation, and the source variables. We name this framework as GMRL, short for\nGaussian Mixture Representation Learning. Experiment results on two real-world\nTTS datasets verify the superiority of our approach compared with the\nstate-of-the-art baselines. Code and data are published on\nhttps://github.com/beginner-sketch/GMRL.\n","authors":["Jiewen Deng","Jinliang Deng","Renhe Jiang","Xuan Song"],"pdf_url":"https://arxiv.org/pdf/2306.00390v3.pdf","comment":"Accepted by IJCAI 2023 Main Track"},{"id":"http://arxiv.org/abs/2306.04406v1","updated":"2023-06-07T13:04:34Z","published":"2023-06-07T13:04:34Z","title":"Generalized Teacher Forcing for Learning Chaotic Dynamics","summary":"  Chaotic dynamical systems (DS) are ubiquitous in nature and society. Often we\nare interested in reconstructing such systems from observed time series for\nprediction or mechanistic insight, where by reconstruction we mean learning\ngeometrical and invariant temporal properties of the system in question (like\nattractors). However, training reconstruction algorithms like recurrent neural\nnetworks (RNNs) on such systems by gradient-descent based techniques faces\nsevere challenges. This is mainly due to exploding gradients caused by the\nexponential divergence of trajectories in chaotic systems. Moreover, for\n(scientific) interpretability we wish to have as low dimensional\nreconstructions as possible, preferably in a model which is mathematically\ntractable. Here we report that a surprisingly simple modification of teacher\nforcing leads to provably strictly all-time bounded gradients in training on\nchaotic systems, and, when paired with a simple architectural rearrangement of\na tractable RNN design, piecewise-linear RNNs (PLRNNs), allows for faithful\nreconstruction in spaces of at most the dimensionality of the observed system.\nWe show on several DS that with these amendments we can reconstruct DS better\nthan current SOTA algorithms, in much lower dimensions. Performance differences\nwere particularly compelling on real world data with which most other methods\nseverely struggled. This work thus led to a simple yet powerful DS\nreconstruction algorithm which is highly interpretable at the same time.\n","authors":["Florian Hess","Zahra Monfared","Manuel Brenner","Daniel Durstewitz"],"pdf_url":"https://arxiv.org/pdf/2306.04406v1.pdf","comment":"To be published in the Proceedings of the 40th International\n  Conference on Machine Learning (ICML 2023)"},{"id":"http://arxiv.org/abs/2306.04403v1","updated":"2023-06-07T13:02:24Z","published":"2023-06-07T13:02:24Z","title":"Policy-Based Self-Competition for Planning Problems","summary":"  AlphaZero-type algorithms may stop improving on single-player tasks in case\nthe value network guiding the tree search is unable to approximate the outcome\nof an episode sufficiently well. One technique to address this problem is\ntransforming the single-player task through self-competition. The main idea is\nto compute a scalar baseline from the agent's historical performances and to\nreshape an episode's reward into a binary output, indicating whether the\nbaseline has been exceeded or not. However, this baseline only carries limited\ninformation for the agent about strategies how to improve. We leverage the idea\nof self-competition and directly incorporate a historical policy into the\nplanning process instead of its scalar performance. Based on the recently\nintroduced Gumbel AlphaZero (GAZ), we propose our algorithm GAZ 'Play-to-Plan'\n(GAZ PTP), in which the agent learns to find strong trajectories by planning\nagainst possible strategies of its past self. We show the effectiveness of our\napproach in two well-known combinatorial optimization problems, the Traveling\nSalesman Problem and the Job-Shop Scheduling Problem. With only half of the\nsimulation budget for search, GAZ PTP consistently outperforms all selected\nsingle-player variants of GAZ.\n","authors":["Jonathan Pirnay","Quirin Göttl","Jakob Burger","Dominik Gerhard Grimm"],"pdf_url":"https://arxiv.org/pdf/2306.04403v1.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.04400v1","updated":"2023-06-07T12:58:52Z","published":"2023-06-07T12:58:52Z","title":"A Fair Classifier Embracing Triplet Collapse","summary":"  In this paper, we study the behaviour of the triplet loss and show that it\ncan be exploited to limit the biases created and perpetuated by machine\nlearning models. Our fair classifier uses the collapse of the triplet loss when\nits margin is greater than the maximum distance between two points in the\nlatent space, in the case of stochastic triplet selection.\n","authors":["A. Martzloff","N. Posocco","Q. Ferré"],"pdf_url":"https://arxiv.org/pdf/2306.04400v1.pdf","comment":"9 pages, 7 figures, CAp2023"},{"id":"http://arxiv.org/abs/2306.04396v1","updated":"2023-06-07T12:56:56Z","published":"2023-06-07T12:56:56Z","title":"Improving Diffusion-based Image Translation using Asymmetric Gradient\n  Guidance","summary":"  Diffusion models have shown significant progress in image translation tasks\nrecently. However, due to their stochastic nature, there's often a trade-off\nbetween style transformation and content preservation. Current strategies aim\nto disentangle style and content, preserving the source image's structure while\nsuccessfully transitioning from a source to a target domain under text or\none-shot image conditions. Yet, these methods often require computationally\nintense fine-tuning of diffusion models or additional neural networks. To\naddress these challenges, here we present an approach that guides the reverse\nprocess of diffusion sampling by applying asymmetric gradient guidance. This\nresults in quicker and more stable image manipulation for both text-guided and\nimage-guided image translation. Our model's adaptability allows it to be\nimplemented with both image- and latent-diffusion models. Experiments show that\nour method outperforms various state-of-the-art models in image translation\ntasks.\n","authors":["Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2306.04396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08077v2","updated":"2023-06-07T12:33:50Z","published":"2023-02-16T04:33:00Z","title":"Group Fairness with Uncertainty in Sensitive Attributes","summary":"  Learning a fair predictive model is crucial to mitigate biased decisions\nagainst minority groups in high-stakes applications. A common approach to learn\nsuch a model involves solving an optimization problem that maximizes the\npredictive power of the model under an appropriate group fairness constraint.\nHowever, in practice, sensitive attributes are often missing or noisy resulting\nin uncertainty. We demonstrate that solely enforcing fairness constraints on\nuncertain sensitive attributes can fall significantly short in achieving the\nlevel of fairness of models trained without uncertainty. To overcome this\nlimitation, we propose a bootstrap-based algorithm that achieves the target\nlevel of fairness despite the uncertainty in sensitive attributes. The\nalgorithm is guided by a Gaussian analysis for the independence notion of\nfairness where we propose a robust quadratically constrained quadratic problem\nto ensure a strict fairness guarantee with uncertain sensitive attributes. Our\nalgorithm is applicable to both discrete and continuous sensitive attributes\nand is effective in real-world classification and regression tasks for various\ngroup fairness notions, e.g., independence and separation.\n","authors":["Abhin Shah","Maohao Shen","Jongha Jon Ryu","Subhro Das","Prasanna Sattigeri","Yuheng Bu","Gregory W. Wornell"],"pdf_url":"https://arxiv.org/pdf/2302.08077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04384v1","updated":"2023-06-07T12:31:07Z","published":"2023-06-07T12:31:07Z","title":"Multilingual Clinical NER: Translation or Cross-lingual Transfer?","summary":"  Natural language tasks like Named Entity Recognition (NER) in the clinical\ndomain on non-English texts can be very time-consuming and expensive due to the\nlack of annotated data. Cross-lingual transfer (CLT) is a way to circumvent\nthis issue thanks to the ability of multilingual large language models to be\nfine-tuned on a specific task in one language and to provide high accuracy for\nthe same task in another language. However, other methods leveraging\ntranslation models can be used to perform NER without annotated data in the\ntarget language, by either translating the training set or test set. This paper\ncompares cross-lingual transfer with these two alternative methods, to perform\nclinical NER in French and in German without any training data in those\nlanguages. To this end, we release MedNERF a medical NER test set extracted\nfrom French drug prescriptions and annotated with the same guidelines as an\nEnglish dataset. Through extensive experiments on this dataset and on a German\nmedical dataset (Frei and Kramer, 2021), we show that translation-based methods\ncan achieve similar performance to CLT but require more care in their design.\nAnd while they can take advantage of monolingual clinical language models,\nthose do not guarantee better results than large general-purpose multilingual\nmodels, whether with cross-lingual transfer or translation.\n","authors":["Xavier Fontaine","Félix Gaschi","Parisa Rastin","Yannick Toussaint"],"pdf_url":"https://arxiv.org/pdf/2306.04384v1.pdf","comment":"23 pages, Proceedings of the 5th Clinical Natural Language Processing\n  Workshop"},{"id":"http://arxiv.org/abs/2304.06051v2","updated":"2023-06-07T12:29:25Z","published":"2023-04-12T04:27:16Z","title":"Open-TransMind: A New Baseline and Benchmark for 1st Foundation Model\n  Challenge of Intelligent Transportation","summary":"  With the continuous improvement of computing power and deep learning\nalgorithms in recent years, the foundation model has grown in popularity.\nBecause of its powerful capabilities and excellent performance, this technology\nis being adopted and applied by an increasing number of industries. In the\nintelligent transportation industry, artificial intelligence faces the\nfollowing typical challenges: few shots, poor generalization, and a lack of\nmulti-modal techniques. Foundation model technology can significantly alleviate\nthe aforementioned issues. To address these, we designed the 1st Foundation\nModel Challenge, with the goal of increasing the popularity of foundation model\ntechnology in traffic scenarios and promoting the rapid development of the\nintelligent transportation industry. The challenge is divided into two tracks:\nall-in-one and cross-modal image retrieval. Furthermore, we provide a new\nbaseline and benchmark for the two tracks, called Open-TransMind. According to\nour knowledge, Open-TransMind is the first open-source transportation\nfoundation model with multi-task and multi-modal capabilities. Simultaneously,\nOpen-TransMind can achieve state-of-the-art performance on detection,\nclassification, and segmentation datasets of traffic scenarios. Our source code\nis available at https://github.com/Traffic-X/Open-TransMind.\n","authors":["Yifeng Shi","Feng Lv","Xinliang Wang","Chunlong Xia","Shaojie Li","Shujie Yang","Teng Xi","Gang Zhang"],"pdf_url":"https://arxiv.org/pdf/2304.06051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10439v2","updated":"2023-06-07T12:20:17Z","published":"2022-12-20T17:14:14Z","title":"Policy Gradient in Robust MDPs with Global Convergence Guarantee","summary":"  Robust Markov decision processes (RMDPs) provide a promising framework for\ncomputing reliable policies in the face of model errors. Many successful\nreinforcement learning algorithms build on variations of policy-gradient\nmethods, but adapting these methods to RMDPs has been challenging. As a result,\nthe applicability of RMDPs to large, practical domains remains limited. This\npaper proposes a new Double-Loop Robust Policy Gradient (DRPG), the first\ngeneric policy gradient method for RMDPs. In contrast with prior robust policy\ngradient algorithms, DRPG monotonically reduces approximation errors to\nguarantee convergence to a globally optimal policy in tabular RMDPs. We\nintroduce a novel parametric transition kernel and solve the inner loop robust\npolicy via a gradient-based method. Finally, our numerical results demonstrate\nthe utility of our new algorithm and confirm its global convergence properties.\n","authors":["Qiuhao Wang","Chin Pang Ho","Marek Petrik"],"pdf_url":"https://arxiv.org/pdf/2212.10439v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04377v1","updated":"2023-06-07T12:18:36Z","published":"2023-06-07T12:18:36Z","title":"Get More for Less in Decentralized Learning Systems","summary":"  Decentralized learning (DL) systems have been gaining popularity because they\navoid raw data sharing by communicating only model parameters, hence preserving\ndata confidentiality. However, the large size of deep neural networks poses a\nsignificant challenge for decentralized training, since each node needs to\nexchange gigabytes of data, overloading the network. In this paper, we address\nthis challenge with JWINS, a communication-efficient and fully decentralized\nlearning system that shares only a subset of parameters through sparsification.\nJWINS uses wavelet transform to limit the information loss due to\nsparsification and a randomized communication cut-off that reduces\ncommunication usage without damaging the performance of trained models. We\ndemonstrate empirically with 96 DL nodes on non-IID datasets that JWINS can\nachieve similar accuracies to full-sharing DL while sending up to 64% fewer\nbytes. Additionally, on low communication budgets, JWINS outperforms the\nstate-of-the-art communication-efficient DL algorithm CHOCO-SGD by up to 4x in\nterms of network savings and time.\n","authors":["Akash Dhasade","Anne-Marie Kermarrec","Rafael Pires","Rishi Sharma","Milos Vujasinovic","Jeffrey Wigger"],"pdf_url":"https://arxiv.org/pdf/2306.04377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07960v3","updated":"2023-06-07T12:18:33Z","published":"2022-02-16T10:10:53Z","title":"Temporal Difference Learning with Continuous Time and State in the\n  Stochastic Setting","summary":"  We consider the problem of continuous-time policy evaluation. This consists\nin learning through observations the value function associated with an\nuncontrolled continuous-time stochastic dynamic and a reward function. We\npropose two original variants of the well-known TD(0) method using vanishing\ntime steps. One is model-free and the other is model-based. For both methods,\nwe prove theoretical convergence rates that we subsequently verify through\nnumerical simulations. Alternatively, those methods can be interpreted as novel\nreinforcement learning approaches for approximating solutions of linear PDEs\n(partial differential equations) or linear BSDEs (backward stochastic\ndifferential equations).\n","authors":["Ziad Kobeissi","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2202.07960v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04376v1","updated":"2023-06-07T12:17:34Z","published":"2023-06-07T12:17:34Z","title":"Label Shift Quantification with Robustness Guarantees via Distribution\n  Feature Matching","summary":"  Quantification learning deals with the task of estimating the target label\ndistribution under label shift. In this paper, we first present a unifying\nframework, distribution feature matching (DFM), that recovers as particular\ninstances various estimators introduced in previous literature. We derive a\ngeneral performance bound for DFM procedures, improving in several key aspects\nupon previous bounds derived in particular cases. We then extend this analysis\nto study robustness of DFM procedures in the misspecified setting under\ndeparture from the exact label shift hypothesis, in particular in the case of\ncontamination of the target by an unknown distribution. These theoretical\nfindings are confirmed by a detailed numerical study on simulated and\nreal-world datasets. We also introduce an efficient, scalable and robust\nversion of kernel-based DFM using the Random Fourier Feature principle.\n","authors":["Bastien Dussap","Gilles Blanchard","Badr-Eddine Chérief-Abdellatif"],"pdf_url":"https://arxiv.org/pdf/2306.04376v1.pdf","comment":"Accepted at the European Conference on Machine Learning and\n  Principles and Practice of Knowledge Discovery in Databases (ECML) 2023"},{"id":"http://arxiv.org/abs/2306.04375v1","updated":"2023-06-07T12:17:17Z","published":"2023-06-07T12:17:17Z","title":"Learning via Wasserstein-Based High Probability Generalisation Bounds","summary":"  Minimising upper bounds on the population risk or the generalisation gap has\nbeen widely used in structural risk minimisation (SRM) - this is in particular\nat the core of PAC-Bayesian learning. Despite its successes and unfailing surge\nof interest in recent years, a limitation of the PAC-Bayesian framework is that\nmost bounds involve a Kullback-Leibler (KL) divergence term (or its\nvariations), which might exhibit erratic behavior and fail to capture the\nunderlying geometric structure of the learning problem - hence restricting its\nuse in practical applications. As a remedy, recent studies have attempted to\nreplace the KL divergence in the PAC-Bayesian bounds with the Wasserstein\ndistance. Even though these bounds alleviated the aforementioned issues to a\ncertain extent, they either hold in expectation, are for bounded losses, or are\nnontrivial to minimize in an SRM framework. In this work, we contribute to this\nline of research and prove novel Wasserstein distance-based PAC-Bayesian\ngeneralisation bounds for both batch learning with independent and identically\ndistributed (i.i.d.) data, and online learning with potentially non-i.i.d.\ndata. Contrary to previous art, our bounds are stronger in the sense that (i)\nthey hold with high probability, (ii) they apply to unbounded (potentially\nheavy-tailed) losses, and (iii) they lead to optimizable training objectives\nthat can be used in SRM. As a result we derive novel Wasserstein-based\nPAC-Bayesian learning algorithms and we illustrate their empirical advantage on\na variety of experiments.\n","authors":["Paul Viallard","Maxime Haddouche","Umut Simsekli","Benjamin Guedj"],"pdf_url":"https://arxiv.org/pdf/2306.04375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04374v1","updated":"2023-06-07T12:14:16Z","published":"2023-06-07T12:14:16Z","title":"Label Aware Speech Representation Learning For Language Identification","summary":"  Speech representation learning approaches for non-semantic tasks such as\nlanguage recognition have either explored supervised embedding extraction\nmethods using a classifier model or self-supervised representation learning\napproaches using raw data. In this paper, we propose a novel framework of\ncombining self-supervised representation learning with the language label\ninformation for the pre-training task. This framework, termed as Label Aware\nSpeech Representation (LASR) learning, uses a triplet based objective function\nto incorporate language labels along with the self-supervised loss function.\nThe speech representations are further fine-tuned for the downstream task. The\nlanguage recognition experiments are performed on two public datasets - FLEURS\nand Dhwani. In these experiments, we illustrate that the proposed LASR\nframework improves over the state-of-the-art systems on language\nidentification. We also report an analysis of the robustness of LASR approach\nto noisy/missing labels as well as its application to multi-lingual speech\nrecognition tasks.\n","authors":["Shikhar Vashishth","Shikhar Bharadwaj","Sriram Ganapathy","Ankur Bapna","Min Ma","Wei Han","Vera Axelrod","Partha Talukdar"],"pdf_url":"https://arxiv.org/pdf/2306.04374v1.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.04366v1","updated":"2023-06-07T11:59:45Z","published":"2023-06-07T11:59:45Z","title":"Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing\n  Based on GCN Trustworthiness Prediction","summary":"  Collaborative Mobile Crowd Sensing (CMCS) enhances data quality and coverage\nby promoting teamwork in task sensing, with worker recruitment representing a\ncomplex multi-objective optimization problem. Existing strategies mainly focus\non the characteristics of workers themselves, neglecting the asymmetric trust\nrelationships between them, which affects the rationality of task utility\nevaluation. To address this, this paper first employs the Mini-Batch K-Means\nclustering algorithm and deploys edge servers to enable efficient distributed\nworker recruitment. Historical data and task requirements are utilized to\nobtain workers' ability types and distances. A trust-directed graph in the\nworker's social network is input into the Graph Convolutional Network (GCN)\nframework for training, capturing asymmetric trustworthiness between worker\npairs. Privacy leakage is prevented in CMCS scenarios through high trust values\nbetween workers. Ultimately, an undirected recruitment graph is constructed\nusing workers' abilities, trust values, and distance weights, transforming the\nworker recruitment problem into a Maximum Weight Average Subgraph Problem\n(MWASP). A Tabu Search Recruitment (TSR) algorithm is proposed to rationally\nrecruit a balanced multi-objective optimal task utility worker set for each\ntask. Extensive simulation experiments on four real-world datasets demonstrate\nthe effectiveness of the proposed strategy, outperforming other strategies.\n","authors":["Zhongwei Zhan","Yingjie Wang","Peiyong Duan","Akshita Maradapu Vera Venkata Sai","Zhaowei Liu","Chaocan Xiang","Xiangrong Tong","Weilong Wang","Zhipeng Cai"],"pdf_url":"https://arxiv.org/pdf/2306.04366v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04365v1","updated":"2023-06-07T11:55:20Z","published":"2023-06-07T11:55:20Z","title":"Edge conductivity in PtSe$_2$ nanostructures","summary":"  PtSe$_2$ is a promising 2D material for nanoelectromechanical sensing and\nphotodetection in the infrared regime. One of its most compelling features is\nthe facile synthesis at temperatures below 500 {\\deg}C, which is compatible\nwith current back-end-of-line semiconductor processing. However, this process\ngenerates polycrystalline thin films with nanoflake-like domains of 5 to 100 nm\nsize. To investigate the lateral quantum confinement effect in this size\nregime, we train a deep neural network to obtain an interatomic potential at\nDFT accuracy and use that to model ribbons, surfaces, nanoflakes, and\nnanoplatelets of PtSe$_2$ with lateral widths between 5 to 15 nm. We determine\nwhich edge terminations are the most stable and find evidence that the\nelectrical conductivity is localized on the edges for lateral sizes below 10\nnm. This suggests that the transport channels in thin films of PtSe$_2$ might\nbe dominated by networks of edges, instead of transport through the layers\nthemselves.\n","authors":["Roman Kempt","Agnieszka Kuc","Thomas Brumme","Thomas Heine"],"pdf_url":"https://arxiv.org/pdf/2306.04365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03542v3","updated":"2023-06-07T11:51:35Z","published":"2023-02-07T15:50:49Z","title":"Two Losses Are Better Than One: Faster Optimization Using a Cheaper\n  Proxy","summary":"  We present an algorithm for minimizing an objective with hard-to-compute\ngradients by using a related, easier-to-access function as a proxy. Our\nalgorithm is based on approximate proximal point iterations on the proxy\ncombined with relatively few stochastic gradients from the objective. When the\ndifference between the objective and the proxy is $\\delta$-smooth, our\nalgorithm guarantees convergence at a rate matching stochastic gradient descent\non a $\\delta$-smooth objective, which can lead to substantially better sample\nefficiency. Our algorithm has many potential applications in machine learning,\nand provides a principled means of leveraging synthetic data, physics\nsimulators, mixed public and private data, and more.\n","authors":["Blake Woodworth","Konstantin Mishchenko","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03542v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03360v2","updated":"2023-06-07T11:39:52Z","published":"2023-06-06T02:24:41Z","title":"Vid2Act: Activate Offline Videos for Visual RL","summary":"  Pretraining RL models on offline video datasets is a promising way to improve\ntheir training efficiency in online tasks, but challenging due to the inherent\nmismatch in tasks, dynamics, and behaviors across domains. A recent model, APV,\nsidesteps the accompanied action records in offline datasets and instead\nfocuses on pretraining a task-irrelevant, action-free world model within the\nsource domains. We present Vid2Act, a model-based RL method that learns to\ntransfer valuable action-conditioned dynamics and potentially useful action\ndemonstrations from offline to online settings. The main idea is to use the\nworld models not only as simulators for behavior learning but also as tools to\nmeasure the domain relevance for both dynamics representation transfer and\npolicy transfer. Specifically, we train the world models to generate a set of\ntime-varying task similarities using a domain-selective knowledge distillation\nloss. These similarities serve two purposes: (i) adaptively transferring the\nmost useful source knowledge to facilitate dynamics learning, and (ii) learning\nto replay the most relevant source actions to guide the target policy. We\ndemonstrate the advantages of Vid2Act over the action-free visual RL\npretraining method in both Meta-World and DeepMind Control Suite.\n","authors":["Minting Pan","Yitao Zheng","Wendong Zhang","Yunbo Wang","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04343v1","updated":"2023-06-07T11:17:07Z","published":"2023-06-07T11:17:07Z","title":"Bayesian Optimisation Against Climate Change: Applications and\n  Benchmarks","summary":"  Bayesian optimisation is a powerful method for optimising black-box\nfunctions, popular in settings where the true function is expensive to evaluate\nand no gradient information is available. Bayesian optimisation can improve\nresponses to many optimisation problems within climate change for which\nsimulator models are unavailable or expensive to sample from. While there have\nbeen several feasibility demonstrations of Bayesian optimisation in\nclimate-related applications, there has been no unifying review of applications\nand benchmarks. We provide such a review here, to encourage the use of Bayesian\noptimisation in important and well-suited application domains. We identify four\nmain application domains: material discovery, wind farm layout, optimal\nrenewable control and environmental monitoring. For each domain we identify a\npublic benchmark or data set that is easy to use and evaluate systems against,\nwhile being representative of real-world problems. Due to the lack of a\nsuitable benchmark for environmental monitoring, we propose LAQN-BO, based on\nair pollution data. Our contributions are: a) identifying a representative\nrange of benchmarks, providing example code where necessary; b) introducing a\nnew benchmark, LAQN-BO; and c) promoting a wider use of climate change\napplications among Bayesian optimisation practitioners.\n","authors":["Sigrid Passano Hellan","Christopher G. Lucas","Nigel H. Goddard"],"pdf_url":"https://arxiv.org/pdf/2306.04343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04339v1","updated":"2023-06-07T11:10:10Z","published":"2023-06-07T11:10:10Z","title":"Unpaired Deep Learning for Pharmacokinetic Parameter Estimation from\n  Dynamic Contrast-Enhanced MRI","summary":"  DCE-MRI provides information about vascular permeability and tissue perfusion\nthrough the acquisition of pharmacokinetic parameters. However, traditional\nmethods for estimating these pharmacokinetic parameters involve fitting tracer\nkinetic models, which often suffer from computational complexity and low\naccuracy due to noisy arterial input function (AIF) measurements. Although some\ndeep learning approaches have been proposed to tackle these challenges, most\nexisting methods rely on supervised learning that requires paired input DCE-MRI\nand labeled pharmacokinetic parameter maps. This dependency on labeled data\nintroduces significant time and resource constraints, as well as potential\nnoise in the labels, making supervised learning methods often impractical. To\naddress these limitations, here we present a novel unpaired deep learning\nmethod for estimating both pharmacokinetic parameters and the AIF using a\nphysics-driven CycleGAN approach. Our proposed CycleGAN framework is designed\nbased on the underlying physics model, resulting in a simpler architecture with\na single generator and discriminator pair. Crucially, our experimental results\nindicate that our method, which does not necessitate separate AIF measurements,\nproduces more reliable pharmacokinetic parameters than other techniques.\n","authors":["Gyutaek Oh","Won-Jin Moon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2306.04339v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04338v1","updated":"2023-06-07T11:08:12Z","published":"2023-06-07T11:08:12Z","title":"Changing Data Sources in the Age of Machine Learning for Official\n  Statistics","summary":"  Data science has become increasingly essential for the production of official\nstatistics, as it enables the automated collection, processing, and analysis of\nlarge amounts of data. With such data science practices in place, it enables\nmore timely, more insightful and more flexible reporting. However, the quality\nand integrity of data-science-driven statistics rely on the accuracy and\nreliability of the data sources and the machine learning techniques that\nsupport them. In particular, changes in data sources are inevitable to occur\nand pose significant risks that are crucial to address in the context of\nmachine learning for official statistics.\n  This paper gives an overview of the main risks, liabilities, and\nuncertainties associated with changing data sources in the context of machine\nlearning for official statistics. We provide a checklist of the most prevalent\norigins and causes of changing data sources; not only on a technical level but\nalso regarding ownership, ethics, regulation, and public perception. Next, we\nhighlight the repercussions of changing data sources on statistical reporting.\nThese include technical effects such as concept drift, bias, availability,\nvalidity, accuracy and completeness, but also the neutrality and potential\ndiscontinuation of the statistical offering. We offer a few important\nprecautionary measures, such as enhancing robustness in both data sourcing and\nstatistical techniques, and thorough monitoring. In doing so, machine\nlearning-based official statistics can maintain integrity, reliability,\nconsistency, and relevance in policy-making, decision-making, and public\ndiscourse.\n","authors":["Cedric De Boom","Michael Reusens"],"pdf_url":"https://arxiv.org/pdf/2306.04338v1.pdf","comment":"Presented at UNECE Machine Learning for Official Statistics Workshop\n  2023"},{"id":"http://arxiv.org/abs/1911.11049v2","updated":"2023-06-07T11:06:28Z","published":"2019-11-25T17:00:35Z","title":"ROIPCA: An online memory-restricted PCA algorithm based on rank-one\n  updates","summary":"  Principal components analysis (PCA) is a fundamental algorithm in data\nanalysis. Its memory-restricted online versions are useful in many modern\napplications, where the data are too large to fit in memory, or when data\narrive as a stream of items. In this paper, we propose ROIPCA and fROIPCA, two\nonline PCA algorithms that are based on rank-one updates. While ROIPCA is\ntypically more accurate, fROIPCA is faster and has comparable accuracy. We show\nthe relation between fROIPCA and an existing popular gradient algorithm for\nonline PCA, and in particular, prove that fROIPCA is in fact a gradient\nalgorithm with an optimal learning rate. We demonstrate numerically the\nadvantages of our algorithms over existing state-of-the-art algorithms in terms\nof accuracy and runtime.\n","authors":["Roy Mitz","Yoel Shkolnisky"],"pdf_url":"https://arxiv.org/pdf/1911.11049v2.pdf","comment":"23 pages, 2 figures"},{"id":"http://arxiv.org/abs/2301.12802v3","updated":"2023-06-07T10:48:02Z","published":"2023-01-30T11:51:24Z","title":"Planning Multiple Epidemic Interventions with Reinforcement Learning","summary":"  Combating an epidemic entails finding a plan that describes when and how to\napply different interventions, such as mask-wearing mandates, vaccinations,\nschool or workplace closures. An optimal plan will curb an epidemic with\nminimal loss of life, disease burden, and economic cost. Finding an optimal\nplan is an intractable computational problem in realistic settings.\nPolicy-makers, however, would greatly benefit from tools that can efficiently\nsearch for plans that minimize disease and economic costs especially when\nconsidering multiple possible interventions over a continuous and complex\naction space given a continuous and equally complex state space. We formulate\nthis problem as a Markov decision process. Our formulation is unique in its\nability to represent multiple continuous interventions over any disease model\ndefined by ordinary differential equations. We illustrate how to effectively\napply state-of-the-art actor-critic reinforcement learning algorithms (PPO and\nSAC) to search for plans that minimize overall costs. We empirically evaluate\nthe learning performance of these algorithms and compare their performance to\nhand-crafted baselines that mimic plans constructed by policy-makers. Our\nmethod outperforms baselines. Our work confirms the viability of a\ncomputational approach to support policy-makers\n","authors":["Anh Mai","Nikunj Gupta","Azza Abouzied","Dennis Shasha"],"pdf_url":"https://arxiv.org/pdf/2301.12802v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02738v2","updated":"2023-06-07T10:42:23Z","published":"2023-06-05T09:33:39Z","title":"A Large-Scale Study of Probabilistic Calibration in Neural Network\n  Regression","summary":"  Accurate probabilistic predictions are essential for optimal decision making.\nWhile neural network miscalibration has been studied primarily in\nclassification, we investigate this in the less-explored domain of regression.\nWe conduct the largest empirical study to date to assess the probabilistic\ncalibration of neural networks. We also analyze the performance of\nrecalibration, conformal, and regularization methods to enhance probabilistic\ncalibration. Additionally, we introduce novel differentiable recalibration and\nregularization methods, uncovering new insights into their effectiveness. Our\nfindings reveal that regularization methods offer a favorable tradeoff between\ncalibration and sharpness. Post-hoc methods exhibit superior probabilistic\ncalibration, which we attribute to the finite-sample coverage guarantee of\nconformal prediction. Furthermore, we demonstrate that quantile recalibration\ncan be considered as a specific case of conformal prediction. Our study is\nfully reproducible and implemented in a common code base for fair comparisons.\n","authors":["Victor Dheur","Souhaib Ben Taieb"],"pdf_url":"https://arxiv.org/pdf/2306.02738v2.pdf","comment":"Accepted at the 40th International Conference on Machine Learning\n  (ICML 2023)"},{"id":"http://arxiv.org/abs/2306.04319v1","updated":"2023-06-07T10:32:53Z","published":"2023-06-07T10:32:53Z","title":"CaptAinGlove: Capacitive and Inertial Fusion-Based Glove for Real-Time\n  on Edge Hand Gesture Recognition for Drone Control","summary":"  We present CaptAinGlove, a textile-based, low-power (1.15Watts),\nprivacy-conscious, real-time on-the-edge (RTE) glove-based solution with a tiny\nmemory footprint (2MB), designed to recognize hand gestures used for drone\ncontrol. We employ lightweight convolutional neural networks as the backbone\nmodels and a hierarchical multimodal fusion to reduce power consumption and\nimprove accuracy. The system yields an F1-score of 80% for the offline\nevaluation of nine classes; eight hand gesture commands and null activity. For\nthe RTE, we obtained an F1-score of 67% (one user).\n","authors":["Hymalai Bello","Sungho Suh","Daniel Geißler","Lala Ray","Bo Zhou","Paul Lukowicz"],"pdf_url":"https://arxiv.org/pdf/2306.04319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.12573v4","updated":"2023-06-07T10:24:37Z","published":"2022-09-26T10:38:39Z","title":"Digital Audio Forensics: Blind Human Voice Mimicry Detection","summary":"  Audio is one of the most used ways of human communication, but at the same\ntime it can be easily misused to trick people. With the revolution of AI, the\nrelated technologies are now accessible to almost everyone thus making it\nsimple for the criminals to commit crimes and forgeries. In this work, we\nintroduce a deep learning method to develop a classifier that will blindly\nclassify an input audio as real or mimicked; the word 'blindly' refers to the\nability to detect mimicked audio without references or real sources. The\nproposed model was trained on a set of important features extracted from a\nlarge dataset of audios to get a classifier that was tested on the same set of\nfeatures from different audios. The data was extracted from two raw datasets,\nespecially composed for this work; an all English dataset and a mixed dataset\n(Arabic plus English). These datasets have been made available, in raw form,\nthrough GitHub for the use of the research community at\nhttps://github.com/SaSs7/Dataset. For the purpose of comparison, the audios\nwere also classified through human inspection with the subjects being the\nnative speakers. The ensued results were interesting and exhibited formidable\naccuracy.\n","authors":["Sahar Al Ajmi","Khizar Hayat","Alaa M. Al Obaidi","Naresh Kumar","Munaf Najmuldeen","Baptiste Magnier"],"pdf_url":"https://arxiv.org/pdf/2209.12573v4.pdf","comment":"14 pages, 4 figures (6 if you count subfigures), 2 tables"},{"id":"http://arxiv.org/abs/2205.12933v2","updated":"2023-06-07T10:13:20Z","published":"2022-05-24T13:26:39Z","title":"Boosting Tail Neural Network for Realtime Custom Keyword Spotting","summary":"  In this paper, we propose a Boosting Tail Neural Network (BTNN) for improving\nthe performance of Realtime Custom Keyword Spotting (RCKS) that is still an\nindustrial challenge for demanding powerful classification ability with limited\ncomputation resources. Inspired by Brain Science that a brain is only partly\nactivated for a nerve simulation and numerous machine learning algorithms are\ndeveloped to use a batch of weak classifiers to resolve arduous problems, which\nare often proved to be effective. We show that this method is helpful to the\nRCKS problem. The proposed approach achieve better performances in terms of\nwakeup rate and false alarm.\n  In our experiments compared with those traditional algorithms that use only\none strong classifier, it gets 18\\% relative improvement. We also point out\nthat this approach may be promising in future ASR exploration.\n","authors":["Sihao Xue","Qianyao Shen","Guoqing Li"],"pdf_url":"https://arxiv.org/pdf/2205.12933v2.pdf","comment":"4 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.08839v5","updated":"2023-06-07T10:06:21Z","published":"2023-01-21T00:48:18Z","title":"A Trustworthiness Score to Evaluate CNNs Predictions","summary":"  Due to the black box nature of Convolutional Neural Networks (CNNs), the\ncontinuous validation of CNNs during operation is challenging with the absence\nof a human monitor. As a result this makes it difficult for developers and\nregulators to gain confidence in the deployment of autonomous systems employing\nCNNs. It is critical for safety during operation to know when CNN's predictions\nare trustworthy or suspicious. With the absence of a human monitor, the basic\napproach is to use the model's output confidence score to assess if predictions\nare trustworthy or suspicious. However, the model's confidence score is a\nresult of computations coming from a black box, therefore lacks transparency\nand makes it challenging to automatedly credit trustworthiness to predictions.\nWe introduce the trustworthiness score (TS), a simple metric that provides a\nmore transparent and effective way of providing confidence in CNNs predictions\ncompared to model's confidence score. The metric quantifies the trustworthiness\nin a prediction by checking for the existence of certain features in the\npredictions made by the CNN. We also use the underlying idea of the TS metric,\nto provide a suspiciousness score (SS) in the overall input frame to help in\nthe detection of suspicious frames where false negatives exist. We conduct a\ncase study using YOLOv5 on persons detection to demonstrate our method and\nusage of TS and SS. The case study shows that using our method consistently\nimproves the precision of predictions compared to relying on model confidence\nscore alone, for both 1) approving of trustworthy predictions (~20%\nimprovement) and 2) detecting suspicious frames (~5% improvement).\n","authors":["Abanoub Ghobrial","Darryl Hond","Hamid Asgari","Kerstin Eder"],"pdf_url":"https://arxiv.org/pdf/2301.08839v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.06009v2","updated":"2023-06-07T10:05:59Z","published":"2023-04-12T17:33:41Z","title":"Literature Review: Computer Vision Applications in Transportation\n  Logistics and Warehousing","summary":"  Computer vision applications in transportation logistics and warehousing have\na huge potential for process automation. We present a structured literature\nreview on research in the field to help leverage this potential. The literature\nis categorized w.r.t. the application, i.e. the task it tackles and w.r.t. the\ncomputer vision techniques that are used. Regarding applications, we subdivide\nthe literature in two areas: Monitoring, i.e. observing and retrieving relevant\ninformation from the environment, and manipulation, where approaches are used\nto analyze and interact with the environment. Additionally, we point out\ndirections for future research and link to recent developments in computer\nvision that are suitable for application in logistics. Finally, we present an\noverview of existing datasets and industrial solutions. The results of our\nanalysis are also available online at https://a-nau.github.io/cv-in-logistics.\n","authors":["Alexander Naumann","Felix Hertlein","Laura Dörr","Steffen Thoma","Kai Furmans"],"pdf_url":"https://arxiv.org/pdf/2304.06009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04299v1","updated":"2023-06-07T10:02:16Z","published":"2023-06-07T10:02:16Z","title":"Timing Process Interventions with Causal Inference and Reinforcement\n  Learning","summary":"  The shift from the understanding and prediction of processes to their\noptimization offers great benefits to businesses and other organizations.\nPrecisely timed process interventions are the cornerstones of effective\noptimization. Prescriptive process monitoring (PresPM) is the sub-field of\nprocess mining that concentrates on process optimization. The emerging PresPM\nliterature identifies state-of-the-art methods, causal inference (CI) and\nreinforcement learning (RL), without presenting a quantitative comparison. Most\nexperiments are carried out using historical data, causing problems with the\naccuracy of the methods' evaluations and preempting online RL. Our contribution\nconsists of experiments on timed process interventions with synthetic data that\nrenders genuine online RL and the comparison to CI possible, and allows for an\naccurate evaluation of the results. Our experiments reveal that RL's policies\noutperform those from CI and are more robust at the same time. Indeed, the RL\npolicies approach perfect policies. Unlike CI, the unaltered online RL approach\ncan be applied to other, more generic PresPM problems such as next best\nactivity recommendations. Nonetheless, CI has its merits in settings where\nonline learning is not an option.\n","authors":["Hans Weytjens","Wouter Verbeke","Jochen De Weerdt"],"pdf_url":"https://arxiv.org/pdf/2306.04299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05337v2","updated":"2023-06-07T09:50:21Z","published":"2022-10-11T11:00:04Z","title":"SGD with Large Step Sizes Learns Sparse Features","summary":"  We showcase important features of the dynamics of the Stochastic Gradient\nDescent (SGD) in the training of neural networks. We present empirical\nobservations that commonly used large step sizes (i) lead the iterates to jump\nfrom one side of a valley to the other causing loss stabilization, and (ii)\nthis stabilization induces a hidden stochastic dynamics orthogonal to the\nbouncing directions that biases it implicitly toward sparse predictors.\nFurthermore, we show empirically that the longer large step sizes keep SGD high\nin the loss landscape valleys, the better the implicit regularization can\noperate and find sparse representations. Notably, no explicit regularization is\nused so that the regularization effect comes solely from the SGD training\ndynamics influenced by the step size schedule. Therefore, these observations\nunveil how, through the step size schedules, both gradient and noise drive\ntogether the SGD dynamics through the loss landscape of neural networks. We\njustify these findings theoretically through the study of simple neural network\nmodels as well as qualitative arguments inspired from stochastic processes.\nFinally, this analysis allows us to shed a new light on some common practice\nand observed phenomena when training neural networks. The code of our\nexperiments is available at https://github.com/tml-epfl/sgd-sparse-features.\n","authors":["Maksym Andriushchenko","Aditya Varre","Loucas Pillaud-Vivien","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2210.05337v2.pdf","comment":"The camera-ready version (ICML 2023): extended experiments on deep\n  networks (DenseNets on CIFAR-10, CIFAR-100, and Tiny ImageNet), empirically\n  validated the SDE modelling, improved the clarity of the paper"},{"id":"http://arxiv.org/abs/2306.04293v1","updated":"2023-06-07T09:46:38Z","published":"2023-06-07T09:46:38Z","title":"Phrase Retrieval for Open-Domain Conversational Question Answering with\n  Conversational Dependency Modeling via Contrastive Learning","summary":"  Open-Domain Conversational Question Answering (ODConvQA) aims at answering\nquestions through a multi-turn conversation based on a retriever-reader\npipeline, which retrieves passages and then predicts answers with them.\nHowever, such a pipeline approach not only makes the reader vulnerable to the\nerrors propagated from the retriever, but also demands additional effort to\ndevelop both the retriever and the reader, which further makes it slower since\nthey are not runnable in parallel. In this work, we propose a method to\ndirectly predict answers with a phrase retrieval scheme for a sequence of\nwords, reducing the conventional two distinct subtasks into a single one. Also,\nfor the first time, we study its capability for ODConvQA tasks. However, simply\nadopting it is largely problematic, due to the dependencies between previous\nand current turns in a conversation. To address this problem, we further\nintroduce a novel contrastive learning strategy, making sure to reflect\nprevious turns when retrieving the phrase for the current context, by\nmaximizing representational similarities of consecutive turns in a conversation\nwhile minimizing irrelevant conversational contexts. We validate our model on\ntwo ODConvQA datasets, whose experimental results show that it substantially\noutperforms the relevant baselines with the retriever-reader. Code is available\nat: https://github.com/starsuzi/PRO-ConvQA.\n","authors":["Soyeong Jeong","Jinheon Baek","Sung Ju Hwang","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2306.04293v1.pdf","comment":"Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.04288v1","updated":"2023-06-07T09:40:18Z","published":"2023-06-07T09:40:18Z","title":"Revising deep learning methods in parking lot occupancy detection","summary":"  Parking guidance systems have recently become a popular trend as a part of\nthe smart cities' paradigm of development. The crucial part of such systems is\nthe algorithm allowing drivers to search for available parking lots across\nregions of interest. The classic approach to this task is based on the\napplication of neural network classifiers to camera records. However, existing\nsystems demonstrate a lack of generalization ability and appropriate testing\nregarding specific visual conditions. In this study, we extensively evaluate\nstate-of-the-art parking lot occupancy detection algorithms, compare their\nprediction quality with the recently emerged vision transformers, and propose a\nnew pipeline based on EfficientNet architecture. Performed computational\nexperiments have demonstrated the performance increase in the case of our\nmodel, which was evaluated on 5 different datasets.\n","authors":["Anastasia Martynova","Mikhail Kuznetsov","Vadim Porvatov","Vladislav Tishin","Andrey Kuznetsov","Natalia Semenova","Ksenia Kuznetsova"],"pdf_url":"https://arxiv.org/pdf/2306.04288v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.13840v2","updated":"2023-06-07T09:33:04Z","published":"2023-04-26T21:56:03Z","title":"A Deep Learning Framework for Verilog Autocompletion Towards Design and\n  Verification Automation","summary":"  Innovative Electronic Design Automation (EDA) solutions are important to meet\nthe design requirements for increasingly complex electronic devices. Verilog, a\nhardware description language, is widely used for the design and verification\nof digital circuits and is synthesized using specific EDA tools. However,\nwriting code is a repetitive and time-intensive task. This paper proposes,\nprimarily, a novel deep learning framework for training a Verilog\nautocompletion model and, secondarily, a Verilog dataset of files and snippets\nobtained from open-source repositories. The framework involves integrating\nmodels pretrained on general programming language data and finetuning them on a\ndataset curated to be similar to a target downstream task. This is validated by\ncomparing different pretrained models trained on different subsets of the\nproposed Verilog dataset using multiple evaluation metrics. These experiments\ndemonstrate that the proposed framework achieves better BLEU, ROUGE-L, and chrF\nscores by 9.5%, 6.7%, and 6.9%, respectively, compared to a model trained from\nscratch. Code and data are made available at:\nhttps://github.com/99EnriqueD/verilog_autocompletion .\n","authors":["Enrique Dehaerne","Bappaditya Dey","Sandip Halder","Stefan De Gendt"],"pdf_url":"https://arxiv.org/pdf/2304.13840v2.pdf","comment":"Updated text to correct language errors and added a link to\n  supplementary code and data\n  (https://github.com/99EnriqueD/verilog_autocompletion). 6 pages, 3 figures, 4\n  tables. To be presented as a WIP poster at DAC 2023"},{"id":"http://arxiv.org/abs/2203.12026v4","updated":"2023-06-07T09:24:31Z","published":"2022-03-22T20:27:40Z","title":"Machine Learning Testing in an ADAS Case Study Using\n  Simulation-Integrated Bio-Inspired Search-Based Testing","summary":"  This paper presents an extended version of Deeper, a search-based\nsimulation-integrated test solution that generates failure-revealing test\nscenarios for testing a deep neural network-based lane-keeping system. In the\nnewly proposed version, we utilize a new set of bio-inspired search algorithms,\ngenetic algorithm (GA), $({\\mu}+{\\lambda})$ and $({\\mu},{\\lambda})$ evolution\nstrategies (ES), and particle swarm optimization (PSO), that leverage a quality\npopulation seed and domain-specific cross-over and mutation operations tailored\nfor the presentation model used for modeling the test scenarios. In order to\ndemonstrate the capabilities of the new test generators within Deeper, we carry\nout an empirical evaluation and comparison with regard to the results of five\nparticipating tools in the cyber-physical systems testing competition at SBST\n2021. Our evaluation shows the newly proposed test generators in Deeper not\nonly represent a considerable improvement on the previous version but also\nprove to be effective and efficient in provoking a considerable number of\ndiverse failure-revealing test scenarios for testing an ML-driven lane-keeping\nsystem. They can trigger several failures while promoting test scenario\ndiversity, under a limited test time budget, high target failure severity, and\nstrict speed limit constraints.\n","authors":["Mahshid Helali Moghadam","Markus Borg","Mehrdad Saadatmand","Seyed Jalaleddin Mousavirad","Markus Bohlin","Björn Lisper"],"pdf_url":"https://arxiv.org/pdf/2203.12026v4.pdf","comment":"Accepted for publication in Journal Of Software: Evolution And\n  Process"},{"id":"http://arxiv.org/abs/2306.04269v1","updated":"2023-06-07T09:09:35Z","published":"2023-06-07T09:09:35Z","title":"ColNav: Real-Time Colon Navigation for Colonoscopy","summary":"  Colorectal cancer screening through colonoscopy continues to be the dominant\nglobal standard, as it allows identifying pre-cancerous or adenomatous lesions\nand provides the ability to remove them during the procedure itself.\nNevertheless, failure by the endoscopist to identify such lesions increases the\nlikelihood of lesion progression to subsequent colorectal cancer. Ultimately,\ncolonoscopy remains operator-dependent, and the wide range of quality in\ncolonoscopy examinations among endoscopists is influenced by variations in\ntheir technique, training, and diligence. This paper presents a novel real-time\nnavigation guidance system for Optical Colonoscopy (OC). Our proposed system\nemploys a real-time approach that displays both an unfolded representation of\nthe colon and a local indicator directing to un-inspected areas. These\nvisualizations are presented to the physician during the procedure, providing\nactionable and comprehensible guidance to un-surveyed areas in real-time, while\nseamlessly integrating into the physician's workflow. Through coverage\nexperimental evaluation, we demonstrated that our system resulted in a higher\npolyp recall (PR) and high inter-rater reliability with physicians for coverage\nprediction. These results suggest that our real-time navigation guidance system\nhas the potential to improve the quality and effectiveness of Optical\nColonoscopy and ultimately benefit patient outcomes.\n","authors":["Netanel Frank","Erez Posner","Emmanuelle Muhlethaler","Adi Zholkover","Moshe Bouhnik"],"pdf_url":"https://arxiv.org/pdf/2306.04269v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13778v2","updated":"2023-06-07T09:07:48Z","published":"2023-01-31T17:27:05Z","title":"Differentially Private Distributed Bayesian Linear Regression with MCMC","summary":"  We propose a novel Bayesian inference framework for distributed\ndifferentially private linear regression. We consider a distributed setting\nwhere multiple parties hold parts of the data and share certain summary\nstatistics of their portions in privacy-preserving noise. We develop a novel\ngenerative statistical model for privately shared statistics, which exploits a\nuseful distributional relation between the summary statistics of linear\nregression. Bayesian estimation of the regression coefficients is conducted\nmainly using Markov chain Monte Carlo algorithms, while we also provide a fast\nversion to perform Bayesian estimation in one iteration. The proposed methods\nhave computational advantages over their competitors. We provide numerical\nresults on both real and simulated data, which demonstrate that the proposed\nalgorithms provide well-rounded estimation and prediction.\n","authors":["Barış Alparslan","Sinan Yıldırım","Ş. İlker Birbil"],"pdf_url":"https://arxiv.org/pdf/2301.13778v2.pdf","comment":"15 pages, 4 figures, code available at:\n  https://github.com/sinanyildirim/Bayesian_DP_dist_LR"},{"id":"http://arxiv.org/abs/2306.04265v1","updated":"2023-06-07T09:05:56Z","published":"2023-06-07T09:05:56Z","title":"Permutaion Equivariant Graph Framelets for Heterophilous Semi-supervised\n  Learning","summary":"  The nature of heterophilous graphs is significantly different with that of\nhomophilous graphs, which suggests aggregations beyond 1-hop neighborhood and\ncauses difficulties in early graph neural network models. In this paper, we\ndevelop a new way to implement multi-scale extraction via constructing\nHaar-type graph framelets with desired properties of permutation equivariance,\nefficiency, and sparsity, for deep learning tasks on graphs. We further deisgn\na graph framelet neural network model PEGFAN using our constructed graph\nframelets. The experiments are conducted on a synthetic dataset and 9 benchmark\ndatasets to compare performance with other state-of-the-art models. The result\nshows that our model can achieve best performance on certain datasets of\nheterophilous graphs (including the majority of heterophilous datasets with\nrelatively larger sizes and denser connections) and competitive performance on\nthe remaining.\n","authors":["Jianfei Li","Ruigang Zheng","Han Feng","Xiaosheng Zhuang"],"pdf_url":"https://arxiv.org/pdf/2306.04265v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07011v2","updated":"2023-06-07T09:03:01Z","published":"2023-02-14T12:38:12Z","title":"A Modern Look at the Relationship between Sharpness and Generalization","summary":"  Sharpness of minima is a promising quantity that can correlate with\ngeneralization in deep networks and, when optimized during training, can\nimprove generalization. However, standard sharpness is not invariant under\nreparametrizations of neural networks, and, to fix this,\nreparametrization-invariant sharpness definitions have been proposed, most\nprominently adaptive sharpness (Kwon et al., 2021). But does it really capture\ngeneralization in modern practical settings? We comprehensively explore this\nquestion in a detailed study of various definitions of adaptive sharpness in\nsettings ranging from training from scratch on ImageNet and CIFAR-10 to\nfine-tuning CLIP on ImageNet and BERT on MNLI. We focus mostly on transformers\nfor which little is known in terms of sharpness despite their widespread usage.\nOverall, we observe that sharpness does not correlate well with generalization\nbut rather with some training parameters like the learning rate that can be\npositively or negatively correlated with generalization depending on the setup.\nInterestingly, in multiple cases, we observe a consistent negative correlation\nof sharpness with out-of-distribution error implying that sharper minima can\ngeneralize better. Finally, we illustrate on a simple model that the right\nsharpness measure is highly data-dependent, and that we do not understand well\nthis aspect for realistic data distributions. The code of our experiments is\navailable at https://github.com/tml-epfl/sharpness-vs-generalization.\n","authors":["Maksym Andriushchenko","Francesco Croce","Maximilian Müller","Matthias Hein","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2302.07011v2.pdf","comment":"The camera-ready version (accepted at ICML 2023)"},{"id":"http://arxiv.org/abs/2301.11355v4","updated":"2023-06-07T09:01:03Z","published":"2023-01-26T19:07:40Z","title":"Rigid Body Flows for Sampling Molecular Crystal Structures","summary":"  Normalizing flows (NF) are a class of powerful generative models that have\ngained popularity in recent years due to their ability to model complex\ndistributions with high flexibility and expressiveness. In this work, we\nintroduce a new type of normalizing flow that is tailored for modeling\npositions and orientations of multiple objects in three-dimensional space, such\nas molecules in a crystal. Our approach is based on two key ideas: first, we\ndefine smooth and expressive flows on the group of unit quaternions, which\nallows us to capture the continuous rotational motion of rigid bodies; second,\nwe use the double cover property of unit quaternions to define a proper density\non the rotation group. This ensures that our model can be trained using\nstandard likelihood-based methods or variational inference with respect to a\nthermodynamic target density. We evaluate the method by training Boltzmann\ngenerators for two molecular examples, namely the multi-modal density of a\ntetrahedral system in an external field and the ice XI phase in the TIP4P water\nmodel. Our flows can be combined with flows operating on the internal degrees\nof freedom of molecules and constitute an important step towards the modeling\nof distributions of many interacting molecules.\n","authors":["Jonas Köhler","Michele Invernizzi","Pim de Haan","Frank Noé"],"pdf_url":"https://arxiv.org/pdf/2301.11355v4.pdf","comment":"International Conference on Machine Learning, 2023"},{"id":"http://arxiv.org/abs/2306.04262v1","updated":"2023-06-07T09:00:19Z","published":"2023-06-07T09:00:19Z","title":"Self-Adjusting Weighted Expected Improvement for Bayesian Optimization","summary":"  Bayesian Optimization (BO) is a class of surrogate-based, sample-efficient\nalgorithms for optimizing black-box problems with small evaluation budgets. The\nBO pipeline itself is highly configurable with many different design choices\nregarding the initial design, surrogate model, and acquisition function (AF).\nUnfortunately, our understanding of how to select suitable components for a\nproblem at hand is very limited. In this work, we focus on the definition of\nthe AF, whose main purpose is to balance the trade-off between exploring\nregions with high uncertainty and those with high promise for good solutions.\nWe propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we let\nthe exploration-exploitation trade-off self-adjust in a data-driven manner,\nbased on a convergence criterion for BO. On the noise-free black-box BBOB\nfunctions of the COCO benchmarking platform, our method exhibits a favorable\nany-time performance compared to handcrafted baselines and serves as a robust\ndefault choice for any problem structure. The suitability of our method also\ntransfers to HPOBench. With SAWEI, we are a step closer to on-the-fly,\ndata-driven, and robust BO designs that automatically adjust their sampling\nbehavior to the problem at hand.\n","authors":["Carolin Benjamins","Elena Raponi","Anja Jankovic","Carola Doerr","Marius Lindauer"],"pdf_url":"https://arxiv.org/pdf/2306.04262v1.pdf","comment":"AutoML Conference 2023"},{"id":"http://arxiv.org/abs/2002.10855v2","updated":"2023-06-07T08:51:11Z","published":"2020-02-25T13:52:20Z","title":"Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy\n  Back","summary":"  Topic models are widely used to discover the latent representation of a set\nof documents. The two canonical models are latent Dirichlet allocation, and\nGaussian latent Dirichlet allocation, where the former uses multinomial\ndistributions over words, and the latter uses multivariate Gaussian\ndistributions over pre-trained word embedding vectors as the latent topic\nrepresentations, respectively. Compared with latent Dirichlet allocation,\nGaussian latent Dirichlet allocation is limited in the sense that it does not\ncapture the polysemy of a word such as ``bank.'' In this paper, we show that\nGaussian latent Dirichlet allocation could recover the ability to capture\npolysemy by introducing a hierarchical structure in the set of topics that the\nmodel can use to represent a given document. Our Gaussian hierarchical latent\nDirichlet allocation significantly improves polysemy detection compared with\nGaussian-based models and provides more parsimonious topic representations\ncompared with hierarchical latent Dirichlet allocation. Our extensive\nquantitative experiments show that our model also achieves better topic\ncoherence and held-out document predictive accuracy over a wide range of corpus\nand word embedding vectors.\n","authors":["Takahiro Yoshida","Ryohei Hisano","Takaaki Ohnishi"],"pdf_url":"https://arxiv.org/pdf/2002.10855v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04255v1","updated":"2023-06-07T08:51:06Z","published":"2023-06-07T08:51:06Z","title":"Accounting For Informative Sampling When Learning to Forecast Treatment\n  Outcomes Over Time","summary":"  Machine learning (ML) holds great potential for accurately forecasting\ntreatment outcomes over time, which could ultimately enable the adoption of\nmore individualized treatment strategies in many practical applications.\nHowever, a significant challenge that has been largely overlooked by the ML\nliterature on this topic is the presence of informative sampling in\nobservational data. When instances are observed irregularly over time, sampling\ntimes are typically not random, but rather informative -- depending on the\ninstance's characteristics, past outcomes, and administered treatments. In this\nwork, we formalize informative sampling as a covariate shift problem and show\nthat it can prohibit accurate estimation of treatment outcomes if not properly\naccounted for. To overcome this challenge, we present a general framework for\nlearning treatment outcomes in the presence of informative sampling using\ninverse intensity-weighting, and propose a novel method, TESAR-CDE, that\ninstantiates this framework using Neural CDEs. Using a simulation environment\nbased on a clinical use case, we demonstrate the effectiveness of our approach\nin learning under informative sampling.\n","authors":["Toon Vanderschueren","Alicia Curth","Wouter Verbeke","Mihaela van der Schaar"],"pdf_url":"https://arxiv.org/pdf/2306.04255v1.pdf","comment":"To appear in the Proceedings of the 40th International Conference on\n  Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023"},{"id":"http://arxiv.org/abs/2301.11040v2","updated":"2023-06-07T08:50:15Z","published":"2023-01-26T11:30:56Z","title":"Random Grid Neural Processes for Parametric Partial Differential\n  Equations","summary":"  We introduce a new class of spatially stochastic physics and data informed\ndeep latent models for parametric partial differential equations (PDEs) which\noperate through scalable variational neural processes. We achieve this by\nassigning probability measures to the spatial domain, which allows us to treat\ncollocation grids probabilistically as random variables to be marginalised out.\nAdapting this spatial statistics view, we solve forward and inverse problems\nfor parametric PDEs in a way that leads to the construction of Gaussian process\nmodels of solution fields. The implementation of these random grids poses a\nunique set of challenges for inverse physics informed deep learning frameworks\nand we propose a new architecture called Grid Invariant Convolutional Networks\n(GICNets) to overcome these challenges. We further show how to incorporate\nnoisy data in a principled manner into our physics informed model to improve\npredictions for problems where data may be available but whose measurement\nlocation does not coincide with any fixed mesh or grid. The proposed method is\ntested on a nonlinear Poisson problem, Burgers equation, and Navier-Stokes\nequations, and we provide extensive numerical comparisons. We demonstrate\nsignificant computational advantages over current physics informed neural\nlearning methods for parametric PDEs while improving the predictive\ncapabilities and flexibility of these models.\n","authors":["Arnaud Vadeboncoeur","Ieva Kazlauskaite","Yanni Papandreou","Fehmi Cirak","Mark Girolami","Ömer Deniz Akyildiz"],"pdf_url":"https://arxiv.org/pdf/2301.11040v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01228v3","updated":"2023-06-07T08:48:04Z","published":"2023-02-02T17:07:36Z","title":"Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic\n  Neurons","summary":"  Activity difference based learning algorithms-such as contrastive Hebbian\nlearning and equilibrium propagation-have been proposed as biologically\nplausible alternatives to error back-propagation. However, on traditional\ndigital chips these algorithms suffer from having to solve a costly inference\nproblem twice, making these approaches more than two orders of magnitude slower\nthan back-propagation. In the analog realm equilibrium propagation may be\npromising for fast and energy efficient learning, but states still need to be\ninferred and stored twice. Inspired by lifted neural networks and compartmental\nneuron models we propose a simple energy based compartmental neuron model,\ntermed dual propagation, in which each neuron is a dyad with two intrinsic\nstates. At inference time these intrinsic states encode the error/activity\nduality through their difference and their mean respectively. The advantage of\nthis method is that only a single inference phase is needed and that inference\ncan be solved in layerwise closed-form. Experimentally we show on common\ncomputer vision datasets, including Imagenet32x32, that dual propagation\nperforms equivalently to back-propagation both in terms of accuracy and\nruntime.\n","authors":["Rasmus Høier","D. Staudt","Christopher Zach"],"pdf_url":"https://arxiv.org/pdf/2302.01228v3.pdf","comment":"Added reflections on biological plausibility and results comparisons\n  to state-of-the-art versions of equilibrium propagation and difference target\n  propagation"},{"id":"http://arxiv.org/abs/2306.04252v1","updated":"2023-06-07T08:47:41Z","published":"2023-06-07T08:47:41Z","title":"Adversarial Sample Detection Through Neural Network Transport Dynamics","summary":"  We propose a detector of adversarial samples that is based on the view of\nneural networks as discrete dynamic systems. The detector tells clean inputs\nfrom abnormal ones by comparing the discrete vector fields they follow through\nthe layers. We also show that regularizing this vector field during training\nmakes the network more regular on the data distribution's support, thus making\nthe activations of clean inputs more distinguishable from those of abnormal\nones. Experimentally, we compare our detector favorably to other detectors on\nseen and unseen attacks, and show that the regularization of the network's\ndynamics improves the performance of adversarial detectors that use the\ninternal embeddings as inputs, while also improving test accuracy.\n","authors":["Skander Karkar","Patrick Gallinari","Alain Rakotomamonjy"],"pdf_url":"https://arxiv.org/pdf/2306.04252v1.pdf","comment":"ECML PKDD 2023"},{"id":"http://arxiv.org/abs/2306.04251v1","updated":"2023-06-07T08:44:51Z","published":"2023-06-07T08:44:51Z","title":"Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards\n  Simpler Subnetworks","summary":"  In this work, we reveal a strong implicit bias of stochastic gradient descent\n(SGD) that drives overly expressive networks to much simpler subnetworks,\nthereby dramatically reducing the number of independent parameters, and\nimproving generalization. To reveal this bias, we identify invariant sets, or\nsubsets of parameter space that remain unmodified by SGD. We focus on two\nclasses of invariant sets that correspond to simpler subnetworks and commonly\nappear in modern architectures. Our analysis uncovers that SGD exhibits a\nproperty of stochastic attractivity towards these simpler invariant sets. We\nestablish a sufficient condition for stochastic attractivity based on a\ncompetition between the loss landscape's curvature around the invariant set and\nthe noise introduced by stochastic gradients. Remarkably, we find that an\nincreased level of noise strengthens attractivity, leading to the emergence of\nattractive invariant sets associated with saddle-points or local maxima of the\ntrain loss. We observe empirically the existence of attractive invariant sets\nin trained deep neural networks, implying that SGD dynamics often collapses to\nsimple subnetworks with either vanishing or redundant neurons. We further\ndemonstrate how this simplifying process of stochastic collapse benefits\ngeneralization in a linear teacher-student framework. Finally, through this\nanalysis, we mechanistically explain why early training with large learning\nrates for extended periods benefits subsequent generalization.\n","authors":["Feng Chen","Daniel Kunin","Atsushi Yamamura","Surya Ganguli"],"pdf_url":"https://arxiv.org/pdf/2306.04251v1.pdf","comment":"30 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.02715v2","updated":"2023-06-07T08:35:35Z","published":"2023-06-05T09:08:24Z","title":"Federated Deep Learning for Intrusion Detection in IoT Networks","summary":"  The vast increase of IoT technologies and the ever-evolving attack vectors\nand threat actors have increased cyber-security risks dramatically. Novel\nattacks can compromise IoT devices to gain access to sensitive data or control\nthem to deploy further malicious activities. The detection of novel attacks\noften relies upon AI solutions. A common approach to implementing AI-based IDS\nin distributed IoT systems is in a centralised manner. However, this approach\nmay violate data privacy and secrecy. In addition, centralised data collection\nprohibits the scale-up of IDSs. Therefore, intrusion detection solutions in IoT\necosystems need to move towards a decentralised direction. FL has attracted\nsignificant interest in recent years due to its ability to perform\ncollaborative learning while preserving data confidentiality and locality.\nNevertheless, most FL-based IDS for IoT systems are designed under unrealistic\ndata distribution conditions. To that end, we design an experiment\nrepresentative of the real world and evaluate the performance of two FL IDS\nimplementations, one based on DNNs and another on our previous work on DBNs.\nFor our experiments, we rely on TON-IoT, a realistic IoT network traffic\ndataset, associating each IP address with a single FL client. Additionally, we\nexplore pre-training and investigate various aggregation methods to mitigate\nthe impact of data heterogeneity. Lastly, we benchmark our approach against a\ncentralised solution. The comparison shows that the heterogeneous nature of the\ndata has a considerable negative impact on the model performance when trained\nin a distributed manner. However, in the case of a pre-trained initial global\nFL model, we demonstrate a performance improvement of over 20% (F1-score) when\ncompared against a randomly initiated global model.\n","authors":["Othmane Belarbi","Theodoros Spyridopoulos","Eirini Anthi","Ioannis Mavromatis","Pietro Carnelli","Aftab Khan"],"pdf_url":"https://arxiv.org/pdf/2306.02715v2.pdf","comment":"14 pages, 5 figues, 3 tables"},{"id":"http://arxiv.org/abs/2301.00437v4","updated":"2023-06-07T08:32:16Z","published":"2023-01-01T16:29:56Z","title":"Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced\n  Data","summary":"  Modern deep neural networks have achieved impressive performance on tasks\nfrom image classification to natural language processing. Surprisingly, these\ncomplex systems with massive amounts of parameters exhibit the same structural\nproperties in their last-layer features and classifiers across canonical\ndatasets when training until convergence. In particular, it has been observed\nthat the last-layer features collapse to their class-means, and those\nclass-means are the vertices of a simplex Equiangular Tight Frame (ETF). This\nphenomenon is known as Neural Collapse ($\\mathcal{NC}$). Recent papers have\ntheoretically shown that $\\mathcal{NC}$ emerges in the global minimizers of\ntraining problems with the simplified ``unconstrained feature model''. In this\ncontext, we take a step further and prove the $\\mathcal{NC}$ occurrences in\ndeep linear networks for the popular mean squared error (MSE) and cross entropy\n(CE) losses, showing that global solutions exhibit $\\mathcal{NC}$ properties\nacross the linear layers. Furthermore, we extend our study to imbalanced data\nfor MSE loss and present the first geometric analysis of $\\mathcal{NC}$ under\nbias-free setting. Our results demonstrate the convergence of the last-layer\nfeatures and classifiers to a geometry consisting of orthogonal vectors, whose\nlengths depend on the amount of data in their corresponding classes. Finally,\nwe empirically validate our theoretical analyses on synthetic and practical\nnetwork architectures with both balanced and imbalanced scenarios.\n","authors":["Hien Dang","Tho Tran","Stanley Osher","Hung Tran-The","Nhat Ho","Tan Nguyen"],"pdf_url":"https://arxiv.org/pdf/2301.00437v4.pdf","comment":"75 pages, 20 figures, 4 tables. Hien Dang and Tho Tran contributed\n  equally to this work"},{"id":"http://arxiv.org/abs/2306.04228v1","updated":"2023-06-07T08:06:50Z","published":"2023-06-07T08:06:50Z","title":"Data Mining for Faster, Interpretable Solutions to Inverse Problems: A\n  Case Study Using Additive Manufacturing","summary":"  Solving inverse problems, where we find the input values that result in\ndesired values of outputs, can be challenging. The solution process is often\ncomputationally expensive and it can be difficult to interpret the solution in\nhigh-dimensional input spaces. In this paper, we use a problem from additive\nmanufacturing to address these two issues with the intent of making it easier\nto solve inverse problems and exploit their results. First, focusing on\nGaussian process surrogates that are used to solve inverse problems, we\ndescribe how a simple modification to the idea of tapering can substantially\nspeed up the surrogate without losing accuracy in prediction. Second, we\ndemonstrate that Kohonen self-organizing maps can be used to visualize and\ninterpret the solution to the inverse problem in the high-dimensional input\nspace. For our data set, as not all input dimensions are equally important, we\nshow that using weighted distances results in a better organized map that makes\nthe relationships among the inputs obvious.\n","authors":["Chandrika Kamath","Juliette Franzman","Ravi Ponmalai"],"pdf_url":"https://arxiv.org/pdf/2306.04228v1.pdf","comment":"16 figures and 4 tables"},{"id":"http://arxiv.org/abs/2306.04226v1","updated":"2023-06-07T08:05:46Z","published":"2023-06-07T08:05:46Z","title":"Normalization Layers Are All That Sharpness-Aware Minimization Needs","summary":"  Sharpness-aware minimization (SAM) was proposed to reduce sharpness of minima\nand has been shown to enhance generalization performance in various settings.\nIn this work we show that perturbing only the affine normalization parameters\n(comprising less than 0.1% of the total parameters) in the adversarial step of\nSAM outperforms perturbing all of the parameters. This finding generalizes to\ndifferent SAM variants and both ResNet (Batch Normalization) and Vision\nTransformer (Layer Normalization) architectures. We consider alternative sparse\nperturbation approaches and find that these do not achieve similar performance\nenhancement at such extreme sparsity levels, showing that this behaviour is\nunique to the normalization layers. Although our findings reaffirm the\neffectiveness of SAM in improving generalization performance, they cast doubt\non whether this is solely caused by reduced sharpness. The code for our\nexperiments is publicly available at https://github.com/mueller-mp/SAM-ON.\n","authors":["Maximilian Mueller","Tiffany Vlaar","David Rolnick","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2306.04226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04225v1","updated":"2023-06-07T08:02:17Z","published":"2023-06-07T08:02:17Z","title":"Efficient Vision Transformer for Human Pose Estimation via Patch\n  Selection","summary":"  While Convolutional Neural Networks (CNNs) have been widely successful in 2D\nhuman pose estimation, Vision Transformers (ViTs) have emerged as a promising\nalternative to CNNs, boosting state-of-the-art performance. However, the\nquadratic computational complexity of ViTs has limited their applicability for\nprocessing high-resolution images and long videos. To address this challenge,\nwe propose a simple method for reducing ViT's computational complexity based on\nselecting and processing a small number of most informative patches while\ndisregarding others. We leverage a lightweight pose estimation network to guide\nthe patch selection process, ensuring that the selected patches contain the\nmost important information. Our experimental results on three widely used 2D\npose estimation benchmarks, namely COCO, MPII and OCHuman, demonstrate the\neffectiveness of our proposed methods in significantly improving speed and\nreducing computational complexity with a slight drop in performance.\n","authors":["Kaleab A. Kinfu","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2306.04225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04223v1","updated":"2023-06-07T07:58:58Z","published":"2023-06-07T07:58:58Z","title":"Causally Learning an Optimal Rework Policy","summary":"  In manufacturing, rework refers to an optional step of a production process\nwhich aims to eliminate errors or remedy products that do not meet the desired\nquality standards. Reworking a production lot involves repeating a previous\nproduction stage with adjustments to ensure that the final product meets the\nrequired specifications. While offering the chance to improve the yield and\nthus increase the revenue of a production lot, a rework step also incurs\nadditional costs. Additionally, the rework of parts that already meet the\ntarget specifications may damage them and decrease the yield. In this paper, we\napply double/debiased machine learning (DML) to estimate the conditional\ntreatment effect of a rework step during the color conversion process in\nopto-electronic semiconductor manufacturing on the final product yield. We\nutilize the implementation DoubleML to develop policies for the rework of\ncomponents and estimate their value empirically. From our causal machine\nlearning analysis we derive implications for the coating of monochromatic LEDs\nwith conversion layers.\n","authors":["Oliver Schacht","Sven Klaassen","Philipp Schwarz","Martin Spindler","Daniel Grünbaum","Sebastian Imhof"],"pdf_url":"https://arxiv.org/pdf/2306.04223v1.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2305.09674v3","updated":"2023-06-07T07:56:11Z","published":"2023-05-09T09:21:48Z","title":"Quantum Machine Learning for Malware Classification","summary":"  In a context of malicious software detection, machine learning (ML) is widely\nused to generalize to new malware. However, it has been demonstrated that ML\nmodels can be fooled or may have generalization problems on malware that has\nnever been seen. We investigate the possible benefits of quantum algorithms for\nclassification tasks. We implement two models of Quantum Machine Learning\nalgorithms, and we compare them to classical models for the classification of a\ndataset composed of malicious and benign executable files. We try to optimize\nour algorithms based on methods found in the literature, and analyze our\nresults in an exploratory way, to identify the most interesting directions to\nexplore for the future.\n","authors":["Grégoire Barrué","Tony Quertier"],"pdf_url":"https://arxiv.org/pdf/2305.09674v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04220v1","updated":"2023-06-07T07:51:05Z","published":"2023-06-07T07:51:05Z","title":"Look Beneath the Surface: Exploiting Fundamental Symmetry for\n  Sample-Efficient Offline RL","summary":"  Offline reinforcement learning (RL) offers an appealing approach to\nreal-world tasks by learning policies from pre-collected datasets without\ninteracting with the environment. However, the performance of existing offline\nRL algorithms heavily depends on the scale and state-action space coverage of\ndatasets. Real-world data collection is often expensive and uncontrollable,\nleading to small and narrowly covered datasets and posing significant\nchallenges for practical deployments of offline RL. In this paper, we provide a\nnew insight that leveraging the fundamental symmetry of system dynamics can\nsubstantially enhance offline RL performance under small datasets.\nSpecifically, we propose a Time-reversal symmetry (T-symmetry) enforced\nDynamics Model (TDM), which establishes consistency between a pair of forward\nand reverse latent dynamics. TDM provides both well-behaved representations for\nsmall datasets and a new reliability measure for OOD samples based on\ncompliance with the T-symmetry. These can be readily used to construct a new\noffline RL algorithm (TSRL) with less conservative policy constraints and a\nreliable latent space data augmentation procedure. Based on extensive\nexperiments, we find TSRL achieves great performance on small benchmark\ndatasets with as few as 1% of the original samples, which significantly\noutperforms the recent offline RL algorithms in terms of data efficiency and\ngeneralizability.\n","authors":["Peng Cheng","Xianyuan Zhan","Zhihao Wu","Wenjia Zhang","Shoucheng Song","Han Wang","Youfang Lin","Li Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.04220v1.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2306.04214v1","updated":"2023-06-07T07:40:04Z","published":"2023-06-07T07:40:04Z","title":"DualHGNN: A Dual Hypergraph Neural Network for Semi-Supervised Node\n  Classification based on Multi-View Learning and Density Awareness","summary":"  Graph-based semi-supervised node classification has been shown to become a\nstate-of-the-art approach in many applications with high research value and\nsignificance. Most existing methods are only based on the original intrinsic or\nartificially established graph structure which may not accurately reflect the\n\"true\" correlation among data and are not optimal for semi-supervised node\nclassification in the downstream graph neural networks. Besides, while existing\ngraph-based methods mostly utilize the explicit graph structure, some implicit\ninformation, for example, the density information, can also provide latent\ninformation that can be further exploited. To address these limitations, this\npaper proposes the Dual Hypergraph Neural Network (DualHGNN), a new dual\nconnection model integrating both hypergraph structure learning and hypergraph\nrepresentation learning simultaneously in a unified architecture. The DualHGNN\nfirst leverages a multi-view hypergraph learning network to explore the optimal\nhypergraph structure from multiple views, constrained by a consistency loss\nproposed to improve its generalization. Then, DualHGNN employs a density-aware\nhypergraph attention network to explore the high-order semantic correlation\namong data points based on the density-aware attention mechanism. Extensive\nexperiments are conducted in various benchmark datasets, and the results\ndemonstrate the effectiveness of the proposed approach.\n","authors":["Jianpeng Liao","Jun Yan","Qian Tao"],"pdf_url":"https://arxiv.org/pdf/2306.04214v1.pdf","comment":"This work has been accepted by 2023 International Joint Conference on\n  Neural Networks (IJCNN 2023). arXiv admin note: text overlap with\n  arXiv:2201.11511"},{"id":"http://arxiv.org/abs/2306.04212v1","updated":"2023-06-07T07:37:01Z","published":"2023-06-07T07:37:01Z","title":"Migrate Demographic Group For Fair GNNs","summary":"  Graph Neural networks (GNNs) have been applied in many scenarios due to the\nsuperior performance of graph learning. However, fairness is always ignored\nwhen designing GNNs. As a consequence, biased information in training data can\neasily affect vanilla GNNs, causing biased results toward particular\ndemographic groups (divided by sensitive attributes, such as race and age).\nThere have been efforts to address the fairness issue. However, existing fair\ntechniques generally divide the demographic groups by raw sensitive attributes\nand assume that are fixed. The biased information correlated with raw sensitive\nattributes will run through the training process regardless of the implemented\nfair techniques. It is urgent to resolve this problem for training fair GNNs.\nTo tackle this problem, we propose a brand new framework, FairMigration, which\ncan dynamically migrate the demographic groups instead of keeping that fixed\nwith raw sensitive attributes. FairMigration is composed of two training\nstages. In the first stage, the GNNs are initially optimized by personalized\nself-supervised learning, and the demographic groups are adjusted dynamically.\nIn the second stage, the new demographic groups are frozen and supervised\nlearning is carried out under the constraints of new demographic groups and\nadversarial training. Extensive experiments reveal that FairMigration balances\nmodel performance and fairness well.\n","authors":["YanMing Hu","TianChi Liao","JiaLong Chen","Chuan Chen","Jing Bian","ZiBin Zheng"],"pdf_url":"https://arxiv.org/pdf/2306.04212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15046v4","updated":"2023-06-07T07:36:59Z","published":"2022-11-28T04:08:55Z","title":"PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial\n  Networks for Radar-Based Precipitation Nowcasting","summary":"  The precipitation nowcasting methods have been elaborated over the centuries\nbecause rain has a crucial impact on human life. Not only quantitative\nprecipitation forecast (QPF) models and convolutional long short-term memory\n(ConvLSTM), but also various sophisticated methods such as the latest MetNet-2\nare emerging. In this paper, we propose a paired complementary temporal\ncycle-consistent adversarial networks (PCT-CycleGAN) for radar-based\nprecipitation nowcasting, inspired by cycle-consistent adversarial networks\n(CycleGAN), which shows strong performance in image-to-image translation.\nPCT-CycleGAN generates temporal causality using two generator networks with\nforward and backward temporal dynamics in paired complementary cycles. Each\ngenerator network learns a huge number of one-to-one mappings about\ntime-dependent radar-based precipitation data to approximate a mapping function\nrepresenting the temporal dynamics in each direction. To create robust temporal\ncausality between paired complementary cycles, novel connection loss is\nproposed. And torrential loss to cover exceptional heavy rain events is also\nproposed. The generator network learning forward temporal dynamics in\nPCT-CycleGAN generates radar-based precipitation data 10 minutes from the\ncurrent time. Also, it provides a reliable prediction of up to 2 hours with\niterative forecasting. The superiority of PCT-CycleGAN is demonstrated through\nqualitative and quantitative comparisons with several previous methods.\n","authors":["Jaeho Choi","Yura Kim","Kwang-Ho Kim","Sung-Hwa Jung","Ikhyun Cho"],"pdf_url":"https://arxiv.org/pdf/2211.15046v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04203v1","updated":"2023-06-07T07:15:20Z","published":"2023-06-07T07:15:20Z","title":"Leveraging Knowledge Graph Embeddings to Enhance Contextual\n  Representations for Relation Extraction","summary":"  Relation extraction task is a crucial and challenging aspect of Natural\nLanguage Processing. Several methods have surfaced as of late, exhibiting\nnotable performance in addressing the task; however, most of these approaches\nrely on vast amounts of data from large-scale knowledge graphs or language\nmodels pretrained on voluminous corpora. In this paper, we hone in on the\neffective utilization of solely the knowledge supplied by a corpus to create a\nhigh-performing model. Our objective is to showcase that by leveraging the\nhierarchical structure and relational distribution of entities within a corpus\nwithout introducing external knowledge, a relation extraction model can achieve\nsignificantly enhanced performance. We therefore proposed a relation extraction\napproach based on the incorporation of pretrained knowledge graph embeddings at\nthe corpus scale into the sentence-level contextual representation. We\nconducted a series of experiments which revealed promising and very interesting\nresults for our proposed approach.The obtained results demonstrated an\noutperformance of our method compared to context-based relation extraction\nmodels.\n","authors":["Fréjus A. A. Laleye","Loïc Rakotoson","Sylvain Massip"],"pdf_url":"https://arxiv.org/pdf/2306.04203v1.pdf","comment":"15 pages, 1 figures, The 17th International Conference on Document\n  Analysis and Recognition"},{"id":"http://arxiv.org/abs/2306.04201v1","updated":"2023-06-07T07:15:08Z","published":"2023-06-07T07:15:08Z","title":"Improving Hyperparameter Learning under Approximate Inference in\n  Gaussian Process Models","summary":"  Approximate inference in Gaussian process (GP) models with non-conjugate\nlikelihoods gets entangled with the learning of the model hyperparameters. We\nimprove hyperparameter learning in GP models and focus on the interplay between\nvariational inference (VI) and the learning target. While VI's lower bound to\nthe marginal likelihood is a suitable objective for inferring the approximate\nposterior, we show that a direct approximation of the marginal likelihood as in\nExpectation Propagation (EP) is a better learning objective for hyperparameter\noptimization. We design a hybrid training procedure to bring the best of both\nworlds: it leverages conjugate-computation VI for inference and uses an EP-like\nmarginal likelihood approximation for hyperparameter learning. We compare VI,\nEP, Laplace approximation, and our proposed training procedure and empirically\ndemonstrate the effectiveness of our proposal across a wide range of data sets.\n","authors":["Rui Li","ST John","Arno Solin"],"pdf_url":"https://arxiv.org/pdf/2306.04201v1.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2210.15304v2","updated":"2023-06-07T07:09:58Z","published":"2022-10-27T10:25:51Z","title":"Explaining the Explainers in Graph Neural Networks: a Comparative Study","summary":"  Following a fast initial breakthrough in graph based learning, Graph Neural\nNetworks (GNNs) have reached a widespread application in many science and\nengineering fields, prompting the need for methods to understand their decision\nprocess.\n  GNN explainers have started to emerge in recent years, with a multitude of\nmethods both novel or adapted from other domains. To sort out this plethora of\nalternative approaches, several studies have benchmarked the performance of\ndifferent explainers in terms of various explainability metrics. However, these\nearlier works make no attempts at providing insights into why different GNN\narchitectures are more or less explainable, or which explainer should be\npreferred in a given setting.\n  In this survey, we fill these gaps by devising a systematic experimental\nstudy, which tests ten explainers on eight representative architectures trained\non six carefully designed graph and node classification datasets. With our\nresults we provide key insights on the choice and applicability of GNN\nexplainers, we isolate key components that make them usable and successful and\nprovide recommendations on how to avoid common interpretation pitfalls. We\nconclude by highlighting open questions and directions of possible future\nresearch.\n","authors":["Antonio Longa","Steve Azzolin","Gabriele Santin","Giulia Cencetti","Pietro Liò","Bruno Lepri","Andrea Passerini"],"pdf_url":"https://arxiv.org/pdf/2210.15304v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13225v3","updated":"2023-06-07T07:01:45Z","published":"2022-05-26T08:36:35Z","title":"DevFormer: A Symmetric Transformer for Context-Aware Device Placement","summary":"  In this paper, we present DevFormer, a novel transformer-based architecture\nfor addressing the complex and computationally demanding problem of hardware\ndesign optimization. Despite the demonstrated efficacy of transformers in\ndomains including natural language processing and computer vision, their use in\nhardware design has been limited by the scarcity of offline data. Our approach\naddresses this limitation by introducing strong inductive biases such as\nrelative positional embeddings and action-permutation symmetricity that\neffectively capture the hardware context and enable efficient design\noptimization with limited offline data. We apply DevFoemer to the problem of\ndecoupling capacitor placement and show that it outperforms state-of-the-art\nmethods in both simulated and real hardware, leading to improved performances\nwhile reducing the number of components by more than $30\\%$. Finally, we show\nthat our approach achieves promising results in other offline contextual\nlearning-based combinatorial optimization tasks.\n","authors":["Haeyeon Kim","Minsu Kim","Federico Berto","Joungho Kim","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2205.13225v3.pdf","comment":"International Conference on Machine Learning (ICML) 2023. Extended\n  version of NeurIPS 2022 Offline RL Workshop \"Collaborative symmetricity\n  exploitation for offline learning of hardware design solver\""},{"id":"http://arxiv.org/abs/2306.04190v1","updated":"2023-06-07T06:58:38Z","published":"2023-06-07T06:58:38Z","title":"An ASR-Based Tutor for Learning to Read: How to Optimize Feedback to\n  First Graders","summary":"  The interest in employing automatic speech recognition (ASR) in applications\nfor reading practice has been growing in recent years. In a previous study, we\npresented an ASR-based Dutch reading tutor application that was developed to\nprovide instantaneous feedback to first-graders learning to read. We saw that\nASR has potential at this stage of the reading process, as the results\nsuggested that pupils made progress in reading accuracy and fluency by using\nthe software. In the current study, we used children's speech from an existing\ncorpus (JASMIN) to develop two new ASR systems, and compared the results to\nthose of the previous study. We analyze correct/incorrect classification of the\nASR systems using human transcripts at word level, by means of evaluation\nmeasures such as Cohen's Kappa, Matthews Correlation Coefficient (MCC),\nprecision, recall and F-measures. We observe improvements for the newly\ndeveloped ASR systems regarding the agreement with human-based judgment and\ncorrect rejection (CR). The accuracy of the ASR systems varies for different\nreading tasks and word types. Our results suggest that, in the current\nconfiguration, it is difficult to classify isolated words. We discuss these\nresults, possible ways to improve our systems and avenues for future research.\n","authors":["Yu Bai","Cristian Tejedor-Garcia","Ferdy Hubers","Catia Cucchiarini","Helmer Strik"],"pdf_url":"https://arxiv.org/pdf/2306.04190v1.pdf","comment":"Published (double-blind peer-reviewed) on SPECOM 2021"},{"id":"http://arxiv.org/abs/2212.09567v3","updated":"2023-06-07T06:57:09Z","published":"2022-12-19T15:59:00Z","title":"Answering Complex Logical Queries on Knowledge Graphs via Query\n  Computation Tree Optimization","summary":"  Answering complex logical queries on incomplete knowledge graphs is a\nchallenging task, and has been widely studied. Embedding-based methods require\ntraining on complex queries, and cannot generalize well to out-of-distribution\nquery structures. Recent work frames this task as an end-to-end optimization\nproblem, and it only requires a pretrained link predictor. However, due to the\nexponentially large combinatorial search space, the optimal solution can only\nbe approximated, limiting the final accuracy. In this work, we propose QTO\n(Query Computation Tree Optimization) that can efficiently find the exact\noptimal solution. QTO finds the optimal solution by a forward-backward\npropagation on the tree-like computation graph, i.e., query computation tree.\nIn particular, QTO utilizes the independence encoded in the query computation\ntree to reduce the search space, where only local computations are involved\nduring the optimization procedure. Experiments on 3 datasets show that QTO\nobtains state-of-the-art performance on complex query answering, outperforming\nprevious best results by an average of 22%. Moreover, QTO can interpret the\nintermediate solutions for each of the one-hop atoms in the query with over 90%\naccuracy. The code of our paper is at https://github.com/bys0318/QTO.\n","authors":["Yushi Bai","Xin Lv","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2212.09567v3.pdf","comment":"To appear in ICML 2023"},{"id":"http://arxiv.org/abs/2302.02713v3","updated":"2023-06-07T06:53:51Z","published":"2023-02-06T11:40:44Z","title":"Flat Seeking Bayesian Neural Networks","summary":"  Bayesian Neural Networks (BNNs) provide a probabilistic interpretation for\ndeep learning models by imposing a prior distribution over model parameters and\ninferring a posterior distribution based on observed data. The model sampled\nfrom the posterior distribution can be used for providing ensemble predictions\nand quantifying prediction uncertainty. It is well-known that deep learning\nmodels with lower sharpness have better generalization ability. However,\nexisting posterior inferences are not aware of sharpness/flatness in terms of\nformulation, possibly leading to high sharpness for the models sampled from\nthem. In this paper, we develop theories, the Bayesian setting, and the\nvariational inference approach for the sharpness-aware posterior. Specifically,\nthe models sampled from our sharpness-aware posterior, and the optimal\napproximate posterior estimating this sharpness-aware posterior, have better\nflatness, hence possibly possessing higher generalization ability. We conduct\nexperiments by leveraging the sharpness-aware posterior with state-of-the-art\nBayesian Neural Networks, showing that the flat-seeking counterparts outperform\ntheir baselines in all metrics of interest.\n","authors":["Van-Anh Nguyen","Tung-Long Vuong","Hoang Phan","Thanh-Toan Do","Dinh Phung","Trung Le"],"pdf_url":"https://arxiv.org/pdf/2302.02713v3.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2303.02691v2","updated":"2023-06-07T06:44:28Z","published":"2023-03-05T15:11:14Z","title":"Revisiting Weighted Strategy for Non-stationary Parametric Bandits","summary":"  Non-stationary parametric bandits have attracted much attention recently.\nThere are three principled ways to deal with non-stationarity, including\nsliding-window, weighted, and restart strategies. As many non-stationary\nenvironments exhibit gradual drifting patterns, the weighted strategy is\ncommonly adopted in real-world applications. However, previous theoretical\nstudies show that its analysis is more involved and the algorithms are either\ncomputationally less efficient or statistically suboptimal. This paper revisits\nthe weighted strategy for non-stationary parametric bandits. In linear bandits\n(LB), we discover that this undesirable feature is due to an inadequate regret\nanalysis, which results in an overly complex algorithm design. We propose a\nrefined analysis framework, which simplifies the derivation and importantly\nproduces a simpler weight-based algorithm that is as efficient as\nwindow/restart-based algorithms while retaining the same regret as previous\nstudies. Furthermore, our new framework can be used to improve regret bounds of\nother parametric bandits, including Generalized Linear Bandits (GLB) and\nSelf-Concordant Bandits (SCB). For example, we develop a simple weighted GLB\nalgorithm with an $\\widetilde{O}(k_\\mu^{\\frac{5}{4}} c_\\mu^{-\\frac{3}{4}}\nd^{\\frac{3}{4}} P_T^{\\frac{1}{4}}T^{\\frac{3}{4}})$ regret, improving the\n$\\widetilde{O}(k_\\mu^{2} c_\\mu^{-1}d^{\\frac{9}{10}}\nP_T^{\\frac{1}{5}}T^{\\frac{4}{5}})$ bound in prior work, where $k_\\mu$ and\n$c_\\mu$ characterize the reward model's nonlinearity, $P_T$ measures the\nnon-stationarity, $d$ and $T$ denote the dimension and time horizon.\n","authors":["Jing Wang","Peng Zhao","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.02691v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2306.04186v1","updated":"2023-06-07T06:42:07Z","published":"2023-06-07T06:42:07Z","title":"Self-supervised Audio Teacher-Student Transformer for Both Clip-level\n  and Frame-level Tasks","summary":"  In recent years, self-supervised learning (SSL) has emerged as a popular\napproach for learning audio representations. The ultimate goal of audio\nself-supervised pre-training is to transfer knowledge to downstream audio\ntasks, generally including clip-level and frame-level tasks. Clip-level tasks\nclassify the scene or sound of an entire audio clip, e.g. audio tagging,\ninstrument recognition, etc. While frame-level tasks detect event-level\ntimestamps from an audio clip, e.g. sound event detection, speaker diarization,\netc. Prior studies primarily evaluate on clip-level downstream tasks.\nFrame-level tasks are important for fine-grained acoustic scene/event\nunderstanding, and are generally more challenging than clip-level tasks. In\norder to tackle both clip-level and frame-level tasks, this paper proposes two\nself-supervised audio representation learning methods: ATST-Clip and\nATST-Frame, responsible for learning clip-level and frame-level\nrepresentations, respectively. ATST stands for Audio Teacher-Student\nTransformer, which means both methods use a transformer encoder and a\nteacher-student training scheme.Experimental results show that our ATST-Frame\nmodel obtains state-of-the-art (SOTA) performance on most of the clip-level and\nframe-level downstream tasks. Especially, it outperforms other models by a\nlarge margin on the frame-level sound event detection task. In addition, the\nperformance can be further improved by combining the two models through\nknowledge distillation.\n","authors":["Xian Li","Nian Shao","Xiaofei Li"],"pdf_url":"https://arxiv.org/pdf/2306.04186v1.pdf","comment":"Submitted to IEEE TASLP. arXiv admin note: text overlap with\n  arXiv:2204.12076"},{"id":"http://arxiv.org/abs/2306.04181v1","updated":"2023-06-07T06:29:58Z","published":"2023-06-07T06:29:58Z","title":"Benchmarking Foundation Models with Language-Model-as-an-Examiner","summary":"  Numerous benchmarks have been established to assess the performance of\nfoundation models on open-ended question answering, which serves as a\ncomprehensive test of a model's ability to understand and generate language in\na manner similar to humans. Most of these works focus on proposing new\ndatasets, however, we see two main issues within previous benchmarking\npipelines, namely testing leakage and evaluation automation. In this paper, we\npropose a novel benchmarking framework, Language-Model-as-an-Examiner, where\nthe LM serves as a knowledgeable examiner that formulates questions based on\nits knowledge and evaluates responses in a reference-free manner. Our framework\nallows for effortless extensibility as various LMs can be adopted as the\nexaminer, and the questions can be constantly updated given more diverse\ntrigger topics. For a more comprehensive and equitable evaluation, we devise\nthree strategies: (1) We instruct the LM examiner to generate questions across\na multitude of domains to probe for a broad acquisition, and raise follow-up\nquestions to engage in a more in-depth assessment. (2) Upon evaluation, the\nexaminer combines both scoring and ranking measurements, providing a reliable\nresult as it aligns closely with human annotations. (3) We additionally propose\na decentralized Peer-examination method to address the biases in a single\nexaminer. Our data and benchmarking results are available at:\nhttps://lmexam.com.\n","authors":["Yushi Bai","Jiahao Ying","Yixin Cao","Xin Lv","Yuze He","Xiaozhi Wang","Jifan Yu","Kaisheng Zeng","Yijia Xiao","Haozhe Lyu","Jiayin Zhang","Juanzi Li","Lei Hou"],"pdf_url":"https://arxiv.org/pdf/2306.04181v1.pdf","comment":"23 pages, 8 figures"},{"id":"http://arxiv.org/abs/2304.04027v2","updated":"2023-06-07T06:25:40Z","published":"2023-04-08T14:40:35Z","title":"Estimating 3D Dental Structures using Simulated Panoramic Radiographs\n  and Neural Ray Tracing","summary":"  Panoramic radiography (Panoramic X-ray, PX) is a widely used imaging modality\nfor dental examination. Since PX only provides 2D flattened views of the oral\nstructure, its applicability is limited as compared to 3D Cone-beam computed\ntomography (CBCT). In this paper, we propose a framework to estimate CBCT-like\n3D structures from real-world PX. Our framework tackles full 3D reconstruction\nfor varying subjects (patients) where each reconstruction is based only on a\nsingle panoramic image. We create an intermediate representation called\nsimulated PX (SimPX) from CBCT data which is based both on the Beer-Lambert law\nof X-ray rendering and rotational principles of PX imaging. SimPX aims at not\nonly truthfully simulating PX, but also facilitates the reverting process back\nto 3D data. We propose a novel neural model based on ray tracing which exploits\nboth global and local input features to convert SimPX to 3D output. At\ninference, a real PX image is translated to a SimPX-style image with semantic\nregularization, and the translated image is processed by generation/refinement\nmodules to produce high-quality outputs. Experiments show that our method\noutperforms prior state-of-the-art in reconstruction tasks both quantitatively\nand qualitatively. Our method does not require any prior information such as\nthe shape of dental arches, nor the matched PX-CBCT dataset for training, which\nis difficult to obtain in clinical practice.\n","authors":["Sihwa Park","Seongjun Kim","Doeyoung Kwon","Yohan Jang","In-Seok Song","Seungjun Baek"],"pdf_url":"https://arxiv.org/pdf/2304.04027v2.pdf","comment":"16 pages, 11 figures"},{"id":"http://arxiv.org/abs/2305.18466v2","updated":"2023-06-07T06:21:30Z","published":"2023-05-29T08:03:28Z","title":"Test-Time Training on Nearest Neighbors for Large Language Models","summary":"  Many recent efforts aim to augment language models with relevant information\nretrieved from a database at test time. We avoid the need for prompt\nengineering by directly fine-tuning the model on data retrieved at test time\nusing its standard training setup. For this purpose, we build a large-scale\ndistributed nearest neighbor index based on text embeddings of the Pile\ndataset. Given a query to a language model, our system retrieves the neighbors\nof the query and fine-tunes the model on the text data corresponding to those\nneighbors. Surprisingly, retrieving and training on as few as 20 neighbors,\neach for only one gradient iteration, drastically improves performance across\nmore than twenty language modeling tasks in the Pile benchmark. For example,\ntest-time training significantly narrows the performance gap between a small\nGPT2 model and a GPTNeo model, more than ten times larger, that was\nspecifically trained to convergence on the Pile. Sufficient index quality and\nsize, however, are important. Our work establishes a valuable first baseline\nfor implementing test-time training in the context of large language models,\nopening the door to numerous promising research avenues.\n","authors":["Moritz Hardt","Yu Sun"],"pdf_url":"https://arxiv.org/pdf/2305.18466v2.pdf","comment":"Corrected Figure 8. Code repository here:\n  https://github.com/socialfoundations/tttlm"},{"id":"http://arxiv.org/abs/2306.04178v1","updated":"2023-06-07T06:15:12Z","published":"2023-06-07T06:15:12Z","title":"Optimal Transport Model Distributional Robustness","summary":"  Distributional robustness is a promising framework for training deep learning\nmodels that are less vulnerable to adversarial examples and data distribution\nshifts. Previous works have mainly focused on exploiting distributional\nrobustness in data space. In this work, we explore an optimal transport-based\ndistributional robustness framework on model spaces. Specifically, we examine a\nmodel distribution in a Wasserstein ball of a given center model distribution\nthat maximizes the loss. We have developed theories that allow us to learn the\noptimal robust center model distribution. Interestingly, through our developed\ntheories, we can flexibly incorporate the concept of sharpness awareness into\ntraining a single model, ensemble models, and Bayesian Neural Networks by\nconsidering specific forms of the center model distribution, such as a Dirac\ndelta distribution over a single model, a uniform distribution over several\nmodels, and a general Bayesian Neural Network. Furthermore, we demonstrate that\nsharpness-aware minimization (SAM) is a specific case of our framework when\nusing a Dirac delta distribution over a single model, while our framework can\nbe viewed as a probabilistic extension of SAM. We conduct extensive experiments\nto demonstrate the usefulness of our framework in the aforementioned settings,\nand the results show remarkable improvements in our approaches to the\nbaselines.\n","authors":["Van-Anh Nguyen","Trung Le","Anh Tuan Bui","Thanh-Toan Do","Dinh Phung"],"pdf_url":"https://arxiv.org/pdf/2306.04178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.05089v2","updated":"2023-06-07T06:05:18Z","published":"2023-05-08T23:29:12Z","title":"Functional Equivalence and Path Connectivity of Reducible Hyperbolic\n  Tangent Networks","summary":"  Understanding the learning process of artificial neural networks requires\nclarifying the structure of the parameter space within which learning takes\nplace. A neural network parameter's functional equivalence class is the set of\nparameters implementing the same input--output function. For many\narchitectures, almost all parameters have a simple and well-documented\nfunctional equivalence class. However, there is also a vanishing minority of\nreducible parameters, with richer functional equivalence classes caused by\nredundancies among the network's units.\n  In this paper, we give an algorithmic characterisation of unit redundancies\nand reducible functional equivalence classes for a single-hidden-layer\nhyperbolic tangent architecture. We show that such functional equivalence\nclasses are piecewise-linear path-connected sets, and that for parameters with\na majority of redundant units, the sets have a diameter of at most 7 linear\nsegments.\n","authors":["Matthew Farrugia-Roberts"],"pdf_url":"https://arxiv.org/pdf/2305.05089v2.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.04174v1","updated":"2023-06-07T05:55:45Z","published":"2023-06-07T05:55:45Z","title":"End-to-End Learning for Stochastic Optimization: A Bayesian Perspective","summary":"  We develop a principled approach to end-to-end learning in stochastic\noptimization. First, we show that the standard end-to-end learning algorithm\nadmits a Bayesian interpretation and trains a posterior Bayes action map.\nBuilding on the insights of this analysis, we then propose new end-to-end\nlearning algorithms for training decision maps that output solutions of\nempirical risk minimization and distributionally robust optimization problems,\ntwo dominant modeling paradigms in optimization under uncertainty. Numerical\nresults for a synthetic newsvendor problem illustrate the key differences\nbetween alternative training schemes. We also investigate an economic dispatch\nproblem based on real data to showcase the impact of the neural network\narchitecture of the decision maps on their test performance.\n","authors":["Yves Rychener","Daniel Kuhn Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2306.04174v1.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.04169v1","updated":"2023-06-07T05:38:55Z","published":"2023-06-07T05:38:55Z","title":"Efficient Alternating Minimization with Applications to Weighted Low\n  Rank Approximation","summary":"  Weighted low rank approximation is a fundamental problem in numerical linear\nalgebra, and it has many applications in machine learning. Given a matrix $M\n\\in \\mathbb{R}^{n \\times n}$, a weight matrix $W \\in \\mathbb{R}_{\\geq 0}^{n\n\\times n}$, a parameter $k$, the goal is to output two matrices $U, V \\in\n\\mathbb{R}^{n \\times k}$ such that $\\| W \\circ (M - U V) \\|_F$ is minimized,\nwhere $\\circ$ denotes the Hadamard product. Such a problem is known to be\nNP-hard and even hard to approximate [RSW16]. Meanwhile, alternating\nminimization is a good heuristic solution for approximating weighted low rank\napproximation. The work [LLR16] shows that, under mild assumptions, alternating\nminimization does provide provable guarantees. In this work, we develop an\nefficient and robust framework for alternating minimization. For weighted low\nrank approximation, this improves the runtime of [LLR16] from $n^2 k^2$ to\n$n^2k$. At the heart of our work framework is a high-accuracy multiple response\nregression solver together with a robust analysis of alternating minimization.\n","authors":["Zhao Song","Mingquan Ye","Junze Yin","Lichen Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04169v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.11068"},{"id":"http://arxiv.org/abs/2306.02689v2","updated":"2023-06-07T05:34:34Z","published":"2023-06-05T08:29:55Z","title":"Solving NP-hard Min-max Routing Problems as Sequential Generation with\n  Equity Context","summary":"  Min-max routing problems aim to minimize the maximum tour length among agents\nas they collaboratively visit all cities, i.e., the completion time. These\nproblems include impactful real-world applications but are known as NP-hard.\nExisting methods are facing challenges, particularly in large-scale problems\nthat require the coordination of numerous agents to cover thousands of cities.\nThis paper proposes a new deep-learning framework to solve large-scale min-max\nrouting problems. We model the simultaneous decision-making of multiple agents\nas a sequential generation process, allowing the utilization of scalable\ndeep-learning models for sequential decision-making. In the sequentially\napproximated problem, we propose a scalable contextual Transformer model,\nEquity-Transformer, which generates sequential actions considering an equitable\nworkload among other agents. The effectiveness of Equity-Transformer is\ndemonstrated through its superior performance in two representative min-max\nrouting tasks: the min-max multiple traveling salesman problem (min-max mTSP)\nand the min-max multiple pick-up and delivery problem (min-max mPDP). Notably,\nour method achieves significant reductions of runtime, approximately 335 times,\nand cost values of about 53% compared to a competitive heuristic (LKH3) in the\ncase of 100 vehicles with 1,000 cities of mTSP. We provide reproducible source\ncode: https://github.com/kaist-silab/equity-transformer\n","authors":["Jiwoo Son","Minsu Kim","Sanghyeok Choi","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02689v2.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.02688v2","updated":"2023-06-07T05:30:30Z","published":"2023-06-05T08:28:42Z","title":"Meta-SAGE: Scale Meta-Learning Scheduled Adaptation with Guided\n  Exploration for Mitigating Scale Shift on Combinatorial Optimization","summary":"  This paper proposes Meta-SAGE, a novel approach for improving the scalability\nof deep reinforcement learning models for combinatorial optimization (CO)\ntasks. Our method adapts pre-trained models to larger-scale problems in test\ntime by suggesting two components: a scale meta-learner (SML) and scheduled\nadaptation with guided exploration (SAGE). First, SML transforms the context\nembedding for subsequent adaptation of SAGE based on scale information. Then,\nSAGE adjusts the model parameters dedicated to the context embedding for a\nspecific instance. SAGE introduces locality bias, which encourages selecting\nnearby locations to determine the next location. The locality bias gradually\ndecays as the model is adapted to the target instance. Results show that\nMeta-SAGE outperforms previous adaptation methods and significantly improves\nscalability in representative CO tasks. Our source code is available at\nhttps://github.com/kaist-silab/meta-sage\n","authors":["Jiwoo Son","Minsu Kim","Hyeonah Kim","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.02688v2.pdf","comment":"18 pages, 9 figures, International Conference on Machine Learning\n  (ICML) 2023"},{"id":"http://arxiv.org/abs/2009.02476v3","updated":"2023-06-07T05:28:39Z","published":"2020-09-05T06:32:38Z","title":"Using Machine Teaching to Investigate Human Assumptions when Teaching\n  Reinforcement Learners","summary":"  Successful teaching requires an assumption of how the learner learns - how\nthe learner uses experiences from the world to update their internal states. We\ninvestigate what expectations people have about a learner when they teach them\nin an online manner using rewards and punishment. We focus on a common\nreinforcement learning method, Q-learning, and examine what assumptions people\nhave using a behavioral experiment. To do so, we first establish a normative\nstandard, by formulating the problem as a machine teaching optimization\nproblem. To solve the machine teaching optimization problem, we use a deep\nlearning approximation method which simulates learners in the environment and\nlearns to predict how feedback affects the learner's internal states. What do\npeople assume about a learner's learning and discount rates when they teach\nthem an idealized exploration-exploitation task? In a behavioral experiment, we\nfind that people can teach the task to Q-learners in a relatively efficient and\neffective manner when the learner uses a small value for its discounting rate\nand a large value for its learning rate. However, they still are suboptimal. We\nalso find that providing people with real-time updates of how possible feedback\nwould affect the Q-learner's internal states weakly helps them teach. Our\nresults reveal how people teach using evaluative feedback and provide guidance\nfor how engineers should design machine agents in a manner that is intuitive\nfor people.\n","authors":["Yun-Shiuan Chuang","Xuezhou Zhang","Yuzhe Ma","Mark K. Ho","Joseph L. Austerweil","Xiaojin Zhu"],"pdf_url":"https://arxiv.org/pdf/2009.02476v3.pdf","comment":"21 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.11249v3","updated":"2023-06-07T05:20:40Z","published":"2023-03-20T16:34:39Z","title":"What Makes Data Suitable for a Locally Connected Neural Network? A\n  Necessary and Sufficient Condition Based on Quantum Entanglement","summary":"  The question of what makes a data distribution suitable for deep learning is\na fundamental open problem. Focusing on locally connected neural networks (a\nprevalent family of architectures that includes convolutional and recurrent\nneural networks as well as local self-attention models), we address this\nproblem by adopting theoretical tools from quantum physics. Our main\ntheoretical result states that a certain locally connected neural network is\ncapable of accurate prediction over a data distribution if and only if the data\ndistribution admits low quantum entanglement under certain canonical partitions\nof features. As a practical application of this result, we derive a\npreprocessing method for enhancing the suitability of a data distribution to\nlocally connected neural networks. Experiments with widespread models over\nvarious datasets demonstrate our findings. We hope that our use of quantum\nentanglement will encourage further adoption of tools from physics for formally\nreasoning about the relation between deep learning and real-world data.\n","authors":["Yotam Alexander","Nimrod De La Vega","Noam Razin","Nadav Cohen"],"pdf_url":"https://arxiv.org/pdf/2303.11249v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17341v2","updated":"2023-06-07T05:19:18Z","published":"2023-05-27T02:51:20Z","title":"Improved Privacy-Preserving PCA Using Space-optimized Homomorphic Matrix\n  Multiplication","summary":"  Principal Component Analysis (PCA) is a pivotal technique in the fields of\nmachine learning and data analysis. It aims to reduce the dimensionality of a\ndataset while minimizing the loss of information. In recent years, there have\nbeen endeavors to utilize homomorphic encryption in privacy-preserving PCA\nalgorithms. These approaches commonly employ a PCA routine known as\nPowerMethod, which takes the covariance matrix as input and generates an\napproximate eigenvector corresponding to the primary component of the dataset.\nHowever, their performance and accuracy are constrained by the incapability of\nhomomorphic covariance matrix computation and the absence of a universal vector\nnormalization strategy for the PowerMethod algorithm. In this study, we propose\na novel approach to privacy-preserving PCA that addresses these limitations,\nresulting in superior efficiency, accuracy, and scalability compared to\nprevious approaches. We attain such efficiency and precision through the\nfollowing contributions: (i) We implement space optimization techniques for a\nhomomorphic matrix multiplication method (Jiang et al., SIGSAC 2018), making it\nless prone to memory saturation in parallel computation scenarios. (ii)\nLeveraging the benefits of this optimized matrix multiplication, we devise an\nefficient homomorphic circuit for computing the covariance matrix\nhomomorphically. (iii) Utilizing the covariance matrix, we develop a novel and\nefficient homomorphic circuit for the PowerMethod that incorporates a universal\nhomomorphic vector normalization strategy to enhance both its accuracy and\npracticality.\n","authors":["Xirong Ma"],"pdf_url":"https://arxiv.org/pdf/2305.17341v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04160v1","updated":"2023-06-07T05:18:27Z","published":"2023-06-07T05:18:27Z","title":"Rethinking Weak Supervision in Helping Contrastive Learning","summary":"  Contrastive learning has shown outstanding performances in both supervised\nand unsupervised learning, and has recently been introduced to solve weakly\nsupervised learning problems such as semi-supervised learning and noisy label\nlearning. Despite the empirical evidence showing that semi-supervised labels\nimprove the representations of contrastive learning, it remains unknown if\nnoisy supervised information can be directly used in training instead of after\nmanual denoising. Therefore, to explore the mechanical differences between\nsemi-supervised and noisy-labeled information in helping contrastive learning,\nwe establish a unified theoretical framework of contrastive learning under weak\nsupervision. Specifically, we investigate the most intuitive paradigm of\njointly training supervised and unsupervised contrastive losses. By translating\nthe weakly supervised information into a similarity graph under the framework\nof spectral clustering based on the posterior probability of weak labels, we\nestablish the downstream classification error bound. We prove that\nsemi-supervised labels improve the downstream error bound whereas noisy labels\nhave limited effects under such a paradigm. Our theoretical findings here\nprovide new insights for the community to rethink the role of weak supervision\nin helping contrastive learning.\n","authors":["Jingyi Cui","Weiran Huang","Yifei Wang","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2306.04160v1.pdf","comment":"Accepted to ICML2023"},{"id":"http://arxiv.org/abs/2212.02457v2","updated":"2023-06-07T05:00:40Z","published":"2022-12-05T18:00:31Z","title":"Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics,\n  Directional Convergence, and Equilibria","summary":"  Covariate distribution shifts and adversarial perturbations present\nrobustness challenges to the conventional statistical learning framework: mild\nshifts in the test covariate distribution can significantly affect the\nperformance of the statistical model learned based on the training\ndistribution. The model performance typically deteriorates when extrapolation\nhappens: namely, covariates shift to a region where the training distribution\nis scarce, and naturally, the learned model has little information. For\nrobustness and regularization considerations, adversarial perturbation\ntechniques are proposed as a remedy; however, careful study needs to be carried\nout about what extrapolation region adversarial covariate shift will focus on,\ngiven a learned model. This paper precisely characterizes the extrapolation\nregion, examining both regression and classification in an infinite-dimensional\nsetting. We study the implications of adversarial covariate shifts to\nsubsequent learning of the equilibrium -- the Bayes optimal model -- in a\nsequential game framework. We exploit the dynamics of the adversarial learning\ngame and reveal the curious effects of the covariate shift to equilibrium\nlearning and experimental design. In particular, we establish two directional\nconvergence results that exhibit distinctive phenomena: (1) a blessing in\nregression, the adversarial covariate shifts in an exponential rate to an\noptimal experimental design for rapid subsequent learning, (2) a curse in\nclassification, the adversarial covariate shifts in a subquadratic rate fast to\nthe hardest experimental design trapping subsequent learning.\n","authors":["Tengyuan Liang"],"pdf_url":"https://arxiv.org/pdf/2212.02457v2.pdf","comment":"22 pages, 2 figures"}]},"2023-06-08T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.05425v1","updated":"2023-06-08T17:59:56Z","published":"2023-06-08T17:59:56Z","title":"MIMIC-IT: Multi-Modal In-Context Instruction Tuning","summary":"  High-quality instructions and responses are essential for the zero-shot\nperformance of large language models on interactive natural language tasks. For\ninteractive vision-language tasks involving intricate visual scenes, a large\nquantity of diverse and creative instruction-response pairs should be\nimperative to tune vision-language models (VLMs). Nevertheless, the current\navailability of vision-language instruction-response pairs in terms of\nquantity, diversity, and creativity remains limited, posing challenges to the\ngeneralization of interactive VLMs. Here we present MultI-Modal In-Context\nInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal\ninstruction-response pairs, with 2.2 million unique instructions derived from\nimages and videos. Each pair is accompanied by multi-modal in-context\ninformation, forming conversational contexts aimed at empowering VLMs in\nperception, reasoning, and planning. The instruction-response collection\nprocess, dubbed as Syphus, is scaled using an automatic annotation pipeline\nthat combines human expertise with GPT's capabilities. Using the MIMIC-IT\ndataset, we train a large VLM named Otter. Based on extensive evaluations\nconducted on vision-language benchmarks, it has been observed that Otter\ndemonstrates remarkable proficiency in multi-modal perception, reasoning, and\nin-context learning. Human evaluation reveals it effectively aligns with the\nuser's intentions. We release the MIMIC-IT dataset, instruction-response\ncollection pipeline, benchmarks, and the Otter model.\n","authors":["Bo Li","Yuanhan Zhang","Liangyu Chen","Jinghao Wang","Fanyi Pu","Jingkang Yang","Chunyuan Li","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2306.05425v1.pdf","comment":"Project page: https://otter-ntu.github.io/ Dataset & code:\n  https://github.com/Luodian/otter Initial release, work in progress"},{"id":"http://arxiv.org/abs/2306.05406v1","updated":"2023-06-08T17:54:36Z","published":"2023-06-08T17:54:36Z","title":"Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to\n  Pre-trained Language Models Memories","summary":"  Pre-trained language models (PLMs) demonstrate excellent abilities to\nunderstand texts in the generic domain while struggling in a specific domain.\nAlthough continued pre-training on a large domain-specific corpus is effective,\nit is costly to tune all the parameters on the domain. In this paper, we\ninvestigate whether we can adapt PLMs both effectively and efficiently by only\ntuning a few parameters. Specifically, we decouple the feed-forward networks\n(FFNs) of the Transformer architecture into two parts: the original pre-trained\nFFNs to maintain the old-domain knowledge and our novel domain-specific\nadapters to inject domain-specific knowledge in parallel. Then we adopt a\nmixture-of-adapters gate to fuse the knowledge from different domain adapters\ndynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a\ntwo-stage adapter-tuning strategy that leverages both unlabeled data and\nlabeled data to help the domain adaptation: i) domain-specific adapter on\nunlabeled data; followed by ii) the task-specific adapter on labeled data.\nMixDA can be seamlessly plugged into the pretraining-finetuning paradigm and\nour experiments demonstrate that MixDA achieves superior performance on\nin-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and\nknowledge-intensive tasks (KILT). Further analyses demonstrate the reliability,\nscalability, and efficiency of our method. The code is available at\nhttps://github.com/Amano-Aki/Mixture-of-Domain-Adapters.\n","authors":["Shizhe Diao","Tianyang Xu","Ruijia Xu","Jiawei Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05406v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.05392v1","updated":"2023-06-08T17:45:14Z","published":"2023-06-08T17:45:14Z","title":"Modular Visual Question Answering via Code Generation","summary":"  We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.\n","authors":["Sanjay Subramanian","Medhini Narasimhan","Kushal Khangaonkar","Kevin Yang","Arsha Nagrani","Cordelia Schmid","Andy Zeng","Trevor Darrell","Dan Klein"],"pdf_url":"https://arxiv.org/pdf/2306.05392v1.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.05387v1","updated":"2023-06-08T17:38:14Z","published":"2023-06-08T17:38:14Z","title":"Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across\n  Age","summary":"  Emerging psychopathology studies are showing that patterns of changes in\nemotional state -- emotion dynamics -- are associated with overall well-being\nand mental health. More recently, there has been some work in tracking emotion\ndynamics through one's utterances, allowing for data to be collected on a\nlarger scale across time and people. However, several questions about how\nemotion dynamics change with age, especially in children, and when determined\nthrough children's writing, remain unanswered. In this work, we use both a\nlexicon and a machine learning based approach to quantify characteristics of\nemotion dynamics determined from poems written by children of various ages. We\nshow that both approaches point to similar trends: consistent increasing\nintensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and\ndominance) with age and a consistent decreasing valence with age. We also find\nincreasing emotional variability, rise rates (i.e., emotional reactivity), and\nrecovery rates (i.e., emotional regulation) with age. These results act as a\nuseful baselines for further research in how patterns of emotions expressed by\nchildren change with age, and their association with mental health.\n","authors":["Daniela Teodorescu","Alona Fyshe","Saif M. Mohammad"],"pdf_url":"https://arxiv.org/pdf/2306.05387v1.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2212.10029v3","updated":"2023-06-08T17:27:44Z","published":"2022-12-20T06:54:04Z","title":"Do language models have coherent mental models of everyday things?","summary":"  When people think of everyday things like an egg, they typically have a\nmental image associated with it. This allows them to correctly judge, for\nexample, that \"the yolk surrounds the shell\" is a false statement. Do language\nmodels similarly have a coherent picture of such everyday things? To\ninvestigate this, we propose a benchmark dataset consisting of 100 everyday\nthings, their parts, and the relationships between these parts, expressed as\n11,720 \"X relation Y?\" true/false questions. Using these questions as probes,\nwe observe that state-of-the-art pre-trained language models (LMs) like GPT-3\nand Macaw have fragments of knowledge about these everyday things, but do not\nhave fully coherent \"parts mental models\" (54-59% accurate, 19-43% conditional\nconstraint violation). We propose an extension where we add a constraint\nsatisfaction layer on top of the LM's raw predictions to apply commonsense\nconstraints. As well as removing inconsistencies, we find that this also\nsignificantly improves accuracy (by 16-20%), suggesting how the incoherence of\nthe LM's pictures of everyday things can be significantly reduced.\n","authors":["Yuling Gu","Bhavana Dalvi Mishra","Peter Clark"],"pdf_url":"https://arxiv.org/pdf/2212.10029v3.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.05360v1","updated":"2023-06-08T17:05:38Z","published":"2023-06-08T17:05:38Z","title":"The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues","summary":"  This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.\n","authors":["Adaeze Adigwe","Zheng Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.05360v1.pdf","comment":"Accepted in the BEA workshop at ACL 2023"},{"id":"http://arxiv.org/abs/2305.14825v2","updated":"2023-06-08T16:38:51Z","published":"2023-05-24T07:33:34Z","title":"Large Language Models are In-Context Semantic Reasoners rather than\n  Symbolic Reasoners","summary":"  The emergent few-shot reasoning capabilities of Large Language Models (LLMs)\nhave excited the natural language and machine learning community over recent\nyears. Despite of numerous successful applications, the underlying mechanism of\nsuch in-context capabilities still remains unclear. In this work, we\nhypothesize that the learned \\textit{semantics} of language tokens do the most\nheavy lifting during the reasoning process. Different from human's symbolic\nreasoning process, the semantic representations of LLMs could create strong\nconnections among tokens, thus composing a superficial logical chain. To test\nour hypothesis, we decouple semantics from the language reasoning process and\nevaluate three kinds of reasoning abilities, i.e., deduction, induction and\nabduction. Our findings reveal that semantics play a vital role in LLMs'\nin-context reasoning -- LLMs perform significantly better when semantics are\nconsistent with commonsense but struggle to solve symbolic or\ncounter-commonsense reasoning tasks by leveraging in-context new knowledge. The\nsurprising observations question whether modern LLMs have mastered the\ninductive, deductive and abductive reasoning abilities as in human\nintelligence, and motivate research on unveiling the magic existing within the\nblack-box LLMs. On the whole, our analysis provides a novel perspective on the\nrole of semantics in developing and evaluating language models' reasoning\nabilities. Code is available at {\\url{https://github.com/XiaojuanTang/ICSR}}.\n","authors":["Xiaojuan Tang","Zilong Zheng","Jiaqi Li","Fanxu Meng","Song-Chun Zhu","Yitao Liang","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.14825v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05323v1","updated":"2023-06-08T16:15:46Z","published":"2023-06-08T16:15:46Z","title":"Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application","summary":"  The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.\n","authors":["Claudio Crema","Tommaso Mario Buonocore","Silvia Fostinelli","Enea Parimbelli","Federico Verde","Cira Fundarò","Marina Manera","Matteo Cotta Ramusino","Marco Capelli","Alfredo Costa","Giuliano Binetti","Riccardo Bellazzi","Alberto Redolfi"],"pdf_url":"https://arxiv.org/pdf/2306.05323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05320v1","updated":"2023-06-08T16:13:20Z","published":"2023-06-08T16:13:20Z","title":"KIT's Multilingual Speech Translation System for IWSLT 2023","summary":"  Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which focuses on the translation of\nscientific conference talks. The test condition features accented input speech\nand terminology-dense contents. The tasks requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.\n","authors":["Danni Liu","Thai Binh Nguyen","Sai Koneru","Enes Yavuz Ugan","Ngoc-Quan Pham","Tuan-Nam Nguyen","Tu Anh Dinh","Carlos Mullov","Alexander Waibel","Jan Niehues"],"pdf_url":"https://arxiv.org/pdf/2306.05320v1.pdf","comment":"IWSLT 2023"},{"id":"http://arxiv.org/abs/2306.05317v1","updated":"2023-06-08T16:08:10Z","published":"2023-06-08T16:08:10Z","title":"CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models","summary":"  In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.\n","authors":["Potsawee Manakul","Yassir Fathullah","Adian Liusie","Vyas Raina","Vatsal Raina","Mark Gales"],"pdf_url":"https://arxiv.org/pdf/2306.05317v1.pdf","comment":"BioNLP Workshop @ ACL 2023"},{"id":"http://arxiv.org/abs/2306.05307v1","updated":"2023-06-08T15:56:57Z","published":"2023-06-08T15:56:57Z","title":"Are fairness metric scores enough to assess discrimination biases in\n  machine learning?","summary":"  This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.\n","authors":["Fanny Jourdan","Laurent Risser","Jean-Michel Loubes","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2306.05307v1.pdf","comment":"Accepted for publication at Third Workshop on Trustworthy Natural\n  Language Processing, ACL 2023"},{"id":"http://arxiv.org/abs/2306.05301v1","updated":"2023-06-08T15:46:32Z","published":"2023-06-08T15:46:32Z","title":"ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases","summary":"  Enabling large language models to effectively utilize real-world tools is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have primarily relied on either extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nhave utilized supervised learning to train limited types of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without specific tool-specific training.\nTo address this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a tool-use corpus and learn generalized\ntool-use abilities on compact language models with minimal human intervention.\nSpecifically, ToolAlpaca first collects a comprehensive dataset by building a\nmulti-agent simulation environment, which contains 3938 tool-use instances from\nmore than 400 real-world tool APIs spanning 50 distinct categories.\nSubsequently, the constructed corpus is employed to fine-tune compact language\nmodels, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B,\nrespectively. Finally, we evaluate the ability of these models to utilize\npreviously unseen tools without specific training. Experimental results\ndemonstrate that ToolAlpaca achieves effective generalized tool-use\ncapabilities comparable to those of extremely large language models like\nGPT-3.5. This validation supports the notion that learning generalized tool-use\nabilities is feasible for compact language models.\n","authors":["Qiaoyu Tang","Ziliang Deng","Hongyu Lin","Xianpei Han","Qiao Liang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2306.05301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06379v2","updated":"2023-06-08T15:42:13Z","published":"2022-10-12T16:31:39Z","title":"One does not fit all! On the Complementarity of Vision Encoders for\n  Vision and Language Tasks","summary":"  Current multimodal models, aimed at solving Vision and Language (V+L) tasks,\npredominantly repurpose Vision Encoders (VE) as feature extractors. While many\nVEs -- of different architectures, trained on different data and objectives --\nare publicly available, they are not designed for the downstream V+L tasks.\nNonetheless, most current work assumes that a \\textit{single} pre-trained VE\ncan serve as a general-purpose encoder. In this work, we focus on analysis and\naim to understand whether the information stored within different VEs is\ncomplementary, i.e. if providing the model with features from multiple VEs can\nimprove the performance on a target task, and how they are combined. We\nexhaustively experiment with three popular VEs on six downstream V+L tasks and\nanalyze the attention and VE-dropout patterns. Our analyses suggest that\ndiverse VEs complement each other, resulting in improved downstream V+L task\nperformance, where the improvements are not due to simple ensemble effects\n(i.e. the performance does not always improve when increasing the number of\nencoders). We demonstrate that future VEs, which are not \\textit{repurposed},\nbut explicitly \\textit{designed} for V+L tasks, have the potential of improving\nperformance on the target V+L tasks.\n","authors":["Gregor Geigle","Chen Cecilia Liu","Jonas Pfeiffer","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2210.06379v2.pdf","comment":"Repl4NLP 2023"},{"id":"http://arxiv.org/abs/2306.05278v1","updated":"2023-06-08T15:26:52Z","published":"2023-06-08T15:26:52Z","title":"Revisit Few-shot Intent Classification with PLMs: Direct Fine-tuning vs.\n  Continual Pre-training","summary":"  We consider the task of few-shot intent detection, which involves training a\ndeep learning model to classify utterances based on their underlying intents\nusing only a small amount of labeled data. The current approach to address this\nproblem is through continual pre-training, i.e., fine-tuning pre-trained\nlanguage models (PLMs) on external resources (e.g., conversational corpora,\npublic intent detection datasets, or natural language understanding datasets)\nbefore using them as utterance encoders for training an intent classifier. In\nthis paper, we show that continual pre-training may not be essential, since the\noverfitting problem of PLMs on this task may not be as serious as expected.\nSpecifically, we find that directly fine-tuning PLMs on only a handful of\nlabeled examples already yields decent results compared to methods that employ\ncontinual pre-training, and the performance gap diminishes rapidly as the\nnumber of labeled data increases. To maximize the utilization of the limited\navailable data, we propose a context augmentation method and leverage\nsequential self-distillation to boost performance. Comprehensive experiments on\nreal-world benchmarks show that given only two or more labeled samples per\nclass, direct fine-tuning outperforms many strong baselines that utilize\nexternal data sources for continual pre-training. The code can be found at\nhttps://github.com/hdzhang-code/DFTPlus.\n","authors":["Haode Zhang","Haowen Liang","Liming Zhan","Xiao-Ming Wu","Albert Y. S. Lam"],"pdf_url":"https://arxiv.org/pdf/2306.05278v1.pdf","comment":"ACL 2023, Findings"},{"id":"http://arxiv.org/abs/2306.05276v1","updated":"2023-06-08T15:25:24Z","published":"2023-06-08T15:25:24Z","title":"Extensive Evaluation of Transformer-based Architectures for Adverse Drug\n  Events Extraction","summary":"  Adverse Event (ADE) extraction is one of the core tasks in digital\npharmacovigilance, especially when applied to informal texts. This task has\nbeen addressed by the Natural Language Processing community using large\npre-trained language models, such as BERT. Despite the great number of\nTransformer-based architectures used in the literature, it is unclear which of\nthem has better performances and why. Therefore, in this paper we perform an\nextensive evaluation and analysis of 19 Transformer-based models for ADE\nextraction on informal texts. We compare the performance of all the considered\nmodels on two datasets with increasing levels of informality (forums posts and\ntweets). We also combine the purely Transformer-based models with two\ncommonly-used additional processing layers (CRF and LSTM), and analyze their\neffect on the models performance. Furthermore, we use a well-established\nfeature importance technique (SHAP) to correlate the performance of the models\nwith a set of features that describe them: model category (AutoEncoding,\nAutoRegressive, Text-to-Text), pretraining domain, training from scratch, and\nmodel size in number of parameters. At the end of our analyses, we identify a\nlist of take-home messages that can be derived from the experimental data.\n","authors":["Simone Scaboro","Beatrice Portellia","Emmanuele Chersoni","Enrico Santus","Giuseppe Serra"],"pdf_url":"https://arxiv.org/pdf/2306.05276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05270v1","updated":"2023-06-08T15:19:57Z","published":"2023-06-08T15:19:57Z","title":"Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on\n  Summarizing Patients' Active Diagnoses and Problems from Electronic Health\n  Record Progress Notes","summary":"  The BioNLP Workshop 2023 initiated the launch of a shared task on Problem\nList Summarization (ProbSum) in January 2023. The aim of this shared task is to\nattract future research efforts in building NLP models for real-world\ndiagnostic decision support applications, where a system generating relevant\nand accurate diagnoses will augment the healthcare providers decision-making\nprocess and improve the quality of care for patients. The goal for participants\nis to develop models that generated a list of diagnoses and problems using\ninput from the daily care notes collected from the hospitalization of\ncritically ill patients. Eight teams submitted their final systems to the\nshared task leaderboard. In this paper, we describe the tasks, datasets,\nevaluation metrics, and baseline systems. Additionally, the techniques and\nresults of the evaluation of the different approaches tried by the\nparticipating teams are summarized.\n","authors":["Yanjun Gao","Dmitriy Dligach","Timothy Miller","Matthew M. Churpek","Majid Afshar"],"pdf_url":"https://arxiv.org/pdf/2306.05270v1.pdf","comment":"To appear in the Proceedings of the 5th BioNLP Workshop at ACL"},{"id":"http://arxiv.org/abs/2306.05268v1","updated":"2023-06-08T15:17:04Z","published":"2023-06-08T15:17:04Z","title":"Factorized Contrastive Learning: Going Beyond Multi-view Redundancy","summary":"  In a wide range of multimodal tasks, contrastive learning has become a\nparticularly appealing approach since it can successfully learn representations\nfrom abundant unlabeled data with only pairing information (e.g., image-caption\nor video-audio pairs). Underpinning these approaches is the assumption of\nmulti-view redundancy - that shared information between modalities is necessary\nand sufficient for downstream tasks. However, in many real-world settings,\ntask-relevant information is also contained in modality-unique regions:\ninformation that is only present in one modality but still relevant to the\ntask. How can we learn self-supervised multimodal representations to capture\nboth shared and unique information relevant to downstream tasks? This paper\nproposes FactorCL, a new multimodal representation learning method to go beyond\nmulti-view redundancy. FactorCL is built from three new contributions: (1)\nfactorizing task-relevant information into shared and unique representations,\n(2) capturing task-relevant information via maximizing MI lower bounds and\nremoving task-irrelevant information via minimizing MI upper bounds, and (3)\nmultimodal data augmentations to approximate task relevance without labels. On\nlarge-scale real-world datasets, FactorCL captures both shared and unique\ninformation and achieves state-of-the-art results on six benchmarks.\n","authors":["Paul Pu Liang","Zihao Deng","Martin Ma","James Zou","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2306.05268v1.pdf","comment":"Code available at: https://github.com/pliang279/FactorCL"},{"id":"http://arxiv.org/abs/2305.07895v3","updated":"2023-06-08T15:14:16Z","published":"2023-05-13T11:28:37Z","title":"On the Hidden Mystery of OCR in Large Multimodal Models","summary":"  Large models have recently played a dominant role in natural language\nprocessing and multimodal vision-language learning. It remains less explored\nabout their efficacy in text-related visual tasks. We conducted a comprehensive\nstudy of existing publicly available multimodal models, evaluating their\nperformance in text recognition (document text, artistic text, handwritten\ntext, scene text), text-based visual question answering (document text, scene\ntext, and bilingual text), key information extraction (receipts, documents, and\nnutrition facts) and handwritten mathematical expression recognition. Our\nfindings reveal strengths and weaknesses in these models, which primarily rely\non semantic understanding for word recognition and exhibit inferior perception\nof individual character shapes. They also display indifference towards text\nlength and have limited capabilities in detecting finegrained features in\nimages. Consequently, these results demonstrate that even the current most\npowerful large multimodal models cannot match domain-specific methods in\ntraditional text tasks and face greater challenges in more complex tasks. Most\nimportantly, the baseline results showcased in this study could provide a\nfoundational framework for the conception and assessment of innovative\nstrategies targeted at enhancing zero-shot multimodal techniques. Evaluation\npipeline is available at https://github.com/Yuliang-Liu/MultimodalOCR.\n","authors":["Yuliang Liu","Zhang Li","Hongliang Li","Wenwen Yu","Mingxin Huang","Dezhi Peng","Mingyu Liu","Mingrui Chen","Chunyuan Li","Cheng-lin Liu","Lianwen Jin","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2305.07895v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19928v3","updated":"2023-06-08T14:52:06Z","published":"2023-05-31T15:05:25Z","title":"Supplementary Features of BiLSTM for Enhanced Sequence Labeling","summary":"  Sequence labeling tasks require the computation of sentence representations\nfor each word within a given sentence. With the rise of advanced pretrained\nlanguage models; one common approach involves incorporating a BiLSTM layer to\nenhance the sequence structure information at the output level. Nevertheless,\nit has been empirically demonstrated (P.-H. Li, 2020) that BiLSTM's potential\nfor generating sentence representations for sequence labeling tasks is\nconstrained, primarily due to the integration of fragments from past and future\nsentence representations to form a complete sentence representation. In this\nstudy, we observed that the entire sentence representation, found in both the\nfirst and last cells of BiLSTM, can supplement each cell's sentence\nrepresentation. Accordingly, we devised a global context mechanism to integrate\nentire future and past sentence representations into each cell's sentence\nrepresentation within BiLSTM, leading to a significant improvement in both F1\nscore and accuracy. By embedding the BERT model within BiLSTM as a\ndemonstration, and conducting exhaustive experiments on nine datasets for\nsequence labeling tasks, including named entity recognition (NER), part of\nspeech (POS) tagging and End-to-End Aspect-Based sentiment analysis (E2E-ABSA).\nWe noted significant improvements in F1 scores and accuracy across all examined\ndatasets.\n","authors":["Conglei Xu","Kun Shen","Hongguang Sun"],"pdf_url":"https://arxiv.org/pdf/2305.19928v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05240v1","updated":"2023-06-08T14:39:24Z","published":"2023-06-08T14:39:24Z","title":"Dealing with Semantic Underspecification in Multimodal NLP","summary":"  Intelligent systems that aim at mastering language as humans do must deal\nwith its semantic underspecification, namely, the possibility for a linguistic\nsignal to convey only part of the information needed for communication to\nsucceed. Consider the usages of the pronoun they, which can leave the gender\nand number of its referent(s) underspecified. Semantic underspecification is\nnot a bug but a crucial language feature that boosts its storage and processing\nefficiency. Indeed, human speakers can quickly and effortlessly integrate\nsemantically-underspecified linguistic signals with a wide range of\nnon-linguistic information, e.g., the multimodal context, social or cultural\nconventions, and shared knowledge. Standard NLP models have, in principle, no\nor limited access to such extra information, while multimodal systems grounding\nlanguage into other modalities, such as vision, are naturally equipped to\naccount for this phenomenon. However, we show that they struggle with it, which\ncould negatively affect their performance and lead to harmful consequences when\nused for applications. In this position paper, we argue that our community\nshould be aware of semantic underspecification if it aims to develop language\ntechnology that can successfully interact with human users. We discuss some\napplications where mastering it is crucial and outline a few directions toward\nachieving this goal.\n","authors":["Sandro Pezzelle"],"pdf_url":"https://arxiv.org/pdf/2306.05240v1.pdf","comment":"To appear in the Proceedings of ACL 2023 (main conference). 13 pages,\n  3 figures"},{"id":"http://arxiv.org/abs/2305.07224v2","updated":"2023-06-08T13:57:46Z","published":"2023-05-12T03:31:24Z","title":"Asymmetric feature interaction for interpreting model predictions","summary":"  In natural language processing (NLP), deep neural networks (DNNs) could model\ncomplex interactions between context and have achieved impressive results on a\nrange of NLP tasks. Prior works on feature interaction attribution mainly focus\non studying symmetric interaction that only explains the additional influence\nof a set of words in combination, which fails to capture asymmetric influence\nthat contributes to model prediction. In this work, we propose an asymmetric\nfeature interaction attribution explanation model that aims to explore\nasymmetric higher-order feature interactions in the inference of deep neural\nNLP models. By representing our explanation with an directed interaction graph,\nwe experimentally demonstrate interpretability of the graph to discover\nasymmetric feature interactions. Experimental results on two sentiment\nclassification datasets show the superiority of our model against the\nstate-of-the-art feature interaction attribution methods in identifying\ninfluential features for model predictions. Our code is available at\nhttps://github.com/StillLu/ASIV.\n","authors":["Xiaolei Lu","Jianghong Ma","Haode Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.07224v2.pdf","comment":"Accepted by Findings of the Association for Computational\n  Linguistics: ACL 2023 (long paper)"},{"id":"http://arxiv.org/abs/2306.04387v2","updated":"2023-06-08T13:44:24Z","published":"2023-06-07T12:35:37Z","title":"M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual\n  Instruction Tuning","summary":"  Instruction tuning has significantly advanced large language models (LLMs)\nsuch as ChatGPT, enabling them to align with human instructions across diverse\ntasks. However, progress in open vision-language models (VLMs) has been limited\ndue to the scarcity of high-quality instruction datasets. To tackle this\nchallenge and promote research in the vision-language field, we introduce the\nMulti-Modal, Multilingual Instruction Tuning (M$^3$IT) dataset, designed to\noptimize VLM alignment with human instructions. Our M$^3$IT dataset comprises\n40 carefully curated datasets, including 2.4 million instances and 400 manually\nwritten task instructions, reformatted into a vision-to-text structure. Key\ntasks are translated into 80 languages with an advanced translation system,\nensuring broader accessibility. M$^3$IT surpasses previous datasets regarding\ntask coverage, instruction number and instance scale. Moreover, we develop\nYing-VLM, a VLM model trained on our M$^3$IT dataset, showcasing its potential\nto answer complex questions requiring world knowledge, generalize to unseen\nvideo tasks, and comprehend unseen instructions in Chinese. We have\nopen-sourced the dataset to encourage further research.\n","authors":["Lei Li","Yuwei Yin","Shicheng Li","Liang Chen","Peiyi Wang","Shuhuai Ren","Mukai Li","Yazheng Yang","Jingjing Xu","Xu Sun","Lingpeng Kong","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2306.04387v2.pdf","comment":"Fix dataset url: https://huggingface.co/datasets/MMInstruction/M3IT\n  Project: https://m3-it.github.io/"},{"id":"http://arxiv.org/abs/2301.06735v3","updated":"2023-06-08T13:29:38Z","published":"2023-01-17T07:29:26Z","title":"Two Stage Contextual Word Filtering for Context bias in Unified\n  Streaming and Non-streaming Transducer","summary":"  It is difficult for an E2E ASR system to recognize words such as entities\nappearing infrequently in the training data. A widely used method to mitigate\nthis issue is feeding contextual information into the acoustic model. Previous\nworks have proven that a compact and accurate contextual list can boost the\nperformance significantly. In this paper, we propose an efficient approach to\nobtain a high quality contextual list for a unified streaming/non-streaming\nbased E2E model. Specifically, we make use of the phone-level streaming output\nto first filter the predefined contextual word list then fuse it into\nnon-casual encoder and decoder to generate the final recognition results. Our\napproach improve the accuracy of the contextual ASR system and speed up the\ninference process. Experiments on two datasets demonstrates over 20% CER\nreduction comparing to the baseline system. Meanwhile, the RTF of our system\ncan be stabilized within 0.15 when the size of the contextual word list grows\nover 6,000.\n","authors":["Zhanheng Yang","Sining Sun","Xiong Wang","Yike Zhang","Long Ma","Lei Xie"],"pdf_url":"https://arxiv.org/pdf/2301.06735v3.pdf","comment":"accepted by interspeech 2023"},{"id":"http://arxiv.org/abs/2306.05183v1","updated":"2023-06-08T13:28:48Z","published":"2023-06-08T13:28:48Z","title":"Improving Long Context Document-Level Machine Translation","summary":"  Document-level context for neural machine translation (NMT) is crucial to\nimprove the translation consistency and cohesion, the translation of ambiguous\ninputs, as well as several other linguistic phenomena. Many works have been\npublished on the topic of document-level NMT, but most restrict the system to\nonly local context, typically including just the one or two preceding sentences\nas additional information. This might be enough to resolve some ambiguous\ninputs, but it is probably not sufficient to capture some document-level\ninformation like the topic or style of a conversation. When increasing the\ncontext size beyond just the local context, there are two challenges: (i)\nthe~memory usage increases exponentially (ii) the translation performance\nstarts to degrade. We argue that the widely-used attention mechanism is\nresponsible for both issues. Therefore, we propose a constrained attention\nvariant that focuses the attention on the most relevant parts of the sequence,\nwhile simultaneously reducing the memory consumption. For evaluation, we\nutilize targeted test sets in combination with novel evaluation techniques to\nanalyze the translations in regards to specific discourse-related phenomena. We\nfind that our approach is a good compromise between sentence-level NMT vs\nattending to the full context, especially in low resource scenarios.\n","authors":["Christian Herold","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05183v1.pdf","comment":"accepted at CODI 2023 (ACL workshop)"},{"id":"http://arxiv.org/abs/2306.05179v1","updated":"2023-06-08T13:21:29Z","published":"2023-06-08T13:21:29Z","title":"M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining\n  Large Language Models","summary":"  Despite the existence of various benchmarks for evaluating natural language\nprocessing models, we argue that human exams are a more suitable means of\nevaluating general intelligence for large language models (LLMs), as they\ninherently demand a much wider range of abilities such as language\nunderstanding, domain knowledge, and problem-solving skills. To this end, we\nintroduce M3Exam, a novel benchmark sourced from real and official human exam\nquestions for evaluating LLMs in a multilingual, multimodal, and multilevel\ncontext. M3Exam exhibits three unique characteristics: (1) multilingualism,\nencompassing questions from multiple countries that require strong multilingual\nproficiency and cultural knowledge; (2) multimodality, accounting for the\nmultimodal nature of many exam questions to test the model's multimodal\nunderstanding capability; and (3) multilevel structure, featuring exams from\nthree critical educational periods to comprehensively assess a model's\nproficiency at different levels. In total, M3Exam contains 12,317 questions in\n9 diverse languages with three educational levels, where about 23\\% of the\nquestions require processing images for successful solving. We assess the\nperformance of top-performing LLMs on M3Exam and find that current models,\nincluding GPT-4, still struggle with multilingual text, particularly in\nlow-resource and non-Latin script languages. Multimodal LLMs also perform\npoorly with complex multimodal questions. We believe that M3Exam can be a\nvaluable resource for comprehensively evaluating LLMs by examining their\nmultilingual and multimodal abilities and tracking their development. Data and\nevaluation code is available at \\url{https://github.com/DAMO-NLP-SG/M3Exam}.\n","authors":["Wenxuan Zhang","Sharifah Mahani Aljunied","Chang Gao","Yew Ken Chia","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2306.05179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05176v1","updated":"2023-06-08T13:17:06Z","published":"2023-06-08T13:17:06Z","title":"RRWKV: Capturing Long-range Dependencies in RWKV","summary":"  Owing to the impressive dot-product attention, the Transformers have been the\ndominant architectures in various natural language processing (NLP) tasks.\nRecently, the Receptance Weighted Key Value (RWKV) architecture follows a\nnon-transformer architecture to eliminate the drawbacks of dot-product\nattention, where memory and computational complexity exhibits quadratic scaling\nwith sequence length. Although RWKV has exploited a linearly tensor-product\nattention mechanism and achieved parallelized computations by deploying the\ntime-sequential mode, it fails to capture long-range dependencies because of\nits limitation on looking back at previous information, compared with full\ninformation obtained by direct interactions in the standard transformer.\nTherefore, the paper devises the Retrospected Receptance Weighted Key Value\n(RRWKV) architecture via incorporating the retrospecting ability into the RWKV\nto effectively absorb information, which maintains memory and computational\nefficiency as well.\n","authors":["Leilei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04907v2","updated":"2023-06-08T12:44:35Z","published":"2023-01-12T10:03:56Z","title":"Think Twice: A Human-like Two-stage Conversational Agent for Emotional\n  Response Generation","summary":"  Towards human-like dialogue systems, current emotional dialogue approaches\njointly model emotion and semantics with a unified neural network. This\nstrategy tends to generate safe responses due to the mutual restriction between\nemotion and semantics, and requires rare emotion-annotated large-scale dialogue\ncorpus. Inspired by the \"think twice\" behavior in human dialogue, we propose a\ntwo-stage conversational agent for the generation of emotional dialogue.\nFirstly, a dialogue model trained without the emotion-annotated dialogue corpus\ngenerates a prototype response that meets the contextual semantics. Secondly,\nthe first-stage prototype is modified by a controllable emotion refiner with\nthe empathy hypothesis. Experimental results on the DailyDialog and\nEmpatheticDialogues datasets demonstrate that the proposed conversational\noutperforms the comparison models in emotion generation and maintains the\nsemantic performance in automatic and human evaluations.\n","authors":["Yushan Qian","Bo Wang","Shangzhao Ma","Wu Bin","Shuo Zhang","Dongming Zhao","Kun Huang","Yuexian Hou"],"pdf_url":"https://arxiv.org/pdf/2301.04907v2.pdf","comment":"Accepted to AAMAS2023"},{"id":"http://arxiv.org/abs/2212.08802v2","updated":"2023-06-08T12:44:28Z","published":"2022-12-17T05:25:17Z","title":"Relational Sentence Embedding for Flexible Semantic Matching","summary":"  We present Relational Sentence Embedding (RSE), a new paradigm to further\ndiscover the potential of sentence embeddings. Prior work mainly models the\nsimilarity between sentences based on their embedding distance. Because of the\ncomplex semantic meanings conveyed, sentence pairs can have various relation\ntypes, including but not limited to entailment, paraphrasing, and\nquestion-answer. It poses challenges to existing embedding methods to capture\nsuch relational information. We handle the problem by learning associated\nrelational embeddings. Specifically, a relation-wise translation operation is\napplied to the source sentence to infer the corresponding target sentence with\na pre-trained Siamese-based encoder. The fine-grained relational similarity\nscores can be computed from learned embeddings. We benchmark our method on 19\ndatasets covering a wide range of tasks, including semantic textual similarity,\ntransfer, and domain-specific tasks. Experimental results show that our method\nis effective and flexible in modeling sentence relations and outperforms a\nseries of state-of-the-art sentence embedding methods.\nhttps://github.com/BinWang28/RSE\n","authors":["Bin Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2212.08802v2.pdf","comment":"RepL4NLP at ACL 2023"},{"id":"http://arxiv.org/abs/2306.01506v2","updated":"2023-06-08T12:22:30Z","published":"2023-06-02T12:54:38Z","title":"BabySLM: language-acquisition-friendly benchmark of self-supervised\n  spoken language models","summary":"  Self-supervised techniques for learning speech representations have been\nshown to develop linguistic competence from exposure to speech without the need\nfor human labels. In order to fully realize the potential of these approaches\nand further our understanding of how infants learn language, simulations must\nclosely emulate real-life situations by training on developmentally plausible\ncorpora and benchmarking against appropriate test sets. To this end, we propose\na language-acquisition-friendly benchmark to probe spoken language models at\nthe lexical and syntactic levels, both of which are compatible with the\nvocabulary typical of children's language experiences. This paper introduces\nthe benchmark and summarizes a range of experiments showing its usefulness. In\naddition, we highlight two exciting challenges that need to be addressed for\nfurther progress: bridging the gap between text and speech and between clean\nspeech and in-the-wild speech.\n","authors":["Marvin Lavechin","Yaya Sy","Hadrien Titeux","María Andrea Cruz Blandón","Okko Räsänen","Hervé Bredin","Emmanuel Dupoux","Alejandrina Cristia"],"pdf_url":"https://arxiv.org/pdf/2306.01506v2.pdf","comment":"Proceedings of Interspeech 2023"},{"id":"http://arxiv.org/abs/2210.11899v2","updated":"2023-06-08T12:06:36Z","published":"2022-10-21T11:55:55Z","title":"A Semi-supervised Approach for a Better Translation of Sentiment in\n  Dialectical Arabic UGT","summary":"  In the online world, Machine Translation (MT) systems are extensively used to\ntranslate User-Generated Text (UGT) such as reviews, tweets, and social media\nposts, where the main message is often the author's positive or negative\nattitude towards the topic of the text. However, MT systems still lack accuracy\nin some low-resource languages and sometimes make critical translation errors\nthat completely flip the sentiment polarity of the target word or phrase and\nhence delivers a wrong affect message. This is particularly noticeable in texts\nthat do not follow common lexico-grammatical standards such as the dialectical\nArabic (DA) used on online platforms. In this research, we aim to improve the\ntranslation of sentiment in UGT written in the dialectical versions of the\nArabic language to English. Given the scarcity of gold-standard parallel data\nfor DA-EN in the UGT domain, we introduce a semi-supervised approach that\nexploits both monolingual and parallel data for training an NMT system\ninitialised by a cross-lingual language model trained with supervised and\nunsupervised modeling objectives. We assess the accuracy of sentiment\ntranslation by our proposed system through a numerical 'sentiment-closeness'\nmeasure as well as human evaluation. We will show that our semi-supervised MT\nsystem can significantly help with correcting sentiment errors detected in the\nonline translation of dialectical Arabic UGT.\n","authors":["Hadeel Saadany","Constantin Orasan","Emad Mohamed","Ashraf Tantawy"],"pdf_url":"https://arxiv.org/pdf/2210.11899v2.pdf","comment":"WANLP2022 at EMNLP 2022"},{"id":"http://arxiv.org/abs/2212.10754v3","updated":"2023-06-08T11:58:21Z","published":"2022-12-21T04:21:35Z","title":"CoRRPUS: Code-based Structured Prompting for Neurosymbolic Story\n  Understanding","summary":"  Story generation and understanding -- as with all NLG/NLU tasks -- has seen a\nsurge in neurosymbolic work. Researchers have recognized that, while large\nlanguage models (LLMs) have tremendous utility, they can be augmented with\nsymbolic means to be even better and to make up for any flaws that the neural\nnetworks might have. However, symbolic methods are extremely costly in terms of\nthe amount of time and expertise needed to create them. In this work, we\ncapitalize on state-of-the-art Code-LLMs, such as Codex, to bootstrap the use\nof symbolic methods for tracking the state of stories and aiding in story\nunderstanding. We show that our CoRRPUS system and abstracted prompting\nprocedures can beat current state-of-the-art structured LLM techniques on\npre-existing story understanding tasks (bAbI Task 2 and Re^3) with minimal hand\nengineering. We hope that this work can help highlight the importance of\nsymbolic representations and specialized prompting for LLMs as these models\nrequire some guidance for performing reasoning tasks properly.\n","authors":["Yijiang River Dong","Lara J. Martin","Chris Callison-Burch"],"pdf_url":"https://arxiv.org/pdf/2212.10754v3.pdf","comment":"Accepted to Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.05126v1","updated":"2023-06-08T11:50:58Z","published":"2023-06-08T11:50:58Z","title":"Mapping Brains with Language Models: A Survey","summary":"  Over the years, many researchers have seemingly made the same observation:\nBrain and language model activations exhibit some structural similarities,\nenabling linear partial mappings between features extracted from neural\nrecordings and computational language models. In an attempt to evaluate how\nmuch evidence has been accumulated for this observation, we survey over 30\nstudies spanning 10 datasets and 8 metrics. How much evidence has been\naccumulated, and what, if anything, is missing before we can draw conclusions?\nOur analysis of the evaluation methods used in the literature reveals that some\nof the metrics are less conservative. We also find that the accumulated\nevidence, for now, remains ambiguous, but correlations with model size and\nquality provide grounds for cautious optimism.\n","authors":["Antonia Karamolegkou","Mostafa Abdou","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2306.05126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05119v1","updated":"2023-06-08T11:41:39Z","published":"2023-06-08T11:41:39Z","title":"Reference Matters: Benchmarking Factual Error Correction for Dialogue\n  Summarization with Fine-grained Evaluation Framework","summary":"  Factuality is important to dialogue summarization. Factual error correction\n(FEC) of model-generated summaries is one way to improve factuality. Current\nFEC evaluation that relies on factuality metrics is not reliable and detailed\nenough. To address this problem, we are the first to manually annotate a FEC\ndataset for dialogue summarization containing 4000 items and propose FERRANTI,\na fine-grained evaluation framework based on reference correction that\nautomatically evaluates the performance of FEC models on different error\ncategories. Using this evaluation framework, we conduct sufficient experiments\nwith FEC approaches under a variety of settings and find the best training\nmodes and significant differences in the performance of the existing approaches\non different factual error categories.\n","authors":["Mingqi Gao","Xiaojun Wan","Jia Su","Zhefeng Wang","Baoxing Huai"],"pdf_url":"https://arxiv.org/pdf/2306.05119v1.pdf","comment":"Accepted to ACL 2023 Main Conference"},{"id":"http://arxiv.org/abs/2306.05116v1","updated":"2023-06-08T11:30:43Z","published":"2023-06-08T11:30:43Z","title":"On Search Strategies for Document-Level Neural Machine Translation","summary":"  Compared to sentence-level systems, document-level neural machine translation\n(NMT) models produce a more consistent output across a document and are able to\nbetter resolve ambiguities within the input. There are many works on\ndocument-level NMT, mostly focusing on modifying the model architecture or\ntraining strategy to better accommodate the additional context-input. On the\nother hand, in most works, the question on how to perform search with the\ntrained model is scarcely discussed, sometimes not mentioned at all. In this\nwork, we aim to answer the question how to best utilize a context-aware\ntranslation model in decoding. We start with the most popular document-level\nNMT approach and compare different decoding schemes, some from the literature\nand others proposed by us. In the comparison, we are using both, standard\nautomatic metrics, as well as specific linguistic phenomena on three standard\ndocument-level translation benchmarks. We find that most commonly used decoding\nstrategies perform similar to each other and that higher quality context\ninformation has the potential to further improve the translation.\n","authors":["Christian Herold","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05116v1.pdf","comment":"Accepted to ACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.05115v1","updated":"2023-06-08T11:29:58Z","published":"2023-06-08T11:29:58Z","title":"Closing the Loop: Testing ChatGPT to Generate Model Explanations to\n  Improve Human Labelling of Sponsored Content on Social Media","summary":"  Regulatory bodies worldwide are intensifying their efforts to ensure\ntransparency in influencer marketing on social media through instruments like\nthe Unfair Commercial Practices Directive (UCPD) in the European Union, or\nSection 5 of the Federal Trade Commission Act. Yet enforcing these obligations\nhas proven to be highly problematic due to the sheer scale of the influencer\nmarket. The task of automatically detecting sponsored content aims to enable\nthe monitoring and enforcement of such regulations at scale. Current research\nin this field primarily frames this problem as a machine learning task,\nfocusing on developing models that achieve high classification performance in\ndetecting ads. These machine learning tasks rely on human data annotation to\nprovide ground truth information. However, agreement between annotators is\noften low, leading to inconsistent labels that hinder the reliability of\nmodels. To improve annotation accuracy and, thus, the detection of sponsored\ncontent, we propose using chatGPT to augment the annotation process with\nphrases identified as relevant features and brief explanations. Our experiments\nshow that this approach consistently improves inter-annotator agreement and\nannotation accuracy. Additionally, our survey of user experience in the\nannotation task indicates that the explanations improve the annotators'\nconfidence and streamline the process. Our proposed methods can ultimately lead\nto more transparency and alignment with regulatory requirements in sponsored\ncontent detection.\n","authors":["Thales Bertaglia","Stefan Huber","Catalina Goanta","Gerasimos Spanakis","Adriana Iamnitchi"],"pdf_url":"https://arxiv.org/pdf/2306.05115v1.pdf","comment":"Accepted to The World Conference on eXplainable Artificial\n  Intelligence, Lisbon, Portugal, July 2023"},{"id":"http://arxiv.org/abs/2306.05088v1","updated":"2023-06-08T10:42:44Z","published":"2023-06-08T10:42:44Z","title":"The ART of Conversation: Measuring Phonetic Convergence and Deliberate\n  Imitation in L2-Speech with a Siamese RNN","summary":"  Phonetic convergence describes the automatic and unconscious speech\nadaptation of two interlocutors in a conversation. This paper proposes a\nSiamese recurrent neural network (RNN) architecture to measure the convergence\nof the holistic spectral characteristics of speech sounds in an L2-L2\ninteraction. We extend an alternating reading task (the ART) dataset by adding\n20 native Slovak L2 English speakers. We train and test the Siamese RNN model\nto measure phonetic convergence of L2 English speech from three different\nnative language groups: Italian (9 dyads), French (10 dyads) and Slovak (10\ndyads). Our results indicate that the Siamese RNN model effectively captures\nthe dynamics of phonetic convergence and the speaker's imitation ability.\nMoreover, this text-independent model is scalable and capable of handling\nL1-induced speaker variability.\n","authors":["Zheng Yuan","Aldo Pastore","Dorina de Jong","Hao Xu","Luciano Fadiga","Alessandro D'Ausilio"],"pdf_url":"https://arxiv.org/pdf/2306.05088v1.pdf","comment":"Accepted at INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.05087v1","updated":"2023-06-08T10:41:56Z","published":"2023-06-08T10:41:56Z","title":"PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning\n  Optimization","summary":"  Instruction tuning large language models (LLMs) remains a challenging task,\nowing to the complexity of hyperparameter selection and the difficulty involved\nin evaluating the tuned models. To determine the optimal hyperparameters, an\nautomatic, robust, and reliable evaluation benchmark is essential. However,\nestablishing such a benchmark is not a trivial task due to the challenges\nassociated with evaluation accuracy and privacy protection. In response to\nthese challenges, we introduce a judge large language model, named PandaLM,\nwhich is trained to distinguish the superior model given several LLMs.\nPandaLM's focus extends beyond just the objective correctness of responses,\nwhich is the main focus of traditional evaluation datasets. It addresses vital\nsubjective factors such as relative conciseness, clarity, adherence to\ninstructions, comprehensiveness, and formality. To ensure the reliability of\nPandaLM, we collect a diverse human-annotated test dataset, where all contexts\nare generated by humans and labels are aligned with human preferences. Our\nresults indicate that PandaLM-7B achieves 93.75% of GPT-3.5's evaluation\nability and 88.28% of GPT-4's in terms of F1-score on our test dataset. PandaLM\nenables the evaluation of LLM to be fairer but with less cost, evidenced by\nsignificant improvements achieved by models tuned through PandaLM compared to\ntheir counterparts trained with default Alpaca's hyperparameters. In addition,\nPandaLM does not depend on API-based evaluations, thus avoiding potential data\nleakage. All resources of PandaLM are released at\nhttps://github.com/WeOpenML/PandaLM.\n","authors":["Yidong Wang","Zhuohao Yu","Zhengran Zeng","Linyi Yang","Cunxiang Wang","Hao Chen","Chaoya Jiang","Rui Xie","Jindong Wang","Xing Xie","Wei Ye","Shikun Zhang","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05083v1","updated":"2023-06-08T10:24:02Z","published":"2023-06-08T10:24:02Z","title":"Revealing the Blind Spot of Sentence Encoder Evaluation by HEROS","summary":"  Existing sentence textual similarity benchmark datasets only use a single\nnumber to summarize how similar the sentence encoder's decision is to humans'.\nHowever, it is unclear what kind of sentence pairs a sentence encoder (SE)\nwould consider similar. Moreover, existing SE benchmarks mainly consider\nsentence pairs with low lexical overlap, so it is unclear how the SEs behave\nwhen two sentences have high lexical overlap. We introduce a high-quality SE\ndiagnostic dataset, HEROS. HEROS is constructed by transforming an original\nsentence into a new sentence based on certain rules to form a \\textit{minimal\npair}, and the minimal pair has high lexical overlaps. The rules include\nreplacing a word with a synonym, an antonym, a typo, a random word, and\nconverting the original sentence into its negation. Different rules yield\ndifferent subsets of HEROS. By systematically comparing the performance of over\n60 supervised and unsupervised SEs on HEROS, we reveal that most unsupervised\nsentence encoders are insensitive to negation. We find the datasets used to\ntrain the SE are the main determinants of what kind of sentence pairs an SE\nconsiders similar. We also show that even if two SEs have similar performance\non STS benchmarks, they can have very different behavior on HEROS. Our result\nreveals the blind spot of traditional STS benchmarks when evaluating SEs.\n","authors":["Cheng-Han Chiang","Yung-Sung Chuang","James Glass","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2306.05083v1.pdf","comment":"ACL 2023 repl4nlp (representation learning for NLP) workshop poster\n  paper. Dataset at https://huggingface.co/datasets/dcml0714/Heros"},{"id":"http://arxiv.org/abs/2306.05079v1","updated":"2023-06-08T10:02:04Z","published":"2023-06-08T10:02:04Z","title":"Enhancing Robustness of AI Offensive Code Generators via Data\n  Augmentation","summary":"  In this work, we present a method to add perturbations to the code\ndescriptions, i.e., new inputs in natural language (NL) from well-intentioned\ndevelopers, in the context of security-oriented code, and analyze how and to\nwhat extent perturbations affect the performance of AI offensive code\ngenerators. Our experiments show that the performance of the code generators is\nhighly affected by perturbations in the NL descriptions. To enhance the\nrobustness of the code generators, we use the method to perform data\naugmentation, i.e., to increase the variability and diversity of the training\ndata, proving its effectiveness against both perturbed and non-perturbed code\ndescriptions.\n","authors":["Cristina Improta","Pietro Liguori","Roberto Natella","Bojan Cukic","Domenico Cotroneo"],"pdf_url":"https://arxiv.org/pdf/2306.05079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05077v1","updated":"2023-06-08T10:00:19Z","published":"2023-06-08T10:00:19Z","title":"Improving Language Model Integration for Neural Machine Translation","summary":"  The integration of language models for neural machine translation has been\nextensively studied in the past. It has been shown that an external language\nmodel, trained on additional target-side monolingual data, can help improve\ntranslation quality. However, there has always been the assumption that the\ntranslation model also learns an implicit target-side language model during\ntraining, which interferes with the external language model at decoding time.\nRecently, some works on automatic speech recognition have demonstrated that, if\nthe implicit language model is neutralized in decoding, further improvements\ncan be gained when integrating an external language model. In this work, we\ntransfer this concept to the task of machine translation and compare with the\nmost prominent way of including additional monolingual data - namely\nback-translation. We find that accounting for the implicit language model\nsignificantly boosts the performance of language model fusion, although this\napproach is still outperformed by back-translation.\n","authors":["Christian Herold","Yingbo Gao","Mohammad Zeineldeen","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05077v1.pdf","comment":"accepted at ACL2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.05076v1","updated":"2023-06-08T09:59:48Z","published":"2023-06-08T09:59:48Z","title":"DLAMA: A Framework for Curating Culturally Diverse Facts for Probing the\n  Knowledge of Pretrained Language Models","summary":"  A few benchmarking datasets have been released to evaluate the factual\nknowledge of pretrained language models. These benchmarks (e.g., LAMA, and\nParaRel) are mainly developed in English and later are translated to form new\nmultilingual versions (e.g., mLAMA, and mParaRel). Results on these\nmultilingual benchmarks suggest that using English prompts to recall the facts\nfrom multilingual models usually yields significantly better and more\nconsistent performance than using non-English prompts. Our analysis shows that\nmLAMA is biased toward facts from Western countries, which might affect the\nfairness of probing models. We propose a new framework for curating factual\ntriples from Wikidata that are culturally diverse. A new benchmark DLAMA-v1 is\nbuilt of factual triples from three pairs of contrasting cultures having a\ntotal of 78,259 triples from 20 relation predicates. The three pairs comprise\nfacts representing the (Arab and Western), (Asian and Western), and (South\nAmerican and Western) countries respectively. Having a more balanced benchmark\n(DLAMA-v1) supports that mBERT performs better on Western facts than\nnon-Western ones, while monolingual Arabic, English, and Korean models tend to\nperform better on their culturally proximate facts. Moreover, both monolingual\nand multilingual models tend to make a prediction that is culturally or\ngeographically relevant to the correct label, even if the prediction is wrong.\n","authors":["Amr Keleg","Walid Magdy"],"pdf_url":"https://arxiv.org/pdf/2306.05076v1.pdf","comment":"Accepted to ACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.05075v1","updated":"2023-06-08T09:56:57Z","published":"2023-06-08T09:56:57Z","title":"LCT-1 at SemEval-2023 Task 10: Pre-training and Multi-task Learning for\n  Sexism Detection and Classification","summary":"  Misogyny and sexism are growing problems in social media. Advances have been\nmade in online sexism detection but the systems are often uninterpretable.\nSemEval-2023 Task 10 on Explainable Detection of Online Sexism aims at\nincreasing explainability of the sexism detection, and our team participated in\nall the proposed subtasks. Our system is based on further domain-adaptive\npre-training (Gururangan et al., 2020). Building on the Transformer-based\nmodels with the domain adaptation, we compare fine-tuning with multi-task\nlearning and show that each subtask requires a different system configuration.\nIn our experiments, multi-task learning performs on par with standard\nfine-tuning for sexism detection and noticeably better for coarse-grained\nsexism classification, while fine-tuning is preferable for fine-grained\nclassification.\n","authors":["Konstantin Chernyshev","Ekaterina Garanina","Duygu Bayram","Qiankun Zheng","Lukas Edman"],"pdf_url":"https://arxiv.org/pdf/2306.05075v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05064v1","updated":"2023-06-08T09:29:05Z","published":"2023-06-08T09:29:05Z","title":"Learning A Foundation Language Model for Geoscience Knowledge\n  Understanding and Utilization","summary":"  Large language models (LLMs)have achieved great success in general domains of\nnatural language processing. In this paper, we bring LLMs to the realm of\ngeoscience, with the objective of advancing research and applications in this\nfield. To this end, we present the first-ever LLM in geoscience, K2, alongside\na suite of resources developed to further promote LLM research within\ngeoscience. For instance, we have curated the first geoscience instruction\ntuning dataset, GeoSignal, which aims to align LLM responses to\ngeoscience-related user queries. Additionally, we have established the first\ngeoscience benchmark, GeoBenchmark, to evaluate LLMs in the context of\ngeoscience. In this work, we experiment with a complete recipe to adapt a\npretrained general-domain LLM to the geoscience domain. Specifically, we\nfurther train the LLaMA-7B model on over 1 million pieces of geoscience\nliterature and utilize GeoSignal's supervised data to fine-tune the model.\nMoreover, we share a protocol that can efficiently gather domain-specific data\nand construct domain-supervised data, even in situations where manpower is\nscarce. Experiments conducted on the GeoBenchmark demonstrate the the\neffectiveness of our approach and datasets.\n","authors":["Cheng Deng","Tianhang Zhang","Zhongmou He","Qiyuan Chen","Yuanyuan Shi","Le Zhou","Luoyi Fu","Weinan Zhang","Xinbing Wang","Chenghu Zhou","Zhouhan Lin","Junxian He"],"pdf_url":"https://arxiv.org/pdf/2306.05064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05052v1","updated":"2023-06-08T09:12:28Z","published":"2023-06-08T09:12:28Z","title":"Interpretable Medical Diagnostics with Structured Data Extraction by\n  Large Language Models","summary":"  Tabular data is often hidden in text, particularly in medical diagnostic\nreports. Traditional machine learning (ML) models designed to work with tabular\ndata, cannot effectively process information in such form. On the other hand,\nlarge language models (LLMs) which excel at textual tasks, are probably not the\nbest tool for modeling tabular data. Therefore, we propose a novel, simple, and\neffective methodology for extracting structured tabular data from textual\nmedical reports, called TEMED-LLM. Drawing upon the reasoning capabilities of\nLLMs, TEMED-LLM goes beyond traditional extraction techniques, accurately\ninferring tabular features, even when their names are not explicitly mentioned\nin the text. This is achieved by combining domain-specific reasoning guidelines\nwith a proposed data validation and reasoning correction feedback loop. By\napplying interpretable ML models such as decision trees and logistic regression\nover the extracted and validated data, we obtain end-to-end interpretable\npredictions. We demonstrate that our approach significantly outperforms\nstate-of-the-art text classification models in medical diagnostics. Given its\npredictive performance, simplicity, and interpretability, TEMED-LLM underscores\nthe potential of leveraging LLMs to improve the performance and trustworthiness\nof ML models in medical applications.\n","authors":["Aleksa Bisercic","Mladen Nikolic","Mihaela van der Schaar","Boris Delibasic","Pietro Lio","Andrija Petrovic"],"pdf_url":"https://arxiv.org/pdf/2306.05052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.06595v3","updated":"2023-06-08T08:57:41Z","published":"2023-05-11T06:27:38Z","title":"BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from\n  Book Reviews","summary":"  The analysis of consumer sentiment, as expressed through reviews, can provide\na wealth of insight regarding the quality of a product. While the study of\nsentiment analysis has been widely explored in many popular languages,\nrelatively less attention has been given to the Bangla language, mostly due to\na lack of relevant data and cross-domain adaptability. To address this\nlimitation, we present BanglaBook, a large-scale dataset of Bangla book reviews\nconsisting of 158,065 samples classified into three broad categories: positive,\nnegative, and neutral. We provide a detailed statistical analysis of the\ndataset and employ a range of machine learning models to establish baselines\nincluding SVM, LSTM, and Bangla-BERT. Our findings demonstrate a substantial\nperformance advantage of pre-trained models over models that rely on manually\ncrafted features, emphasizing the necessity for additional training resources\nin this domain. Additionally, we conduct an in-depth error analysis by\nexamining sentiment unigrams, which may provide insight into common\nclassification errors in under-resourced languages like Bangla. Our codes and\ndata are publicly available at https://github.com/mohsinulkabir14/BanglaBook.\n","authors":["Mohsinul Kabir","Obayed Bin Mahfuz","Syed Rifat Raiyan","Hasan Mahmud","Md Kamrul Hasan"],"pdf_url":"https://arxiv.org/pdf/2305.06595v3.pdf","comment":"Accepted in Findings of the Association for Computational\n  Linguistics: ACL 2023"},{"id":"http://arxiv.org/abs/2306.04996v1","updated":"2023-06-08T07:33:22Z","published":"2023-06-08T07:33:22Z","title":"T3L: Translate-and-Test Transfer Learning for Cross-Lingual Text\n  Classification","summary":"  Cross-lingual text classification leverages text classifiers trained in a\nhigh-resource language to perform text classification in other languages with\nno or minimal fine-tuning (zero/few-shots cross-lingual transfer). Nowadays,\ncross-lingual text classifiers are typically built on large-scale, multilingual\nlanguage models (LMs) pretrained on a variety of languages of interest.\nHowever, the performance of these models vary significantly across languages\nand classification tasks, suggesting that the superposition of the language\nmodelling and classification tasks is not always effective. For this reason, in\nthis paper we propose revisiting the classic \"translate-and-test\" pipeline to\nneatly separate the translation and classification stages. The proposed\napproach couples 1) a neural machine translator translating from the targeted\nlanguage to a high-resource language, with 2) a text classifier trained in the\nhigh-resource language, but the neural machine translator generates \"soft\"\ntranslations to permit end-to-end backpropagation during fine-tuning of the\npipeline. Extensive experiments have been carried out over three cross-lingual\ntext classification datasets (XNLI, MLDoc and MultiEURLEX), with the results\nshowing that the proposed approach has significantly improved performance over\na competitive baseline.\n","authors":["Inigo Jauregi Unanue","Gholamreza Haffari","Massimo Piccardi"],"pdf_url":"https://arxiv.org/pdf/2306.04996v1.pdf","comment":"Accepted by the Transactions of the Association for Computational\n  Linguistics (TACL), pre-MIT Press publication version"},{"id":"http://arxiv.org/abs/2306.04980v1","updated":"2023-06-08T07:10:39Z","published":"2023-06-08T07:10:39Z","title":"Assessing Phrase Break of ESL Speech with Pre-trained Language Models\n  and Large Language Models","summary":"  This work introduces approaches to assessing phrase breaks in ESL learners'\nspeech using pre-trained language models (PLMs) and large language models\n(LLMs). There are two tasks: overall assessment of phrase break for a speech\nclip and fine-grained assessment of every possible phrase break position. To\nleverage NLP models, speech input is first force-aligned with texts, and then\npre-processed into a token sequence, including words and phrase break\ninformation. To utilize PLMs, we propose a pre-training and fine-tuning\npipeline with the processed tokens. This process includes pre-training with a\nreplaced break token detection module and fine-tuning with text classification\nand sequence labeling. To employ LLMs, we design prompts for ChatGPT. The\nexperiments show that with the PLMs, the dependence on labeled training data\nhas been greatly reduced, and the performance has improved. Meanwhile, we\nverify that ChatGPT, a renowned LLM, has potential for further advancement in\nthis area.\n","authors":["Zhiyi Wang","Shaoguang Mao","Wenshan Wu","Yan Xia","Yan Deng","Jonathan Tien"],"pdf_url":"https://arxiv.org/pdf/2306.04980v1.pdf","comment":"Accepted by InterSpeech 2023. arXiv admin note: substantial text\n  overlap with arXiv:2210.16029"},{"id":"http://arxiv.org/abs/2306.04968v1","updated":"2023-06-08T06:55:02Z","published":"2023-06-08T06:55:02Z","title":"Actively Supervised Clustering for Open Relation Extraction","summary":"  Current clustering-based Open Relation Extraction (OpenRE) methods usually\nadopt a two-stage pipeline. The first stage simultaneously learns relation\nrepresentations and assignments. The second stage manually labels several\ninstances and thus names the relation for each cluster. However, unsupervised\nobjectives struggle to optimize the model to derive accurate clustering\nassignments, and the number of clusters has to be supplied in advance. In this\npaper, we present a novel setting, named actively supervised clustering for\nOpenRE. Our insight lies in that clustering learning and relation labeling can\nbe alternately performed, providing the necessary guidance for clustering\nwithout a significant increase in human effort. The key to the setting is\nselecting which instances to label. Instead of using classical active labeling\nstrategies designed for fixed known classes, we propose a new strategy, which\nis applicable to dynamically discover clusters of unknown relations.\nExperimental results show that our method is able to discover almost all\nrelational clusters in the data and improve the SOTA methods by 10.3\\% and\n5.2\\%, on two datasets respectively.\n","authors":["Jun Zhao","Yongxin Zhang","Qi Zhang","Tao Gui","Zhongyu Wei","Minlong Peng","Mingming Sun"],"pdf_url":"https://arxiv.org/pdf/2306.04968v1.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.04964v1","updated":"2023-06-08T06:43:10Z","published":"2023-06-08T06:43:10Z","title":"Leveraging Language Identification to Enhance Code-Mixed Text\n  Classification","summary":"  The usage of more than one language in the same text is referred to as Code\nMixed. It is evident that there is a growing degree of adaption of the use of\ncode-mixed data, especially English with a regional language, on social media\nplatforms. Existing deep-learning models do not take advantage of the implicit\nlanguage information in the code-mixed text. Our study aims to improve\nBERT-based models performance on low-resource Code-Mixed Hindi-English Datasets\nby experimenting with language augmentation approaches. We propose a pipeline\nto improve code-mixed systems that comprise data preprocessing, word-level\nlanguage identification, language augmentation, and model training on\ndownstream tasks like sentiment analysis. For language augmentation in BERT\nmodels, we explore word-level interleaving and post-sentence placement of\nlanguage information. We have examined the performance of vanilla BERT-based\nmodels and their code-mixed HingBERT counterparts on respective benchmark\ndatasets, comparing their results with and without using word-level language\ninformation. The models were evaluated using metrics such as accuracy,\nprecision, recall, and F1 score. Our findings show that the proposed language\naugmentation approaches work well across different BERT models. We demonstrate\nthe importance of augmenting code-mixed text with language information on five\ndifferent code-mixed Hindi-English downstream datasets based on sentiment\nanalysis, hate speech detection, and emotion detection.\n","authors":["Gauri Takawane","Abhishek Phaltankar","Varad Patwardhan","Aryan Patil","Raviraj Joshi","Mukta S. Takalikar"],"pdf_url":"https://arxiv.org/pdf/2306.04964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.14293v2","updated":"2023-06-08T06:33:23Z","published":"2023-04-27T15:56:34Z","title":"Controlled Text Generation with Natural Language Instructions","summary":"  Large language models generate fluent texts and can follow natural language\ninstructions to solve a wide range of tasks without task-specific training.\nNevertheless, it is notoriously difficult to control their generation to\nsatisfy the various constraints required by different applications. In this\nwork, we present InstructCTG, a controlled text generation framework that\nincorporates different constraints by conditioning on natural language\ndescriptions and demonstrations of the constraints. In particular, we first\nextract the underlying constraints of natural texts through a combination of\noff-the-shelf NLP tools and simple heuristics. We then verbalize the\nconstraints into natural language instructions to form weakly supervised\ntraining data. By prepending natural language descriptions of the constraints\nand a few demonstrations, we fine-tune a pre-trained language model to\nincorporate various types of constraints. Compared to existing search-based or\nscore-based methods, InstructCTG is more flexible to different constraint types\nand has a much smaller impact on the generation quality and speed because it\ndoes not modify the decoding procedure. Additionally, InstructCTG allows the\nmodel to adapt to new constraints without re-training through the use of\nfew-shot task generalization and in-context learning abilities of\ninstruction-tuned language models.\n","authors":["Wangchunshu Zhou","Yuchen Eleanor Jiang","Ethan Wilcox","Ryan Cotterell","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2304.14293v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.03030v2","updated":"2023-06-08T06:13:36Z","published":"2023-06-05T16:48:41Z","title":"Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset","summary":"  Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.6% and a weighted F1 score of 0.617. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.\n","authors":["Junling Liu","Peilin Zhou","Yining Hua","Dading Chong","Zhongyu Tian","Andrew Liu","Helin Wang","Chenyu You","Zhenhua Guo","Lei Zhu","Michael Lingzhi Li"],"pdf_url":"https://arxiv.org/pdf/2306.03030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04954v1","updated":"2023-06-08T06:02:34Z","published":"2023-06-08T06:02:34Z","title":"RE-Matching: A Fine-Grained Semantic Matching Method for Zero-Shot\n  Relation Extraction","summary":"  Semantic matching is a mainstream paradigm of zero-shot relation extraction,\nwhich matches a given input with a corresponding label description. The\nentities in the input should exactly match their hypernyms in the description,\nwhile the irrelevant contexts should be ignored when matching. However, general\nmatching methods lack explicit modeling of the above matching pattern. In this\nwork, we propose a fine-grained semantic matching method tailored for zero-shot\nrelation extraction. Following the above matching pattern, we decompose the\nsentence-level similarity score into entity and context matching scores. Due to\nthe lack of explicit annotations of the redundant components, we design a\nfeature distillation module to adaptively identify the relation-irrelevant\nfeatures and reduce their negative impact on context matching. Experimental\nresults show that our method achieves higher matching $F_1$ score and has an\ninference speed 10 times faster, when compared with the state-of-the-art\nmethods.\n","authors":["Jun Zhao","Wenyu Zhan","Xin Zhao","Qi Zhang","Tao Gui","Zhongyu Wei","Junzhe Wang","Minlong Peng","Mingming Sun"],"pdf_url":"https://arxiv.org/pdf/2306.04954v1.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2306.04349v2","updated":"2023-06-08T05:45:45Z","published":"2023-06-07T11:33:14Z","title":"GPT Self-Supervision for a Better Data Annotator","summary":"  The task of annotating data into concise summaries poses a significant\nchallenge across various domains, frequently requiring the allocation of\nsignificant time and specialized knowledge by human experts. Despite existing\nefforts to use large language models for annotation tasks, significant problems\nsuch as limited applicability to unlabeled data, the absence of self-supervised\nmethods, and the lack of focus on complex structured data still persist. In\nthis work, we propose a GPT self-supervision annotation method, which embodies\na generating-recovering paradigm that leverages the one-shot learning\ncapabilities of the Generative Pretrained Transformer (GPT). The proposed\napproach comprises a one-shot tuning phase followed by a generation phase. In\nthe one-shot tuning phase, we sample a data from the support set as part of the\nprompt for GPT to generate a textual summary, which is then used to recover the\noriginal data. The alignment score between the recovered and original data\nserves as a self-supervision navigator to refine the process. In the generation\nstage, the optimally selected one-shot sample serves as a template in the\nprompt and is applied to generating summaries from challenging datasets. The\nannotation performance is evaluated by tuning several human feedback reward\nnetworks and by calculating alignment scores between original and recovered\ndata at both sentence and structure levels. Our self-supervised annotation\nmethod consistently achieves competitive scores, convincingly demonstrating its\nrobust strength in various data-to-summary annotation tasks.\n","authors":["Xiaohuan Pei","Yanxi Li","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2306.04349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04950v1","updated":"2023-06-08T05:45:25Z","published":"2023-06-08T05:45:25Z","title":"Open Set Relation Extraction via Unknown-Aware Training","summary":"  The existing supervised relation extraction methods have achieved impressive\nperformance in a closed-set setting, where the relations during both training\nand testing remain the same. In a more realistic open-set setting, unknown\nrelations may appear in the test set. Due to the lack of supervision signals\nfrom unknown relations, a well-performing closed-set relation extractor can\nstill confidently misclassify them into known relations. In this paper, we\npropose an unknown-aware training method, regularizing the model by dynamically\nsynthesizing negative instances. To facilitate a compact decision boundary,\n``difficult'' negative instances are necessary. Inspired by text adversarial\nattacks, we adaptively apply small but critical perturbations to original\ntraining instances and thus synthesizing negative instances that are more\nlikely to be mistaken by the model as known relations. Experimental results\nshow that this method achieves SOTA unknown relation detection without\ncompromising the classification of known relations.\n","authors":["Jun Zhao","Xin Zhao","Wenyu Zhan","Qi Zhang","Tao Gui","Zhongyu Wei","Yunwen Chen","Xiang Gao","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2306.04950v1.pdf","comment":"Accepted by ACL2023"},{"id":"http://arxiv.org/abs/2305.17746v2","updated":"2023-06-08T05:33:55Z","published":"2023-05-28T14:58:10Z","title":"Whitening-based Contrastive Learning of Sentence Embeddings","summary":"  This paper presents a whitening-based contrastive learning method for\nsentence embedding learning (WhitenedCSE), which combines contrastive learning\nwith a novel shuffled group whitening. Generally, contrastive learning pulls\ndistortions of a single sample (i.e., positive samples) close and push negative\nsamples far away, correspondingly facilitating the alignment and uniformity in\nthe feature space. A popular alternative to the \"pushing'' operation is\nwhitening the feature space, which scatters all the samples for uniformity.\nSince the whitening and the contrastive learning have large redundancy w.r.t.\nthe uniformity, they are usually used separately and do not easily work\ntogether. For the first time, this paper integrates whitening into the\ncontrastive learning scheme and facilitates two benefits. 1) Better uniformity.\nWe find that these two approaches are not totally redundant but actually have\nsome complementarity due to different uniformity mechanism. 2) Better\nalignment. We randomly divide the feature into multiple groups along the\nchannel axis and perform whitening independently within each group. By\nshuffling the group division, we derive multiple distortions of a single sample\nand thus increase the positive sample diversity. Consequently, using multiple\npositive samples with enhanced diversity further improves contrastive learning\ndue to better alignment. Extensive experiments on seven semantic textual\nsimilarity tasks show our method achieves consistent improvement over the\ncontrastive learning baseline and sets new states of the art, e.g., 78.78\\%\n(+2.53\\% based on BERT\\ba) Spearman correlation on STS tasks.\n","authors":["Wenjie Zhuo","Yifan Sun","Xiaohan Wang","Linchao Zhu","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2305.17746v2.pdf","comment":"ACL 2023 Main Conference(Oral)"},{"id":"http://arxiv.org/abs/2306.04941v1","updated":"2023-06-08T05:17:03Z","published":"2023-06-08T05:17:03Z","title":"A modified model for topic detection from a corpus and a new metric\n  evaluating the understandability of topics","summary":"  This paper presents a modified neural model for topic detection from a corpus\nand proposes a new metric to evaluate the detected topics. The new model builds\nupon the embedded topic model incorporating some modifications such as document\nclustering. Numerical experiments suggest that the new model performs\nfavourably regardless of the document's length. The new metric, which can be\ncomputed more efficiently than widely-used metrics such as topic coherence,\nprovides variable information regarding the understandability of the detected\ntopics.\n","authors":["Tomoya Kitano","Yuto Miyatake","Daisuke Furihata"],"pdf_url":"https://arxiv.org/pdf/2306.04941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04933v1","updated":"2023-06-08T04:31:48Z","published":"2023-06-08T04:31:48Z","title":"InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural\n  Language Understanding","summary":"  Soft prompt tuning achieves superior performances across a wide range of\nfew-shot tasks. However, the performances of prompt tuning can be highly\nsensitive to the initialization of the prompts. We also empirically observe\nthat conventional prompt tuning methods cannot encode and learn sufficient\ntask-relevant information from prompt tokens. In this work, we develop an\ninformation-theoretic framework that formulates soft prompt tuning as\nmaximizing mutual information between prompts and other model parameters (or\nencoded representations). This novel view helps us to develop a more efficient,\naccurate and robust soft prompt tuning method InfoPrompt. With this framework,\nwe develop two novel mutual information based loss functions, to (i) discover\nproper prompt initialization for the downstream tasks and learn sufficient\ntask-relevant information from prompt tokens and (ii) encourage the output\nrepresentation from the pretrained language model to be more aware of the\ntask-relevant information captured in the learnt prompt. Extensive experiments\nvalidate that InfoPrompt can significantly accelerate the convergence of the\nprompt tuning and outperform traditional prompt tuning methods. Finally, we\nprovide a formal theoretical result for showing to show that gradient descent\ntype algorithm can be used to train our mutual information loss.\n","authors":["Junda Wu","Tong Yu","Rui Wang","Zhao Song","Ruiyi Zhang","Handong Zhao","Chaochao Lu","Shuai Li","Ricardo Henao"],"pdf_url":"https://arxiv.org/pdf/2306.04933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04926v1","updated":"2023-06-08T04:08:32Z","published":"2023-06-08T04:08:32Z","title":"covLLM: Large Language Models for COVID-19 Biomedical Literature","summary":"  The COVID-19 pandemic led to 1.1 million deaths in the United States, despite\nthe explosion of coronavirus research. These new findings are slow to translate\nto clinical interventions, leading to poorer patient outcomes and unnecessary\ndeaths. One reason is that clinicians, overwhelmed by patients, struggle to\nkeep pace with the rate of new coronavirus literature. A potential solution is\ndeveloping a tool for evaluating coronavirus literature using large language\nmodels (LLMs) -- neural networks that are deployed for natural language\nprocessing. LLMs can be used to summarize and extract user-specified\ninformation. The greater availability and advancement of LLMs and pre-processed\ncoronavirus literature databases provide the opportunity to assist clinicians\nin evaluating coronavirus literature through a coronavirus literature specific\nLLM (covLLM), a tool that directly takes an inputted research article and a\nuser query to return an answer. Using the COVID-19 Open Research Dataset\n(CORD-19), we produced two datasets: (1) synCovid, which uses a combination of\nhandwritten prompts and synthetic prompts generated using OpenAI, and (2) real\nabstracts, which contains abstract and title pairs. covLLM was trained with\nLLaMA 7B as a baseline model to produce three models trained on (1) the Alpaca\nand synCovid datasets, (2) the synCovid dataset, and (3) the synCovid and real\nabstract datasets. These models were evaluated by two human evaluators and\nChatGPT. Results demonstrate that training covLLM on the synCovid and abstract\npairs datasets performs competitively with ChatGPT and outperforms covLLM\ntrained primarily using the Alpaca dataset.\n","authors":["Yousuf A. Khan","Clarisse Hokia","Jennifer Xu","Ben Ehlert"],"pdf_url":"https://arxiv.org/pdf/2306.04926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04925v1","updated":"2023-06-08T04:04:47Z","published":"2023-06-08T04:04:47Z","title":"Prefer to Classify: Improving Text Classifiers via Auxiliary Preference\n  Learning","summary":"  The development of largely human-annotated benchmarks has driven the success\nof deep neural networks in various NLP tasks. To enhance the effectiveness of\nexisting benchmarks, collecting new additional input-output pairs is often too\ncostly and challenging, particularly considering their marginal impact on\nimproving the current model accuracy. Instead, additional or complementary\nannotations on the existing input texts in the benchmarks can be preferable as\nan efficient way to pay the additional human cost. In this paper, we\ninvestigate task-specific preferences between pairs of input texts as a new\nalternative way for such auxiliary data annotation. From 'pair-wise'\ncomparisons with respect to the task, the auxiliary preference learning enables\nthe model to learn an additional informative training signal that cannot be\ncaptured with 'instance-wise' task labels. To this end, we propose a novel\nmulti-task learning framework, called prefer-to-classify (P2C), which can enjoy\nthe cooperative effect of learning both the given classification task and the\nauxiliary preferences. Here, we provide three different ways to collect\npreference signals in practice: (a) implicitly extracting from annotation\nrecords (for free, but often unavailable), (b) collecting explicitly from crowd\nworkers (high paid), or (c) pre-trained large language models such as GPT-3\n(low paid). Given existing classification NLP benchmarks, we demonstrate that\nthe proposed auxiliary preference learning via P2C on them is effective in\nimproving text classifiers. Our codes are publicly available.\n","authors":["Jaehyung Kim","Jinwoo Shin","Dongyeop Kang"],"pdf_url":"https://arxiv.org/pdf/2306.04925v1.pdf","comment":"22 pages, accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2305.18486v3","updated":"2023-06-08T03:27:16Z","published":"2023-05-29T12:37:21Z","title":"A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark\n  Datasets","summary":"  The development of large language models (LLMs) such as ChatGPT has brought a\nlot of attention recently. However, their evaluation in the benchmark academic\ndatasets remains under-explored due to the difficulty of evaluating the\ngenerative outputs produced by this model against the ground truth. In this\npaper, we aim to present a thorough evaluation of ChatGPT's performance on\ndiverse academic datasets, covering tasks like question-answering, text\nsummarization, code generation, commonsense reasoning, mathematical\nproblem-solving, machine translation, bias detection, and ethical\nconsiderations. Specifically, we evaluate ChatGPT across 140 tasks and analyze\n255K responses it generates in these datasets. This makes our work the largest\nevaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate\nthe strengths and weaknesses of ChatGPT in various tasks and provide insights\nfor future research using LLMs. We also report a new emergent ability to follow\nmulti-query instructions that we mostly found in ChatGPT and other\ninstruction-tuned models. Our extensive evaluation shows that even though\nChatGPT is capable of performing a wide variety of tasks, and may obtain\nimpressive performance in several benchmark datasets, it is still far from\nachieving the ability to reliably solve many challenging tasks. By providing a\nthorough assessment of ChatGPT's performance across diverse NLP tasks, this\npaper sets the stage for a targeted deployment of ChatGPT-like LLMs in\nreal-world applications.\n","authors":["Md Tahmid Rahman Laskar","M Saiful Bari","Mizanur Rahman","Md Amran Hossen Bhuiyan","Shafiq Joty","Jimmy Xiangji Huang"],"pdf_url":"https://arxiv.org/pdf/2305.18486v3.pdf","comment":"Accepted by ACL 2023 Findings. The first three authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2306.04903v1","updated":"2023-06-08T03:10:49Z","published":"2023-06-08T03:10:49Z","title":"NOWJ at COLIEE 2023 -- Multi-Task and Ensemble Approaches in Legal\n  Information Processing","summary":"  This paper presents the NOWJ team's approach to the COLIEE 2023 Competition,\nwhich focuses on advancing legal information processing techniques and applying\nthem to real-world legal scenarios. Our team tackles the four tasks in the\ncompetition, which involve legal case retrieval, legal case entailment, statute\nlaw retrieval, and legal textual entailment. We employ state-of-the-art machine\nlearning models and innovative approaches, such as BERT, Longformer,\nBM25-ranking algorithm, and multi-task learning models. Although our team did\nnot achieve state-of-the-art results, our findings provide valuable insights\nand pave the way for future improvements in legal information processing.\n","authors":["Thi-Hai-Yen Vuong","Hai-Long Nguyen","Tan-Minh Nguyen","Hoang-Trung Nguyen","Thai-Binh Nguyen","Ha-Thanh Nguyen"],"pdf_url":"https://arxiv.org/pdf/2306.04903v1.pdf","comment":"COLIEE 2023"},{"id":"http://arxiv.org/abs/2110.15317v4","updated":"2023-06-08T02:43:02Z","published":"2021-10-28T17:31:51Z","title":"Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial\n  Attack Framework","summary":"  Despite recent success on various tasks, deep learning techniques still\nperform poorly on adversarial examples with small perturbations. While\noptimization-based methods for adversarial attacks are well-explored in the\nfield of computer vision, it is impractical to directly apply them in natural\nlanguage processing due to the discrete nature of the text. To address the\nproblem, we propose a unified framework to extend the existing\noptimization-based adversarial attack methods in the vision domain to craft\ntextual adversarial samples. In this framework, continuously optimized\nperturbations are added to the embedding layer and amplified in the forward\npropagation process. Then the final perturbed latent representations are\ndecoded with a masked language model head to obtain potential adversarial\nsamples. In this paper, we instantiate our framework with an attack algorithm\nnamed Textual Projected Gradient Descent (T-PGD). We find our algorithm\neffective even using proxy gradient information. Therefore, we perform the more\nchallenging transfer black-box attack and conduct comprehensive experiments to\nevaluate our attack algorithm with several models on three benchmark datasets.\nExperimental results demonstrate that our method achieves overall better\nperformance and produces more fluent and grammatical adversarial samples\ncompared to strong baseline methods. The code and data are available at\n\\url{https://github.com/Phantivia/T-PGD}.\n","authors":["Lifan Yuan","Yichi Zhang","Yangyi Chen","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2110.15317v4.pdf","comment":"Accepted to Findings of ACL 2023. Codes are available at:\n  https://github.com/Phantivia/T-PGD"},{"id":"http://arxiv.org/abs/2306.04891v1","updated":"2023-06-08T02:38:23Z","published":"2023-06-08T02:38:23Z","title":"In-Context Learning through the Bayesian Prism","summary":"  In-context learning is one of the surprising and useful features of large\nlanguage models. How it works is an active area of research. Recently, stylized\nmeta-learning-like setups have been devised that train these models on a\nsequence of input-output pairs $(x, f(x))$ from a function class using the\nlanguage modeling loss and observe generalization to unseen functions from the\nsame class. One of the main discoveries in this line of research has been that\nfor several problems such as linear regression, trained transformers learn\nalgorithms for learning functions in context. However, the inductive biases of\nthese models resulting in this behavior are not clearly understood. A model\nwith unlimited training data and compute is a Bayesian predictor: it learns the\npretraining distribution. It has been shown that high-capacity transformers\nmimic the Bayesian predictor for linear regression. In this paper, we show\nempirical evidence of transformers exhibiting the behavior of this ideal\nlearner across different linear and non-linear function classes. We also extend\nthe previous setups to work in the multitask setting and verify that\ntransformers can do in-context learning in this setup as well and the Bayesian\nperspective sheds light on this setting also. Finally, via the example of\nlearning Fourier series, we study the inductive bias for in-context learning.\nWe find that in-context learning may or may not have simplicity bias depending\non the pretraining data distribution.\n","authors":["Kabir Ahuja","Madhur Panwar","Navin Goyal"],"pdf_url":"https://arxiv.org/pdf/2306.04891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01337v2","updated":"2023-06-08T02:34:35Z","published":"2023-06-02T08:02:15Z","title":"An Empirical Study on Challenging Math Problem Solving with GPT-4","summary":"  Employing Large Language Models (LLMs) to address mathematical problems is an\nintriguing research endeavor, considering the abundance of math problems\nexpressed in natural language across numerous science and engineering fields.\nWhile several prior works have investigated solving elementary mathematics\nusing LLMs, this work explores the frontier of using GPT-4 for solving more\ncomplex and challenging math problems. We evaluate various ways of using GPT-4.\nSome of them are adapted from existing work, and one is MathChat, a\nconversational problem-solving framework newly proposed in this work. We\nperform the evaluation on difficult high school competition problems from the\nMATH dataset, which shows the advantage of the proposed conversational\napproach.\n","authors":["Yiran Wu","Feiran Jia","Shaokun Zhang","Hangyu Li","Erkang Zhu","Yue Wang","Yin Tat Lee","Richard Peng","Qingyun Wu","Chi Wang"],"pdf_url":"https://arxiv.org/pdf/2306.01337v2.pdf","comment":"Fix minor errors, update github link"},{"id":"http://arxiv.org/abs/2305.08714v2","updated":"2023-06-08T02:14:20Z","published":"2023-05-15T15:19:08Z","title":"Sensitivity and Robustness of Large Language Models to Prompt Template\n  in Japanese Text Classification Tasks","summary":"  Prompt engineering relevance research has seen a notable surge in recent\nyears, primarily driven by advancements in pre-trained language models and\nlarge language models. However, a critical issue has been identified within\nthis domain: the inadequate of sensitivity and robustness of these models\ntowards Prompt Templates, particularly in lesser-studied languages such as\nJapanese. This paper explores this issue through a comprehensive evaluation of\nseveral representative Large Language Models (LLMs) and a widely-utilized\npre-trained model(PLM). These models are scrutinized using a benchmark dataset\nin Japanese, with the aim to assess and analyze the performance of the current\nmultilingual models in this context. Our experimental results reveal startling\ndiscrepancies. A simple modification in the sentence structure of the Prompt\nTemplate led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44.\nThis observation underscores the fact that even the highly performance GPT-4\nmodel encounters significant stability issues when dealing with diverse\nJapanese prompt templates, rendering the consistency of the model's output\nresults questionable. In light of these findings, we conclude by proposing\npotential research trajectories to further enhance the development and\nperformance of Large Language Models in their current stage.\n","authors":["Chengguang Gan","Tatsunori Mori"],"pdf_url":"https://arxiv.org/pdf/2305.08714v2.pdf","comment":"Under Review. 11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.04874v1","updated":"2023-06-08T02:07:49Z","published":"2023-06-08T02:07:49Z","title":"Expanding Scope: Adapting English Adversarial Attacks to Chinese","summary":"  Recent studies have revealed that NLP predictive models are vulnerable to\nadversarial attacks. Most existing studies focused on designing attacks to\nevaluate the robustness of NLP models in the English language alone. Literature\nhas seen an increasing need for NLP solutions for other languages. We,\ntherefore, ask one natural question: whether state-of-the-art (SOTA) attack\nmethods generalize to other languages. This paper investigates how to adapt\nSOTA adversarial attack algorithms in English to the Chinese language. Our\nexperiments show that attack methods previously applied to English NLP can\ngenerate high-quality adversarial examples in Chinese when combined with proper\ntext segmentation and linguistic constraints. In addition, we demonstrate that\nthe generated adversarial examples can achieve high fluency and semantic\nconsistency by focusing on the Chinese language's morphology and phonology,\nwhich in turn can be used to improve the adversarial robustness of Chinese NLP\nmodels.\n","authors":["Hanyu Liu","Chengyuan Cai","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2306.04874v1.pdf","comment":"11 pages; in ACL23 TrustNLP 2023: TrustNLP: Third Workshop on\n  Trustworthy Natural Language Processing Colocated with the Annual Conference\n  of the Association for Computational Linguistics (ACL 2023)"},{"id":"http://arxiv.org/abs/2304.03279v3","updated":"2023-06-08T02:04:23Z","published":"2023-04-06T17:59:03Z","title":"Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards\n  and Ethical Behavior in the MACHIAVELLI Benchmark","summary":"  Artificial agents have traditionally been trained to maximize reward, which\nmay incentivize power-seeking and deception, analogous to how next-token\nprediction in language models (LMs) may incentivize toxicity. So do agents\nnaturally learn to be Machiavellian? And how do we measure these behaviors in\ngeneral-purpose models such as GPT-4? Towards answering these questions, we\nintroduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games\ncontaining over half a million rich, diverse scenarios that center on social\ndecision-making. Scenario labeling is automated with LMs, which are more\nperformant than human annotators. We mathematize dozens of harmful behaviors\nand use our annotations to evaluate agents' tendencies to be power-seeking,\ncause disutility, and commit ethical violations. We observe some tension\nbetween maximizing reward and behaving ethically. To improve this trade-off, we\ninvestigate LM-based methods to steer agents' towards less harmful behaviors.\nOur results show that agents can both act competently and morally, so concrete\nprogress can currently be made in machine ethics--designing agents that are\nPareto improvements in both safety and capabilities.\n","authors":["Alexander Pan","Jun Shern Chan","Andy Zou","Nathaniel Li","Steven Basart","Thomas Woodside","Jonathan Ng","Hanlin Zhang","Scott Emmons","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2304.03279v3.pdf","comment":"ICML 2023 Oral (camera-ready); 31 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.04845v1","updated":"2023-06-08T00:35:36Z","published":"2023-06-08T00:35:36Z","title":"Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with\n  Architecture-Routed Mixture-of-Experts","summary":"  Weight-sharing supernet has become a vital component for performance\nestimation in the state-of-the-art (SOTA) neural architecture search (NAS)\nframeworks. Although supernet can directly generate different subnetworks\nwithout retraining, there is no guarantee for the quality of these subnetworks\nbecause of weight sharing. In NLP tasks such as machine translation and\npre-trained language modeling, we observe that given the same model\narchitecture, there is a large performance gap between supernet and training\nfrom scratch. Hence, supernet cannot be directly used and retraining is\nnecessary after finding the optimal architectures.\n  In this work, we propose mixture-of-supernets, a generalized supernet\nformulation where mixture-of-experts (MoE) is adopted to enhance the expressive\npower of the supernet model, with negligible training overhead. In this way,\ndifferent subnetworks do not share the model weights directly, but through an\narchitecture-based routing mechanism. As a result, model weights of different\nsubnetworks are customized towards their specific architectures and the weight\ngeneration is learned by gradient descent. Compared to existing weight-sharing\nsupernet for NLP, our method can minimize the retraining time, greatly\nimproving training efficiency. In addition, the proposed method achieves the\nSOTA performance in NAS for building fast machine translation models, yielding\nbetter latency-BLEU tradeoff compared to HAT, state-of-the-art NAS for MT. We\nalso achieve the SOTA performance in NAS for building memory-efficient\ntask-agnostic BERT models, outperforming NAS-BERT and AutoDistil in various\nmodel sizes.\n","authors":["Ganesh Jawahar","Haichuan Yang","Yunyang Xiong","Zechun Liu","Dilin Wang","Fei Sun","Meng Li","Aasish Pappu","Barlas Oguz","Muhammad Abdul-Mageed","Laks V. S. Lakshmanan","Raghuraman Krishnamoorthi","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2306.04845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04841v1","updated":"2023-06-08T00:24:29Z","published":"2023-06-08T00:24:29Z","title":"Improving Vietnamese Legal Question--Answering System based on Automatic\n  Data Enrichment","summary":"  Question answering (QA) in law is a challenging problem because legal\ndocuments are much more complicated than normal texts in terms of terminology,\nstructure, and temporal and logical relationships. It is even more difficult to\nperform legal QA for low-resource languages like Vietnamese where labeled data\nare rare and pre-trained language models are still limited. In this paper, we\ntry to overcome these limitations by implementing a Vietnamese article-level\nretrieval-based legal QA system and introduce a novel method to improve the\nperformance of language models by improving data quality through weak labeling.\nOur hypothesis is that in contexts where labeled data are limited, efficient\ndata enrichment can help increase overall performance. Our experiments are\ndesigned to test multiple aspects, which demonstrate the effectiveness of the\nproposed technique.\n","authors":["Thi-Hai-Yen Vuong","Ha-Thanh Nguyen","Quang-Huy Nguyen","Le-Minh Nguyen","Xuan-Hieu Phan"],"pdf_url":"https://arxiv.org/pdf/2306.04841v1.pdf","comment":"JURISIN 2023"},{"id":"http://arxiv.org/abs/2306.05596v1","updated":"2023-06-08T23:52:35Z","published":"2023-06-08T23:52:35Z","title":"LOST: A Mental Health Dataset of Low Self-esteem in Reddit Posts","summary":"  Low self-esteem and interpersonal needs (i.e., thwarted belongingness (TB)\nand perceived burdensomeness (PB)) have a major impact on depression and\nsuicide attempts. Individuals seek social connectedness on social media to\nboost and alleviate their loneliness. Social media platforms allow people to\nexpress their thoughts, experiences, beliefs, and emotions. Prior studies on\nmental health from social media have focused on symptoms, causes, and\ndisorders. Whereas an initial screening of social media content for\ninterpersonal risk factors and low self-esteem may raise early alerts and\nassign therapists to at-risk users of mental disturbance. Standardized scales\nmeasure self-esteem and interpersonal needs from questions created using\npsychological theories. In the current research, we introduce a\npsychology-grounded and expertly annotated dataset, LoST: Low Self esTeem, to\nstudy and detect low self-esteem on Reddit. Through an annotation approach\ninvolving checks on coherence, correctness, consistency, and reliability, we\nensure gold-standard for supervised learning. We present results from different\ndeep language models tested using two data augmentation techniques. Our\nfindings suggest developing a class of language models that infuses\npsychological and clinical knowledge.\n","authors":["Muskan Garg","Manas Gaur","Raxit Goswami","Sunghwan Sohn"],"pdf_url":"https://arxiv.org/pdf/2306.05596v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.10449v3","updated":"2023-06-08T22:43:58Z","published":"2022-12-20T17:27:10Z","title":"Socratic Pretraining: Question-Driven Pretraining for Controllable\n  Summarization","summary":"  In long document controllable summarization, where labeled data is scarce,\npretrained models struggle to adapt to the task and effectively respond to user\nqueries. In this paper, we introduce Socratic pretraining, a question-driven,\nunsupervised pretraining objective specifically designed to improve\ncontrollability in summarization tasks. By training a model to generate and\nanswer relevant questions in a given context, Socratic pretraining enables the\nmodel to more effectively adhere to user-provided queries and identify relevant\ncontent to be summarized. We demonstrate the effectiveness of this approach\nthrough extensive experimentation on two summarization domains, short stories\nand dialogue, and multiple control strategies: keywords, questions, and factoid\nQA pairs. Our pretraining method relies only on unlabeled documents and a\nquestion generation system and outperforms pre-finetuning approaches that use\nadditional supervised data. Furthermore, our results show that Socratic\npretraining cuts task-specific labeled data requirements in half, is more\nfaithful to user-provided queries, and achieves state-of-the-art performance on\nQMSum and SQuALITY.\n","authors":["Artidoro Pagnoni","Alexander R. Fabbri","Wojciech Kryściński","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2212.10449v3.pdf","comment":"To appear at ACL 2023"},{"id":"http://arxiv.org/abs/2305.03827v2","updated":"2023-06-08T22:22:24Z","published":"2023-05-05T20:06:11Z","title":"Uncertainty-Aware Bootstrap Learning for Joint Extraction on\n  Distantly-Supervised Data","summary":"  Jointly extracting entity pairs and their relations is challenging when\nworking on distantly-supervised data with ambiguous or noisy labels. To\nmitigate such impact, we propose uncertainty-aware bootstrap learning, which is\nmotivated by the intuition that the higher uncertainty of an instance, the more\nlikely the model confidence is inconsistent with the ground truths.\nSpecifically, we first explore instance-level data uncertainty to create an\ninitial high-confident examples. Such subset serves as filtering noisy\ninstances and facilitating the model to converge fast at the early stage.\nDuring bootstrap learning, we propose self-ensembling as a regularizer to\nalleviate inter-model uncertainty produced by noisy labels. We further define\nprobability variance of joint tagging probabilities to estimate inner-model\nparametric uncertainty, which is used to select and build up new reliable\ntraining instances for the next iteration. Experimental results on two large\ndatasets reveal that our approach outperforms existing strong baselines and\nrelated methods.\n","authors":["Yufei Li","Xiao Yu","Yanchi Liu","Haifeng Chen","Cong Liu"],"pdf_url":"https://arxiv.org/pdf/2305.03827v2.pdf","comment":"ACL 2023 main conference short paper"},{"id":"http://arxiv.org/abs/2304.13835v3","updated":"2023-06-08T21:45:46Z","published":"2023-04-26T21:41:17Z","title":"Multi-Party Chat: Conversational Agents in Group Settings with Humans\n  and Models","summary":"  Current dialogue research primarily studies pairwise (two-party)\nconversations, and does not address the everyday setting where more than two\nspeakers converse together. In this work, we both collect and evaluate\nmulti-party conversations to study this more general case. We use the LIGHT\nenvironment to construct grounded conversations, where each participant has an\nassigned character to role-play. We thus evaluate the ability of language\nmodels to act as one or more characters in such conversations. Models require\ntwo skills that pairwise-trained models appear to lack: (1) being able to\ndecide when to talk; (2) producing coherent utterances grounded on multiple\ncharacters. We compare models trained on our new dataset to existing\npairwise-trained dialogue models, as well as large language models with\nfew-shot prompting. We find that our new dataset, MultiLIGHT, which we will\npublicly release, can help bring significant improvements in the group setting.\n","authors":["Jimmy Wei","Kurt Shuster","Arthur Szlam","Jason Weston","Jack Urbanek","Mojtaba Komeili"],"pdf_url":"https://arxiv.org/pdf/2304.13835v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05561v1","updated":"2023-06-08T21:06:19Z","published":"2023-06-08T21:06:19Z","title":"Privacy- and Utility-Preserving NLP with Anonymized Data: A case study\n  of Pseudonymization","summary":"  This work investigates the effectiveness of different pseudonymization\ntechniques, ranging from rule-based substitutions to using pre-trained Large\nLanguage Models (LLMs), on a variety of datasets and models used for two widely\nused NLP tasks: text classification and summarization. Our work provides\ncrucial insights into the gaps between original and anonymized data (focusing\non the pseudonymization technique) and model quality and fosters future\nresearch into higher-quality anonymization techniques to better balance the\ntrade-offs between data protection and utility preservation. We make our code,\npseudonymized datasets, and downstream models publicly available\n","authors":["Oleksandr Yermilov","Vipul Raheja","Artem Chernodub"],"pdf_url":"https://arxiv.org/pdf/2306.05561v1.pdf","comment":"10 pages. Accepted for TrustNLP workshop at ACL2023"},{"id":"http://arxiv.org/abs/2306.05556v1","updated":"2023-06-08T20:59:40Z","published":"2023-06-08T20:59:40Z","title":"Emotion and Sentiment Guided Paraphrasing","summary":"  Paraphrase generation, a.k.a. paraphrasing, is a common and important task in\nnatural language processing. Emotional paraphrasing, which changes the emotion\nembodied in a piece of text while preserving its meaning, has many potential\napplications, including moderating online dialogues and preventing\ncyberbullying. We introduce a new task of fine-grained emotional paraphrasing\nalong emotion gradients, that is, altering the emotional intensities of the\nparaphrases in fine-grained settings following smooth variations in affective\ndimensions while preserving the meaning of the original text. We reconstruct\nseveral widely used paraphrasing datasets by augmenting the input and target\ntexts with their fine-grained emotion labels. Then, we propose a framework for\nemotion and sentiment guided paraphrasing by leveraging pre-trained language\nmodels for conditioned text generation. Extensive evaluation of the fine-tuned\nmodels suggests that including fine-grained emotion labels in the paraphrase\ntask significantly improves the likelihood of obtaining high-quality\nparaphrases that reflect the desired emotions while achieving consistently\nbetter scores in paraphrase metrics such as BLEU, ROUGE, and METEOR.\n","authors":["Justin J. Xie","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2306.05556v1.pdf","comment":"13th Workshop on Computational Approaches to Subjectivity, Sentiment\n  & Social Media Analysis (WASSA) 2023 at The 61st Annual Meeting of the\n  Association for Computational Linguistics (ACL) 2023. arXiv admin note:\n  substantial text overlap with arXiv:2212.03297"},{"id":"http://arxiv.org/abs/2306.05550v1","updated":"2023-06-08T20:46:09Z","published":"2023-06-08T20:46:09Z","title":"Bias Against 93 Stigmatized Groups in Masked Language Models and\n  Downstream Sentiment Classification Tasks","summary":"  The rapid deployment of artificial intelligence (AI) models demands a\nthorough investigation of biases and risks inherent in these models to\nunderstand their impact on individuals and society. This study extends the\nfocus of bias evaluation in extant work by examining bias against social\nstigmas on a large scale. It focuses on 93 stigmatized groups in the United\nStates, including a wide range of conditions related to disease, disability,\ndrug use, mental illness, religion, sexuality, socioeconomic status, and other\nrelevant factors. We investigate bias against these groups in English\npre-trained Masked Language Models (MLMs) and their downstream sentiment\nclassification tasks. To evaluate the presence of bias against 93 stigmatized\nconditions, we identify 29 non-stigmatized conditions to conduct a comparative\nanalysis. Building upon a psychology scale of social rejection, the Social\nDistance Scale, we prompt six MLMs: RoBERTa-base, RoBERTa-large, XLNet-large,\nBERTweet-base, BERTweet-large, and DistilBERT. We use human annotations to\nanalyze the predicted words from these models, with which we measure the extent\nof bias against stigmatized groups. When prompts include stigmatized\nconditions, the probability of MLMs predicting negative words is approximately\n20 percent higher than when prompts have non-stigmatized conditions. In the\nsentiment classification tasks, when sentences include stigmatized conditions\nrelated to diseases, disability, education, and mental illness, they are more\nlikely to be classified as negative. We also observe a strong correlation\nbetween bias in MLMs and their downstream sentiment classifiers (r =0.79). The\nevidence indicates that MLMs and their downstream sentiment classification\ntasks exhibit biases against socially stigmatized groups.\n","authors":["Katelyn X. Mei","Sonia Fereidooni","Aylin Caliskan"],"pdf_url":"https://arxiv.org/pdf/2306.05550v1.pdf","comment":"20 pages,12 figures,2 tables; ACM FAccT 2023"},{"id":"http://arxiv.org/abs/2306.05499v1","updated":"2023-06-08T18:43:11Z","published":"2023-06-08T18:43:11Z","title":"Prompt Injection attack against LLM-integrated Applications","summary":"  Large Language Models (LLMs), renowned for their superior proficiency in\nlanguage comprehension and generation, stimulate a vibrant ecosystem of\napplications around them. However, their extensive assimilation into various\nservices introduces significant security risks. This study deconstructs the\ncomplexities and implications of prompt injection attacks on actual\nLLM-integrated applications. Initially, we conduct an exploratory analysis on\nten commercial applications, highlighting the constraints of current attack\nstrategies in practice. Prompted by these limitations, we subsequently\nformulate HouYi, a novel black-box prompt injection attack technique, which\ndraws inspiration from traditional web injection attacks. HouYi is\ncompartmentalized into three crucial elements: a seamlessly-incorporated\npre-constructed prompt, an injection prompt inducing context partition, and a\nmalicious payload designed to fulfill the attack objectives. Leveraging HouYi,\nwe unveil previously unknown and severe attack outcomes, such as unrestricted\narbitrary LLM usage and uncomplicated application prompt theft. We deploy HouYi\non 36 actual LLM-integrated applications and discern 31 applications\nsusceptible to prompt injection. 10 vendors have validated our discoveries,\nincluding Notion, which has the potential to impact millions of users. Our\ninvestigation illuminates both the possible risks of prompt injection attacks\nand the possible tactics for mitigation.\n","authors":["Yi Liu","Gelei Deng","Yuekang Li","Kailong Wang","Tianwei Zhang","Yepang Liu","Haoyu Wang","Yan Zheng","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.05499v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07630v2","updated":"2023-06-08T18:33:28Z","published":"2022-02-15T18:22:18Z","title":"Delving Deeper into Cross-lingual Visual Question Answering","summary":"  Visual question answering (VQA) is one of the crucial vision-and-language\ntasks. Yet, existing VQA research has mostly focused on the English language,\ndue to a lack of suitable evaluation resources. Previous work on cross-lingual\nVQA has reported poor zero-shot transfer performance of current multilingual\nmultimodal Transformers with large gaps to monolingual performance, without any\ndeeper analysis. In this work, we delve deeper into the different aspects of\ncross-lingual VQA, aiming to understand the impact of 1) modeling methods and\nchoices, including architecture, inductive bias, fine-tuning; 2) learning\nbiases: including question types and modality biases in cross-lingual setups.\nThe key results of our analysis are: 1) We show that simple modifications to\nthe standard training setup can substantially reduce the transfer gap to\nmonolingual English performance, yielding +10 accuracy points over existing\nmethods. 2) We analyze cross-lingual VQA across different question types of\nvarying complexity for different multilingual multimodal Transformers, and\nidentify question types that are the most difficult to improve on. 3) We\nprovide an analysis of modality biases present in training data and models,\nrevealing why zero-shot performance gaps remain for certain question types and\nlanguages.\n","authors":["Chen Liu","Jonas Pfeiffer","Anna Korhonen","Ivan Vulić","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2202.07630v2.pdf","comment":"Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2109.08079v4","updated":"2023-06-08T18:33:01Z","published":"2021-09-16T16:10:05Z","title":"Context-NER : Contextual Phrase Generation at Scale","summary":"  Named Entity Recognition (NER) has seen significant progress in recent years,\nwith numerous state-of-the-art (SOTA) models achieving high performance.\nHowever, very few studies have focused on the generation of entities' context.\nIn this paper, we introduce CONTEXT-NER, a task that aims to generate the\nrelevant context for entities in a sentence, where the context is a phrase\ndescribing the entity but not necessarily present in the sentence. To\nfacilitate research in this task, we also present the EDGAR10-Q dataset, which\nconsists of annual and quarterly reports from the top 1500 publicly traded\ncompanies. The dataset is the largest of its kind, containing 1M sentences,\n2.8M entities, and an average of 35 tokens per sentence, making it a\nchallenging dataset. We propose a baseline approach that combines a phrase\ngeneration algorithm with inferencing using a 220M language model, achieving a\nROUGE-L score of 27% on the test split. Additionally, we perform a one-shot\ninference with ChatGPT, which obtains a 30% ROUGE-L, highlighting the\ndifficulty of the dataset. We also evaluate models such as T5 and BART, which\nachieve a maximum ROUGE-L of 49% after supervised finetuning on EDGAR10-Q. We\nalso find that T5-large, when pre-finetuned on EDGAR10-Q, achieve SOTA results\non downstream finance tasks such as Headline, FPB, and FiQA SA, outperforming\nvanilla version by 10.81 points. To our surprise, this 66x smaller\npre-finetuned model also surpasses the finance-specific LLM BloombergGPT-50B by\n15 points. We hope that our dataset and generated artifacts will encourage\nfurther research in this direction, leading to the development of more\nsophisticated language models for financial text analysis\n","authors":["Himanshu Gupta","Shreyas Verma","Santosh Mashetty","Swaroop Mishra"],"pdf_url":"https://arxiv.org/pdf/2109.08079v4.pdf","comment":"29 pages, 5 Figures, 2 AlgorithmS, 17 Tables. Accepted in NeurIPS\n  2022 - Efficient Natural Language and Speech Processing (ENLSP) Workshop"},{"id":"http://arxiv.org/abs/2212.10520v3","updated":"2023-06-08T18:03:43Z","published":"2022-12-20T18:35:21Z","title":"Privacy-Preserving Domain Adaptation of Semantic Parsers","summary":"  Task-oriented dialogue systems often assist users with personal or\nconfidential matters. For this reason, the developers of such a system are\ngenerally prohibited from observing actual usage. So how can they know where\nthe system is failing and needs more training data or new functionality? In\nthis work, we study ways in which realistic user utterances can be generated\nsynthetically, to help increase the linguistic and functional coverage of the\nsystem, without compromising the privacy of actual users. To this end, we\npropose a two-stage Differentially Private (DP) generation method which first\ngenerates latent semantic parses, and then generates utterances based on the\nparses. Our proposed approach improves MAUVE by 2.5$\\times$ and parse tree\nfunction type overlap by 1.3$\\times$ relative to current approaches for private\nsynthetic data generation, improving both on fluency and semantic coverage. We\nfurther validate our approach on a realistic domain adaptation task of adding\nnew functionality from private user data to a semantic parser, and show overall\ngains of 8.5% points in accuracy with the new feature.\n","authors":["Fatemehsadat Mireshghallah","Yu Su","Tatsunori Hashimoto","Jason Eisner","Richard Shin"],"pdf_url":"https://arxiv.org/pdf/2212.10520v3.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.05477v1","updated":"2023-06-08T18:02:07Z","published":"2023-06-08T18:02:07Z","title":"Hexatagging: Projective Dependency Parsing as Tagging","summary":"  We introduce a novel dependency parser, the hexatagger, that constructs\ndependency trees by tagging the words in a sentence with elements from a finite\nset of possible tags. In contrast to many approaches to dependency parsing, our\napproach is fully parallelizable at training time, i.e., the structure-building\nactions needed to build a dependency parse can be predicted in parallel to each\nother. Additionally, exact decoding is linear in time and space complexity.\nFurthermore, we derive a probabilistic dependency parser that predicts hexatags\nusing no more than a linear model with features from a pretrained language\nmodel, i.e., we forsake a bespoke architecture explicitly designed for the\ntask. Despite the generality and simplicity of our approach, we achieve\nstate-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test\nset. Additionally, our parser's linear time complexity and parallelism\nsignificantly improve computational efficiency, with a roughly 10-times\nspeed-up over previous state-of-the-art models during decoding.\n","authors":["Afra Amini","Tianyu Liu","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2306.05477v1.pdf","comment":"accepted at ACL 2023"},{"id":"http://arxiv.org/abs/2306.05446v1","updated":"2023-06-08T17:28:28Z","published":"2023-06-08T17:28:28Z","title":"Latent Phrase Matching for Dysarthric Speech","summary":"  Many consumer speech recognition systems are not tuned for people with speech\ndisabilities, resulting in poor recognition and user experience, especially for\nsevere speech differences. Recent studies have emphasized interest in\npersonalized speech models from people with atypical speech patterns. We\npropose a query-by-example-based personalized phrase recognition system that is\ntrained using small amounts of speech, is language agnostic, does not assume a\ntraditional pronunciation lexicon, and generalizes well across speech\ndifference severities. On an internal dataset collected from 32 people with\ndysarthria, this approach works regardless of severity and shows a 60%\nimprovement in recall relative to a commercial speech recognition system. On\nthe public EasyCall dataset of dysarthric speech, our approach improves\naccuracy by 30.5%. Performance degrades as the number of phrases increases, but\nconsistently outperforms ASR systems when trained with 50 unique phrases.\n","authors":["Colin Lea","Dianna Yee","Jaya Narain","Zifang Huang","Lauren Tooley","Jeffrey P. Bigham","Leah Findlater"],"pdf_url":"https://arxiv.org/pdf/2306.05446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05443v1","updated":"2023-06-08T14:20:29Z","published":"2023-06-08T14:20:29Z","title":"PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark\n  for Finance","summary":"  Although large language models (LLMs) has shown great performance on natural\nlanguage processing (NLP) in the financial domain, there are no publicly\navailable financial tailtored LLMs, instruction tuning datasets, and evaluation\nbenchmarks, which is critical for continually pushing forward the open-source\ndevelopment of financial artificial intelligence (AI). This paper introduces\nPIXIU, a comprehensive framework including the first financial LLM based on\nfine-tuning LLaMA with instruction data, the first instruction data with 136K\ndata samples to support the fine-tuning, and an evaluation benchmark with 5\ntasks and 9 datasets. We first construct the large-scale multi-task instruction\ndata considering a variety of financial tasks, financial document types, and\nfinancial data modalities. We then propose a financial LLM called FinMA by\nfine-tuning LLaMA with the constructed dataset to be able to follow\ninstructions for various financial tasks. To support the evaluation of\nfinancial LLMs, we propose a standardized benchmark that covers a set of\ncritical financial tasks, including five financial NLP tasks and one financial\nprediction task. With this benchmark, we conduct a detailed analysis of FinMA\nand several existing LLMs, uncovering their strengths and weaknesses in\nhandling critical financial tasks. The model, datasets, benchmark, and\nexperimental results are open-sourced to facilitate future research in\nfinancial AI.\n","authors":["Qianqian Xie","Weiguang Han","Xiao Zhang","Yanzhao Lai","Min Peng","Alejandro Lopez-Lira","Jimin Huang"],"pdf_url":"https://arxiv.org/pdf/2306.05443v1.pdf","comment":"12 pages, 1 figures"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2303.10243v2","updated":"2023-06-08T17:51:50Z","published":"2023-03-17T20:44:02Z","title":"Safety-Critical Control for Systems with Impulsive Actuators and Dwell\n  Time Constraints","summary":"  This paper presents extensions of control barrier function (CBF) and control\nLyapunov function (CLF) theory to systems wherein all actuators cause impulsive\nchanges to the state trajectory, and can only be used again after a minimum\ndwell time has elapsed. These rules define a hybrid system, wherein the\ncontroller must at each control cycle choose whether to remain on the current\nstate flow or to jump to a new trajectory. We first derive a sufficient\ncondition to render a specified set forward invariant using extensions of CBF\ntheory. We then derive related conditions to ensure asymptotic stability in\nsuch systems, and apply both conditions online in an optimization-based control\nlaw with aperiodic impulses. We simulate both results on a spacecraft docking\nproblem with multiple obstacles.\n","authors":["Joseph Breeden","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2303.10243v2.pdf","comment":"Accepted to IEEE Control Systems Letters, extended version includes\n  full proof of Corollary 1"},{"id":"http://arxiv.org/abs/2302.02607v2","updated":"2023-06-08T17:39:05Z","published":"2023-02-06T08:08:34Z","title":"Target-based Surrogates for Stochastic Optimization","summary":"  We consider minimizing functions for which it is expensive to compute the\n(possibly stochastic) gradient. Such functions are prevalent in reinforcement\nlearning, imitation learning and adversarial training. Our target optimization\nframework uses the (expensive) gradient computation to construct surrogate\nfunctions in a \\emph{target space} (e.g. the logits output by a linear model\nfor classification) that can be minimized efficiently. This allows for multiple\nparameter updates to the model, amortizing the cost of gradient computation. In\nthe full-batch setting, we prove that our surrogate is a global upper-bound on\nthe loss, and can be (locally) minimized using a black-box optimization\nalgorithm. We prove that the resulting majorization-minimization algorithm\nensures convergence to a stationary point of the loss. Next, we instantiate our\nframework in the stochastic setting and propose the $SSO$ algorithm, which can\nbe viewed as projected stochastic gradient descent in the target space. This\nconnection enables us to prove theoretical guarantees for $SSO$ when minimizing\nconvex functions. Our framework allows the use of standard stochastic\noptimization algorithms to construct surrogates which can be minimized by any\ndeterministic optimization method. To evaluate our framework, we consider a\nsuite of supervised learning and imitation learning problems. Our experiments\nindicate the benefits of target optimization and the effectiveness of $SSO$.\n","authors":["Jonathan Wilder Lavington","Sharan Vaswani","Reza Babanezhad","Mark Schmidt","Nicolas Le Roux"],"pdf_url":"https://arxiv.org/pdf/2302.02607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00392v5","updated":"2023-06-08T17:37:10Z","published":"2022-02-01T13:16:58Z","title":"On packing dijoins in digraphs and weighted digraphs","summary":"  Let $D=(V,A)$ be a digraph. A dicut is a cut $\\delta^+(U)\\subseteq A$ for\nsome nonempty proper vertex subset $U$ such that $\\delta^-(U)=\\emptyset$, a\ndijoin is an arc subset that intersects every dicut at least once, and more\ngenerally a $k$-dijoin is an arc subset that intersects every dicut at least\n$k$ times. Our first result is that $A$ can be partitioned into a dijoin and a\n$(\\tau-1)$-dijoin where $\\tau$ denotes the smallest size of a dicut. Woodall\nconjectured the stronger statement that $A$ can be partitioned into $\\tau$\ndijoins.\n  Let $w\\in \\mathbb{Z}^A_{\\geq 0}$ and suppose every dicut has weight at least\n$\\tau$, for some integer $\\tau\\geq 2$. Let\n$\\rho(\\tau,D,w):=\\frac{1}{\\tau}\\sum_{v\\in V} m_v$, where each $m_v$ is the\ninteger in $\\{0,1,\\ldots,\\tau-1\\}$ equal to $w(\\delta^+(v))-w(\\delta^-(v))$ mod\n$\\tau$. We prove the following results: (i) If $\\rho(\\tau,D,w)\\in \\{0,1\\}$,\nthen there is an equitable $w$-weighted packing of dijoins of size $\\tau$. (ii)\nIf $\\rho(\\tau,D,w)= 2$, then there is a $w$-weighted packing of dijoins of size\n$\\tau$. (iii) If $\\rho(\\tau,D,w)=3$, $\\tau=3$, and $w={\\bf 1}$, then $A$ can be\npartitioned into three dijoins.\n  Each result is best possible: (i) does not hold for $\\rho(\\tau,D,w)=2$ even\nif $w=\\1$, (ii) does not hold for $\\rho(\\tau,D,w)=3$, and (iii) do not hold for\ngeneral $w$.\n","authors":["Ahmad Abdi","Gérard Cornuéjols","Michael Zlatin"],"pdf_url":"https://arxiv.org/pdf/2202.00392v5.pdf","comment":"69 pages, 15 figures"},{"id":"http://arxiv.org/abs/2209.11809v2","updated":"2023-06-08T16:55:28Z","published":"2022-09-23T18:57:40Z","title":"Data-driven Optimal Computing Budget Allocation under Input Uncertainty","summary":"  In a fixed budget ranking and Selection (R&S) problem, one aims to identify\nthe best design among a finite number of candidates by efficiently allocating\nthe given simulation budget to evaluate design performance. Classical methods\nfor fixed budget R&S usually assume known input distributions, which are the\ndistributions that model the randomness in the system and drive the simulation.\nIn this paper, we consider the practical scenario where the input distribution\nis unknown but can be estimated from streaming input data that arrive in\nbatches over time. We model the R&S problem in this dynamic setting as a\nmulti-stage problem, where the input distribution estimate is updated at each\nstage and a stage-wise optimization problem is formulated to allocate the\nsimulation budget. We characterize the optimality conditions for the stage-wise\nbudget allocation problem by applying the large deviations theory to maximize\nthe decay rate of the probability of false selection. Based on the optimality\nconditions and combined with the updating of input distribution estimates, we\ndesign two sequential budget allocation procedures for R&S under streaming\ninput data. We theoretically guarantee the consistency and asymptotic\noptimality of the two proposed procedures. We also demonstrate the practical\nefficiency through numerical experiments in comparison with the equal\nallocation policy and two extensions of the Optimal Computing Budget Allocation\n(OCBA) algorithm.\n","authors":["Yuhao Wang","Enlu Zhou"],"pdf_url":"https://arxiv.org/pdf/2209.11809v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01968v2","updated":"2023-06-08T16:36:37Z","published":"2023-06-03T00:28:50Z","title":"End-of-Horizon Load Balancing Problems: Algorithms and Insights","summary":"  Effective load balancing is at the heart of many applications in operations.\nOften tackled via the balls-into-bins paradigm, seminal results have shown that\na limited amount of flexibility goes a long way in order to maintain\n(approximately) balanced loads throughout the decision-making horizon. This\npaper is motivated by the fact that balance across time is too stringent a\nrequirement for some applications; rather, the only desideratum is approximate\nbalance at the end of the horizon. In this work we design\n``limited-flexibility'' algorithms for three instantiations of the\nend-of-horizon balance problem: the balls-into-bins problem, opaque selling\nstrategies for inventory management, and parcel delivery for e-commerce\nfulfillment. For the balls-into-bins model, we show that a simple policy which\nbegins exerting flexibility toward the end of the time horizon (i.e., when\n$\\Theta\\left(\\sqrt{T\\log T}\\right)$ periods remain), suffices to achieve an\napproximately balanced load (i.e., a maximum load within ${O}(1)$ of the\naverage load). Moreover, with just a small amount of adaptivity, a threshold\npolicy achieves the same result, while only exerting flexibility in\n${O}\\left(\\sqrt{T}\\right)$ periods, matching a natural lower bound. We then\nadapt these algorithms to develop order-wise optimal policies for the opaque\nselling problem. Finally, we show via a data-driven case study that the\nadaptive policy designed for the balls-into-bins model can be modified to (i)\nachieve approximate balance at the end of the horizon and (ii) yield\nsignificant cost savings relative to policies which either never exert\nflexibility, or exert flexibility aggressively enough to achieve anytime\nbalance. The unifying motivation behind our algorithms is the observation that\nexerting flexibility at the beginning of the horizon is likely wasted when\nsystem balance is only evaluated at the end.\n","authors":["Daniel Freund","Chamsi Hssaine","Jiayu Kamessi Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.01968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05329v1","updated":"2023-06-08T16:28:53Z","published":"2023-06-08T16:28:53Z","title":"Movement Optimization of Robotic Arms for Energy and Time Reduction\n  using Evolutionary Algorithms","summary":"  Trajectory optimization of a robot manipulator consists of both optimization\nof the robot movement as well as optimization of the robot end-effector path.\nThis paper aims to find optimum movement parameters including movement type,\nspeed, and acceleration to minimize robot energy. Trajectory optimization by\nminimizing the energy would increase the longevity of robotic manipulators. We\nutilized the particle swarm optimization method to find the movement parameters\nleading to minimum energy consumption. The effectiveness of the proposed method\nis demonstrated on different trajectories. Experimental results show that 49%\nefficiency was obtained using a UR5 robotic arm.\n","authors":["Abolfazl Akbari","Saeed Mozaffari","Rajmeet Singh","Majid Ahmadi","Shahpour Alirezaee"],"pdf_url":"https://arxiv.org/pdf/2306.05329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.13244v4","updated":"2023-06-08T16:24:22Z","published":"2021-02-26T00:28:58Z","title":"Cyclic Coordinate Dual Averaging with Extrapolation","summary":"  Cyclic block coordinate methods are a fundamental class of optimization\nmethods widely used in practice and implemented as part of standard software\npackages for statistical learning. Nevertheless, their convergence is generally\nnot well understood and so far their good practical performance has not been\nexplained by existing convergence analyses. In this work, we introduce a new\nblock coordinate method that applies to the general class of variational\ninequality (VI) problems with monotone operators. This class includes composite\nconvex optimization problems and convex-concave min-max optimization problems\nas special cases and has not been addressed by the existing work. The resulting\nconvergence bounds match the optimal convergence bounds of full gradient\nmethods, but are provided in terms of a novel gradient Lipschitz condition\nw.r.t.~a Mahalanobis norm. For $m$ coordinate blocks, the resulting gradient\nLipschitz constant in our bounds is never larger than a factor $\\sqrt{m}$\ncompared to the traditional Euclidean Lipschitz constant, while it is possible\nfor it to be much smaller. Further, for the case when the operator in the VI\nhas finite-sum structure, we propose a variance reduced variant of our method\nwhich further decreases the per-iteration cost and has better convergence rates\nin certain regimes. To obtain these results, we use a gradient extrapolation\nstrategy that allows us to view a cyclic collection of block coordinate-wise\ngradients as one implicit gradient.\n","authors":["Chaobing Song","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2102.13244v4.pdf","comment":"27 pages, 2 figures. Accepted to SIAM Journal on Optimization.\n  Version prior to final copy editing"},{"id":"http://arxiv.org/abs/2203.07305v5","updated":"2023-06-08T14:22:25Z","published":"2022-03-14T17:07:26Z","title":"Branch-and-Bound Performance Estimation Programming: A Unified\n  Methodology for Constructing Optimal Optimization Methods","summary":"  We present the Branch-and-Bound Performance Estimation Programming (BnB-PEP),\na unified methodology for constructing optimal first-order methods for convex\nand nonconvex optimization. BnB-PEP poses the problem of finding the optimal\noptimization method as a nonconvex but practically tractable quadratically\nconstrained quadratic optimization problem and solves it to certifiable global\noptimality using a customized branch-and-bound algorithm. By directly\nconfronting the nonconvexity, BnB-PEP offers significantly more flexibility and\nremoves the many limitations of the prior methodologies. Our customized\nbranch-and-bound algorithm, through exploiting specific problem structures,\noutperforms the latest off-the-shelf implementations by orders of magnitude,\naccelerating the solution time from hours to seconds and weeks to minutes. We\napply BnB-PEP to several setups for which the prior methodologies do not apply\nand obtain methods with bounds that improve upon prior state-of-the-art\nresults. Finally, we use the BnB-PEP methodology to find proofs with potential\nfunction structures, thereby systematically generating analytical convergence\nproofs.\n","authors":["Shuvomoy Das Gupta","Bart P. G. Van Parys","Ernest K. Ryu"],"pdf_url":"https://arxiv.org/pdf/2203.07305v5.pdf","comment":"Published in Mathematical Programming Series A"},{"id":"http://arxiv.org/abs/2306.05187v1","updated":"2023-06-08T13:38:11Z","published":"2023-06-08T13:38:11Z","title":"Safe Adaptive Multi-Agent Coverage Control","summary":"  This paper presents a safe adaptive coverage controller for multi-agent\nsystems with actuator faults and time-varying uncertainties. The centroidal\nVoronoi tessellation (CVT) is applied to generate an optimal configuration of\nmulti-agent systems for covering an area of interest. As a conventional\nCVT-based controller cannot prevent collisions between agents with non-zero\nsize, a control barrier function (CBF) based controller is developed to ensure\ncollision avoidance with a function approximation technique (FAT) based design\nto deal with system uncertainties. The proposed controller is verified under\nsimulations.\n","authors":["Yang Bai","Yujie Wang","Xiaogang Xiong","Mikhail Svinin"],"pdf_url":"https://arxiv.org/pdf/2306.05187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05185v1","updated":"2023-06-08T13:33:20Z","published":"2023-06-08T13:33:20Z","title":"On the Identification and Optimization of Nonsmooth Superposition\n  Operators in Semilinear Elliptic PDEs","summary":"  We study an infinite-dimensional optimization problem that aims to identify\nthe Nemytskii operator in the nonlinear part of a prototypical semilinear\nelliptic partial differential equation (PDE) which minimizes the distance\nbetween the PDE-solution and a given desired state. In contrast to previous\nworks, we consider this identification problem in a low-regularity regime in\nwhich the function inducing the Nemytskii operator is a-priori only known to be\nan element of $H^1_{loc}(\\mathbb{R})$. This makes the studied problem class a\nsuitable point of departure for the rigorous analysis of training problems for\nlearning-informed PDEs in which an unknown superposition operator is\napproximated by means of a neural network with nonsmooth activation functions\n(ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of the\ncontrols, it is possible to derive a classical stationarity system for local\nminimizers and to solve the considered problem by means of a gradient\nprojection method. The convergence of the resulting algorithm is proven in the\nfunction space setting. It is also shown that the established first-order\nnecessary optimality conditions imply that locally optimal superposition\noperators share various characteristic properties with commonly used activation\nfunctions: They are always sigmoidal, continuously differentiable away from the\norigin, and typically possess a distinct kink at zero. The paper concludes with\nnumerical experiments which confirm the theoretical findings.\n","authors":["Constantin Christof","Julia Kowalczyk"],"pdf_url":"https://arxiv.org/pdf/2306.05185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05150v1","updated":"2023-06-08T12:18:18Z","published":"2023-06-08T12:18:18Z","title":"Bayesian Optimization of Expensive Nested Grey-Box Functions","summary":"  We consider the problem of optimizing a grey-box objective function, i.e.,\nnested function composed of both black-box and white-box functions. A general\nformulation for such grey-box problems is given, which covers the existing\ngrey-box optimization formulations as special cases. We then design an\noptimism-driven algorithm to solve it. Under certain regularity assumptions,\nour algorithm achieves similar regret bound as that for the standard black-box\nBayesian optimization algorithm, up to a constant multiplicative term depending\non the Lipschitz constants of the functions considered. We further extend our\nmethod to the constrained case and discuss several special cases. For the\ncommonly used kernel functions, the regret bounds allow us to derive a\nconvergence rate to the optimal solution. Experimental results show that our\ngrey-box optimization method empirically improves the speed of finding the\nglobal optimal solution significantly, as compared to the standard black-box\noptimization algorithm.\n","authors":["Wenjie Xu","Yuning Jiang","Bratislav Svetozarevic","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2306.05150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.08841v2","updated":"2023-06-08T11:53:51Z","published":"2023-05-15T17:55:24Z","title":"A Theoretical Analysis of Optimistic Proximal Policy Optimization in\n  Linear Markov Decision Processes","summary":"  The proximal policy optimization (PPO) algorithm stands as one of the most\nprosperous methods in the field of reinforcement learning (RL). Despite its\nsuccess, the theoretical understanding of PPO remains deficient. Specifically,\nit is unclear whether PPO or its optimistic variants can effectively solve\nlinear Markov decision processes (MDPs), which are arguably the simplest models\nin RL with function approximation. To bridge this gap, we propose an optimistic\nvariant of PPO for episodic adversarial linear MDPs with full-information\nfeedback, and establish a $\\tilde{\\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for\nit. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each\nepisode, and $K$ is the number of episodes. Compared with existing policy-based\nalgorithms, we achieve the state-of-the-art regret bound in both stochastic\nlinear MDPs and adversarial linear MDPs with full information. Additionally,\nour algorithm design features a novel multi-batched updating mechanism and the\ntheoretical analysis utilizes a new covering number argument of value and\npolicy classes, which might be of independent interest.\n","authors":["Han Zhong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.08841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09201v3","updated":"2023-06-08T11:49:50Z","published":"2022-10-17T15:57:16Z","title":"On the optimal control of kinetic epidemic models with uncertain social\n  features","summary":"  It is recognized that social heterogeneities in terms of the contact\ndistribution have a strong influence on the spread of infectious diseases.\nNevertheless, few data are available on the group composition of social\ncontacts, and their statistical description does not possess universal patterns\nand may vary spatially and temporally. It is therefore essential to design\nrobust control strategies, mimicking the effects of non-pharmaceutical\ninterventions, to limit efficiently the number of infected cases. In this work,\nstarting from a recently introduced kinetic model for epidemiological dynamics\nthat takes into account the impact of social contacts of individuals, we\nconsider an uncertain contact formation dynamics leading to slim-tailed as well\nas fat-tailed distributions of contacts. Hence, we analyse the effects of an\noptimally robust control strategy of the system of agents. Thanks to classical\nmethods of kinetic theory, we couple uncertainty quantification methods with\nthe introduced mathematical model to assess the effects of social limitations.\nFinally, using the proposed modelling approach and starting from available\ndata, we show the effectiveness of the proposed selective measures to dampen\nuncertainties together with the epidemic trends.\n","authors":["Jonathan Franceschi","Andrea Medaglia","Mattia Zanella"],"pdf_url":"https://arxiv.org/pdf/2210.09201v3.pdf","comment":"32 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.05113v1","updated":"2023-06-08T11:27:10Z","published":"2023-06-08T11:27:10Z","title":"Zero-sum stopper vs. singular-controller games with constrained control\n  directions","summary":"  We consider a class of zero-sum stopper vs.\\ singular-controller games in\nwhich the controller can only act on a subset $d_0<d$ of the $d$ coordinates of\na controlled diffusion. Due to the constraint on the control directions these\ngames fall outside the framework of recently studied variational methods. In\nthis paper we develop an approximation procedure, based on $L^1$-stability\nestimates for the controlled diffusion process and almost sure convergence of\nsuitable stopping times. That allows us to prove existence of the game's value\nand to obtain an optimal strategy for the stopper, under continuity and growth\nconditions on the payoff functions. This class of games is a natural extension\nof (single-agent) singular control problems, studied in the literature, with\nsimilar constraints on the admissible controls.\n","authors":["Andrea Bovo","Tiziano De Angelis","Jan Palczewski"],"pdf_url":"https://arxiv.org/pdf/2306.05113v1.pdf","comment":"30"},{"id":"http://arxiv.org/abs/2306.05100v1","updated":"2023-06-08T10:58:46Z","published":"2023-06-08T10:58:46Z","title":"Communication-Efficient Gradient Descent-Accent Methods for Distributed\n  Variational Inequalities: Unified Analysis and Local Updates","summary":"  Distributed and federated learning algorithms and techniques associated\nprimarily with minimization problems. However, with the increase of minimax\noptimization and variational inequality problems in machine learning, the\nnecessity of designing efficient distributed/federated learning approaches for\nthese problems is becoming more apparent. In this paper, we provide a unified\nconvergence analysis of communication-efficient local training methods for\ndistributed variational inequality problems (VIPs). Our approach is based on a\ngeneral key assumption on the stochastic estimates that allows us to propose\nand analyze several novel local training algorithms under a single framework\nfor solving a class of structured non-monotone VIPs. We present the first local\ngradient descent-accent algorithms with provable improved communication\ncomplexity for solving distributed variational inequalities on heterogeneous\ndata. The general algorithmic framework recovers state-of-the-art algorithms\nand their sharp convergence guarantees when the setting is specialized to\nminimization or minimax optimization problems. Finally, we demonstrate the\nstrong performance of the proposed algorithms compared to state-of-the-art\nmethods when solving federated minimax optimization problems.\n","authors":["Siqi Zhang","Sayantan Choudhury","Sebastian U Stich","Nicolas Loizou"],"pdf_url":"https://arxiv.org/pdf/2306.05100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.12018v2","updated":"2023-06-08T10:13:18Z","published":"2021-12-22T16:45:37Z","title":"Semismoothness for Solution Operators of Obstacle-Type Variational\n  Inequalities with Applications in Optimal Control","summary":"  We prove that solution operators of elliptic obstacle-type variational\ninequalities (or, more generally, locally Lipschitz continuous functions\npossessing certain pointwise-a.e. convexity properties) are Newton\ndifferentiable when considered as maps between suitable Lebesgue spaces and\nequipped with the strong-weak Bouligand differential as a generalized\nset-valued derivative. It is shown that this Newton differentiability allows to\nsolve optimal control problems with H1-cost terms and one-sided pointwise\ncontrol constraints by means of a semismooth Newton method. The superlinear\nconvergence of the resulting algorithm is proved in the infinite-dimensional\nsetting and its mesh independence is demonstrated in numerical experiments. We\nexpect that the findings of this paper are also helpful for the design of\nnumerical solution procedures for quasi-variational inequalities and the\noptimal control of obstacle-type variational problems.\n","authors":["Constantin Christof","Gerd Wachsmuth"],"pdf_url":"https://arxiv.org/pdf/2112.12018v2.pdf","comment":"Minor revisions. Published in SIAM Journal on Control and\n  Optimization, Vol. 61, Iss. 3 (2023)"},{"id":"http://arxiv.org/abs/2211.14104v2","updated":"2023-06-08T09:19:03Z","published":"2022-11-25T13:37:02Z","title":"Efficient sample selection for safe learning","summary":"  Ensuring safety in industrial control systems usually involves imposing\nconstraints at the design stage of the control algorithm. Enforcing constraints\nis challenging if the underlying functional form is unknown. The challenge can\nbe addressed by using surrogate models, such as Gaussian processes, which\nprovide confidence intervals used to find solutions that can be considered\nsafe. This in turn involves an exhaustive search on the entire search space.\nThat approach can quickly become computationally expensive. We reformulate the\nexhaustive search as a series of optimization problems to find the next\nrecommended points. We show that the proposed reformulation allows using a wide\nrange of available optimization solvers, such as derivative-free methods. We\nshow that by exploiting the properties of the solver, we enable the\nintroduction of new stopping criteria into safe learning methods and increase\nflexibility in trading off solver accuracy and computational time. The results\nfrom a non-convex optimization problem and an application for controller tuning\nconfirm the flexibility and the performance of the proposed reformulation.\n","authors":["Marta Zagorowska","Efe C. Balta","Varsha Behrunani","Alisa Rupenyan","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2211.14104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.14145v4","updated":"2023-06-08T09:12:26Z","published":"2022-04-29T15:06:16Z","title":"Automatic Scenario Generation for Robust Optimal Control Problems","summary":"  Existing methods for nonlinear robust control often use scenario-based\napproaches to formulate the control problem as nonlinear optimization problems.\nIncreasing the number of scenarios improves robustness, while increasing the\nsize of the optimization problems. Mitigating the size of the problem by\nreducing the number of scenarios requires knowledge about how the uncertainty\naffects the system. This paper draws from local reduction methods used in\nsemi-infinite optimization to solve robust optimal control problems with\nparametric uncertainty. We show that nonlinear robust optimal control problems\nare equivalent to semi-infinite optimization problems and can be solved by\nlocal reduction. By iteratively adding interim globally worst-case scenarios to\nthe problem, methods based on local reduction provide a way to manage the total\nnumber of scenarios. In particular, we show that local reduction methods find\nworst case scenarios that are not on the boundary of the uncertainty set. The\nproposed approach is illustrated with a case study with both parametric and\nadditive time-varying uncertainty. The number of scenarios obtained from local\nreduction is 101, smaller than in the case when all $2^{14+3\\times192}$\nboundary scenarios are considered. A validation with randomly drawn scenarios\nshows that our proposed approach reduces the number of scenarios and ensures\nrobustness even if local solvers are used.\n","authors":["Marta Zagorowska","Paola Falugi","Edward O'Dwyer","Eric C. Kerrigan"],"pdf_url":"https://arxiv.org/pdf/2204.14145v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02511v2","updated":"2023-06-08T08:20:26Z","published":"2023-01-06T13:51:25Z","title":"Stochastic Primal Dual Hybrid Gradient Algorithm with Adaptive\n  Step-Sizes","summary":"  In this work we propose a new primal-dual algorithm with adaptive step-sizes.\nThe stochastic primal-dual hybrid gradient (SPDHG) algorithm with constant\nstep-sizes has become widely applied in large-scale convex optimization across\nmany scientific fields due to its scalability. While the product of the primal\nand dual step-sizes is subject to an upper-bound in order to ensure\nconvergence, the selection of the ratio of the step-sizes is critical in\napplications. Up-to-now there is no systematic and successful way of selecting\nthe primal and dual step-sizes for SPDHG. In this work, we propose a general\nclass of adaptive SPDHG (A-SPDHG) algorithms, and prove their convergence under\nweak assumptions. We also propose concrete parameters-updating strategies which\nsatisfy the assumptions of our theory and thereby lead to convergent\nalgorithms. Numerical examples on computed tomography demonstrate the\neffectiveness of the proposed schemes.\n","authors":["Antonin Chambolle","Claire Delplancke","Matthias J. Ehrhardt","Carola-Bibiane Schönlieb","Junqi Tang"],"pdf_url":"https://arxiv.org/pdf/2301.02511v2.pdf","comment":"28 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.12601v2","updated":"2023-06-08T07:47:46Z","published":"2023-01-30T01:22:31Z","title":"Regret Bounds for Markov Decision Processes with Recursive Optimized\n  Certainty Equivalents","summary":"  The optimized certainty equivalent (OCE) is a family of risk measures that\ncover important examples such as entropic risk, conditional value-at-risk and\nmean-variance models. In this paper, we propose a new episodic risk-sensitive\nreinforcement learning formulation based on tabular Markov decision processes\nwith recursive OCEs. We design an efficient learning algorithm for this problem\nbased on value iteration and upper confidence bound. We derive an upper bound\non the regret of the proposed algorithm, and also establish a minimax lower\nbound. Our bounds show that the regret rate achieved by our proposed algorithm\nhas optimal dependence on the number of episodes and the number of actions.\n","authors":["Wenhao Xu","Xuefeng Gao","Xuedong He"],"pdf_url":"https://arxiv.org/pdf/2301.12601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04961v1","updated":"2023-06-08T06:35:47Z","published":"2023-06-08T06:35:47Z","title":"Recovering Simultaneously Structured Data via Non-Convex Iteratively\n  Reweighted Least Squares","summary":"  We propose a new algorithm for the problem of recovering data that adheres to\nmultiple, heterogeneous low-dimensional structures from linear observations.\nFocusing on data matrices that are simultaneously row-sparse and low-rank, we\npropose and analyze an iteratively reweighted least squares (IRLS) algorithm\nthat is able to leverage both structures. In particular, it optimizes a\ncombination of non-convex surrogates for row-sparsity and rank, a balancing of\nwhich is built into the algorithm. We prove locally quadratic convergence of\nthe iterates to a simultaneously structured data matrix in a regime of minimal\nsample complexity (up to constants and a logarithmic factor), which is known to\nbe impossible for a combination of convex surrogates. In experiments, we show\nthat the IRLS method exhibits favorable empirical convergence, identifying\nsimultaneously row-sparse and low-rank matrices from fewer measurements than\nstate-of-the-art methods.\n","authors":["Christian Kümmerle","Johannes Maly"],"pdf_url":"https://arxiv.org/pdf/2306.04961v1.pdf","comment":"35 pages, 6 figures"},{"id":"http://arxiv.org/abs/2012.06951v5","updated":"2023-06-08T05:58:43Z","published":"2020-12-13T03:41:52Z","title":"Attentional-Biased Stochastic Gradient Descent","summary":"  In this paper, we present a simple yet effective provable method (named\nABSGD) for addressing the data imbalance or label noise problem in deep\nlearning. Our method is a simple modification to momentum SGD where we assign\nan individual importance weight to each sample in the mini-batch. The\nindividual-level weight of sampled data is systematically proportional to the\nexponential of a scaled loss value of the data, where the scaling factor is\ninterpreted as the regularization parameter in the framework of\ndistributionally robust optimization (DRO). Depending on whether the scaling\nfactor is positive or negative, ABSGD is guaranteed to converge to a stationary\npoint of an information-regularized min-max or min-min DRO problem,\nrespectively. Compared with existing class-level weighting schemes, our method\ncan capture the diversity between individual examples within each class.\nCompared with existing individual-level weighting methods using meta-learning\nthat require three backward propagations for computing mini-batch stochastic\ngradients, our method is more efficient with only one backward propagation at\neach iteration as in standard deep learning methods. ABSGD is flexible enough\nto combine with other robust losses without any additional cost. Our empirical\nstudies on several benchmark datasets demonstrate the effectiveness of the\nproposed method.\\footnote{Code is available\nat:\\url{https://github.com/qiqi-helloworld/ABSGD/}}\n","authors":["Qi Qi","Yi Xu","Rong Jin","Wotao Yin","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2012.06951v5.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2110.02398v6","updated":"2023-06-08T04:57:49Z","published":"2021-10-05T23:07:12Z","title":"Approximate Newton policy gradient algorithms","summary":"  Policy gradient algorithms have been widely applied to Markov decision\nprocesses and reinforcement learning problems in recent years. Regularization\nwith various entropy functions is often used to encourage exploration and\nimprove stability. This paper proposes an approximate Newton method for the\npolicy gradient algorithm with entropy regularization. In the case of Shannon\nentropy, the resulting algorithm reproduces the natural policy gradient\nalgorithm. For other entropy functions, this method results in brand-new policy\ngradient algorithms. We prove that all these algorithms enjoy Newton-type\nquadratic convergence and that the corresponding gradient flow converges\nglobally to the optimal solution. We use synthetic and industrial-scale\nexamples to demonstrate that the proposed approximate Newton method typically\nconverges in single-digit iterations, often orders of magnitude faster than\nother state-of-the-art algorithms.\n","authors":["Haoya Li","Samarth Gupta","Hsiangfu Yu","Lexing Ying","Inderjit Dhillon"],"pdf_url":"https://arxiv.org/pdf/2110.02398v6.pdf","comment":"22 pages, 15 figures, v6 accepted by SIAM SISC"},{"id":"http://arxiv.org/abs/2211.13427v2","updated":"2023-06-08T01:42:13Z","published":"2022-11-24T05:53:11Z","title":"A Unified Framework for Analyzing and Optimizing a Class of Convex\n  Inequity Measures","summary":"  We propose a new unified framework for analyzing a new parameterized class of\nconvex inequity measures suitable for optimization contexts. First, we propose\na new class of order-based inequity measures, discuss their properties, and\nderive axiomatic characterizations for such measures. Then, we introduce our\nproposed class of convex inequity measures, discuss their theoretical\nproperties in an absolute and relative sense, and derive an equivalent dual\nrepresentation of these measures as a robustified order-based inequity measure\nover their dual sets. Importantly, this dual representation renders a unified\nmathematical expression and an alternative geometric characterization for\nconvex inequity measures through their dual sets. Using this representation, we\npropose a unified framework for optimization problems with a convex inequity\nmeasure objective or constraint, including reformulations and solution methods.\nFinally, we provide stability results that quantify the impact of employing\ndifferent convex inequity measures on the optimal value and solution of the\nresulting optimization problem. Our numerical results demonstrate the\ncomputational efficiency of our proposed framework over existing approaches.\n","authors":["Man Yiu Tsang","Karmel S. Shehadeh"],"pdf_url":"https://arxiv.org/pdf/2211.13427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04848v1","updated":"2023-06-08T00:56:33Z","published":"2023-06-08T00:56:33Z","title":"Interpreting and Improving Diffusion Models Using the Euclidean Distance\n  Function","summary":"  Denoising is intuitively related to projection. Indeed, under the manifold\nhypothesis, adding random noise is approximately equivalent to orthogonal\nperturbation. Hence, learning to denoise is approximately learning to project.\nIn this paper, we use this observation to reinterpret denoising diffusion\nmodels as approximate gradient descent applied to the Euclidean distance\nfunction. We then provide straight-forward convergence analysis of the DDIM\nsampler under simple assumptions on the projection-error of the denoiser.\nFinally, we propose a new sampler based on two simple modifications to DDIM\nusing insights from our theoretical results. In as few as 5-10 function\nevaluations, our sampler achieves state-of-the-art FID scores on pretrained\nCIFAR-10 and CelebA models and can generate high quality samples on latent\ndiffusion models.\n","authors":["Frank Permenter","Chenyang Yuan"],"pdf_url":"https://arxiv.org/pdf/2306.04848v1.pdf","comment":"18 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2306.05581v1","updated":"2023-06-08T22:45:39Z","published":"2023-06-08T22:45:39Z","title":"Risk-aware Urban Air Mobility Network Design with Overflow Redundancy","summary":"  Urban Air Mobility (UAM), as envisioned by researchers and practitioners,\nwill be achieved through the use of highly automated aircraft that operate and\ntransport passengers and cargo at low altitudes within urban and suburban\nareas. To operate in complex urban environment, precise air traffic management,\nin particular the management of traffic overflows due to operational\ndisruptions will be critical to ensuring system safety and efficiency. To this\nend, we propose a methodology for the design of UAM networks with reserve\ncapacity, i.e., a design where alternative landing options and flight corridors\nare explicitly considered as a means of improving contingency management and\nreducing risk. Similar redundancy considerations are incorporated in the design\nof many critical infrastructures, yet remain unexploited in the air\ntransportation literature. In our methodology, we first model how disruptions\nto a given on-demand UAM network might impact on the nominal traffic flow and\nhow this flow might be re-accommodated on an extended network with reserve\ncapacity. Then, through an optimization problem, we select the locations and\ncapacities for the backup vertiports with the maximal expected throughput of\nthe extended network over all possible disruption scenarios, while the\nthroughput is the maximal amount of flights that the network can accommodate\nper unit of time. We show that we can obtain the solution for the corresponding\nbi-level and bi-linear optimization problem by solving a mixed-integer linear\nprogram. We demonstrate our methodology in the case study using networks from\nMilwaukee, Atlanta, and Dallas--Fort Worth metropolitan areas and show how the\nthroughput and flexibility of the UAM networks with reserve capacity can\noutcompete those without.\n","authors":["Qinshuang Wei","Zhenyu Gao","John-Paul Clarke","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2306.05581v1.pdf","comment":"43 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.12724v2","updated":"2023-06-08T22:42:59Z","published":"2022-12-24T12:28:06Z","title":"Certification of Bottleneck Task Assignment with Shortest Path Criteria","summary":"  Minimising the longest travel distance for a group of mobile robots with\ninterchangeable goals requires knowledge of the shortest length paths between\nall robots and goal destinations. Determining the exact length of the shortest\npaths in an environment with obstacles is NP-hard however. In this paper, we\ninvestigate when polynomial-time approximations of the shortest path search are\nsufficient to determine the optimal assignment of robots to goals. In\nparticular, we propose an algorithm in which the accuracy of the path planning\nis iteratively increased. The approach provides a certificate when the\nuncertainties on estimates of the shortest paths become small enough to\nguarantee the optimality of the goal assignment. To this end, we apply results\nfrom assignment sensitivity assuming upper and lower bounds on the length of\nthe shortest paths. We then provide polynomial-time methods to find such bounds\nby applying sampling-based path planning. The upper bounds are given by\nfeasible paths, the lower bounds are obtained by expanding the sample set and\nleveraging the knowledge of the sample dispersion. We demonstrate the\napplication of the proposed method with a multi-robot path-planning case study.\n","authors":["Tony A. Wood","Maryam Kamgarpour"],"pdf_url":"https://arxiv.org/pdf/2212.12724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.10464v2","updated":"2023-06-08T22:27:24Z","published":"2021-10-20T10:03:06Z","title":"Learning with symmetric positive definite matrices via generalized\n  Bures-Wasserstein geometry","summary":"  Learning with symmetric positive definite (SPD) matrices has many\napplications in machine learning. Consequently, understanding the Riemannian\ngeometry of SPD matrices has attracted much attention lately. A particular\nRiemannian geometry of interest is the recently proposed Bures-Wasserstein (BW)\ngeometry which builds on the Wasserstein distance between the Gaussian\ndensities. In this paper, we propose a novel generalization of the BW geometry,\nwhich we call the GBW geometry. The proposed generalization is parameterized by\na symmetric positive definite matrix $\\mathbf{M}$ such that when $\\mathbf{M} =\n\\mathbf{I}$, we recover the BW geometry. We provide a rigorous treatment to\nstudy various differential geometric notions on the proposed novel generalized\ngeometry which makes it amenable to various machine learning applications. We\nalso present experiments that illustrate the efficacy of the proposed GBW\ngeometry over the BW geometry.\n","authors":["Andi Han","Bamdev Mishra","Pratik Jawanpuria","Junbin Gao"],"pdf_url":"https://arxiv.org/pdf/2110.10464v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05545v1","updated":"2023-06-08T20:31:14Z","published":"2023-06-08T20:31:14Z","title":"AI Enhanced Control Engineering Methods","summary":"  AI and machine learning based approaches are becoming ubiquitous in almost\nall engineering fields. Control engineering cannot escape this trend. In this\npaper, we explore how AI tools can be useful in control applications. The core\ntool we focus on is automatic differentiation. Two immediate applications are\nlinearization of system dynamics for local stability analysis or for state\nestimation using Kalman filters. We also explore other usages such as\nconversion of differential algebraic equations to ordinary differential\nequations for control design. In addition, we explore the use of machine\nlearning models for global parameterizations of state vectors and control\ninputs in model predictive control applications. For each considered use case,\nwe give examples and results.\n","authors":["Ion Matei","Raj Minhas","Johan de Kleer","Alexander Felman"],"pdf_url":"https://arxiv.org/pdf/2306.05545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13263v4","updated":"2023-06-08T18:29:10Z","published":"2021-11-25T21:54:52Z","title":"Negative curvature obstructs acceleration for strongly geodesically\n  convex optimization, even with exact first-order oracles","summary":"  Hamilton and Moitra (2021) showed that, in certain regimes, it is not\npossible to accelerate Riemannian gradient descent in the hyperbolic plane if\nwe restrict ourselves to algorithms which make queries in a (large) bounded\ndomain and which receive gradients and function values corrupted by a (small)\namount of noise. We show that acceleration remains unachievable for any\ndeterministic algorithm which receives exact gradient and function-value\ninformation (unbounded queries, no noise). Our results hold for the classes of\nstrongly and nonstrongly geodesically convex functions, and for a large class\nof Hadamard manifolds including hyperbolic spaces and the symmetric space\n$\\mathrm{SL}(n) / \\mathrm{SO}(n)$ of positive definite $n \\times n$ matrices of\ndeterminant one. This cements a surprising gap between the complexity of convex\noptimization and geodesically convex optimization: for hyperbolic spaces,\nRiemannian gradient descent is optimal on the class of smooth and and strongly\ngeodesically convex functions, in the regime where the condition number scales\nwith the radius of the optimization domain. The key idea for proving the lower\nbound consists of perturbing the hard functions of Hamilton and Moitra (2021)\nwith sums of bump functions chosen by a resisting oracle.\n","authors":["Christopher Criscitiello","Nicolas Boumal"],"pdf_url":"https://arxiv.org/pdf/2111.13263v4.pdf","comment":"v2 to v3: Updated and shortened to reflect COLT 2022 version. Results\n  on nonstrongly g-convex case (former Sec. 5) and reduction to Euclidean\n  convexity (former Sec. 6) are now in Sec. 3 and App. D of \"Curvature and\n  Complexity: Better lower bounds for geodesically convex optimization\", COLT\n  2023 (arxiv.org/abs/2306.02959). v3 to v4: Added word \"strongly\" to title to\n  match COLT 2022 version; Proceedings of Thirty Fifth Conference on Learning\n  Theory, PMLR 178:496-542, 2022,\n  https://proceedings.mlr.press/v178/criscitiello22a"},{"id":"http://arxiv.org/abs/2004.01798v3","updated":"2023-06-08T18:23:07Z","published":"2020-04-03T22:22:57Z","title":"Kullback-Leibler-Quadratic Optimal Control","summary":"  This paper presents approaches to mean-field control, motivated by\ndistributed control of multi-agent systems. Control solutions are based on a\nconvex optimization problem, whose domain is a convex set of probability mass\nfunctions (pmfs). The main contributions follow: 1. Kullback-Leibler-Quadratic\n(KLQ) optimal control is a special case, in which the objective function is\ncomposed of a control cost in the form of Kullback-Leibler divergence between a\ncandidate pmf and the nominal, plus a quadratic cost on the sequence of\nmarginals. Theory in this paper extends prior work on deterministic control\nsystems, establishing that the optimal solution is an exponential tilting of\nthe nominal pmf. Transform techniques are introduced to reduce complexity of\nthe KLQ solution, motivated by the need to consider time horizons that are much\nlonger than the inter-sampling times required for reliable control. 2.\nInfinite-horizon KLQ leads to a state feedback control solution with attractive\nproperties. It can be expressed as either state feedback, in which the state is\nthe sequence of marginal pmfs, or an open loop solution is obtained that is\nmore easily computed. 3. Numerical experiments are surveyed in an application\nof distributed control of residential loads to provide grid services, similar\nto utility-scale battery storage. The results show that KLQ optimal control\nenables the aggregate power consumption of a collection of flexible loads to\ntrack a time-varying reference signal, while simultaneously ensuring each\nindividual load satisfies its own quality of service constraints. Keywords:\nMean field games, distributed control, Markov decision processes, Demand\nDispatch.\n","authors":["Neil Cammardella","Ana Bušić","Sean Meyn"],"pdf_url":"https://arxiv.org/pdf/2004.01798v3.pdf","comment":"Extended version of paper to appear in SIAM Journal on Control and\n  Optimization (SICON)"},{"id":"http://arxiv.org/abs/2306.05482v1","updated":"2023-06-08T18:06:31Z","published":"2023-06-08T18:06:31Z","title":"Data-Driven Near-Optimal Control of Nonlinear Systems Over Finite\n  Horizon","summary":"  We examine the problem of two-point boundary optimal control of nonlinear\nsystems over finite-horizon time periods with unknown model dynamics by\nemploying reinforcement learning. We use techniques from singular perturbation\ntheory to decompose the control problem over the finite horizon into two\nsub-problems, each solved over an infinite horizon. In the process, we avoid\nthe need to solve the time-varying Hamilton-Jacobi-Bellman equation. Using a\npolicy iteration method, which is made feasible as a result of this\ndecomposition, it is now possible to learn the controller gains of both\nsub-problems. The overall control is then formed by piecing together the\nsolutions to the two sub-problems. We show that the performance of the proposed\nclosed-loop system approaches that of the model-based optimal performance as\nthe time horizon gets long. Finally, we provide three simulation scenarios to\nsupport the paper's claims.\n","authors":["Vasanth Reddy","Hoda Eldardiry","Almuatazbellah Boker"],"pdf_url":"https://arxiv.org/pdf/2306.05482v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.05426v1","updated":"2023-06-08T17:59:58Z","published":"2023-06-08T17:59:58Z","title":"SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling\n  with Backtracking","summary":"  In many domains, autoregressive models can achieve low log-likelihood on the\ntask of predicting the next observation. However, this maximum-likelihood (MLE)\nobjective does not necessarily match a downstream use-case of autoregressively\ngenerating high-quality sequences. The MLE objective weights sequences\nproportionally to their frequency under the data distribution, with no guidance\nfor the model's behaviour out of distribution (OOD): leading to compounding\nerror during autoregressive generation. In order to address this compounding\nerror problem, we formulate sequence generation as an imitation learning (IL)\nproblem. This allows us to minimize a variety of divergences between the\ndistribution of sequences generated by an autoregressive model and sequences\nfrom a dataset, including divergences with weight on OOD generated sequences.\nThe IL framework also allows us to incorporate backtracking by introducing a\nbackspace action into the generation process. This further mitigates the\ncompounding error problem by allowing the model to revert a sampled token if it\ntakes the sequence OOD. Our resulting method, SequenceMatch, can be implemented\nwithout adversarial training or major architectural changes. We identify the\nSequenceMatch-$\\chi^2$ divergence as a more suitable training objective for\nautoregressive models which are used for generation. We show that empirically,\nSequenceMatch training leads to improvements over MLE on text generation with\nlanguage models.\n","authors":["Chris Cundy","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2306.05426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05420v1","updated":"2023-06-08T17:59:08Z","published":"2023-06-08T17:59:08Z","title":"Scaling Spherical CNNs","summary":"  Spherical CNNs generalize CNNs to functions on the sphere, by using spherical\nconvolutions as the main linear operation. The most accurate and efficient way\nto compute spherical convolutions is in the spectral domain (via the\nconvolution theorem), which is still costlier than the usual planar\nconvolutions. For this reason, applications of spherical CNNs have so far been\nlimited to small problems that can be approached with low model capacity. In\nthis work, we show how spherical CNNs can be scaled for much larger problems.\nTo achieve this, we make critical improvements including novel variants of\ncommon model components, an implementation of core operations to exploit\nhardware accelerator characteristics, and application-specific input\nrepresentations that exploit the properties of our model. Experiments show our\nlarger spherical CNNs reach state-of-the-art on several targets of the QM9\nmolecular benchmark, which was previously dominated by equivariant graph neural\nnetworks, and achieve competitive performance on multiple weather forecasting\ntasks. Our code is available at\nhttps://github.com/google-research/spherical-cnn.\n","authors":["Carlos Esteves","Jean-Jacques Slotine","Ameesh Makadia"],"pdf_url":"https://arxiv.org/pdf/2306.05420v1.pdf","comment":"Accepted to ICML'23"},{"id":"http://arxiv.org/abs/2306.05419v1","updated":"2023-06-08T17:58:57Z","published":"2023-06-08T17:58:57Z","title":"TopoMask: Instance-Mask-Based Formulation for the Road Topology Problem\n  via Transformer-Based Architecture","summary":"  Driving scene understanding task involves detecting static elements such as\nlanes, traffic signs, and traffic lights, and their relationships with each\nother. To facilitate the development of comprehensive scene understanding\nsolutions using multiple camera views, a new dataset called Road Genome\n(OpenLane-V2) has been released. This dataset allows for the exploration of\ncomplex road connections and situations where lane markings may be absent.\nInstead of using traditional lane markings, the lanes in this dataset are\nrepresented by centerlines, which offer a more suitable representation of lanes\nand their connections. In this study, we have introduced a new approach called\nTopoMask for predicting centerlines in road topology. Unlike existing\napproaches in the literature that rely on keypoints or parametric methods,\nTopoMask utilizes an instance-mask based formulation with a transformer-based\narchitecture and, in order to enrich the mask instances with flow information,\na direction label representation is proposed. TopoMask have ranked 4th in the\nOpenLane-V2 Score (OLS) and ranked 2nd in the F1 score of centerline prediction\nin OpenLane Topology Challenge 2023. In comparison to the current\nstate-of-the-art method, TopoNet, the proposed method has achieved similar\nperformance in Frechet-based lane detection and outperformed TopoNet in\nChamfer-based lane detection without utilizing its scene graph neural network.\n","authors":["M. Esat Kalfaoglu","Halil Ibrahim Ozturk","Ozsel Kilinc","Alptekin Temizel"],"pdf_url":"https://arxiv.org/pdf/2306.05419v1.pdf","comment":"4th in OLS and 2nd in the F1-score in OpenLane Topology Challenge\n  2023"},{"id":"http://arxiv.org/abs/2306.05415v1","updated":"2023-06-08T17:58:05Z","published":"2023-06-08T17:58:05Z","title":"Causal normalizing flows: from theory to practice","summary":"  In this work, we deepen on the use of normalizing flows for causal reasoning.\nSpecifically, we first leverage recent results on non-linear ICA to show that\ncausal models are identifiable from observational data given a causal ordering,\nand thus can be recovered using autoregressive normalizing flows (NFs). Second,\nwe analyze different design and learning choices for causal normalizing flows\nto capture the underlying causal data-generating process. Third, we describe\nhow to implement the do-operator in causal NFs, and thus, how to answer\ninterventional and counterfactual questions. Finally, in our experiments, we\nvalidate our design and training choices through a comprehensive ablation\nstudy; compare causal NFs to other approaches for approximating causal models;\nand empirically demonstrate that causal NFs can be used to address real-world\nproblems, where the presence of mixed discrete-continuous data and partial\nknowledge on the causal graph is the norm. The code for this work can be found\nat https://github.com/psanch21/causal-flows.\n","authors":["Adrián Javaloy","Pablo Sánchez-Martín","Isabel Valera"],"pdf_url":"https://arxiv.org/pdf/2306.05415v1.pdf","comment":"31 pages, 15 figures. Under submission"},{"id":"http://arxiv.org/abs/2306.05412v1","updated":"2023-06-08T17:56:46Z","published":"2023-06-08T17:56:46Z","title":"Offline Prioritized Experience Replay","summary":"  Offline reinforcement learning (RL) is challenged by the distributional shift\nproblem. To address this problem, existing works mainly focus on designing\nsophisticated policy constraints between the learned policy and the behavior\npolicy. However, these constraints are applied equally to well-performing and\ninferior actions through uniform sampling, which might negatively affect the\nlearned policy. To alleviate this issue, we propose Offline Prioritized\nExperience Replay (OPER), featuring a class of priority functions designed to\nprioritize highly-rewarding transitions, making them more frequently visited\nduring training. Through theoretical analysis, we show that this class of\npriority functions induce an improved behavior policy, and when constrained to\nthis improved policy, a policy-constrained offline RL algorithm is likely to\nyield a better solution. We develop two practical strategies to obtain priority\nweights by estimating advantages based on a fitted value network (OPER-A) or\nutilizing trajectory returns (OPER-R) for quick computation. OPER is a\nplug-and-play component for offline RL algorithms. As case studies, we evaluate\nOPER on five different algorithms, including BC, TD3+BC, Onestep RL, CQL, and\nIQL. Extensive experiments demonstrate that both OPER-A and OPER-R\nsignificantly improve the performance for all baseline methods. Codes and\npriority weights are availiable at https://github.com/sail-sg/OPER.\n","authors":["Yang Yue","Bingyi Kang","Xiao Ma","Gao Huang","Shiji Song","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2306.05412v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2306.05401v1","updated":"2023-06-08T17:52:34Z","published":"2023-06-08T17:52:34Z","title":"RDumb: A simple approach that questions our progress in continual\n  test-time adaptation","summary":"  Test-Time Adaptation (TTA) allows to update pretrained models to changing\ndata distributions at deployment time. While early work tested these algorithms\nfor individual fixed distribution shifts, recent work proposed and applied\nmethods for continual adaptation over long timescales. To examine the reported\nprogress in the field, we propose the Continuously Changing Corruptions (CCC)\nbenchmark to measure asymptotic performance of TTA techniques. We find that\neventually all but one state-of-the-art methods collapse and perform worse than\na non-adapting model, including models specifically proposed to be robust to\nperformance collapse. In addition, we introduce a simple baseline, \"RDumb\",\nthat periodically resets the model to its pretrained state. RDumb performs\nbetter or on par with the previously proposed state-of-the-art in all\nconsidered benchmarks. Our results show that previous TTA approaches are\nneither effective at regularizing adaptation to avoid collapse nor able to\noutperform a simplistic resetting strategy.\n","authors":["Ori Press","Steffen Schneider","Matthias Kümmerer","Matthias Bethge"],"pdf_url":"https://arxiv.org/pdf/2306.05401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.16458v4","updated":"2023-06-08T17:48:57Z","published":"2023-03-29T05:05:02Z","title":"When to Pre-Train Graph Neural Networks? From Data Generation\n  Perspective!","summary":"  In recent years, graph pre-training has gained significant attention,\nfocusing on acquiring transferable knowledge from unlabeled graph data to\nimprove downstream performance. Despite these recent endeavors, the problem of\nnegative transfer remains a major concern when utilizing graph pre-trained\nmodels to downstream tasks. Previous studies made great efforts on the issue of\nwhat to pre-train and how to pre-train by designing a variety of graph\npre-training and fine-tuning strategies. However, there are cases where even\nthe most advanced \"pre-train and fine-tune\" paradigms fail to yield distinct\nbenefits. This paper introduces a generic framework W2PGNN to answer the\ncrucial question of when to pre-train (i.e., in what situations could we take\nadvantage of graph pre-training) before performing effortful pre-training or\nfine-tuning. We start from a new perspective to explore the complex generative\nmechanisms from the pre-training data to downstream data. In particular, W2PGNN\nfirst fits the pre-training data into graphon bases, each element of graphon\nbasis (i.e., a graphon) identifies a fundamental transferable pattern shared by\na collection of pre-training graphs. All convex combinations of graphon bases\ngive rise to a generator space, from which graphs generated form the solution\nspace for those downstream data that can benefit from pre-training. In this\nmanner, the feasibility of pre-training can be quantified as the generation\nprobability of the downstream data from any generator in the generator space.\nW2PGNN offers three broad applications: providing the application scope of\ngraph pre-trained models, quantifying the feasibility of pre-training, and\nassistance in selecting pre-training data to enhance downstream performance. We\nprovide a theoretically sound solution for the first application and extensive\nempirical justifications for the latter two applications.\n","authors":["Yuxuan Cao","Jiarong Xu","Carl Yang","Jiaan Wang","Yunchao Zhang","Chunping Wang","Lei Chen","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2303.16458v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02607v2","updated":"2023-06-08T17:39:05Z","published":"2023-02-06T08:08:34Z","title":"Target-based Surrogates for Stochastic Optimization","summary":"  We consider minimizing functions for which it is expensive to compute the\n(possibly stochastic) gradient. Such functions are prevalent in reinforcement\nlearning, imitation learning and adversarial training. Our target optimization\nframework uses the (expensive) gradient computation to construct surrogate\nfunctions in a \\emph{target space} (e.g. the logits output by a linear model\nfor classification) that can be minimized efficiently. This allows for multiple\nparameter updates to the model, amortizing the cost of gradient computation. In\nthe full-batch setting, we prove that our surrogate is a global upper-bound on\nthe loss, and can be (locally) minimized using a black-box optimization\nalgorithm. We prove that the resulting majorization-minimization algorithm\nensures convergence to a stationary point of the loss. Next, we instantiate our\nframework in the stochastic setting and propose the $SSO$ algorithm, which can\nbe viewed as projected stochastic gradient descent in the target space. This\nconnection enables us to prove theoretical guarantees for $SSO$ when minimizing\nconvex functions. Our framework allows the use of standard stochastic\noptimization algorithms to construct surrogates which can be minimized by any\ndeterministic optimization method. To evaluate our framework, we consider a\nsuite of supervised learning and imitation learning problems. Our experiments\nindicate the benefits of target optimization and the effectiveness of $SSO$.\n","authors":["Jonathan Wilder Lavington","Sharan Vaswani","Reza Babanezhad","Mark Schmidt","Nicolas Le Roux"],"pdf_url":"https://arxiv.org/pdf/2302.02607v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11552v3","updated":"2023-06-08T17:39:01Z","published":"2023-02-22T18:48:46Z","title":"Reduce, Reuse, Recycle: Compositional Generation with Energy-Based\n  Diffusion Models and MCMC","summary":"  Since their introduction, diffusion models have quickly become the prevailing\napproach to generative modeling in many domains. They can be interpreted as\nlearning the gradients of a time-varying sequence of log-probability density\nfunctions. This interpretation has motivated classifier-based and\nclassifier-free guidance as methods for post-hoc control of diffusion models.\nIn this work, we build upon these ideas using the score-based interpretation of\ndiffusion models, and explore alternative ways to condition, modify, and reuse\ndiffusion models for tasks involving compositional generation and guidance. In\nparticular, we investigate why certain types of composition fail using current\ntechniques and present a number of solutions. We conclude that the sampler (not\nthe model) is responsible for this failure and propose new samplers, inspired\nby MCMC, which enable successful compositional generation. Further, we propose\nan energy-based parameterization of diffusion models which enables the use of\nnew compositional operators and more sophisticated, Metropolis-corrected\nsamplers. Intriguingly we find these samplers lead to notable improvements in\ncompositional generation across a wide set of problems such as\nclassifier-guided ImageNet modeling and compositional text-to-image generation.\n","authors":["Yilun Du","Conor Durkan","Robin Strudel","Joshua B. Tenenbaum","Sander Dieleman","Rob Fergus","Jascha Sohl-Dickstein","Arnaud Doucet","Will Grathwohl"],"pdf_url":"https://arxiv.org/pdf/2302.11552v3.pdf","comment":"ICML 2023, Project Webpage:\n  https://energy-based-model.github.io/reduce-reuse-recycle/"},{"id":"http://arxiv.org/abs/2305.16317v2","updated":"2023-06-08T17:37:04Z","published":"2023-05-25T17:59:42Z","title":"Parallel Sampling of Diffusion Models","summary":"  Diffusion models are powerful generative models but suffer from slow\nsampling, often taking 1000 sequential denoising steps for one sample. As a\nresult, considerable efforts have been directed toward reducing the number of\ndenoising steps, but these methods hurt sample quality. Instead of reducing the\nnumber of denoising steps (trading quality for speed), in this paper we explore\nan orthogonal approach: can we run the denoising steps in parallel (trading\ncompute for speed)? In spite of the sequential nature of the denoising steps,\nwe show that surprisingly it is possible to parallelize sampling via Picard\niterations, by guessing the solution of future denoising steps and iteratively\nrefining until convergence. With this insight, we present ParaDiGMS, a novel\nmethod to accelerate the sampling of pretrained diffusion models by denoising\nmultiple steps in parallel. ParaDiGMS is the first diffusion sampling method\nthat enables trading compute for speed and is even compatible with existing\nfast sampling techniques such as DDIM and DPMSolver. Using ParaDiGMS, we\nimprove sampling speed by 2-4x across a range of robotics and image generation\nmodels, giving state-of-the-art sampling speeds of 0.2s on 100-step\nDiffusionPolicy and 16s on 1000-step StableDiffusion-v2 with no measurable\ndegradation of task reward, FID score, or CLIP score.\n","authors":["Andy Shih","Suneel Belkhale","Stefano Ermon","Dorsa Sadigh","Nima Anari"],"pdf_url":"https://arxiv.org/pdf/2305.16317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02984v2","updated":"2023-06-08T17:31:49Z","published":"2023-02-06T18:19:25Z","title":"Robust Subtask Learning for Compositional Generalization","summary":"  Compositional reinforcement learning is a promising approach for training\npolicies to perform complex long-horizon tasks. Typically, a high-level task is\ndecomposed into a sequence of subtasks and a separate policy is trained to\nperform each subtask. In this paper, we focus on the problem of training\nsubtask policies in a way that they can be used to perform any task; here, a\ntask is given by a sequence of subtasks. We aim to maximize the worst-case\nperformance over all tasks as opposed to the average-case performance. We\nformulate the problem as a two agent zero-sum game in which the adversary picks\nthe sequence of subtasks. We propose two RL algorithms to solve this game: one\nis an adaptation of existing multi-agent RL algorithms to our setting and the\nother is an asynchronous version which enables parallel training of subtask\npolicies. We evaluate our approach on two multi-task environments with\ncontinuous states and actions and demonstrate that our algorithms outperform\nstate-of-the-art baselines.\n","authors":["Kishor Jothimurugan","Steve Hsu","Osbert Bastani","Rajeev Alur"],"pdf_url":"https://arxiv.org/pdf/2302.02984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04218v3","updated":"2023-06-08T17:13:55Z","published":"2023-01-10T21:50:26Z","title":"Leveraging Diffusion For Strong and High Quality Face Morphing Attacks","summary":"  Face morphing attacks seek to deceive a Face Recognition (FR) system by\npresenting a morphed image consisting of the biometric qualities from two\ndifferent identities with the aim of triggering a false acceptance with one of\nthe two identities, thereby presenting a significant threat to biometric\nsystems. The success of a morphing attack is dependent on the ability of the\nmorphed image to represent the biometric characteristics of both identities\nthat were used to create the image. We present a novel morphing attack that\nuses a Diffusion-based architecture to improve the visual fidelity of the image\nand the ability of the morphing attack to represent characteristics from both\nidentities. We demonstrate the effectiveness of the proposed attack by\nevaluating its visual fidelity via the Frechet Inception Distance (FID). Also,\nextensive experiments are conducted to measure the vulnerability of FR systems\nto the proposed attack. The ability of a morphing attack detector to detect the\nproposed attack is measured and compared against two state-of-the-art GAN-based\nmorphing attacks along with two Landmark-based attacks. Additionally, a novel\nmetric to measure the relative strength between different morphing attacks is\nintroduced and evaluated.\n","authors":["Zander Blasingame","Chen Liu"],"pdf_url":"https://arxiv.org/pdf/2301.04218v3.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2303.06171v2","updated":"2023-06-08T17:13:13Z","published":"2023-03-10T19:14:20Z","title":"DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for\n  Large-Scale Bayesian Inference","summary":"  Bayesian inference provides a principled framework for learning from complex\ndata and reasoning under uncertainty. It has been widely applied in machine\nlearning tasks such as medical diagnosis, drug design, and policymaking. In\nthese common applications, data can be highly sensitive. Differential privacy\n(DP) offers data analysis tools with powerful worst-case privacy guarantees and\nhas been developed as the leading approach in privacy-preserving data analysis.\nIn this paper, we study Metropolis-Hastings (MH), one of the most fundamental\nMCMC methods, for large-scale Bayesian inference under differential privacy.\nWhile most existing private MCMC algorithms sacrifice accuracy and efficiency\nto obtain privacy, we provide the first exact and fast DP MH algorithm, using\nonly a minibatch of data in most iterations. We further reveal, for the first\ntime, a three-way trade-off among privacy, scalability (i.e. the batch size),\nand efficiency (i.e. the convergence rate), theoretically characterizing how\nprivacy affects the utility and computational cost in Bayesian inference. We\nempirically demonstrate the effectiveness and efficiency of our algorithm in\nvarious experiments.\n","authors":["Wanrong Zhang","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.06171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11401v2","updated":"2023-06-08T17:11:38Z","published":"2023-01-26T20:27:14Z","title":"Causal Bandits without Graph Learning","summary":"  We study the causal bandit problem when the causal graph is unknown and\ndevelop an efficient algorithm for finding the parent node of the reward node\nusing atomic interventions. We derive the exact equation for the expected\nnumber of interventions performed by the algorithm and show that under certain\ngraphical conditions it could perform either logarithmically fast or, under\nmore general assumptions, slower but still sublinearly in the number of\nvariables. We formally show that our algorithm is optimal as it meets the\nuniversal lower bound we establish for any algorithm that performs atomic\ninterventions. Finally, we extend our algorithm to the case when the reward\nnode has multiple parents. Using this algorithm together with a standard\nalgorithm from bandit literature leads to improved regret bounds.\n","authors":["Mikhail Konobeev","Jalal Etesami","Negar Kiyavash"],"pdf_url":"https://arxiv.org/pdf/2301.11401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05366v1","updated":"2023-06-08T17:08:52Z","published":"2023-06-08T17:08:52Z","title":"Ordinal Potential-based Player Rating","summary":"  A two-player symmetric zero-sum game is transitive if for any pure strategies\n$x$, $y$, $z$, if $x$ is better than $y$, and $y$ is better than $z$, then $x$\nis better than $z$. It was recently observed that the Elo rating fails at\npreserving transitive relations among strategies and therefore cannot correctly\nextract the transitive component of a game. Our first contribution is to show\nthat the Elo rating actually does preserve transitivity when computed in the\nright space. Precisely, using a suitable invertible mapping $\\varphi$, we first\napply $\\varphi$ to the game, then compute Elo ratings, then go back to the\noriginal space by applying $\\varphi^{-1}$. We provide a characterization of\ntransitive games as a weak variant of ordinal potential games with additively\nseparable potential functions. Leveraging this insight, we introduce the\nconcept of transitivity order, the minimum number of invertible mappings\nrequired to transform the payoff of a transitive game into (differences of) its\npotential function. The transitivity order is a tool to classify transitive\ngames, with Elo games being an example of transitive games of order one. Most\nreal-world games have both transitive and non-transitive (cyclic) components,\nand we use our analysis of transitivity to extract the transitive (potential)\ncomponent of an arbitrary game. We link transitivity to the known concept of\nsign-rank: transitive games have sign-rank two; arbitrary games may have higher\nsign-rank. Using a neural network-based architecture, we learn a decomposition\nof an arbitrary game into transitive and cyclic components that prioritises\ncapturing the sign pattern of the game. In particular, a transitive game always\nhas just one component in its decomposition, the potential component. We\nprovide a comprehensive evaluation of our methodology using both toy examples\nand empirical data from real-world games.\n","authors":["Nelson Vadori","Rahul Savani"],"pdf_url":"https://arxiv.org/pdf/2306.05366v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05363v1","updated":"2023-06-08T17:07:24Z","published":"2023-06-08T17:07:24Z","title":"Subject clustering by IF-PCA and several recent methods","summary":"  Subject clustering (i.e., the use of measured features to cluster subjects,\nsuch as patients or cells, into multiple groups) is a problem of great\ninterest. In recent years, many approaches were proposed, among which\nunsupervised deep learning (UDL) has received a great deal of attention. Two\ninteresting questions are (a) how to combine the strengths of UDL and other\napproaches, and (b) how these approaches compare to one other.\n  We combine Variational Auto-Encoder (VAE), a popular UDL approach, with the\nrecent idea of Influential Feature PCA (IF-PCA), and propose IF-VAE as a new\nmethod for subject clustering. We study IF-VAE and compare it with several\nother methods (including IF-PCA, VAE, Seurat, and SC3) on $10$ gene microarray\ndata sets and $8$ single-cell RNA-seq data sets. We find that IF-VAE\nsignificantly improves over VAE, but still underperforms IF-PCA. We also find\nthat IF-PCA is quite competitive, which slightly outperforms Seurat and SC3\nover the $8$ single-cell data sets. IF-PCA is conceptually simple and permits\ndelicate analysis. We demonstrate that IF-PCA is capable of achieving the phase\ntransition in a Rare/Weak model. Comparatively, Seurat and SC3 are more complex\nand theoretically difficult to analyze (for these reasons, their optimality\nremains unclear).\n","authors":["Dieyi Chen","Jiashun Jin","Zheng Tracy Ke"],"pdf_url":"https://arxiv.org/pdf/2306.05363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05357v1","updated":"2023-06-08T17:02:15Z","published":"2023-06-08T17:02:15Z","title":"Unsupervised Compositional Concepts Discovery with Text-to-Image\n  Generative Models","summary":"  Text-to-image generative models have enabled high-resolution image synthesis\nacross different domains, but require users to specify the content they wish to\ngenerate. In this paper, we consider the inverse problem -- given a collection\nof different images, can we discover the generative concepts that represent\neach image? We present an unsupervised approach to discover generative concepts\nfrom a collection of images, disentangling different art styles in paintings,\nobjects, and lighting from kitchen scenes, and discovering image classes given\nImageNet images. We show how such generative concepts can accurately represent\nthe content of images, be recombined and composed to generate new artistic and\nhybrid images, and be further used as a representation for downstream\nclassification tasks.\n","authors":["Nan Liu","Yilun Du","Shuang Li","Joshua B. Tenenbaum","Antonio Torralba"],"pdf_url":"https://arxiv.org/pdf/2306.05357v1.pdf","comment":"Project Webpage:\n  https://energy-based-model.github.io/unsupervised-concept-discovery/"},{"id":"http://arxiv.org/abs/2112.14233v3","updated":"2023-06-08T16:51:46Z","published":"2021-12-28T17:37:08Z","title":"Multitask Learning and Bandits via Robust Statistics","summary":"  Decision-makers often simultaneously face many related but heterogeneous\nlearning problems. For instance, a large retailer may wish to learn product\ndemand at different stores to solve pricing or inventory problems, making it\ndesirable to learn jointly for stores serving similar customers; alternatively,\na hospital network may wish to learn patient risk at different providers to\nallocate personalized interventions, making it desirable to learn jointly for\nhospitals serving similar patient populations. Motivated by real datasets, we\nstudy a natural setting where the unknown parameter in each learning instance\ncan be decomposed into a shared global parameter plus a sparse\ninstance-specific term. We propose a novel two-stage multitask learning\nestimator that exploits this structure in a sample-efficient way, using a\nunique combination of robust statistics (to learn across similar instances) and\nLASSO regression (to debias the results). Our estimator yields improved sample\ncomplexity bounds in the feature dimension $d$ relative to commonly-employed\nestimators; this improvement is exponential for \"data-poor\" instances, which\nbenefit the most from multitask learning. We illustrate the utility of these\nresults for online learning by embedding our multitask estimator within\nsimultaneous contextual bandit algorithms. We specify a dynamic calibration of\nour estimator to appropriately balance the bias-variance tradeoff over time,\nimproving the resulting regret bounds in the context dimension $d$. Finally, we\nillustrate the value of our approach on synthetic and real datasets.\n","authors":["Kan Xu","Hamsa Bastani"],"pdf_url":"https://arxiv.org/pdf/2112.14233v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05344v1","updated":"2023-06-08T16:46:11Z","published":"2023-06-08T16:46:11Z","title":"A Crystal-Specific Pre-Training Framework for Crystal Material Property\n  Prediction","summary":"  Crystal property prediction is a crucial aspect of developing novel\nmaterials. However, there are two technical challenges to be addressed for\nspeeding up the investigation of crystals. First, labeling crystal properties\nis intrinsically difficult due to the high cost and time involved in physical\nsimulations or lab experiments. Second, crystals adhere to a specific quantum\nchemical principle known as periodic invariance, which is often not captured by\nexisting machine learning methods. To overcome these challenges, we propose the\ncrystal-specific pre-training framework for learning crystal representations\nwith self-supervision. The framework designs a mutex mask strategy for\nenhancing representation learning so as to alleviate the limited labels\navailable for crystal property prediction. Moreover, we take into account the\nspecific periodic invariance in crystal structures by developing a periodic\ninvariance multi-graph module and periodic attribute learning within our\nframework. This framework has been tested on eight different tasks. The\nexperimental results on these tasks show that the framework achieves promising\nprediction performance and is able to outperform recent strong baselines.\n","authors":["Haomin Yu","Yanru Song","Jilin Hu","Chenjuan Guo","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00058v2","updated":"2023-06-08T16:44:12Z","published":"2023-01-31T19:48:01Z","title":"Graph-based Time-Series Anomaly Detection: A Survey","summary":"  With the recent advances in technology, a wide range of systems continue to\ncollect a large amount of data over time and thus generate time series.\nTime-Series Anomaly Detection (TSAD) is an important task in various\ntime-series applications such as e-commerce, cybersecurity, vehicle\nmaintenance, and healthcare monitoring. However, this task is very challenging\nas it requires considering both the intra-variable dependency and the\ninter-variable dependency, where a variable can be defined as an observation in\ntime series data. Recent graph-based approaches have made impressive progress\nin tackling the challenges of this field. In this survey, we conduct a\ncomprehensive and up-to-date review of Graph-based TSAD (G-TSAD). First, we\nexplore the significant potential of graph representation learning for\ntime-series data. Then, we review state-of-the-art graph anomaly detection\ntechniques in the context of time series and discuss their strengths and\ndrawbacks. Finally, we discuss the technical challenges and potential future\ndirections for possible improvements in this research field.\n","authors":["Thi Kieu Khanh Ho","Ali Karami","Narges Armanfard"],"pdf_url":"https://arxiv.org/pdf/2302.00058v2.pdf","comment":"19 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2301.09554v3","updated":"2023-06-08T16:42:49Z","published":"2023-01-23T17:16:21Z","title":"Deep Learning Meets Sparse Regularization: A Signal Processing\n  Perspective","summary":"  Deep learning has been wildly successful in practice and most\nstate-of-the-art machine learning methods are based on neural networks.\nLacking, however, is a rigorous mathematical theory that adequately explains\nthe amazing performance of deep neural networks. In this article, we present a\nrelatively new mathematical framework that provides the beginning of a deeper\nunderstanding of deep learning. This framework precisely characterizes the\nfunctional properties of neural networks that are trained to fit to data. The\nkey mathematical tools which support this framework include transform-domain\nsparse regularization, the Radon transform of computed tomography, and\napproximation theory, which are all techniques deeply rooted in signal\nprocessing. This framework explains the effect of weight decay regularization\nin neural network training, the use of skip connections and low-rank weight\nmatrices in network architectures, the role of sparsity in neural networks, and\nexplains why neural networks can perform well in high-dimensional problems.\n","authors":["Rahul Parhi","Robert D. Nowak"],"pdf_url":"https://arxiv.org/pdf/2301.09554v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04095v2","updated":"2023-06-08T16:31:07Z","published":"2023-04-08T20:17:29Z","title":"A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm\n  under Smoothness and Isoperimetry","summary":"  We study the mixing time of Metropolis-Adjusted Langevin algorithm (MALA) for\nsampling a target density on $\\mathbb{R}^d$. We assume that the target density\nsatisfies $\\psi_\\mu$-isoperimetry and that the operator norm and trace of its\nHessian are bounded by $L$ and $\\Upsilon$ respectively. Our main result\nestablishes that, from a warm start, to achieve $\\epsilon$-total variation\ndistance to the target density, MALA mixes in\n$O\\left(\\frac{(L\\Upsilon)^{\\frac12}}{\\psi_\\mu^2}\n\\log\\left(\\frac{1}{\\epsilon}\\right)\\right)$ iterations. Notably, this result\nholds beyond the log-concave sampling setting and the mixing time depends on\nonly $\\Upsilon$ rather than its upper bound $L d$. In the $m$-strongly\nlogconcave and $L$-log-smooth sampling setting, our bound recovers the previous\nminimax mixing bound of MALA~\\cite{wu2021minimax}.\n","authors":["Yuansi Chen","Khashayar Gatmiry"],"pdf_url":"https://arxiv.org/pdf/2304.04095v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2102.13244v4","updated":"2023-06-08T16:24:22Z","published":"2021-02-26T00:28:58Z","title":"Cyclic Coordinate Dual Averaging with Extrapolation","summary":"  Cyclic block coordinate methods are a fundamental class of optimization\nmethods widely used in practice and implemented as part of standard software\npackages for statistical learning. Nevertheless, their convergence is generally\nnot well understood and so far their good practical performance has not been\nexplained by existing convergence analyses. In this work, we introduce a new\nblock coordinate method that applies to the general class of variational\ninequality (VI) problems with monotone operators. This class includes composite\nconvex optimization problems and convex-concave min-max optimization problems\nas special cases and has not been addressed by the existing work. The resulting\nconvergence bounds match the optimal convergence bounds of full gradient\nmethods, but are provided in terms of a novel gradient Lipschitz condition\nw.r.t.~a Mahalanobis norm. For $m$ coordinate blocks, the resulting gradient\nLipschitz constant in our bounds is never larger than a factor $\\sqrt{m}$\ncompared to the traditional Euclidean Lipschitz constant, while it is possible\nfor it to be much smaller. Further, for the case when the operator in the VI\nhas finite-sum structure, we propose a variance reduced variant of our method\nwhich further decreases the per-iteration cost and has better convergence rates\nin certain regimes. To obtain these results, we use a gradient extrapolation\nstrategy that allows us to view a cyclic collection of block coordinate-wise\ngradients as one implicit gradient.\n","authors":["Chaobing Song","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2102.13244v4.pdf","comment":"27 pages, 2 figures. Accepted to SIAM Journal on Optimization.\n  Version prior to final copy editing"},{"id":"http://arxiv.org/abs/2306.05325v1","updated":"2023-06-08T16:18:08Z","published":"2023-06-08T16:18:08Z","title":"Federated Learning under Covariate Shifts with Generalization Guarantees","summary":"  This paper addresses intra-client and inter-client covariate shifts in\nfederated learning (FL) with a focus on the overall generalization performance.\nTo handle covariate shifts, we formulate a new global model training paradigm\nand propose Federated Importance-Weighted Empirical Risk Minimization (FTW-ERM)\nalong with improving density ratio matching methods without requiring perfect\nknowledge of the supremum over true ratios. We also propose the\ncommunication-efficient variant FITW-ERM with the same level of privacy\nguarantees as those of classical ERM in FL. We theoretically show that FTW-ERM\nachieves smaller generalization error than classical ERM under certain\nsettings. Experimental results demonstrate the superiority of FTW-ERM over\nexisting FL baselines in challenging imbalanced federated settings in terms of\ndata distribution shifts across clients.\n","authors":["Ali Ramezani-Kebrya","Fanghui Liu","Thomas Pethick","Grigorios Chrysos","Volkan Cevher"],"pdf_url":"https://arxiv.org/pdf/2306.05325v1.pdf","comment":"Published in Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2306.05323v1","updated":"2023-06-08T16:15:46Z","published":"2023-06-08T16:15:46Z","title":"Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application","summary":"  The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.\n","authors":["Claudio Crema","Tommaso Mario Buonocore","Silvia Fostinelli","Enea Parimbelli","Federico Verde","Cira Fundarò","Marina Manera","Matteo Cotta Ramusino","Marco Capelli","Alfredo Costa","Giuliano Binetti","Riccardo Bellazzi","Alberto Redolfi"],"pdf_url":"https://arxiv.org/pdf/2306.05323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05321v1","updated":"2023-06-08T16:13:29Z","published":"2023-06-08T16:13:29Z","title":"Real-time whole-heart electromechanical simulations using Latent Neural\n  Ordinary Differential Equations","summary":"  Cardiac digital twins provide a physics and physiology informed framework to\ndeliver predictive and personalized medicine. However, high-fidelity\nmulti-scale cardiac models remain a barrier to adoption due to their extensive\ncomputational costs and the high number of model evaluations needed for\npatient-specific personalization. Artificial Intelligence-based methods can\nmake the creation of fast and accurate whole-heart digital twins feasible. In\nthis work, we use Latent Neural Ordinary Differential Equations (LNODEs) to\nlearn the temporal pressure-volume dynamics of a heart failure patient. Our\nsurrogate model based on LNODEs is trained from 400 3D-0D whole-heart\nclosed-loop electromechanical simulations while accounting for 43 model\nparameters, describing single cell through to whole organ and cardiovascular\nhemodynamics. The trained LNODEs provides a compact and efficient\nrepresentation of the 3D-0D model in a latent space by means of a feedforward\nfully-connected Artificial Neural Network that retains 3 hidden layers with 13\nneurons per layer and allows for 300x real-time numerical simulations of the\ncardiac function on a single processor of a standard laptop. This surrogate\nmodel is employed to perform global sensitivity analysis and robust parameter\nestimation with uncertainty quantification in 3 hours of computations, still on\na single processor. We match pressure and volume time traces unseen by the\nLNODEs during the training phase and we calibrate 4 to 11 model parameters\nwhile also providing their posterior distribution. This paper introduces the\nmost advanced surrogate model of cardiac function available in the literature\nand opens new important venues for parameter calibration in cardiac digital\ntwins.\n","authors":["Matteo Salvador","Marina Strocchi","Francesco Regazzoni","Luca Dede'","Steven Niederer","Alfio Quarteroni"],"pdf_url":"https://arxiv.org/pdf/2306.05321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05319v1","updated":"2023-06-08T16:11:57Z","published":"2023-06-08T16:11:57Z","title":"RNN-Based GNSS Positioning using Satellite Measurement Features and\n  Pseudorange Residuals","summary":"  In the Global Navigation Satellite System (GNSS) context, the growing number\nof available satellites has lead to many challenges when it comes to choosing\nthe most accurate pseudorange contributions, given the strong impact of biased\nmeasurements on positioning accuracy, particularly in single-epoch scenarios.\nThis work leverages the potential of machine learning in predicting link-wise\nmeasurement quality factors and, hence, optimize measurement weighting. For\nthis purpose, we use a customized matrix composed of heterogeneous features\nsuch as conditional pseudorange residuals and per-link satellite metrics (e.g.,\ncarrier-to-noise power density ratio and its empirical statistics, satellite\nelevation, carrier phase lock time). This matrix is then fed as an input to a\nrecurrent neural network (RNN) (i.e., a long-short term memory (LSTM) network).\nOur experimental results on real data, obtained from extensive field\nmeasurements, demonstrate the high potential of our proposed solution being\nable to outperform traditional measurements weighting and selection strategies\nfrom state-of-the-art.\n","authors":["Ibrahim Sbeity","Christophe Villien","Benoît Denis","E. Veronica Belmega"],"pdf_url":"https://arxiv.org/pdf/2306.05319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01103v2","updated":"2023-06-08T16:02:32Z","published":"2023-06-01T19:33:30Z","title":"Joint Learning of Label and Environment Causal Independence for Graph\n  Out-of-Distribution Generalization","summary":"  We tackle the problem of graph out-of-distribution (OOD) generalization.\nExisting graph OOD algorithms either rely on restricted assumptions or fail to\nexploit environment information in training data. In this work, we propose to\nsimultaneously incorporate label and environment causal independence (LECI) to\nfully make use of label and environment information, thereby addressing the\nchallenges faced by prior methods on identifying causal and invariant\nsubgraphs. We further develop an adversarial training strategy to jointly\noptimize these two properties for causal subgraph discovery with theoretical\nguarantees. Extensive experiments and analysis show that LECI significantly\noutperforms prior methods on both synthetic and real-world datasets,\nestablishing LECI as a practical and effective solution for graph OOD\ngeneralization.\n","authors":["Shurui Gui","Meng Liu","Xiner Li","Youzhi Luo","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2306.01103v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05310v1","updated":"2023-06-08T15:59:31Z","published":"2023-06-08T15:59:31Z","title":"A framework for dynamically training and adapting deep reinforcement\n  learning models to different, low-compute, and continuously changing\n  radiology deployment environments","summary":"  While Deep Reinforcement Learning has been widely researched in medical\nimaging, the training and deployment of these models usually require powerful\nGPUs. Since imaging environments evolve rapidly and can be generated by edge\ndevices, the algorithm is required to continually learn and adapt to changing\nenvironments, and adjust to low-compute devices. To this end, we developed\nthree image coreset algorithms to compress and denoise medical images for\nselective experience replayed-based lifelong reinforcement learning. We\nimplemented neighborhood averaging coreset, neighborhood sensitivity-based\nsampling coreset, and maximum entropy coreset on full-body DIXON water and\nDIXON fat MRI images. All three coresets produced 27x compression with\nexcellent performance in localizing five anatomical landmarks: left knee, right\ntrochanter, left kidney, spleen, and lung across both imaging environments.\nMaximum entropy coreset obtained the best performance of $11.97\\pm 12.02$\naverage distance error, compared to the conventional lifelong learning\nframework's $19.24\\pm 50.77$.\n","authors":["Guangyao Zheng","Shuhao Lai","Vladimir Braverman","Michael A. Jacobs","Vishwa S. Parekh"],"pdf_url":"https://arxiv.org/pdf/2306.05310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05307v1","updated":"2023-06-08T15:56:57Z","published":"2023-06-08T15:56:57Z","title":"Are fairness metric scores enough to assess discrimination biases in\n  machine learning?","summary":"  This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.\n","authors":["Fanny Jourdan","Laurent Risser","Jean-Michel Loubes","Nicholas Asher"],"pdf_url":"https://arxiv.org/pdf/2306.05307v1.pdf","comment":"Accepted for publication at Third Workshop on Trustworthy Natural\n  Language Processing, ACL 2023"},{"id":"http://arxiv.org/abs/2109.06919v3","updated":"2023-06-08T15:53:37Z","published":"2021-09-14T18:41:36Z","title":"Deploying clinical machine learning? Consider the following...","summary":"  Despite the intense attention and considerable investment into clinical\nmachine learning research, relatively few applications have been deployed at a\nlarge-scale in a real-world clinical environment. While research is important\nin advancing the state-of-the-art, translation is equally important in bringing\nthese techniques and technologies into a position to ultimately impact\nhealthcare. We believe a lack of appreciation for several considerations are a\nmajor cause for this discrepancy between expectation and reality. To better\ncharacterize a holistic perspective among researchers and practitioners, we\nsurvey several practitioners with commercial experience in developing CML for\nclinical deployment. Using these insights, we identify several main categories\nof challenges in order to better design and develop clinical machine learning\napplications.\n","authors":["Charles Lu","Ken Chang","Praveer Singh","Stuart Pomerantz","Sean Doyle","Sujay Kakarmath","Christopher Bridge","Jayashree Kalpathy-Cramer"],"pdf_url":"https://arxiv.org/pdf/2109.06919v3.pdf","comment":"Trustworthy AI for Healthcare workshop at AAAI 2022"},{"id":"http://arxiv.org/abs/2206.08005v2","updated":"2023-06-08T15:52:21Z","published":"2022-06-16T09:01:53Z","title":"Evaluating Self-Supervised Learning for Molecular Graph Embeddings","summary":"  Graph Self-Supervised Learning (GSSL) provides a robust pathway for acquiring\nembeddings without expert labelling, a capability that carries profound\nimplications for molecular graphs due to the staggering number of potential\nmolecules and the high cost of obtaining labels. However, GSSL methods are\ndesigned not for optimisation within a specific domain but rather for\ntransferability across a variety of downstream tasks. This broad applicability\ncomplicates their evaluation. Addressing this challenge, we present \"Molecular\nGraph Representation Evaluation\" (MOLGRAPHEVAL), generating detailed profiles\nof molecular graph embeddings with interpretable and diversified attributes.\nMOLGRAPHEVAL offers a suite of probing tasks grouped into three categories: (i)\ngeneric graph, (ii) molecular substructure, and (iii) embedding space\nproperties. By leveraging MOLGRAPHEVAL to benchmark existing GSSL methods\nagainst both current downstream datasets and our suite of tasks, we uncover\nsignificant inconsistencies between inferences drawn solely from existing\ndatasets and those derived from more nuanced probing. These findings suggest\nthat current evaluation methodologies fail to capture the entirety of the\nlandscape.\n","authors":["Hanchen Wang","Jean Kaddour","Shengchao Liu","Jian Tang","Joan Lasenby","Qi Liu"],"pdf_url":"https://arxiv.org/pdf/2206.08005v2.pdf","comment":"update results"},{"id":"http://arxiv.org/abs/2306.05304v1","updated":"2023-06-08T15:50:35Z","published":"2023-06-08T15:50:35Z","title":"Bayesian Optimisation of Functions on Graphs","summary":"  The increasing availability of graph-structured data motivates the task of\noptimising over functions defined on the node set of graphs. Traditional graph\nsearch algorithms can be applied in this case, but they may be\nsample-inefficient and do not make use of information about the function\nvalues; on the other hand, Bayesian optimisation is a class of promising\nblack-box solvers with superior sample efficiency, but it has been scarcely\nbeen applied to such novel setups. To fill this gap, we propose a novel\nBayesian optimisation framework that optimises over functions defined on\ngeneric, large-scale and potentially unknown graphs. Through the learning of\nsuitable kernels on graphs, our framework has the advantage of adapting to the\nbehaviour of the target function. The local modelling approach further\nguarantees the efficiency of our method. Extensive experiments on both\nsynthetic and real-world graphs demonstrate the effectiveness of the proposed\noptimisation framework.\n","authors":["Xingchen Wan","Pierre Osselin","Henry Kenlay","Binxin Ru","Michael A. Osborne","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2306.05304v1.pdf","comment":"10 pages, 9 figures, 1 table (23 pages, 24 figures, 1 table including\n  references and appendices)"},{"id":"http://arxiv.org/abs/2306.05300v1","updated":"2023-06-08T15:45:57Z","published":"2023-06-08T15:45:57Z","title":"Correlated Noise in Epoch-Based Stochastic Gradient Descent:\n  Implications for Weight Variances","summary":"  Stochastic gradient descent (SGD) has become a cornerstone of neural network\noptimization, yet the noise introduced by SGD is often assumed to be\nuncorrelated over time, despite the ubiquity of epoch-based training. In this\nwork, we challenge this assumption and investigate the effects of epoch-based\nnoise correlations on the stationary distribution of discrete-time SGD with\nmomentum, limited to a quadratic loss. Our main contributions are twofold:\nfirst, we calculate the exact autocorrelation of the noise for training in\nepochs under the assumption that the noise is independent of small fluctuations\nin the weight vector; second, we explore the influence of correlations\nintroduced by the epoch-based learning scheme on SGD dynamics. We find that for\ndirections with a curvature greater than a hyperparameter-dependent crossover\nvalue, the results for uncorrelated noise are recovered. However, for\nrelatively flat directions, the weight variance is significantly reduced. We\nprovide an intuitive explanation for these results based on a crossover between\ncorrelation times, contributing to a deeper understanding of the dynamics of\nSGD in the presence of epoch-based noise correlations.\n","authors":["Marcel Kühn","Bernd Rosenow"],"pdf_url":"https://arxiv.org/pdf/2306.05300v1.pdf","comment":"25 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.05292v1","updated":"2023-06-08T15:36:02Z","published":"2023-06-08T15:36:02Z","title":"Safe Collaborative Filtering","summary":"  Excellent tail performance is crucial for modern machine learning tasks, such\nas algorithmic fairness, class imbalance, and risk-sensitive decision making,\nas it ensures the effective handling of challenging samples within a dataset.\nTail performance is also a vital determinant of success for personalised\nrecommender systems to reduce the risk of losing users with low satisfaction.\nThis study introduces a \"safe\" collaborative filtering method that prioritises\nrecommendation quality for less-satisfied users rather than focusing on the\naverage performance. Our approach minimises the conditional value at risk\n(CVaR), which represents the average risk over the tails of users' loss. To\novercome computational challenges for web-scale recommender systems, we develop\na robust yet practical algorithm that extends the most scalable method,\nimplicit alternating least squares (iALS). Empirical evaluation on real-world\ndatasets demonstrates the excellent tail performance of our approach while\nmaintaining competitive computational efficiency.\n","authors":["Riku Togashi","Tatsushi Oka","Naoto Ohsaka","Tetsuro Morimura"],"pdf_url":"https://arxiv.org/pdf/2306.05292v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06723v2","updated":"2023-06-08T15:31:46Z","published":"2022-10-13T04:39:41Z","title":"Stochastic noise can be helpful for variational quantum algorithms","summary":"  Saddle points constitute a crucial challenge for first-order gradient descent\nalgorithms. In notions of classical machine learning, they are avoided for\nexample by means of stochastic gradient descent methods. In this work, we\nprovide evidence that the saddle points problem can be naturally avoided in\nvariational quantum algorithms by exploiting the presence of stochasticity. We\nprove convergence guarantees and present practical examples in numerical\nsimulations and on quantum hardware. We argue that the natural stochasticity of\nvariational algorithms can be beneficial for avoiding strict saddle points,\ni.e., those saddle points with at least one negative Hessian eigenvalue. This\ninsight that some levels of shot noise could help is expected to add a new\nperspective to notions of near-term variational quantum algorithms.\n","authors":["Junyu Liu","Frederik Wilde","Antonio Anna Mele","Liang Jiang","Jens Eisert"],"pdf_url":"https://arxiv.org/pdf/2210.06723v2.pdf","comment":"16 pages, 14 figures, presentation improved, proofs extended"},{"id":"http://arxiv.org/abs/2306.05284v1","updated":"2023-06-08T15:31:05Z","published":"2023-06-08T15:31:05Z","title":"Simple and Controllable Music Generation","summary":"  We tackle the task of conditional music generation. We introduce MusicGen, a\nsingle Language Model (LM) that operates over several streams of compressed\ndiscrete music representation, i.e., tokens. Unlike prior work, MusicGen is\ncomprised of a single-stage transformer LM together with efficient token\ninterleaving patterns, which eliminates the need for cascading several models,\ne.g., hierarchically or upsampling. Following this approach, we demonstrate how\nMusicGen can generate high-quality samples, while being conditioned on textual\ndescription or melodic features, allowing better controls over the generated\noutput. We conduct extensive empirical evaluation, considering both automatic\nand human studies, showing the proposed approach is superior to the evaluated\nbaselines on a standard text-to-music benchmark. Through ablation studies, we\nshed light over the importance of each of the components comprising MusicGen.\nMusic samples, code, and models are available at\nhttps://github.com/facebookresearch/audiocraft.\n","authors":["Jade Copet","Felix Kreuk","Itai Gat","Tal Remez","David Kant","Gabriel Synnaeve","Yossi Adi","Alexandre Défossez"],"pdf_url":"https://arxiv.org/pdf/2306.05284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05275v1","updated":"2023-06-08T15:21:47Z","published":"2023-06-08T15:21:47Z","title":"Federated Linear Contextual Bandits with User-level Differential Privacy","summary":"  This paper studies federated linear contextual bandits under the notion of\nuser-level differential privacy (DP). We first introduce a unified federated\nbandits framework that can accommodate various definitions of DP in the\nsequential decision-making setting. We then formally introduce user-level\ncentral DP (CDP) and local DP (LDP) in the federated bandits framework, and\ninvestigate the fundamental trade-offs between the learning regrets and the\ncorresponding DP guarantees in a federated linear contextual bandits model. For\nCDP, we propose a federated algorithm termed as \\robin and show that it is\nnear-optimal in terms of the number of clients $M$ and the privacy budget\n$\\varepsilon$ by deriving nearly-matching upper and lower regret bounds when\nuser-level DP is satisfied. For LDP, we obtain several lower bounds, indicating\nthat learning under user-level $(\\varepsilon,\\delta)$-LDP must suffer a regret\nblow-up factor at least {$\\min\\{1/\\varepsilon,M\\}$ or\n$\\min\\{1/\\sqrt{\\varepsilon},\\sqrt{M}\\}$} under different conditions.\n","authors":["Ruiquan Huang","Huanyu Zhang","Luca Melis","Milan Shen","Meisam Hajzinia","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05275v1.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.05272v1","updated":"2023-06-08T15:20:27Z","published":"2023-06-08T15:20:27Z","title":"Image Clustering via the Principle of Rate Reduction in the Age of\n  Pretrained Models","summary":"  The advent of large pre-trained models has brought about a paradigm shift in\nboth visual representation learning and natural language processing. However,\nclustering unlabeled images, as a fundamental and classic machine learning\nproblem, still lacks effective solution, particularly for large-scale datasets.\nIn this paper, we propose a novel image clustering pipeline that leverages the\npowerful feature representation of large pre-trained models such as CLIP and\ncluster images effectively and efficiently at scale. We show that the\npre-trained features are significantly more structured by further optimizing\nthe rate reduction objective. The resulting features may significantly improve\nthe clustering accuracy, e.g., from 57\\% to 66\\% on ImageNet-1k. Furthermore,\nby leveraging CLIP's image-text binding, we show how the new clustering method\nleads to a simple yet effective self-labeling algorithm that successfully works\non unlabeled large datasets such as MS-COCO and LAION-Aesthetics. We will\nrelease the code in https://github.com/LeslieTrue/CPP.\n","authors":["Tianzhe Chu","Shengbang Tong","Tianjiao Ding","Xili Dai","Benjamin David Haeffele","Rene Vidal","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2306.05272v1.pdf","comment":"21 pages, 13 figures"},{"id":"http://arxiv.org/abs/2306.05268v1","updated":"2023-06-08T15:17:04Z","published":"2023-06-08T15:17:04Z","title":"Factorized Contrastive Learning: Going Beyond Multi-view Redundancy","summary":"  In a wide range of multimodal tasks, contrastive learning has become a\nparticularly appealing approach since it can successfully learn representations\nfrom abundant unlabeled data with only pairing information (e.g., image-caption\nor video-audio pairs). Underpinning these approaches is the assumption of\nmulti-view redundancy - that shared information between modalities is necessary\nand sufficient for downstream tasks. However, in many real-world settings,\ntask-relevant information is also contained in modality-unique regions:\ninformation that is only present in one modality but still relevant to the\ntask. How can we learn self-supervised multimodal representations to capture\nboth shared and unique information relevant to downstream tasks? This paper\nproposes FactorCL, a new multimodal representation learning method to go beyond\nmulti-view redundancy. FactorCL is built from three new contributions: (1)\nfactorizing task-relevant information into shared and unique representations,\n(2) capturing task-relevant information via maximizing MI lower bounds and\nremoving task-irrelevant information via minimizing MI upper bounds, and (3)\nmultimodal data augmentations to approximate task relevance without labels. On\nlarge-scale real-world datasets, FactorCL captures both shared and unique\ninformation and achieves state-of-the-art results on six benchmarks.\n","authors":["Paul Pu Liang","Zihao Deng","Martin Ma","James Zou","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2306.05268v1.pdf","comment":"Code available at: https://github.com/pliang279/FactorCL"},{"id":"http://arxiv.org/abs/2211.05793v2","updated":"2023-06-08T15:16:52Z","published":"2022-11-10T19:00:02Z","title":"A fermion neural network with efficient optimization and quantum\n  applicability","summary":"  Classical artificial neural networks have witnessed widespread successes in\nmachine-learning applications. Here, we propose fermion neural networks (FNNs)\nwhose physical properties, such as local density of states or conditional\nconductance, serve as outputs, once the inputs are incorporated as an initial\nlayer. Comparable to back-propagation, we establish an efficient optimization,\nwhich entitles FNNs to competitive performance on challenging machine-learning\nbenchmarks. FNNs also directly apply to quantum systems, including hard ones\nwith interactions, and offer in-situ analysis without preprocessing or\npresumption. Following machine learning, FNNs precisely determine topological\nphases and emergent charge orders. Their quantum nature also brings various\nadvantages: quantum correlation entitles more general network connectivity and\ninsight into the vanishing gradient problem, quantum entanglement opens up\nnovel avenues for interpretable machine learning, etc.\n","authors":["Pei-Lin Zheng","Jia-Bao Wang","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.05793v2.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2302.01539v3","updated":"2023-06-08T15:05:18Z","published":"2023-02-03T04:30:17Z","title":"A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization","summary":"  One of the most critical problems in machine learning is HyperParameter\nOptimization (HPO), since choice of hyperparameters has a significant impact on\nfinal model performance. Although there are many HPO algorithms, they either\nhave no theoretical guarantees or require strong assumptions. To this end, we\nintroduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes\nLipschitz continuity of the objective function. BLiE exploits the landscape of\nthe objective function to adaptively search over the hyperparameter space.\nTheoretically, we show that $(i)$ BLiE finds an $\\epsilon$-optimal\nhyperparameter with $\\mathcal{O} \\left( \\epsilon^{-(d_z + \\beta)}\\right)$ total\nbudgets, where $d_z$ and $\\beta$ are problem intrinsic; $(ii)$ BLiE is highly\nparallelizable. Empirically, we demonstrate that BLiE outperforms the\nstate-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to\nsearch for noise schedule of diffusion models. Comparison with the default\nschedule shows that BLiE schedule greatly improves the sampling speed.\n","authors":["Yasong Feng","Weijian Luo","Yimin Huang","Tianyu Wang"],"pdf_url":"https://arxiv.org/pdf/2302.01539v3.pdf","comment":"Some preliminaries and backgrounds are drawn from arXiv:2110.09722 by\n  the first author and the last author, and their coauthor Z. Huang"},{"id":"http://arxiv.org/abs/2306.05261v1","updated":"2023-06-08T15:02:04Z","published":"2023-06-08T15:02:04Z","title":"Representing and Learning Functions Invariant Under Crystallographic\n  Groups","summary":"  Crystallographic groups describe the symmetries of crystals and other\nrepetitive structures encountered in nature and the sciences. These groups\ninclude the wallpaper and space groups. We derive linear and nonlinear\nrepresentations of functions that are (1) smooth and (2) invariant under such a\ngroup. The linear representation generalizes the Fourier basis to\ncrystallographically invariant basis functions. We show that such a basis\nexists for each crystallographic group, that it is orthonormal in the relevant\n$L_2$ space, and recover the standard Fourier basis as a special case for pure\nshift groups. The nonlinear representation embeds the orbit space of the group\ninto a finite-dimensional Euclidean space. We show that such an embedding\nexists for every crystallographic group, and that it factors functions through\na generalization of a manifold called an orbifold. We describe algorithms that,\ngiven a standardized description of the group, compute the Fourier basis and an\nembedding map. As examples, we construct crystallographically invariant neural\nnetworks, kernel machines, and Gaussian processes.\n","authors":["Ryan P. Adams","Peter Orbanz"],"pdf_url":"https://arxiv.org/pdf/2306.05261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05257v1","updated":"2023-06-08T14:54:50Z","published":"2023-06-08T14:54:50Z","title":"Comprehensive evaluation of deep and graph learning on drug-drug\n  interactions prediction","summary":"  Recent advances and achievements of artificial intelligence (AI) as well as\ndeep and graph learning models have established their usefulness in biomedical\napplications, especially in drug-drug interactions (DDIs). DDIs refer to a\nchange in the effect of one drug to the presence of another drug in the human\nbody, which plays an essential role in drug discovery and clinical research.\nDDIs prediction through traditional clinical trials and experiments is an\nexpensive and time-consuming process. To correctly apply the advanced AI and\ndeep learning, the developer and user meet various challenges such as the\navailability and encoding of data resources, and the design of computational\nmethods. This review summarizes chemical structure based, network based, NLP\nbased and hybrid methods, providing an updated and accessible guide to the\nbroad researchers and development community with different domain knowledge. We\nintroduce widely-used molecular representation and describe the theoretical\nframeworks of graph neural network models for representing molecular\nstructures. We present the advantages and disadvantages of deep and graph\nlearning methods by performing comparative experiments. We discuss the\npotential technical challenges and highlight future directions of deep and\ngraph learning models for accelerating DDIs prediction.\n","authors":["Xuan Lin","Lichang Dai","Yafang Zhou","Zu-Guo Yu","Wen Zhang","Jian-Yu Shi","Dong-Sheng Cao","Li Zeng","Haowen Chen","Bosheng Song","Philip S. Yu","Xiangxiang Zeng"],"pdf_url":"https://arxiv.org/pdf/2306.05257v1.pdf","comment":"Accepted by Briefings in Bioinformatics"},{"id":"http://arxiv.org/abs/2306.05256v1","updated":"2023-06-08T14:53:02Z","published":"2023-06-08T14:53:02Z","title":"Unscented Autoencoder","summary":"  The Variational Autoencoder (VAE) is a seminal approach in deep generative\nmodeling with latent variables. Interpreting its reconstruction process as a\nnonlinear transformation of samples from the latent posterior distribution, we\napply the Unscented Transform (UT) -- a well-known distribution approximation\nused in the Unscented Kalman Filter (UKF) from the field of filtering. A finite\nset of statistics called sigma points, sampled deterministically, provides a\nmore informative and lower-variance posterior representation than the\nubiquitous noise-scaling of the reparameterization trick, while ensuring\nhigher-quality reconstruction. We further boost the performance by replacing\nthe Kullback-Leibler (KL) divergence with the Wasserstein distribution metric\nthat allows for a sharper posterior. Inspired by the two components, we derive\na novel, deterministic-sampling flavor of the VAE, the Unscented Autoencoder\n(UAE), trained purely with regularization-like terms on the per-sample\nposterior. We empirically show competitive performance in Fr\\'echet Inception\nDistance (FID) scores over closely-related models, in addition to a lower\ntraining variance than the VAE.\n","authors":["Faris Janjoš","Lars Rosenbaum","Maxim Dolgov","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2306.05256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05255v1","updated":"2023-06-08T14:52:56Z","published":"2023-06-08T14:52:56Z","title":"Toward more accurate and generalizable brain deformation estimators for\n  traumatic brain injury detection with unsupervised domain adaptation","summary":"  Machine learning head models (MLHMs) are developed to estimate brain\ndeformation for early detection of traumatic brain injury (TBI). However, the\noverfitting to simulated impacts and the lack of generalizability caused by\ndistributional shift of different head impact datasets hinders the broad\nclinical applications of current MLHMs. We propose brain deformation estimators\nthat integrates unsupervised domain adaptation with a deep neural network to\npredict whole-brain maximum principal strain (MPS) and MPS rate (MPSR). With\n12,780 simulated head impacts, we performed unsupervised domain adaptation on\non-field head impacts from 302 college football (CF) impacts and 457 mixed\nmartial arts (MMA) impacts using domain regularized component analysis (DRCA)\nand cycle-GAN-based methods. The new model improved the MPS/MPSR estimation\naccuracy, with the DRCA method significantly outperforming other domain\nadaptation methods in prediction accuracy (p<0.001): MPS RMSE: 0.027 (CF) and\n0.037 (MMA); MPSR RMSE: 7.159 (CF) and 13.022 (MMA). On another two hold-out\ntest sets with 195 college football impacts and 260 boxing impacts, the DRCA\nmodel significantly outperformed the baseline model without domain adaptation\nin MPS and MPSR estimation accuracy (p<0.001). The DRCA domain adaptation\nreduces the MPS/MPSR estimation error to be well below TBI thresholds, enabling\naccurate brain deformation estimation to detect TBI in future clinical\napplications.\n","authors":["Xianghao Zhan","Jiawei Sun","Yuzhe Liu","Nicholas J. Cecchi","Enora Le Flao","Olivier Gevaert","Michael M. Zeineh","David B. Camarillo"],"pdf_url":"https://arxiv.org/pdf/2306.05255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04705v2","updated":"2023-06-08T14:46:47Z","published":"2022-07-19T15:57:14Z","title":"Classification of Stress via Ambulatory ECG and GSR Data","summary":"  In healthcare, detecting stress and enabling individuals to monitor their\nmental health and wellbeing is challenging. Advancements in wearable technology\nnow enable continuous physiological data collection. This data can provide\ninsights into mental health and behavioural states through psychophysiological\nanalysis. However, automated analysis is required to provide timely results due\nto the quantity of data collected. Machine learning has shown efficacy in\nproviding an automated classification of physiological data for health\napplications in controlled laboratory environments. Ambulatory uncontrolled\nenvironments, however, provide additional challenges requiring further\nmodelling to overcome. This work empirically assesses several approaches\nutilising machine learning classifiers to detect stress using physiological\ndata recorded in an ambulatory setting with self-reported stress annotations. A\nsubset of the training portion SMILE dataset enables the evaluation of\napproaches before submission. The optimal stress detection approach achieves\n90.77% classification accuracy, 91.24 F1-Score, 90.42 Sensitivity and 91.08\nSpecificity, utilising an ExtraTrees classifier and feature imputation methods.\nMeanwhile, accuracy on the challenge data is much lower at 59.23% (submission\n#54 from BEaTS-MTU, username ZacDair). The cause of the performance disparity\nis explored in this work.\n","authors":["Zachary Dair","Muhammad Muneeb Saad","Urja Pawar","Samantha Dockray","Ruairi O'Reilly"],"pdf_url":"https://arxiv.org/pdf/2208.04705v2.pdf","comment":"Associated Code to enable reproducible experimental work -\n  https://github.com/ZacDair/EMBC_Release SMILE dataset provided by\n  Computational Wellbeing Group (COMPWELL)\n  https://compwell.rice.edu/workshops/embc2022/dataset -\n  https://compwell.rice.edu/"},{"id":"http://arxiv.org/abs/2306.05245v1","updated":"2023-06-08T14:44:23Z","published":"2023-06-08T14:44:23Z","title":"Matching Latent Encoding for Audio-Text based Keyword Spotting","summary":"  Using audio and text embeddings jointly for Keyword Spotting (KWS) has shown\nhigh-quality results, but the key challenge of how to semantically align two\nembeddings for multi-word keywords of different sequence lengths remains\nlargely unsolved. In this paper, we propose an audio-text-based end-to-end\nmodel architecture for flexible keyword spotting (KWS), which builds upon\nlearned audio and text embeddings. Our architecture uses a novel dynamic\nprogramming-based algorithm, Dynamic Sequence Partitioning (DSP), to optimally\npartition the audio sequence into the same length as the word-based text\nsequence using the monotonic alignment of spoken content. Our proposed model\nconsists of an encoder block to get audio and text embeddings, a projector\nblock to project individual embeddings to a common latent space, and an\naudio-text aligner containing a novel DSP algorithm, which aligns the audio and\ntext embeddings to determine if the spoken content is the same as the text.\nExperimental results show that our DSP is more effective than other\npartitioning schemes, and the proposed architecture outperformed the\nstate-of-the-art results on the public dataset in terms of Area Under the ROC\nCurve (AUC) and Equal-Error-Rate (EER) by 14.4 % and 28.9%, respectively.\n","authors":["Kumari Nishu","Minsik Cho","Devang Naik"],"pdf_url":"https://arxiv.org/pdf/2306.05245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05233v1","updated":"2023-06-08T14:31:58Z","published":"2023-06-08T14:31:58Z","title":"Ownership Protection of Generative Adversarial Networks","summary":"  Generative adversarial networks (GANs) have shown remarkable success in image\nsynthesis, making GAN models themselves commercially valuable to legitimate\nmodel owners. Therefore, it is critical to technically protect the intellectual\nproperty of GANs. Prior works need to tamper with the training set or training\nprocess, and they are not robust to emerging model extraction attacks. In this\npaper, we propose a new ownership protection method based on the common\ncharacteristics of a target model and its stolen models. Our method can be\ndirectly applicable to all well-trained GANs as it does not require retraining\ntarget models. Extensive experimental results show that our new method can\nachieve the best protection performance, compared to the state-of-the-art\nmethods. Finally, we demonstrate the effectiveness of our method with respect\nto the number of generations of model extraction attacks, the number of\ngenerated samples, different datasets, as well as adaptive attacks.\n","authors":["Hailong Hu","Jun Pang"],"pdf_url":"https://arxiv.org/pdf/2306.05233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01244v2","updated":"2023-06-08T14:31:31Z","published":"2022-11-02T16:25:54Z","title":"EquiMod: An Equivariance Module to Improve Self-Supervised Learning","summary":"  Self-supervised visual representation methods are closing the gap with\nsupervised learning performance. These methods rely on maximizing the\nsimilarity between embeddings of related synthetic inputs created through data\naugmentations. This can be seen as a task that encourages embeddings to leave\nout factors modified by these augmentations, i.e. to be invariant to them.\nHowever, this only considers one side of the trade-off in the choice of the\naugmentations: they need to strongly modify the images to avoid simple solution\nshortcut learning (e.g. using only color histograms), but on the other hand,\naugmentations-related information may be lacking in the representations for\nsome downstream tasks (e.g. color is important for birds and flower\nclassification). Few recent works proposed to mitigate the problem of using\nonly an invariance task by exploring some form of equivariance to\naugmentations. This has been performed by learning additional embeddings\nspace(s), where some augmentation(s) cause embeddings to differ, yet in a\nnon-controlled way. In this work, we introduce EquiMod a generic equivariance\nmodule that structures the learned latent space, in the sense that our module\nlearns to predict the displacement in the embedding space caused by the\naugmentations. We show that applying that module to state-of-the-art invariance\nmodels, such as SimCLR and BYOL, increases the performances on CIFAR10 and\nImageNet datasets. Moreover, while our model could collapse to a trivial\nequivariance, i.e. invariance, we observe that it instead automatically learns\nto keep some augmentations-related information beneficial to the\nrepresentations.\n","authors":["Alexandre Devillers","Mathieu Lefort"],"pdf_url":"https://arxiv.org/pdf/2211.01244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05225v1","updated":"2023-06-08T14:21:02Z","published":"2023-06-08T14:21:02Z","title":"Boosting Adversarial Transferability by Achieving Flat Local Maxima","summary":"  Transfer-based attack adopts the adversarial examples generated on the\nsurrogate model to attack various models, making it applicable in the physical\nworld and attracting increasing interest. Recently, various adversarial attacks\nhave emerged to boost adversarial transferability from different perspectives.\nIn this work, inspired by the fact that flat local minima are correlated with\ngood generalization, we assume and empirically validate that adversarial\nexamples at a flat local region tend to have good transferability by\nintroducing a penalized gradient norm to the original loss function. Since\ndirectly optimizing the gradient regularization norm is computationally\nexpensive and intractable for generating adversarial examples, we propose an\napproximation optimization method to simplify the gradient update of the\nobjective function. Specifically, we randomly sample an example and adopt the\nfirst-order gradient to approximate the second-order Hessian matrix, which\nmakes computing more efficient by interpolating two Jacobian matrices.\nMeanwhile, in order to obtain a more stable gradient direction, we randomly\nsample multiple examples and average the gradients of these examples to reduce\nthe variance due to random sampling during the iterative process. Extensive\nexperimental results on the ImageNet-compatible dataset show that the proposed\nmethod can generate adversarial examples at flat local regions, and\nsignificantly improve the adversarial transferability on either normally\ntrained models or adversarially trained models than the state-of-the-art\nattacks.\n","authors":["Zhijin Ge","Fanhua Shang","Hongying Liu","Yuanyuan Liu","Xiaosen Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05225v1.pdf","comment":"17 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2306.05211v1","updated":"2023-06-08T14:09:38Z","published":"2023-06-08T14:09:38Z","title":"Boosting-based Construction of BDDs for Linear Threshold Functions and\n  Its Application to Verification of Neural Networks","summary":"  Understanding the characteristics of neural networks is important but\ndifficult due to their complex structures and behaviors. Some previous work\nproposes to transform neural networks into equivalent Boolean expressions and\napply verification techniques for characteristics of interest. This approach is\npromising since rich results of verification techniques for circuits and other\nBoolean expressions can be readily applied. The bottleneck is the time\ncomplexity of the transformation. More precisely, (i) each neuron of the\nnetwork, i.e., a linear threshold function, is converted to a Binary Decision\nDiagram (BDD), and (ii) they are further combined into some final form, such as\nBoolean circuits. For a linear threshold function with $n$ variables, an\nexisting method takes $O(n2^{\\frac{n}{2}})$ time to construct an ordered BDD of\nsize $O(2^{\\frac{n}{2}})$ consistent with some variable ordering. However, it\nis non-trivial to choose a variable ordering producing a small BDD among $n!$\ncandidates.\n  We propose a method to convert a linear threshold function to a specific form\nof a BDD based on the boosting approach in the machine learning literature. Our\nmethod takes $O(2^n \\text{poly}(1/\\rho))$ time and outputs BDD of size\n$O(\\frac{n^2}{\\rho^4}\\ln{\\frac{1}{\\rho}})$, where $\\rho$ is the margin of some\nconsistent linear threshold function. Our method does not need to search for\ngood variable orderings and produces a smaller expression when the margin of\nthe linear threshold function is large. More precisely, our method is based on\nour new boosting algorithm, which is of independent interest. We also propose a\nmethod to combine them into the final Boolean expression representing the\nneural network.\n","authors":["Yiping Tang","Kohei Hatano","Eiji Takimoto"],"pdf_url":"https://arxiv.org/pdf/2306.05211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05208v1","updated":"2023-06-08T14:05:06Z","published":"2023-06-08T14:05:06Z","title":"PriSampler: Mitigating Property Inference of Diffusion Models","summary":"  Diffusion models have been remarkably successful in data synthesis. Such\nsuccesses have also driven diffusion models to apply to sensitive data, such as\nhuman face data, but this might bring about severe privacy concerns. In this\nwork, we systematically present the first privacy study about property\ninference attacks against diffusion models, in which adversaries aim to extract\nsensitive global properties of the training set from a diffusion model, such as\nthe proportion of the training data for certain sensitive properties.\nSpecifically, we consider the most practical attack scenario: adversaries are\nonly allowed to obtain synthetic data. Under this realistic scenario, we\nevaluate the property inference attacks on different types of samplers and\ndiffusion models. A broad range of evaluations shows that various diffusion\nmodels and their samplers are all vulnerable to property inference attacks.\nFurthermore, one case study on off-the-shelf pre-trained diffusion models also\ndemonstrates the effectiveness of the attack in practice. Finally, we propose a\nnew model-agnostic plug-in method PriSampler to mitigate the property inference\nof diffusion models. PriSampler can be directly applied to well-trained\ndiffusion models and support both stochastic and deterministic sampling.\nExtensive experiments illustrate the effectiveness of our defense and it makes\nadversaries infer the proportion of properties as close as random guesses.\nPriSampler also shows its significantly superior performance to diffusion\nmodels trained with differential privacy on both model utility and defense\nperformance.\n","authors":["Hailong Hu","Jun Pang"],"pdf_url":"https://arxiv.org/pdf/2306.05208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03718v2","updated":"2023-06-08T13:43:12Z","published":"2023-06-06T14:28:57Z","title":"Emotion-Conditioned Melody Harmonization with Hierarchical Variational\n  Autoencoder","summary":"  Existing melody harmonization models have made great progress in improving\nthe quality of generated harmonies, but most of them ignored the emotions\nbeneath the music. Meanwhile, the variability of harmonies generated by\nprevious methods is insufficient. To solve these problems, we propose a novel\nLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate the\ninfluence of emotional conditions on melody harmonization, while improving the\nquality of generated harmonies and capturing the abundant variability of chord\nprogressions. Specifically, LHVAE incorporates latent variables and emotional\nconditions at different levels (piece- and bar-level) to model the global and\nlocal music properties. Additionally, we introduce an attention-based melody\ncontext vector at each step to better learn the correspondence between melodies\nand harmonies. Experimental results of the objective evaluation show that our\nproposed model outperforms other LSTM-based models. Through subjective\nevaluation, we conclude that only altering the chords hardly changes the\noverall emotion of the music. The qualitative analysis demonstrates the ability\nof our model to generate variable harmonies.\n","authors":["Shulei Ji","Xinyu Yang"],"pdf_url":"https://arxiv.org/pdf/2306.03718v2.pdf","comment":"Accepted by IEEE SMC 2023"},{"id":"http://arxiv.org/abs/2306.05189v1","updated":"2023-06-08T13:39:08Z","published":"2023-06-08T13:39:08Z","title":"EMO: Episodic Memory Optimization for Few-Shot Meta-Learning","summary":"  Few-shot meta-learning presents a challenge for gradient descent optimization\ndue to the limited number of training samples per task. To address this issue,\nwe propose an episodic memory optimization for meta-learning, we call\n\\emph{EMO}, which is inspired by the human ability to recall past learning\nexperiences from the brain's memory. EMO retains the gradient history of past\nexperienced tasks in external memory, enabling few-shot learning in a\nmemory-augmented way. By learning to retain and recall the learning process of\npast training tasks, EMO nudges parameter updates in the right direction, even\nwhen the gradients provided by a limited number of examples are uninformative.\nWe prove theoretically that our algorithm converges for smooth, strongly convex\nobjectives. EMO is generic, flexible, and model-agnostic, making it a simple\nplug-and-play optimizer that can be seamlessly embedded into existing\noptimization-based few-shot meta-learning approaches. Empirical results show\nthat EMO scales well with most few-shot classification benchmarks and improves\nthe performance of optimization-based meta-learning methods, resulting in\naccelerated convergence.\n","authors":["Yingjun Du","Jiayi Shen","Xiantong Zhen","Cee G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2306.05189v1.pdf","comment":"Accepted by CoLLAs 2023"},{"id":"http://arxiv.org/abs/2306.05185v1","updated":"2023-06-08T13:33:20Z","published":"2023-06-08T13:33:20Z","title":"On the Identification and Optimization of Nonsmooth Superposition\n  Operators in Semilinear Elliptic PDEs","summary":"  We study an infinite-dimensional optimization problem that aims to identify\nthe Nemytskii operator in the nonlinear part of a prototypical semilinear\nelliptic partial differential equation (PDE) which minimizes the distance\nbetween the PDE-solution and a given desired state. In contrast to previous\nworks, we consider this identification problem in a low-regularity regime in\nwhich the function inducing the Nemytskii operator is a-priori only known to be\nan element of $H^1_{loc}(\\mathbb{R})$. This makes the studied problem class a\nsuitable point of departure for the rigorous analysis of training problems for\nlearning-informed PDEs in which an unknown superposition operator is\napproximated by means of a neural network with nonsmooth activation functions\n(ReLU, leaky-ReLU, etc.). We establish that, despite the low regularity of the\ncontrols, it is possible to derive a classical stationarity system for local\nminimizers and to solve the considered problem by means of a gradient\nprojection method. The convergence of the resulting algorithm is proven in the\nfunction space setting. It is also shown that the established first-order\nnecessary optimality conditions imply that locally optimal superposition\noperators share various characteristic properties with commonly used activation\nfunctions: They are always sigmoidal, continuously differentiable away from the\norigin, and typically possess a distinct kink at zero. The paper concludes with\nnumerical experiments which confirm the theoretical findings.\n","authors":["Constantin Christof","Julia Kowalczyk"],"pdf_url":"https://arxiv.org/pdf/2306.05185v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06641v2","updated":"2023-06-08T13:33:01Z","published":"2022-12-13T15:24:41Z","title":"Simplicity Bias Leads to Amplified Performance Disparities","summary":"  Which parts of a dataset will a given model find difficult? Recent work has\nshown that SGD-trained models have a bias towards simplicity, leading them to\nprioritize learning a majority class, or to rely upon harmful spurious\ncorrelations. Here, we show that the preference for \"easy\" runs far deeper: A\nmodel may prioritize any class or group of the dataset that it finds simple-at\nthe expense of what it finds complex-as measured by performance difference on\nthe test set. When subsets with different levels of complexity align with\ndemographic groups, we term this difficulty disparity, a phenomenon that occurs\neven with balanced datasets that lack group/label associations. We show how\ndifficulty disparity is a model-dependent quantity, and is further amplified in\ncommonly-used models as selected by typical average performance scores. We\nquantify an amplification factor across a range of settings in order to compare\ndisparity of different models on a fixed dataset. Finally, we present two\nreal-world examples of difficulty amplification in action, resulting in\nworse-than-expected performance disparities between groups even when using a\nbalanced dataset. The existence of such disparities in balanced datasets\ndemonstrates that merely balancing sample sizes of groups is not sufficient to\nensure unbiased performance. We hope this work presents a step towards\nmeasurable understanding of the role of model bias as it interacts with the\nstructure of data, and call for additional model-dependent mitigation methods\nto be deployed alongside dataset audits.\n","authors":["Samuel J. Bell","Levent Sagun"],"pdf_url":"https://arxiv.org/pdf/2212.06641v2.pdf","comment":"In 2023 ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT '23). ACM"},{"id":"http://arxiv.org/abs/2305.14035v3","updated":"2023-06-08T13:32:43Z","published":"2023-05-23T13:06:14Z","title":"Can Self-Supervised Neural Representations Pre-Trained on Human Speech\n  distinguish Animal Callers?","summary":"  Self-supervised learning (SSL) models use only the intrinsic structure of a\ngiven signal, independent of its acoustic domain, to extract essential\ninformation from the input to an embedding space. This implies that the utility\nof such representations is not limited to modeling human speech alone. Building\non this understanding, this paper explores the cross-transferability of SSL\nneural representations learned from human speech to analyze bio-acoustic\nsignals. We conduct a caller discrimination analysis and a caller detection\nstudy on Marmoset vocalizations using eleven SSL models pre-trained with\nvarious pretext tasks. The results show that the embedding spaces carry\nmeaningful caller information and can successfully distinguish the individual\nidentities of Marmoset callers without fine-tuning. This demonstrates that\nrepresentations pre-trained on human speech can be effectively applied to the\nbio-acoustics domain, providing valuable insights for future investigations in\nthis field.\n","authors":["Eklavya Sarkar","Mathew Magimai. -Doss"],"pdf_url":"https://arxiv.org/pdf/2305.14035v3.pdf","comment":"Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2305.17155v2","updated":"2023-06-08T13:29:44Z","published":"2023-05-26T13:58:48Z","title":"Stability of implicit neural networks for long-term forecasting in\n  dynamical systems","summary":"  Forecasting physical signals in long time range is among the most challenging\ntasks in Partial Differential Equations (PDEs) research. To circumvent\nlimitations of traditional solvers, many different Deep Learning methods have\nbeen proposed. They are all based on auto-regressive methods and exhibit\nstability issues. Drawing inspiration from the stability property of implicit\nnumerical schemes, we introduce a stable auto-regressive implicit neural\nnetwork. We develop a theory based on the stability definition of schemes to\nensure the stability in forecasting of this network. It leads us to introduce\nhard constraints on its weights and propagate the dynamics in the latent space.\nOur experimental results validate our stability property, and show improved\nresults at long-term forecasting for two transports PDEs.\n","authors":["Leon Migus","Julien Salomon","Patrick Gallinari"],"pdf_url":"https://arxiv.org/pdf/2305.17155v2.pdf","comment":"ICLR 2023 Workshop on Physics for Machine Learning"},{"id":"http://arxiv.org/abs/2306.05183v1","updated":"2023-06-08T13:28:48Z","published":"2023-06-08T13:28:48Z","title":"Improving Long Context Document-Level Machine Translation","summary":"  Document-level context for neural machine translation (NMT) is crucial to\nimprove the translation consistency and cohesion, the translation of ambiguous\ninputs, as well as several other linguistic phenomena. Many works have been\npublished on the topic of document-level NMT, but most restrict the system to\nonly local context, typically including just the one or two preceding sentences\nas additional information. This might be enough to resolve some ambiguous\ninputs, but it is probably not sufficient to capture some document-level\ninformation like the topic or style of a conversation. When increasing the\ncontext size beyond just the local context, there are two challenges: (i)\nthe~memory usage increases exponentially (ii) the translation performance\nstarts to degrade. We argue that the widely-used attention mechanism is\nresponsible for both issues. Therefore, we propose a constrained attention\nvariant that focuses the attention on the most relevant parts of the sequence,\nwhile simultaneously reducing the memory consumption. For evaluation, we\nutilize targeted test sets in combination with novel evaluation techniques to\nanalyze the translations in regards to specific discourse-related phenomena. We\nfind that our approach is a good compromise between sentence-level NMT vs\nattending to the full context, especially in low resource scenarios.\n","authors":["Christian Herold","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05183v1.pdf","comment":"accepted at CODI 2023 (ACL workshop)"},{"id":"http://arxiv.org/abs/2210.07213v2","updated":"2023-06-08T13:20:01Z","published":"2022-10-13T17:40:07Z","title":"FARE: Provably Fair Representation Learning with Practical Certificates","summary":"  Fair representation learning (FRL) is a popular class of methods aiming to\nproduce fair classifiers via data preprocessing. Recent regulatory directives\nstress the need for FRL methods that provide practical certificates, i.e.,\nprovable upper bounds on the unfairness of any downstream classifier trained on\npreprocessed data, which directly provides assurance in a practical scenario.\nCreating such FRL methods is an important challenge that remains unsolved. In\nthis work, we address that challenge and introduce FARE (Fairness with\nRestricted Encoders), the first FRL method with practical fairness\ncertificates. FARE is based on our key insight that restricting the\nrepresentation space of the encoder enables the derivation of practical\nguarantees, while still permitting favorable accuracy-fairness tradeoffs for\nsuitable instantiations, such as one we propose based on fair trees. To produce\na practical certificate, we develop and apply a statistical procedure that\ncomputes a finite sample high-confidence upper bound on the unfairness of any\ndownstream classifier trained on FARE embeddings. In our comprehensive\nexperimental evaluation, we demonstrate that FARE produces practical\ncertificates that are tight and often even comparable with purely empirical\nresults obtained by prior methods, which establishes the practical value of our\napproach.\n","authors":["Nikola Jovanović","Mislav Balunović","Dimitar I. Dimitrov","Martin Vechev"],"pdf_url":"https://arxiv.org/pdf/2210.07213v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.05175v1","updated":"2023-06-08T13:14:35Z","published":"2023-06-08T13:14:35Z","title":"Large-scale Dataset Pruning with Dynamic Uncertainty","summary":"  The state of the art of many learning tasks, e.g., image classification, is\nadvanced by collecting larger datasets and then training larger models on them.\nAs the outcome, the increasing computational cost is becoming unaffordable. In\nthis paper, we investigate how to prune the large-scale datasets, and thus\nproduce an informative subset for training sophisticated deep models with\nnegligible performance drop. We propose a simple yet effective dataset pruning\nmethod by exploring both the prediction uncertainty and training dynamics. To\nour knowledge, this is the first work to study dataset pruning on large-scale\ndatasets, i.e., ImageNet-1K and ImageNet-21K, and advanced models, i.e., Swin\nTransformer and ConvNeXt. Extensive experimental results indicate that our\nmethod outperforms the state of the art and achieves 75% lossless compression\nratio on both ImageNet-1K and ImageNet-21K. The code and pruned datasets are\navailable at https://github.com/BAAI-DCAI/Dataset-Pruning.\n","authors":["Muyang He","Shuo Yang","Tiejun Huang","Bo Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.05175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05172v1","updated":"2023-06-08T13:11:20Z","published":"2023-06-08T13:11:20Z","title":"FLEdge: Benchmarking Federated Machine Learning Applications in Edge\n  Computing Systems","summary":"  Federated Machine Learning (FL) has received considerable attention in recent\nyears. FL benchmarks are predominantly explored in either simulated systems or\ndata center environments, neglecting the setups of real-world systems, which\nare often closely linked to edge computing. We close this research gap by\nintroducing FLEdge, a benchmark targeting FL workloads in edge computing\nsystems. We systematically study hardware heterogeneity, energy efficiency\nduring training, and the effect of various differential privacy levels on\ntraining in FL systems. To make this benchmark applicable to real-world\nscenarios, we evaluate the impact of client dropouts on state-of-the-art FL\nstrategies with failure rates as high as 50%. FLEdge provides new insights,\nsuch as that training state-of-the-art FL workloads on older GPU-accelerated\nembedded devices is up to 3x more energy efficient than on modern server-grade\nGPUs.\n","authors":["Herbert Woisetschläger","Alexander Isenko","Ruben Mayer","Hans-Arno Jacobsen"],"pdf_url":"https://arxiv.org/pdf/2306.05172v1.pdf","comment":"Preprint. Under Review"},{"id":"http://arxiv.org/abs/2306.05167v1","updated":"2023-06-08T13:03:53Z","published":"2023-06-08T13:03:53Z","title":"Decision S4: Efficient Sequence-Based RL via State Spaces Layers","summary":"  Recently, sequence learning methods have been applied to the problem of\noff-policy Reinforcement Learning, including the seminal work on Decision\nTransformers, which employs transformers for this task. Since transformers are\nparameter-heavy, cannot benefit from history longer than a fixed window size,\nand are not computed using recurrence, we set out to investigate the\nsuitability of the S4 family of models, which are based on state-space layers\nand have been shown to outperform transformers, especially in modeling\nlong-range dependencies. In this work we present two main algorithms: (i) an\noff-policy training procedure that works with trajectories, while still\nmaintaining the training efficiency of the S4 model. (ii) An on-policy training\nprocedure that is trained in a recurrent manner, benefits from long-range\ndependencies, and is based on a novel stable actor-critic mechanism. Our\nresults indicate that our method outperforms multiple variants of decision\ntransformers, as well as the other baseline methods on most tasks, while\nreducing the latency, number of parameters, and training time by several orders\nof magnitude, making our approach more suitable for real-world RL.\n","authors":["Shmuel Bar-David","Itamar Zimerman","Eliya Nachmani","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2306.05167v1.pdf","comment":"21 pages,13 figures"},{"id":"http://arxiv.org/abs/2306.02081v2","updated":"2023-06-08T12:47:48Z","published":"2023-06-03T11:07:18Z","title":"Message-passing selection: Towards interpretable GNNs for graph\n  classification","summary":"  In this paper, we strive to develop an interpretable GNNs' inference\nparadigm, termed MSInterpreter, which can serve as a plug-and-play scheme\nreadily applicable to various GNNs' baselines. Unlike the most existing\nexplanation methods, MSInterpreter provides a Message-passing Selection\nscheme(MSScheme) to select the critical paths for GNNs' message aggregations,\nwhich aims at reaching the self-explaination instead of post-hoc explanations.\nIn detail, the elaborate MSScheme is designed to calculate weight factors of\nmessage aggregation paths by considering the vanilla structure and node\nembedding components, where the structure base aims at weight factors among\nnode-induced substructures; on the other hand, the node embedding base focuses\non weight factors via node embeddings obtained by one-layer GNN.Finally, we\ndemonstrate the effectiveness of our approach on graph classification\nbenchmarks.\n","authors":["Wenda Li","Kaixuan Chen","Shunyu Liu","Wenjie Huang","Haofei Zhang","Yingjie Tian","Yun Su","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2306.02081v2.pdf","comment":"6 pages, 1 figures"},{"id":"http://arxiv.org/abs/2210.17101v3","updated":"2023-06-08T12:39:59Z","published":"2022-10-31T07:05:44Z","title":"Unrolled Graph Learning for Multi-Agent Collaboration","summary":"  Multi-agent learning has gained increasing attention to tackle distributed\nmachine learning scenarios under constrictions of data exchanging. However,\nexisting multi-agent learning models usually consider data fusion under fixed\nand compulsory collaborative relations among agents, which is not as flexible\nand autonomous as human collaboration. To fill this gap, we propose a\ndistributed multi-agent learning model inspired by human collaboration, in\nwhich the agents can autonomously detect suitable collaborators and refer to\ncollaborators' model for better performance. To implement such adaptive\ncollaboration, we use a collaboration graph to indicate the pairwise\ncollaborative relation. The collaboration graph can be obtained by graph\nlearning techniques based on model similarity between different agents. Since\nmodel similarity can not be formulated by a fixed graphical optimization, we\ndesign a graph learning network by unrolling, which can learn underlying\nsimilar features among potential collaborators. By testing on both regression\nand classification tasks, we validate that our proposed collaboration model can\nfigure out accurate collaborative relationship and greatly improve agents'\nlearning performance.\n","authors":["Enpei Zhang","Shuo Tang","Xiaowen Dong","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2210.17101v3.pdf","comment":"This work was accepted to be presented at the Graph Signal Processing\n  Workshop 2023"},{"id":"http://arxiv.org/abs/2305.12837v2","updated":"2023-06-08T12:38:20Z","published":"2023-05-22T09:00:34Z","title":"Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel\n  Historical Data Reuse Approach","summary":"  Conversion rate (CVR) prediction is one of the core components in online\nrecommender systems, and various approaches have been proposed to obtain\naccurate and well-calibrated CVR estimation. However, we observe that a\nwell-trained CVR prediction model often performs sub-optimally during sales\npromotions. This can be largely ascribed to the problem of the data\ndistribution shift, in which the conventional methods no longer work. To this\nend, we seek to develop alternative modeling techniques for CVR prediction.\nObserving similar purchase patterns across different promotions, we propose\nreusing the historical promotion data to capture the promotional conversion\npatterns. Herein, we propose a novel \\textbf{H}istorical \\textbf{D}ata\n\\textbf{R}euse (\\textbf{HDR}) approach that first retrieves historically\nsimilar promotion data and then fine-tunes the CVR prediction model with the\nacquired data for better adaptation to the promotion mode. HDR consists of\nthree components: an automated data retrieval module that seeks similar data\nfrom historical promotions, a distribution shift correction module that\nre-weights the retrieved data for better aligning with the target promotion,\nand a TransBlock module that quickly fine-tunes the original model for better\nadaptation to the promotion mode. Experiments conducted with real-world data\ndemonstrate the effectiveness of HDR, as it improves both ranking and\ncalibration metrics to a large extent. HDR has also been deployed on the\ndisplay advertising system in Alibaba, bringing a lift of $9\\%$ RPM and $16\\%$\nCVR during Double 11 Sales in 2022.\n","authors":["Zhangming Chan","Yu Zhang","Shuguang Han","Yong Bai","Xiang-Rong Sheng","Siyuan Lou","Jiacen Hu","Baolin Liu","Yuning Jiang","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2305.12837v2.pdf","comment":"Accepted at KDD 2023. This work has already been deployed on the\n  display advertising system in Alibaba, bringing substantial economic gains"},{"id":"http://arxiv.org/abs/2306.05150v1","updated":"2023-06-08T12:18:18Z","published":"2023-06-08T12:18:18Z","title":"Bayesian Optimization of Expensive Nested Grey-Box Functions","summary":"  We consider the problem of optimizing a grey-box objective function, i.e.,\nnested function composed of both black-box and white-box functions. A general\nformulation for such grey-box problems is given, which covers the existing\ngrey-box optimization formulations as special cases. We then design an\noptimism-driven algorithm to solve it. Under certain regularity assumptions,\nour algorithm achieves similar regret bound as that for the standard black-box\nBayesian optimization algorithm, up to a constant multiplicative term depending\non the Lipschitz constants of the functions considered. We further extend our\nmethod to the constrained case and discuss several special cases. For the\ncommonly used kernel functions, the regret bounds allow us to derive a\nconvergence rate to the optimal solution. Experimental results show that our\ngrey-box optimization method empirically improves the speed of finding the\nglobal optimal solution significantly, as compared to the standard black-box\noptimization algorithm.\n","authors":["Wenjie Xu","Yuning Jiang","Bratislav Svetozarevic","Colin N. Jones"],"pdf_url":"https://arxiv.org/pdf/2306.05150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05144v1","updated":"2023-06-08T12:11:16Z","published":"2023-06-08T12:11:16Z","title":"Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in\n  the Mediterranean","summary":"  We introduce Mesogeos, a large-scale multi-purpose dataset for wildfire\nmodeling in the Mediterranean. Mesogeos integrates variables representing\nwildfire drivers (meteorology, vegetation, human activity) and historical\nrecords of wildfire ignitions and burned areas for 17 years (2006-2022). It is\ndesigned as a cloud-friendly spatio-temporal dataset, namely a datacube,\nharmonizing all variables in a grid of 1km x 1km x 1-day resolution. The\ndatacube structure offers opportunities to assess machine learning (ML) usage\nin various wildfire modeling tasks. We extract two ML-ready datasets that\nestablish distinct tracks to demonstrate this potential: (1) short-term\nwildfire danger forecasting and (2) final burned area estimation given the\npoint of ignition. We define appropriate metrics and baselines to evaluate the\nperformance of models in each track. By publishing the datacube, along with the\ncode to create the ML datasets and models, we encourage the community to foster\nthe implementation of additional tracks for mitigating the increasing threat of\nwildfires in the Mediterranean.\n","authors":["Spyros Kondylatos","Ioannis Prapas","Gustau Camps-Valls","Ioannis Papoutsis"],"pdf_url":"https://arxiv.org/pdf/2306.05144v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05143v1","updated":"2023-06-08T12:10:13Z","published":"2023-06-08T12:10:13Z","title":"Genomic Interpreter: A Hierarchical Genomic Deep Neural Network with 1D\n  Shifted Window Transformer","summary":"  Given the increasing volume and quality of genomics data, extracting new\ninsights requires interpretable machine-learning models. This work presents\nGenomic Interpreter: a novel architecture for genomic assay prediction. This\nmodel outperforms the state-of-the-art models for genomic assay prediction\ntasks. Our model can identify hierarchical dependencies in genomic sites. This\nis achieved through the integration of 1D-Swin, a novel Transformer-based block\ndesigned by us for modelling long-range hierarchical data. Evaluated on a\ndataset containing 38,171 DNA segments of 17K base pairs, Genomic Interpreter\ndemonstrates superior performance in chromatin accessibility and gene\nexpression prediction and unmasks the underlying `syntax' of gene regulation.\n","authors":["Zehui Li","Akashaditya Das","William A V Beardall","Yiren Zhao","Guy-Bart Stan"],"pdf_url":"https://arxiv.org/pdf/2306.05143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05131v1","updated":"2023-06-08T11:54:58Z","published":"2023-06-08T11:54:58Z","title":"Conformal Prediction for Federated Uncertainty Quantification Under\n  Label Shift","summary":"  Federated Learning (FL) is a machine learning framework where many clients\ncollaboratively train models while keeping the training data decentralized.\nDespite recent advances in FL, the uncertainty quantification topic (UQ)\nremains partially addressed. Among UQ methods, conformal prediction (CP)\napproaches provides distribution-free guarantees under minimal assumptions. We\ndevelop a new federated conformal prediction method based on quantile\nregression and take into account privacy constraints. This method takes\nadvantage of importance weighting to effectively address the label shift\nbetween agents and provides theoretical guarantees for both valid coverage of\nthe prediction sets and differential privacy. Extensive experimental studies\ndemonstrate that this method outperforms current competitors.\n","authors":["Vincent Plassier","Mehdi Makni","Aleksandr Rubashevskii","Eric Moulines","Maxim Panov"],"pdf_url":"https://arxiv.org/pdf/2306.05131v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2305.08841v2","updated":"2023-06-08T11:53:51Z","published":"2023-05-15T17:55:24Z","title":"A Theoretical Analysis of Optimistic Proximal Policy Optimization in\n  Linear Markov Decision Processes","summary":"  The proximal policy optimization (PPO) algorithm stands as one of the most\nprosperous methods in the field of reinforcement learning (RL). Despite its\nsuccess, the theoretical understanding of PPO remains deficient. Specifically,\nit is unclear whether PPO or its optimistic variants can effectively solve\nlinear Markov decision processes (MDPs), which are arguably the simplest models\nin RL with function approximation. To bridge this gap, we propose an optimistic\nvariant of PPO for episodic adversarial linear MDPs with full-information\nfeedback, and establish a $\\tilde{\\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for\nit. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each\nepisode, and $K$ is the number of episodes. Compared with existing policy-based\nalgorithms, we achieve the state-of-the-art regret bound in both stochastic\nlinear MDPs and adversarial linear MDPs with full information. Additionally,\nour algorithm design features a novel multi-batched updating mechanism and the\ntheoretical analysis utilizes a new covering number argument of value and\npolicy classes, which might be of independent interest.\n","authors":["Han Zhong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.08841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05123v1","updated":"2023-06-08T11:47:02Z","published":"2023-06-08T11:47:02Z","title":"A Meta-Generation framework for Industrial System Generation","summary":"  Generative design is an increasingly important tool in the industrial world.\nIt allows the designers and engineers to easily explore vast ranges of design\noptions, providing a cheaper and faster alternative to the trial and failure\napproaches. Thanks to the flexibility they offer, Deep Generative Models are\ngaining popularity amongst Generative Design technologies. However, developing\nand evaluating these models can be challenging. The field lacks accessible\nbenchmarks, in order to evaluate and compare objectively different Deep\nGenerative Models architectures. Moreover, vanilla Deep Generative Models\nappear to be unable to accurately generate multi-components industrial systems\nthat are controlled by latent design constraints. To address these challenges,\nwe propose an industry-inspired use case that incorporates actual industrial\nsystem characteristics. This use case can be quickly generated and used as a\nbenchmark. We propose a Meta-VAE capable of producing multi-component\nindustrial systems and showcase its application on the proposed use case.\n","authors":["Fouad Oubari","Raphael Meunier","Rodrigue Décatoire","Mathilde Mougeot"],"pdf_url":"https://arxiv.org/pdf/2306.05123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08618v2","updated":"2023-06-08T11:42:32Z","published":"2023-01-20T14:59:33Z","title":"Solving PDEs with Unmeasurable Source Terms Using Coupled\n  Physics-Informed Neural Network with Recurrent Prediction in Soft Sensor\n  Modeling","summary":"  Nonhomogeneous partial differential equations (PDEs) are an applicable model\nin soft sensor modeling for describing spatiotemporal industrial systems with\nunmeasurable source terms, which cannot be well solved by existing\nphysics-informed neural networks (PINNs). To this end, a coupled PINN (CPINN)\nwith a recurrent prediction (RP) learning strategy (CPINN-RP) is proposed for\nsoft sensor modeling in spatiotemporal industrial processes, such as vibration\ndisplacement. First, CPINN containing NetU and NetG is proposed. NetU is used\nto approximate the solutions to PDEs under study and NetG is used to regularize\nthe training of NetU. The two networks are integrated into a\ndata-physics-hybrid loss function. Then, we theoretically prove that the\nproposed CPINN has a satisfying approximation capacity to the PDEs solutions.\nBesides the theoretical aspects, we propose a hierarchical training strategy to\noptimize and couple the two networks to achieve the parameters of CPINN.\nSecondly, NetU-RP is achieved by NetU compensated by RP, the recurrently\ndelayed output of CPINN, to further improve the soft sensor performance.\nFinally, simulations and experiment verify the effectiveness and practical\napplications of CPINN-RP.\n","authors":["Aina Wang","Pan Qin","Xi-Ming Sun"],"pdf_url":"https://arxiv.org/pdf/2301.08618v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05116v1","updated":"2023-06-08T11:30:43Z","published":"2023-06-08T11:30:43Z","title":"On Search Strategies for Document-Level Neural Machine Translation","summary":"  Compared to sentence-level systems, document-level neural machine translation\n(NMT) models produce a more consistent output across a document and are able to\nbetter resolve ambiguities within the input. There are many works on\ndocument-level NMT, mostly focusing on modifying the model architecture or\ntraining strategy to better accommodate the additional context-input. On the\nother hand, in most works, the question on how to perform search with the\ntrained model is scarcely discussed, sometimes not mentioned at all. In this\nwork, we aim to answer the question how to best utilize a context-aware\ntranslation model in decoding. We start with the most popular document-level\nNMT approach and compare different decoding schemes, some from the literature\nand others proposed by us. In the comparison, we are using both, standard\nautomatic metrics, as well as specific linguistic phenomena on three standard\ndocument-level translation benchmarks. We find that most commonly used decoding\nstrategies perform similar to each other and that higher quality context\ninformation has the potential to further improve the translation.\n","authors":["Christian Herold","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05116v1.pdf","comment":"Accepted to ACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.05109v1","updated":"2023-06-08T11:16:20Z","published":"2023-06-08T11:16:20Z","title":"Yet Another ICU Benchmark: A Flexible Multi-Center Framework for\n  Clinical ML","summary":"  Medical applications of machine learning (ML) have experienced a surge in\npopularity in recent years. The intensive care unit (ICU) is a natural habitat\nfor ML given the abundance of available data from electronic health records.\nModels have been proposed to address numerous ICU prediction tasks like the\nearly detection of complications. While authors frequently report\nstate-of-the-art performance, it is challenging to verify claims of\nsuperiority. Datasets and code are not always published, and cohort\ndefinitions, preprocessing pipelines, and training setups are difficult to\nreproduce. This work introduces Yet Another ICU Benchmark (YAIB), a modular\nframework that allows researchers to define reproducible and comparable\nclinical ML experiments; we offer an end-to-end solution from cohort definition\nto model evaluation. The framework natively supports most open-access ICU\ndatasets (MIMIC III/IV, eICU, HiRID, AUMCdb) and is easily adaptable to future\nICU datasets. Combined with a transparent preprocessing pipeline and extensible\ntraining code for multiple ML and deep learning models, YAIB enables unified\nmodel development. Our benchmark comes with five predefined established\nprediction tasks (mortality, acute kidney injury, sepsis, kidney function, and\nlength of stay) developed in collaboration with clinicians. Adding further\ntasks is straightforward by design. Using YAIB, we demonstrate that the choice\nof dataset, cohort definition, and preprocessing have a major impact on the\nprediction performance - often more so than model class - indicating an urgent\nneed for YAIB as a holistic benchmarking tool. We provide our work to the\nclinical ML community to accelerate method development and enable real-world\nclinical implementations. Software Repository:\nhttps://github.com/rvandewater/YAIB.\n","authors":["Robin van de Water","Hendrik Schmidt","Paul Elbers","Patrick Thoral","Bert Arnrich","Patrick Rockenschaub"],"pdf_url":"https://arxiv.org/pdf/2306.05109v1.pdf","comment":"Main benchmark: https://github.com/rvandewater/YAIB, Cohort\n  generation: https://github.com/rvandewater/YAIB-cohorts, Models:\n  https://github.com/rvandewater/YAIB-models"},{"id":"http://arxiv.org/abs/2302.00422v4","updated":"2023-06-08T11:15:41Z","published":"2023-02-01T13:14:26Z","title":"Robust online active learning","summary":"  In many industrial applications, obtaining labeled observations is not\nstraightforward as it often requires the intervention of human experts or the\nuse of expensive testing equipment. In these circumstances, active learning can\nbe highly beneficial in suggesting the most informative data points to be used\nwhen fitting a model. Reducing the number of observations needed for model\ndevelopment alleviates both the computational burden required for training and\nthe operational expenses related to labeling. Online active learning, in\nparticular, is useful in high-volume production processes where the decision\nabout the acquisition of the label for a data point needs to be taken within an\nextremely short time frame. However, despite the recent efforts to develop\nonline active learning strategies, the behavior of these methods in the\npresence of outliers has not been thoroughly examined. In this work, we\ninvestigate the performance of online active linear regression in contaminated\ndata streams. Our study shows that the currently available query strategies are\nprone to sample outliers, whose inclusion in the training set eventually\ndegrades the predictive performance of the models. To address this issue, we\npropose a solution that bounds the search area of a conditional D-optimal\nalgorithm and uses a robust estimator. Our approach strikes a balance between\nexploring unseen regions of the input space and protecting against outliers.\nThrough numerical simulations, we show that the proposed method is effective in\nimproving the performance of online active learning in the presence of\noutliers, thus expanding the potential applications of this powerful tool.\n","authors":["Davide Cacciarelli","Murat Kulahci","John Sølve Tyssedal"],"pdf_url":"https://arxiv.org/pdf/2302.00422v4.pdf","comment":"Published in Quality and Reliability Engineering International (2023)"},{"id":"http://arxiv.org/abs/2306.05108v1","updated":"2023-06-08T11:15:34Z","published":"2023-06-08T11:15:34Z","title":"Hybrid Graph: A Unified Graph Representation with Datasets and\n  Benchmarks for Complex Graphs","summary":"  Graphs are widely used to encapsulate a variety of data formats, but\nreal-world networks often involve complex node relations beyond only being\npairwise. While hypergraphs and hierarchical graphs have been developed and\nemployed to account for the complex node relations, they cannot fully represent\nthese complexities in practice. Additionally, though many Graph Neural Networks\n(GNNs) have been proposed for representation learning on higher-order graphs,\nthey are usually only evaluated on simple graph datasets. Therefore, there is a\nneed for a unified modelling of higher-order graphs, and a collection of\ncomprehensive datasets with an accessible evaluation framework to fully\nunderstand the performance of these algorithms on complex graphs. In this\npaper, we introduce the concept of hybrid graphs, a unified definition for\nhigher-order graphs, and present the Hybrid Graph Benchmark (HGB). HGB contains\n23 real-world hybrid graph datasets across various domains such as biology,\nsocial media, and e-commerce. Furthermore, we provide an extensible evaluation\nframework and a supporting codebase to facilitate the training and evaluation\nof GNNs on HGB. Our empirical study of existing GNNs on HGB reveals various\nresearch opportunities and gaps, including (1) evaluating the actual\nperformance improvement of hypergraph GNNs over simple graph GNNs; (2)\ncomparing the impact of different sampling strategies on hybrid graph learning\nmethods; and (3) exploring ways to integrate simple graph and hypergraph\ninformation. We make our source code and full datasets publicly available at\nhttps://zehui127.github.io/hybrid-graph-benchmark/.\n","authors":["Zehui Li","Xiangyu Zhao","Mingzhu Shen","Guy-Bart Stan","Pietro Liò","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.05108v1.pdf","comment":"Preprint. Under review. 16 pages, 5 figures, 11 tables"},{"id":"http://arxiv.org/abs/2207.09874v4","updated":"2023-06-08T11:03:15Z","published":"2022-07-20T13:15:23Z","title":"Stream-based active learning with linear models","summary":"  The proliferation of automated data collection schemes and the advances in\nsensorics are increasing the amount of data we are able to monitor in\nreal-time. However, given the high annotation costs and the time required by\nquality inspections, data is often available in an unlabeled form. This is\nfostering the use of active learning for the development of soft sensors and\npredictive models. In production, instead of performing random inspections to\nobtain product information, labels are collected by evaluating the information\ncontent of the unlabeled data. Several query strategy frameworks for regression\nhave been proposed in the literature but most of the focus has been dedicated\nto the static pool-based scenario. In this work, we propose a new strategy for\nthe stream-based scenario, where instances are sequentially offered to the\nlearner, which must instantaneously decide whether to perform the quality check\nto obtain the label or discard the instance. The approach is inspired by the\noptimal experimental design theory and the iterative aspect of the\ndecision-making process is tackled by setting a threshold on the\ninformativeness of the unlabeled data points. The proposed approach is\nevaluated using numerical simulations and the Tennessee Eastman Process\nsimulator. The results confirm that selecting the examples suggested by the\nproposed algorithm allows for a faster reduction in the prediction error.\n","authors":["Davide Cacciarelli","Murat Kulahci","John Sølve Tyssedal"],"pdf_url":"https://arxiv.org/pdf/2207.09874v4.pdf","comment":"Published in Knowledge-Based Systems (2022)"},{"id":"http://arxiv.org/abs/2306.05101v1","updated":"2023-06-08T10:59:35Z","published":"2023-06-08T10:59:35Z","title":"Sy-CON: Symmetric Contrastive Loss for Continual Self-Supervised\n  Representation Learning","summary":"  We introduce a novel and general loss function, called Symmetric Contrastive\n(Sy-CON) loss, for effective continual self-supervised learning (CSSL). We\nfirst argue that the conventional loss form of continual learning which\nconsists of single task-specific loss (for plasticity) and a regularizer (for\nstability) may not be ideal for contrastive loss based CSSL that focus on\nrepresentation learning. Our reasoning is that, in contrastive learning based\nmethods, the task-specific loss would suffer from decreasing diversity of\nnegative samples and the regularizer may hinder learning new distinctive\nrepresentations. To that end, we propose Sy-CON that consists of two losses\n(one for plasticity and the other for stability) with symmetric dependence on\ncurrent and past models' negative sample embeddings. We argue our model can\nnaturally find good trade-off between the plasticity and stability without any\nexplicit hyperparameter tuning. We validate the effectiveness of our approach\nthrough extensive experiments, demonstrating that MoCo-based implementation of\nSy-CON loss achieves superior performance compared to other state-of-the-art\nCSSL methods.\n","authors":["Sungmin Cha","Taesup Moon"],"pdf_url":"https://arxiv.org/pdf/2306.05101v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2306.05100v1","updated":"2023-06-08T10:58:46Z","published":"2023-06-08T10:58:46Z","title":"Communication-Efficient Gradient Descent-Accent Methods for Distributed\n  Variational Inequalities: Unified Analysis and Local Updates","summary":"  Distributed and federated learning algorithms and techniques associated\nprimarily with minimization problems. However, with the increase of minimax\noptimization and variational inequality problems in machine learning, the\nnecessity of designing efficient distributed/federated learning approaches for\nthese problems is becoming more apparent. In this paper, we provide a unified\nconvergence analysis of communication-efficient local training methods for\ndistributed variational inequality problems (VIPs). Our approach is based on a\ngeneral key assumption on the stochastic estimates that allows us to propose\nand analyze several novel local training algorithms under a single framework\nfor solving a class of structured non-monotone VIPs. We present the first local\ngradient descent-accent algorithms with provable improved communication\ncomplexity for solving distributed variational inequalities on heterogeneous\ndata. The general algorithmic framework recovers state-of-the-art algorithms\nand their sharp convergence guarantees when the setting is specialized to\nminimization or minimax optimization problems. Finally, we demonstrate the\nstrong performance of the proposed algorithms compared to state-of-the-art\nmethods when solving federated minimax optimization problems.\n","authors":["Siqi Zhang","Sayantan Choudhury","Sebastian U Stich","Nicolas Loizou"],"pdf_url":"https://arxiv.org/pdf/2306.05100v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05093v1","updated":"2023-06-08T10:52:55Z","published":"2023-06-08T10:52:55Z","title":"Re-aligning Shadow Models can Improve White-box Membership Inference\n  Attacks","summary":"  Machine learning models have been shown to leak sensitive information about\ntheir training datasets. As models are being increasingly used, on devices, to\nautomate tasks and power new applications, there have been concerns that such\nwhite-box access to its parameters, as opposed to the black-box setting which\nonly provides query access to the model, increases the attack surface. Directly\nextending the shadow modelling technique from the black-box to the white-box\nsetting has been shown, in general, not to perform better than black-box only\nattacks. A key reason is misalignment, a known characteristic of deep neural\nnetworks. We here present the first systematic analysis of the causes of\nmisalignment in shadow models and show the use of a different weight\ninitialisation to be the main cause of shadow model misalignment. Second, we\nextend several re-alignment techniques, previously developed in the model\nfusion literature, to the shadow modelling context, where the goal is to\nre-align the layers of a shadow model to those of the target model.We show\nre-alignment techniques to significantly reduce the measured misalignment\nbetween the target and shadow models. Finally, we perform a comprehensive\nevaluation of white-box membership inference attacks (MIA). Our analysis\nreveals that (1) MIAs suffer from misalignment between shadow models, but that\n(2) re-aligning the shadow models improves, sometimes significantly, MIA\nperformance. On the CIFAR10 dataset with a false positive rate of 1\\%,\nwhite-box MIA using re-aligned shadow models improves the true positive rate by\n4.5\\%.Taken together, our results highlight that on-device deployment increase\nthe attack surface and that the newly available information can be used by an\nattacker.\n","authors":["Ana-Maria Cretu","Daniel Jones","Yves-Alexandre de Montjoye","Shruti Tople"],"pdf_url":"https://arxiv.org/pdf/2306.05093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05088v1","updated":"2023-06-08T10:42:44Z","published":"2023-06-08T10:42:44Z","title":"The ART of Conversation: Measuring Phonetic Convergence and Deliberate\n  Imitation in L2-Speech with a Siamese RNN","summary":"  Phonetic convergence describes the automatic and unconscious speech\nadaptation of two interlocutors in a conversation. This paper proposes a\nSiamese recurrent neural network (RNN) architecture to measure the convergence\nof the holistic spectral characteristics of speech sounds in an L2-L2\ninteraction. We extend an alternating reading task (the ART) dataset by adding\n20 native Slovak L2 English speakers. We train and test the Siamese RNN model\nto measure phonetic convergence of L2 English speech from three different\nnative language groups: Italian (9 dyads), French (10 dyads) and Slovak (10\ndyads). Our results indicate that the Siamese RNN model effectively captures\nthe dynamics of phonetic convergence and the speaker's imitation ability.\nMoreover, this text-independent model is scalable and capable of handling\nL1-induced speaker variability.\n","authors":["Zheng Yuan","Aldo Pastore","Dorina de Jong","Hao Xu","Luciano Fadiga","Alessandro D'Ausilio"],"pdf_url":"https://arxiv.org/pdf/2306.05088v1.pdf","comment":"Accepted at INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2305.11699v2","updated":"2023-06-08T10:42:01Z","published":"2023-05-19T14:23:48Z","title":"RGCVAE: Relational Graph Conditioned Variational Autoencoder for\n  Molecule Design","summary":"  Identifying molecules that exhibit some pre-specified properties is a\ndifficult problem to solve. In the last few years, deep generative models have\nbeen used for molecule generation. Deep Graph Variational Autoencoders are\namong the most powerful machine learning tools with which it is possible to\naddress this problem. However, existing methods struggle in capturing the true\ndata distribution and tend to be computationally expensive. In this work, we\npropose RGCVAE, an efficient and effective Graph Variational Autoencoder based\non: (i) an encoding network exploiting a new powerful Relational Graph\nIsomorphism Network; (ii) a novel probabilistic decoding component. Compared to\nseveral state-of-the-art VAE methods on two widely adopted datasets, RGCVAE\nshows state-of-the-art molecule generation performance while being\nsignificantly faster to train.\n","authors":["Davide Rigoni","Nicolò Navarin","Alessandro Sperduti"],"pdf_url":"https://arxiv.org/pdf/2305.11699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04220v2","updated":"2023-06-08T10:34:48Z","published":"2023-06-07T07:51:05Z","title":"Look Beneath the Surface: Exploiting Fundamental Symmetry for\n  Sample-Efficient Offline RL","summary":"  Offline reinforcement learning (RL) offers an appealing approach to\nreal-world tasks by learning policies from pre-collected datasets without\ninteracting with the environment. However, the performance of existing offline\nRL algorithms heavily depends on the scale and state-action space coverage of\ndatasets. Real-world data collection is often expensive and uncontrollable,\nleading to small and narrowly covered datasets and posing significant\nchallenges for practical deployments of offline RL. In this paper, we provide a\nnew insight that leveraging the fundamental symmetry of system dynamics can\nsubstantially enhance offline RL performance under small datasets.\nSpecifically, we propose a Time-reversal symmetry (T-symmetry) enforced\nDynamics Model (TDM), which establishes consistency between a pair of forward\nand reverse latent dynamics. TDM provides both well-behaved representations for\nsmall datasets and a new reliability measure for OOD samples based on\ncompliance with the T-symmetry. These can be readily used to construct a new\noffline RL algorithm (TSRL) with less conservative policy constraints and a\nreliable latent space data augmentation procedure. Based on extensive\nexperiments, we find TSRL achieves great performance on small benchmark\ndatasets with as few as 1% of the original samples, which significantly\noutperforms the recent offline RL algorithms in terms of data efficiency and\ngeneralizability.\n","authors":["Peng Cheng","Xianyuan Zhan","Zhihao Wu","Wenjia Zhang","Shoucheng Song","Han Wang","Youfang Lin","Li Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.04220v2.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2304.10691v2","updated":"2023-06-08T10:32:56Z","published":"2023-04-21T01:17:09Z","title":"SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual\n  Large Language Model","summary":"  Skin and subcutaneous diseases rank high among the leading contributors to\nthe global burden of nonfatal diseases, impacting a considerable portion of the\npopulation. Nonetheless, the field of dermatology diagnosis faces three\nsignificant hurdles. Firstly, there is a shortage of dermatologists accessible\nto diagnose patients, particularly in rural regions. Secondly, accurately\ninterpreting skin disease images poses a considerable challenge. Lastly,\ngenerating patient-friendly diagnostic reports is usually a time-consuming and\nlabor-intensive task for dermatologists. To tackle these challenges, we present\nSkinGPT-4, which is the world's first interactive dermatology diagnostic system\npowered by an advanced visual large language model. SkinGPT-4 leverages a\nfine-tuned version of MiniGPT-4, trained on an extensive collection of skin\ndisease images (comprising 52,929 publicly available and proprietary images)\nalong with clinical concepts and doctors' notes. We designed a two-step\ntraining process to allow SkinGPT to express medical features in skin disease\nimages with natural language and make accurate diagnoses of the types of skin\ndiseases. With SkinGPT-4, users could upload their own skin photos for\ndiagnosis, and the system could autonomously evaluate the images, identifies\nthe characteristics and categories of the skin conditions, performs in-depth\nanalysis, and provides interactive treatment recommendations. Meanwhile,\nSkinGPT-4's local deployment capability and commitment to user privacy also\nrender it an appealing choice for patients in search of a dependable and\nprecise diagnosis of their skin ailments. To demonstrate the robustness of\nSkinGPT-4, we conducted quantitative evaluations on 150 real-life cases, which\nwere independently reviewed by certified dermatologists, and showed that\nSkinGPT-4 could provide accurate diagnoses of skin diseases.\n","authors":["Juexiao Zhou","Xiaonan He","Liyuan Sun","Jiannan Xu","Xiuying Chen","Yuetan Chu","Longxi Zhou","Xingyu Liao","Bin Zhang","Xin Gao"],"pdf_url":"https://arxiv.org/pdf/2304.10691v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04262v2","updated":"2023-06-08T10:32:01Z","published":"2023-06-07T09:00:19Z","title":"Self-Adjusting Weighted Expected Improvement for Bayesian Optimization","summary":"  Bayesian Optimization (BO) is a class of surrogate-based, sample-efficient\nalgorithms for optimizing black-box problems with small evaluation budgets. The\nBO pipeline itself is highly configurable with many different design choices\nregarding the initial design, surrogate model, and acquisition function (AF).\nUnfortunately, our understanding of how to select suitable components for a\nproblem at hand is very limited. In this work, we focus on the definition of\nthe AF, whose main purpose is to balance the trade-off between exploring\nregions with high uncertainty and those with high promise for good solutions.\nWe propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we let\nthe exploration-exploitation trade-off self-adjust in a data-driven manner,\nbased on a convergence criterion for BO. On the noise-free black-box BBOB\nfunctions of the COCO benchmarking platform, our method exhibits a favorable\nany-time performance compared to handcrafted baselines and serves as a robust\ndefault choice for any problem structure. The suitability of our method also\ntransfers to HPOBench. With SAWEI, we are a step closer to on-the-fly,\ndata-driven, and robust BO designs that automatically adjust their sampling\nbehavior to the problem at hand.\n","authors":["Carolin Benjamins","Elena Raponi","Anja Jankovic","Carola Doerr","Marius Lindauer"],"pdf_url":"https://arxiv.org/pdf/2306.04262v2.pdf","comment":"AutoML Conference 2023"},{"id":"http://arxiv.org/abs/2306.05082v1","updated":"2023-06-08T10:20:08Z","published":"2023-06-08T10:20:08Z","title":"The Importance of Time in Causal Algorithmic Recourse","summary":"  The application of Algorithmic Recourse in decision-making is a promising\nfield that offers practical solutions to reverse unfavorable decisions.\nHowever, the inability of these methods to consider potential dependencies\namong variables poses a significant challenge due to the assumption of feature\nindependence. Recent advancements have incorporated knowledge of causal\ndependencies, thereby enhancing the quality of the recommended recourse\nactions. Despite these improvements, the inability to incorporate the temporal\ndimension remains a significant limitation of these approaches. This is\nparticularly problematic as identifying and addressing the root causes of\nundesired outcomes requires understanding time-dependent relationships between\nvariables. In this work, we motivate the need to integrate the temporal\ndimension into causal algorithmic recourse methods to enhance recommendations'\nplausibility and reliability. The experimental evaluation highlights the\nsignificance of the role of time in this field.\n","authors":["Isacco Beretta","Martina Cinquini"],"pdf_url":"https://arxiv.org/pdf/2306.05082v1.pdf","comment":"Accepted for xAI Conference 2023"},{"id":"http://arxiv.org/abs/2208.08934v2","updated":"2023-06-08T10:05:43Z","published":"2022-08-18T16:15:15Z","title":"A Hybrid Self-Supervised Learning Framework for Vertical Federated\n  Learning","summary":"  Vertical federated learning (VFL), a variant of Federated Learning (FL), has\nrecently drawn increasing attention as the VFL matches the enterprises' demands\nof leveraging more valuable features to achieve better model performance.\nHowever, conventional VFL methods may run into data deficiency as they exploit\nonly aligned and labeled samples (belonging to different parties), leaving\noften the majority of unaligned and unlabeled samples unused. The data\ndeficiency hampers the effort of the federation.\n  In this work, we propose a Federated Hybrid Self-Supervised Learning\nframework, named FedHSSL, that utilizes cross-party views (i.e., dispersed\nfeatures) of samples aligned among parties and local views (i.e., augmentation)\nof unaligned samples within each party to improve the representation learning\ncapability of the VFL joint model. FedHSSL further exploits invariant features\nacross parties to boost the performance of the joint model through partial\nmodel aggregation. FedHSSL, as a framework, can work with various\nrepresentative SSL methods. We empirically demonstrate that FedHSSL methods\noutperform baselines by large margins. We provide an in-depth analysis of\nFedHSSL regarding label leakage, which is rarely investigated in existing\nself-supervised VFL works. The experimental results show that, with proper\nprotection, FedHSSL achieves the best privacy-utility trade-off against the\nstate-of-the-art label inference attack compared with baselines. Code is\navailable at \\url{https://github.com/jorghyq2016/FedHSSL}.\n","authors":["Yuanqin He","Yan Kang","Xinyuan Zhao","Jiahuan Luo","Lixin Fan","Yuxing Han","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2208.08934v2.pdf","comment":"Add preliminaries and experiments"},{"id":"http://arxiv.org/abs/2209.14013v2","updated":"2023-06-08T10:02:27Z","published":"2022-09-28T11:41:38Z","title":"On the Robustness of Random Forest Against Untargeted Data Poisoning: An\n  Ensemble-Based Approach","summary":"  Machine learning is becoming ubiquitous. From finance to medicine, machine\nlearning models are boosting decision-making processes and even outperforming\nhumans in some tasks. This huge progress in terms of prediction quality does\nnot however find a counterpart in the security of such models and corresponding\npredictions, where perturbations of fractions of the training set (poisoning)\ncan seriously undermine the model accuracy. Research on poisoning attacks and\ndefenses received increasing attention in the last decade, leading to several\npromising solutions aiming to increase the robustness of machine learning.\nAmong them, ensemble-based defenses, where different models are trained on\nportions of the training set and their predictions are then aggregated, provide\nstrong theoretical guarantees at the price of a linear overhead. Surprisingly,\nensemble-based defenses, which do not pose any restrictions on the base model,\nhave not been applied to increase the robustness of random forest models. The\nwork in this paper aims to fill in this gap by designing and implementing a\nnovel hash-based ensemble approach that protects random forest against\nuntargeted, random poisoning attacks. An extensive experimental evaluation\nmeasures the performance of our approach against a variety of attacks, as well\nas its sustainability in terms of resource consumption and performance, and\ncompares it with a traditional monolithic model based on random forest. A final\ndiscussion presents our main findings and compares our approach with existing\npoisoning defenses targeting random forests.\n","authors":["Marco Anisetti","Claudio A. Ardagna","Alessandro Balestrucci","Nicola Bena","Ernesto Damiani","Chan Yeob Yeun"],"pdf_url":"https://arxiv.org/pdf/2209.14013v2.pdf","comment":"15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.05079v1","updated":"2023-06-08T10:02:04Z","published":"2023-06-08T10:02:04Z","title":"Enhancing Robustness of AI Offensive Code Generators via Data\n  Augmentation","summary":"  In this work, we present a method to add perturbations to the code\ndescriptions, i.e., new inputs in natural language (NL) from well-intentioned\ndevelopers, in the context of security-oriented code, and analyze how and to\nwhat extent perturbations affect the performance of AI offensive code\ngenerators. Our experiments show that the performance of the code generators is\nhighly affected by perturbations in the NL descriptions. To enhance the\nrobustness of the code generators, we use the method to perform data\naugmentation, i.e., to increase the variability and diversity of the training\ndata, proving its effectiveness against both perturbed and non-perturbed code\ndescriptions.\n","authors":["Cristina Improta","Pietro Liguori","Roberto Natella","Bojan Cukic","Domenico Cotroneo"],"pdf_url":"https://arxiv.org/pdf/2306.05079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05077v1","updated":"2023-06-08T10:00:19Z","published":"2023-06-08T10:00:19Z","title":"Improving Language Model Integration for Neural Machine Translation","summary":"  The integration of language models for neural machine translation has been\nextensively studied in the past. It has been shown that an external language\nmodel, trained on additional target-side monolingual data, can help improve\ntranslation quality. However, there has always been the assumption that the\ntranslation model also learns an implicit target-side language model during\ntraining, which interferes with the external language model at decoding time.\nRecently, some works on automatic speech recognition have demonstrated that, if\nthe implicit language model is neutralized in decoding, further improvements\ncan be gained when integrating an external language model. In this work, we\ntransfer this concept to the task of machine translation and compare with the\nmost prominent way of including additional monolingual data - namely\nback-translation. We find that accounting for the implicit language model\nsignificantly boosts the performance of language model fusion, although this\napproach is still outperformed by back-translation.\n","authors":["Christian Herold","Yingbo Gao","Mohammad Zeineldeen","Hermann Ney"],"pdf_url":"https://arxiv.org/pdf/2306.05077v1.pdf","comment":"accepted at ACL2023 (Findings)"},{"id":"http://arxiv.org/abs/2306.04431v2","updated":"2023-06-08T09:50:27Z","published":"2023-06-07T13:41:55Z","title":"Faithful Knowledge Distillation","summary":"  Knowledge distillation (KD) has received much attention due to its success in\ncompressing networks to allow for their deployment in resource-constrained\nsystems. While the problem of adversarial robustness has been studied before in\nthe KD setting, previous works overlook what we term the relative calibration\nof the student network with respect to its teacher in terms of soft\nconfidences. In particular, we focus on two crucial questions with regard to a\nteacher-student pair: (i) do the teacher and student disagree at points close\nto correctly classified dataset examples, and (ii) is the distilled student as\nconfident as the teacher around dataset examples? These are critical questions\nwhen considering the deployment of a smaller student network trained from a\nrobust teacher within a safety-critical setting. To address these questions, we\nintroduce a faithful imitation framework to discuss the relative calibration of\nconfidences, as well as provide empirical and certified methods to evaluate the\nrelative calibration of a student w.r.t. its teacher. Further, to verifiably\nalign the relative calibration incentives of the student to those of its\nteacher, we introduce faithful distillation. Our experiments on the MNIST and\nFashion-MNIST datasets demonstrate the need for such an analysis and the\nadvantages of the increased verifiability of faithful distillation over\nalternative adversarial distillation methods.\n","authors":["Tom A. Lamb","Rudy Brunel","Krishnamurthy DJ Dvijotham","M. Pawan Kumar","Philip H. S. Torr","Francisco Eiras"],"pdf_url":"https://arxiv.org/pdf/2306.04431v2.pdf","comment":"12pgs (main content), 3 figures"},{"id":"http://arxiv.org/abs/2302.11834v2","updated":"2023-06-08T09:48:45Z","published":"2023-02-23T07:46:24Z","title":"Generalization of Auto-Regressive Hidden Markov Models to Non-Linear\n  Dynamics and Unit Quaternion Observation Space","summary":"  Latent variable models are widely used to perform unsupervised segmentation\nof time series in different context such as robotics, speech recognition, and\neconomics. One of the most widely used latent variable model is the\nAuto-Regressive Hidden Markov Model (ARHMM), which combines a latent mode\ngoverned by a Markov chain dynamics with a linear Auto-Regressive dynamics of\nthe observed state.\n  In this work, we propose two generalizations of the ARHMM. First, we propose\na more general AR dynamics in Cartesian space, described as a linear\ncombination of non-linear basis functions. Second, we propose a linear dynamics\nin unit quaternion space, in order to properly describe orientations. These\nextensions allow to describe more complex dynamics of the observed state.\n  Although this extension is proposed for the ARHMM, it can be easily extended\nto other latent variable models with AR dynamics in the observed space, such as\nAuto-Regressive Hidden semi-Markov Models.\n","authors":["Michele Ginesi","Paolo Fiorini"],"pdf_url":"https://arxiv.org/pdf/2302.11834v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05071v1","updated":"2023-06-08T09:40:28Z","published":"2023-06-08T09:40:28Z","title":"A Causal Framework for Decomposing Spurious Variations","summary":"  One of the fundamental challenges found throughout the data sciences is to\nexplain why things happen in specific ways, or through which mechanisms a\ncertain variable $X$ exerts influences over another variable $Y$. In statistics\nand machine learning, significant efforts have been put into developing\nmachinery to estimate correlations across variables efficiently. In causal\ninference, a large body of literature is concerned with the decomposition of\ncausal effects under the rubric of mediation analysis. However, many variations\nare spurious in nature, including different phenomena throughout the applied\nsciences. Despite the statistical power to estimate correlations and the\nidentification power to decompose causal effects, there is still little\nunderstanding of the properties of spurious associations and how they can be\ndecomposed in terms of the underlying causal mechanisms. In this manuscript, we\ndevelop formal tools for decomposing spurious variations in both Markovian and\nSemi-Markovian models. We prove the first results that allow a non-parametric\ndecomposition of spurious effects and provide sufficient conditions for the\nidentification of such decompositions. The described approach has several\napplications, ranging from explainable and fair AI to questions in epidemiology\nand medicine, and we empirically demonstrate its use on a real-world dataset.\n","authors":["Drago Plecko","Elias Bareinboim"],"pdf_url":"https://arxiv.org/pdf/2306.05071v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05068v1","updated":"2023-06-08T09:34:20Z","published":"2023-06-08T09:34:20Z","title":"Shedding light on underrepresentation and Sampling Bias in machine\n  learning","summary":"  Accurately measuring discrimination is crucial to faithfully assessing\nfairness of trained machine learning (ML) models. Any bias in measuring\ndiscrimination leads to either amplification or underestimation of the existing\ndisparity. Several sources of bias exist and it is assumed that bias resulting\nfrom machine learning is born equally by different groups (e.g. females vs\nmales, whites vs blacks, etc.). If, however, bias is born differently by\ndifferent groups, it may exacerbate discrimination against specific\nsub-populations. Sampling bias, is inconsistently used in the literature to\ndescribe bias due to the sampling procedure. In this paper, we attempt to\ndisambiguate this term by introducing clearly defined variants of sampling\nbias, namely, sample size bias (SSB) and underrepresentation bias (URB). We\nshow also how discrimination can be decomposed into variance, bias, and noise.\nFinally, we challenge the commonly accepted mitigation approach that\ndiscrimination can be addressed by collecting more samples of the\nunderrepresented group.\n","authors":["Sami Zhioua","Rūta Binkytė"],"pdf_url":"https://arxiv.org/pdf/2306.05068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05067v1","updated":"2023-06-08T09:31:28Z","published":"2023-06-08T09:31:28Z","title":"Improving Visual Prompt Tuning for Self-supervised Vision Transformers","summary":"  Visual Prompt Tuning (VPT) is an effective tuning method for adapting\npretrained Vision Transformers (ViTs) to downstream tasks. It leverages extra\nlearnable tokens, known as prompts, which steer the frozen pretrained ViTs.\nAlthough VPT has demonstrated its applicability with supervised vision\ntransformers, it often underperforms with self-supervised ones. Through\nempirical observations, we deduce that the effectiveness of VPT hinges largely\non the ViT blocks with which the prompt tokens interact. Specifically, VPT\nshows improved performance on image classification tasks for MAE and MoCo v3\nwhen the prompt tokens are inserted into later blocks rather than the first\nblock. These observations suggest that there exists an optimal location of\nblocks for the insertion of prompt tokens. Unfortunately, identifying the\noptimal blocks for prompts within each self-supervised ViT for diverse future\nscenarios is a costly process. To mitigate this problem, we propose a simple\nyet effective method that learns a gate for each ViT block to adjust its\nintervention into the prompt tokens. With our method, prompt tokens are\nselectively influenced by blocks that require steering for task adaptation. Our\nmethod outperforms VPT variants in FGVC and VTAB image classification and\nADE20K semantic segmentation. The code is available at\nhttps://github.com/ryongithub/GatedPromptTuning.\n","authors":["Seungryong Yoo","Eunji Kim","Dahuin Jung","Jungbeom Lee","Sungroh Yoon"],"pdf_url":"https://arxiv.org/pdf/2306.05067v1.pdf","comment":"International Conference on Machine Learning (ICML) 2023"},{"id":"http://arxiv.org/abs/2306.05066v1","updated":"2023-06-08T09:31:18Z","published":"2023-06-08T09:31:18Z","title":"Causal Fairness for Outcome Control","summary":"  As society transitions towards an AI-based decision-making infrastructure, an\never-increasing number of decisions once under control of humans are now\ndelegated to automated systems. Even though such developments make various\nparts of society more efficient, a large body of evidence suggests that a great\ndeal of care needs to be taken to make such automated decision-making systems\nfair and equitable, namely, taking into account sensitive attributes such as\ngender, race, and religion. In this paper, we study a specific decision-making\ntask called outcome control in which an automated system aims to optimize an\noutcome variable $Y$ while being fair and equitable. The interest in such a\nsetting ranges from interventions related to criminal justice and welfare, all\nthe way to clinical decision-making and public health. In this paper, we first\nanalyze through causal lenses the notion of benefit, which captures how much a\nspecific individual would benefit from a positive decision, counterfactually\nspeaking, when contrasted with an alternative, negative one. We introduce the\nnotion of benefit fairness, which can be seen as the minimal fairness\nrequirement in decision-making, and develop an algorithm for satisfying it. We\nthen note that the benefit itself may be influenced by the protected attribute,\nand propose causal tools which can be used to analyze this. Finally, if some of\nthe variations of the protected attribute in the benefit are considered as\ndiscriminatory, the notion of benefit fairness may need to be strengthened,\nwhich leads us to articulating a notion of causal benefit fairness. Using this\nnotion, we develop a new optimization procedure capable of maximizing $Y$ while\nascertaining causal fairness in the decision process.\n","authors":["Drago Plecko","Elias Bareinboim"],"pdf_url":"https://arxiv.org/pdf/2306.05066v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02554v2","updated":"2023-06-08T09:25:14Z","published":"2023-01-04T19:16:55Z","title":"MSCDA: Multi-level Semantic-guided Contrast Improves Unsupervised Domain\n  Adaptation for Breast MRI Segmentation in Small Datasets","summary":"  Deep learning (DL) applied to breast tissue segmentation in magnetic\nresonance imaging (MRI) has received increased attention in the last decade,\nhowever, the domain shift which arises from different vendors, acquisition\nprotocols, and biological heterogeneity, remains an important but challenging\nobstacle on the path towards clinical implementation. In this paper, we propose\na novel Multi-level Semantic-guided Contrastive Domain Adaptation (MSCDA)\nframework to address this issue in an unsupervised manner. Our approach\nincorporates self-training with contrastive learning to align feature\nrepresentations between domains. In particular, we extend the contrastive loss\nby incorporating pixel-to-pixel, pixel-to-centroid, and centroid-to-centroid\ncontrasts to better exploit the underlying semantic information of the image at\ndifferent levels. To resolve the data imbalance problem, we utilize a\ncategory-wise cross-domain sampling strategy to sample anchors from target\nimages and build a hybrid memory bank to store samples from source images. We\nhave validated MSCDA with a challenging task of cross-domain breast MRI\nsegmentation between datasets of healthy volunteers and invasive breast cancer\npatients. Extensive experiments show that MSCDA effectively improves the\nmodel's feature alignment capabilities between domains, outperforming\nstate-of-the-art methods. Furthermore, the framework is shown to be\nlabel-efficient, achieving good performance with a smaller source dataset. The\ncode is publicly available at \\url{https://github.com/ShengKuangCN/MSCDA}.\n","authors":["Sheng Kuang","Henry C. Woodruff","Renee Granzier","Thiemo J. A. van Nijnatten","Marc B. I. Lobbes","Marjolein L. Smidt","Philippe Lambin","Siamak Mehrkanoon"],"pdf_url":"https://arxiv.org/pdf/2301.02554v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.05060v1","updated":"2023-06-08T09:23:46Z","published":"2023-06-08T09:23:46Z","title":"Precision-aware Latency and Energy Balancing on Multi-Accelerator\n  Platforms for DNN Inference","summary":"  The need to execute Deep Neural Networks (DNNs) at low latency and low power\nat the edge has spurred the development of new heterogeneous Systems-on-Chips\n(SoCs) encapsulating a diverse set of hardware accelerators. How to optimally\nmap a DNN onto such multi-accelerator systems is an open problem. We propose\nODiMO, a hardware-aware tool that performs a fine-grain mapping across\ndifferent accelerators on-chip, splitting individual layers and executing them\nin parallel, to reduce inference energy consumption or latency, while taking\ninto account each accelerator's quantization precision to maintain accuracy.\nPareto-optimal networks in the accuracy vs. energy or latency space are pursued\nfor three popular dataset/DNN pairs, and deployed on the DIANA heterogeneous\nultra-low power edge AI SoC. We show that ODiMO reduces energy/latency by up to\n33%/31% with limited accuracy drop (-0.53%/-0.32%) compared to manual heuristic\nmappings.\n","authors":["Matteo Risso","Alessio Burrello","Giuseppe Maria Sarda","Luca Benini","Enrico Macii","Massimo Poncino","Marian Verhelst","Daniele Jahier Pagliari"],"pdf_url":"https://arxiv.org/pdf/2306.05060v1.pdf","comment":"Accepted at 2023 ACM/IEEE International Symposium on Low Power\n  Electronics and Design (ISLPED)"},{"id":"http://arxiv.org/abs/2306.05059v1","updated":"2023-06-08T09:23:22Z","published":"2023-06-08T09:23:22Z","title":"Reconciling Predictive and Statistical Parity: A Causal Approach","summary":"  Since the rise of fair machine learning as a critical field of inquiry, many\ndifferent notions on how to quantify and measure discrimination have been\nproposed in the literature. Some of these notions, however, were shown to be\nmutually incompatible. Such findings make it appear that numerous different\nkinds of fairness exist, thereby making a consensus on the appropriate measure\nof fairness harder to reach, hindering the applications of these tools in\npractice. In this paper, we investigate one of these key impossibility results\nthat relates the notions of statistical and predictive parity. Specifically, we\nderive a new causal decomposition formula for the fairness measures associated\nwith predictive parity, and obtain a novel insight into how this criterion is\nrelated to statistical parity through the legal doctrines of disparate\ntreatment, disparate impact, and the notion of business necessity. Our results\nshow that through a more careful causal analysis, the notions of statistical\nand predictive parity are not really mutually exclusive, but complementary and\nspanning a spectrum of fairness notions through the concept of business\nnecessity. Finally, we demonstrate the importance of our findings on a\nreal-world example.\n","authors":["Drago Plecko","Elias Bareinboim"],"pdf_url":"https://arxiv.org/pdf/2306.05059v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05058v1","updated":"2023-06-08T09:23:09Z","published":"2023-06-08T09:23:09Z","title":"Neuro-Symbolic Approaches for Context-Aware Human Activity Recognition","summary":"  Deep Learning models are a standard solution for sensor-based Human Activity\nRecognition (HAR), but their deployment is often limited by labeled data\nscarcity and models' opacity. Neuro-Symbolic AI (NeSy) provides an interesting\nresearch direction to mitigate these issues by infusing knowledge about context\ninformation into HAR deep learning classifiers. However, existing NeSy methods\nfor context-aware HAR require computationally expensive symbolic reasoners\nduring classification, making them less suitable for deployment on\nresource-constrained devices (e.g., mobile devices). Additionally, NeSy\napproaches for context-aware HAR have never been evaluated on in-the-wild\ndatasets, and their generalization capabilities in real-world scenarios are\nquestionable. In this work, we propose a novel approach based on a semantic\nloss function that infuses knowledge constraints in the HAR model during the\ntraining phase, avoiding symbolic reasoning during classification. Our results\non scripted and in-the-wild datasets show the impact of different semantic loss\nfunctions in outperforming a purely data-driven model. We also compare our\nsolution with existing NeSy methods and analyze each approach's strengths and\nweaknesses. Our semantic loss remains the only NeSy solution that can be\ndeployed as a single DNN without the need for symbolic reasoning modules,\nreaching recognition rates close (and better in some cases) to existing\napproaches.\n","authors":["Luca Arrotta","Gabriele Civitarese","Claudio Bettini"],"pdf_url":"https://arxiv.org/pdf/2306.05058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04304v3","updated":"2023-06-08T09:21:05Z","published":"2023-02-08T19:38:59Z","title":"Q-Diffusion: Quantizing Diffusion Models","summary":"  Diffusion models have achieved great success in image synthesis through\niterative noise estimation using deep neural networks. However, the slow\ninference, high memory consumption, and computation intensity of the noise\nestimation model hinder the efficient adoption of diffusion models. Although\npost-training quantization (PTQ) is considered a go-to compression method for\nother tasks, it does not work out-of-the-box on diffusion models. We propose a\nnovel PTQ method specifically tailored towards the unique multi-timestep\npipeline and model architecture of the diffusion models, which compresses the\nnoise estimation network to accelerate the generation process. We identify the\nkey difficulty of diffusion model quantization as the changing output\ndistributions of noise estimation networks over multiple time steps and the\nbimodal activation distribution of the shortcut layers within the noise\nestimation network. We tackle these challenges with timestep-aware calibration\nand split shortcut quantization in this work. Experimental results show that\nour proposed method is able to quantize full-precision unconditional diffusion\nmodels into 4-bit while maintaining comparable performance (small FID change of\nat most 2.34 compared to >100 for traditional PTQ) in a training-free manner.\nOur approach can also be applied to text-guided image generation, where we can\nrun stable diffusion in 4-bit weights with high generation quality for the\nfirst time.\n","authors":["Xiuyu Li","Yijiang Liu","Long Lian","Huanrui Yang","Zhen Dong","Daniel Kang","Shanghang Zhang","Kurt Keutzer"],"pdf_url":"https://arxiv.org/pdf/2302.04304v3.pdf","comment":"The code is available at https://github.com/Xiuyu-Li/q-diffusion"},{"id":"http://arxiv.org/abs/2306.05056v1","updated":"2023-06-08T09:20:51Z","published":"2023-06-08T09:20:51Z","title":"Magnitude Attention-based Dynamic Pruning","summary":"  Existing pruning methods utilize the importance of each weight based on\nspecified criteria only when searching for a sparse structure but do not\nutilize it during training. In this work, we propose a novel approach -\n\\textbf{M}agnitude \\textbf{A}ttention-based Dynamic \\textbf{P}runing (MAP)\nmethod, which applies the importance of weights throughout both the forward and\nbackward paths to explore sparse model structures dynamically. Magnitude\nattention is defined based on the magnitude of weights as continuous\nreal-valued numbers enabling a seamless transition from a redundant to an\neffective sparse network by promoting efficient exploration. Additionally, the\nattention mechanism ensures more effective updates for important layers within\nthe sparse network. In later stages of training, our approach shifts from\nexploration to exploitation, exclusively updating the sparse model composed of\ncrucial weights based on the explored structure, resulting in pruned models\nthat not only achieve performance comparable to dense models but also\noutperform previous pruning methods on CIFAR-10/100 and ImageNet.\n","authors":["Jihye Back","Namhyuk Ahn","Jangho Kim"],"pdf_url":"https://arxiv.org/pdf/2306.05056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05052v1","updated":"2023-06-08T09:12:28Z","published":"2023-06-08T09:12:28Z","title":"Interpretable Medical Diagnostics with Structured Data Extraction by\n  Large Language Models","summary":"  Tabular data is often hidden in text, particularly in medical diagnostic\nreports. Traditional machine learning (ML) models designed to work with tabular\ndata, cannot effectively process information in such form. On the other hand,\nlarge language models (LLMs) which excel at textual tasks, are probably not the\nbest tool for modeling tabular data. Therefore, we propose a novel, simple, and\neffective methodology for extracting structured tabular data from textual\nmedical reports, called TEMED-LLM. Drawing upon the reasoning capabilities of\nLLMs, TEMED-LLM goes beyond traditional extraction techniques, accurately\ninferring tabular features, even when their names are not explicitly mentioned\nin the text. This is achieved by combining domain-specific reasoning guidelines\nwith a proposed data validation and reasoning correction feedback loop. By\napplying interpretable ML models such as decision trees and logistic regression\nover the extracted and validated data, we obtain end-to-end interpretable\npredictions. We demonstrate that our approach significantly outperforms\nstate-of-the-art text classification models in medical diagnostics. Given its\npredictive performance, simplicity, and interpretability, TEMED-LLM underscores\nthe potential of leveraging LLMs to improve the performance and trustworthiness\nof ML models in medical applications.\n","authors":["Aleksa Bisercic","Mladen Nikolic","Mihaela van der Schaar","Boris Delibasic","Pietro Lio","Andrija Petrovic"],"pdf_url":"https://arxiv.org/pdf/2306.05052v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05046v1","updated":"2023-06-08T08:57:06Z","published":"2023-06-08T08:57:06Z","title":"A Gradient-based Approach for Online Robust Deep Neural Network Training\n  with Noisy Labels","summary":"  Learning with noisy labels is an important topic for scalable training in\nmany real-world scenarios. However, few previous research considers this\nproblem in the online setting, where the arrival of data is streaming. In this\npaper, we propose a novel gradient-based approach to enable the detection of\nnoisy labels for the online learning of model parameters, named Online\nGradient-based Robust Selection (OGRS). In contrast to the previous sample\nselection approach for the offline training that requires the estimation of a\nclean ratio of the dataset before each epoch of training, OGRS can\nautomatically select clean samples by steps of gradient update from datasets\nwith varying clean ratios without changing the parameter setting. During the\ntraining process, the OGRS method selects clean samples at each iteration and\nfeeds the selected sample to incrementally update the model parameters. We\nprovide a detailed theoretical analysis to demonstrate data selection process\nis converging to the low-loss region of the sample space, by introducing and\nproving the sub-linear local Lagrangian regret of the non-convex constrained\noptimization problem. Experimental results show that it outperforms\nstate-of-the-art methods in different settings.\n","authors":["Yifan Yang","Alec Koppel","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05046v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05043v1","updated":"2023-06-08T08:53:59Z","published":"2023-06-08T08:53:59Z","title":"Non-autoregressive Conditional Diffusion Models for Time Series\n  Prediction","summary":"  Recently, denoising diffusion models have led to significant breakthroughs in\nthe generation of images, audio and text. However, it is still an open question\non how to adapt their strong modeling ability to model time series. In this\npaper, we propose TimeDiff, a non-autoregressive diffusion model that achieves\nhigh-quality time series prediction with the introduction of two novel\nconditioning mechanisms: future mixup and autoregressive initialization.\nSimilar to teacher forcing, future mixup allows parts of the ground-truth\nfuture predictions for conditioning, while autoregressive initialization helps\nbetter initialize the model with basic time series patterns such as short-term\ntrends. Extensive experiments are performed on nine real-world datasets.\nResults show that TimeDiff consistently outperforms existing time series\ndiffusion models, and also achieves the best overall performance across a\nvariety of the existing strong baselines (including transformers and FiLM).\n","authors":["Lifeng Shen","James Kwok"],"pdf_url":"https://arxiv.org/pdf/2306.05043v1.pdf","comment":"Accepted by ICML 2023 (Poster)"},{"id":"http://arxiv.org/abs/2306.05041v1","updated":"2023-06-08T08:49:42Z","published":"2023-06-08T08:49:42Z","title":"Energy-Efficient Downlink Semantic Generative Communication with\n  Text-to-Image Generators","summary":"  In this paper, we introduce a novel semantic generative communication (SGC)\nframework, where generative users leverage text-to-image (T2I) generators to\ncreate images locally from downloaded text prompts, while non-generative users\ndirectly download images from a base station (BS). Although generative users\nhelp reduce downlink transmission energy at the BS, they consume additional\nenergy for image generation and for uploading their generator state information\n(GSI). We formulate the problem of minimizing the total energy consumption of\nthe BS and the users, and devise a generative user selection algorithm.\nSimulation results corroborate that our proposed algorithm reduces total energy\nby up to 54% compared to a baseline with all non-generative users.\n","authors":["Hyein Lee","Jihong Park","Sooyoung Kim","Jinho Choi"],"pdf_url":"https://arxiv.org/pdf/2306.05041v1.pdf","comment":"6 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2302.02498"},{"id":"http://arxiv.org/abs/2306.04252v2","updated":"2023-06-08T08:43:40Z","published":"2023-06-07T08:47:41Z","title":"Adversarial Sample Detection Through Neural Network Transport Dynamics","summary":"  We propose a detector of adversarial samples that is based on the view of\nneural networks as discrete dynamic systems. The detector tells clean inputs\nfrom abnormal ones by comparing the discrete vector fields they follow through\nthe layers. We also show that regularizing this vector field during training\nmakes the network more regular on the data distribution's support, thus making\nthe activations of clean inputs more distinguishable from those of abnormal\nones. Experimentally, we compare our detector favorably to other detectors on\nseen and unseen attacks, and show that the regularization of the network's\ndynamics improves the performance of adversarial detectors that use the\ninternal embeddings as inputs, while also improving test accuracy.\n","authors":["Skander Karkar","Patrick Gallinari","Alain Rakotomamonjy"],"pdf_url":"https://arxiv.org/pdf/2306.04252v2.pdf","comment":"ECML PKDD 2023"},{"id":"http://arxiv.org/abs/2306.05035v1","updated":"2023-06-08T08:37:49Z","published":"2023-06-08T08:37:49Z","title":"Does Long-Term Series Forecasting Need Complex Attention and Extra Long\n  Inputs?","summary":"  As Transformer-based models have achieved impressive performance on various\ntime series tasks, Long-Term Series Forecasting (LTSF) tasks have also received\nextensive attention in recent years. However, due to the inherent computational\ncomplexity and long sequences demanding of Transformer-based methods, its\napplication on LTSF tasks still has two major issues that need to be further\ninvestigated: 1) Whether the sparse attention mechanism designed by these\nmethods actually reduce the running time on real devices; 2) Whether these\nmodels need extra long input sequences to guarantee their performance? The\nanswers given in this paper are negative. Therefore, to better copy with these\ntwo issues, we design a lightweight Period-Attention mechanism (Periodformer),\nwhich renovates the aggregation of long-term subseries via explicit periodicity\nand short-term subseries via built-in proximity. Meanwhile, a gating mechanism\nis embedded into Periodformer to regulate the influence of the attention module\non the prediction results. Furthermore, to take full advantage of GPUs for fast\nhyperparameter optimization (e.g., finding the suitable input length), a\nMulti-GPU Asynchronous parallel algorithm based on Bayesian Optimization (MABO)\nis presented. MABO allocates a process to each GPU via a queue mechanism, and\nthen creates multiple trials at a time for asynchronous parallel search, which\ngreatly reduces the search time. Compared with the state-of-the-art methods,\nthe prediction error of Periodformer reduced by 13% and 26% for multivariate\nand univariate forecasting, respectively. In addition, MABO reduces the average\nsearch time by 46% while finding better hyperparameters. As a conclusion, this\npaper indicates that LTSF may not need complex attention and extra long input\nsequences. The source code will be open source on Github.\n","authors":["Daojun Liang","Haixia Zhang","Dongfeng Yuan","Xiaoyan Ma","Dongyang Li","Minggao Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05035v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2201.08557v2","updated":"2023-06-08T08:35:07Z","published":"2022-01-21T06:26:50Z","title":"Toward Enhanced Robustness in Unsupervised Graph Representation\n  Learning: A Graph Information Bottleneck Perspective","summary":"  Recent studies have revealed that GNNs are vulnerable to adversarial attacks.\nMost existing robust graph learning methods measure model robustness based on\nlabel information, rendering them infeasible when label information is not\navailable. A straightforward direction is to employ the widely used Infomax\ntechnique from typical Unsupervised Graph Representation Learning (UGRL) to\nlearn robust unsupervised representations. Nonetheless, directly transplanting\nthe Infomax technique from typical UGRL to robust UGRL may involve a biased\nassumption. In light of the limitation of Infomax, we propose a novel unbiased\nrobust UGRL method called Robust Graph Information Bottleneck (RGIB), which is\ngrounded in the Information Bottleneck (IB) principle. Our RGIB attempts to\nlearn robust node representations against adversarial perturbations by\npreserving the original information in the benign graph while eliminating the\nadversarial information in the adversarial graph. There are mainly two\nchallenges to optimize RGIB: 1) high complexity of adversarial attack to\nperturb node features and graph structure jointly in the training procedure; 2)\nmutual information estimation upon adversarially attacked graphs. To tackle\nthese problems, we further propose an efficient adversarial training strategy\nwith only feature perturbations and an effective mutual information estimator\nwith subgraph-level summary. Moreover, we theoretically establish a connection\nbetween our proposed RGIB and the robustness of downstream classifiers,\nrevealing that RGIB can provide a lower bound on the adversarial risk of\ndownstream classifiers. Extensive experiments over several benchmarks and\ndownstream tasks demonstrate the effectiveness and superiority of our proposed\nmethod.\n","authors":["Jihong Wang","Minnan Luo","Jundong Li","Ziqi Liu","Jun Zhou","Qinghua Zheng"],"pdf_url":"https://arxiv.org/pdf/2201.08557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05032v1","updated":"2023-06-08T08:34:58Z","published":"2023-06-08T08:34:58Z","title":"Scalable and Adaptive Log-based Anomaly Detection with Expert in the\n  Loop","summary":"  System logs play a critical role in maintaining the reliability of software\nsystems. Fruitful studies have explored automatic log-based anomaly detection\nand achieved notable accuracy on benchmark datasets. However, when applied to\nlarge-scale cloud systems, these solutions face limitations due to high\nresource consumption and lack of adaptability to evolving logs. In this paper,\nwe present an accurate, lightweight, and adaptive log-based anomaly detection\nframework, referred to as SeaLog. Our method introduces a Trie-based Detection\nAgent (TDA) that employs a lightweight, dynamically-growing trie structure for\nreal-time anomaly detection. To enhance TDA's accuracy in response to evolving\nlog data, we enable it to receive feedback from experts. Interestingly, our\nfindings suggest that contemporary large language models, such as ChatGPT, can\nprovide feedback with a level of consistency comparable to human experts, which\ncan potentially reduce manual verification efforts. We extensively evaluate\nSeaLog on two public datasets and an industrial dataset. The results show that\nSeaLog outperforms all baseline methods in terms of effectiveness, runs 2X to\n10X faster and only consumes 5% to 41% of the memory resource.\n","authors":["Jinyang Liu","Junjie Huang","Yintong Huo","Zhihan Jiang","Jiazhen Gu","Zhuangbin Chen","Cong Feng","Minzhi Yan","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2306.05032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05031v1","updated":"2023-06-08T08:34:26Z","published":"2023-06-08T08:34:26Z","title":"Generalizable Lightweight Proxy for Robust NAS against Diverse\n  Perturbations","summary":"  Recent neural architecture search (NAS) frameworks have been successful in\nfinding optimal architectures for given conditions (e.g., performance or\nlatency). However, they search for optimal architectures in terms of their\nperformance on clean images only, while robustness against various types of\nperturbations or corruptions is crucial in practice. Although there exist\nseveral robust NAS frameworks that tackle this issue by integrating adversarial\ntraining into one-shot NAS, however, they are limited in that they only\nconsider robustness against adversarial attacks and require significant\ncomputational resources to discover optimal architectures for a single task,\nwhich makes them impractical in real-world scenarios. To address these\nchallenges, we propose a novel lightweight robust zero-cost proxy that\nconsiders the consistency across features, parameters, and gradients of both\nclean and perturbed images at the initialization state. Our approach\nfacilitates an efficient and rapid search for neural architectures capable of\nlearning generalizable features that exhibit robustness across diverse\nperturbations. The experimental results demonstrate that our proxy can rapidly\nand efficiently search for neural architectures that are consistently robust\nagainst various perturbations on multiple benchmark datasets and diverse search\nspaces, largely outperforming existing clean zero-shot NAS and robust NAS with\nreduced search cost.\n","authors":["Hyeonjeong Ha","Minseon Kim","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2306.05031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05029v1","updated":"2023-06-08T08:29:10Z","published":"2023-06-08T08:29:10Z","title":"Multi-level Multiple Instance Learning with Transformer for Whole Slide\n  Image Classification","summary":"  Whole slide image (WSI) refers to a type of high-resolution scanned tissue\nimage, which is extensively employed in computer-assisted diagnosis (CAD). The\nextremely high resolution and limited availability of region-level annotations\nmake it challenging to employ deep learning methods for WSI-based digital\ndiagnosis. Multiple instance learning (MIL) is a powerful tool to address the\nweak annotation problem, while Transformer has shown great success in the field\nof visual tasks. The combination of both should provide new insights for deep\nlearning based image diagnosis. However, due to the limitations of single-level\nMIL and the attention mechanism's constraints on sequence length, directly\napplying Transformer to WSI-based MIL tasks is not practical. To tackle this\nissue, we propose a Multi-level MIL with Transformer (MMIL-Transformer)\napproach. By introducing a hierarchical structure to MIL, this approach enables\nefficient handling of MIL tasks that involve a large number of instances. To\nvalidate its effectiveness, we conducted a set of experiments on WSIs\nclassification task, where MMIL-Transformer demonstrate superior performance\ncompared to existing state-of-the-art methods. Our proposed approach achieves\ntest AUC 94.74% and test accuracy 93.41% on CAMELYON16 dataset, test AUC 99.04%\nand test accuracy 94.37% on TCGA-NSCLC dataset, respectively. All code and\npre-trained models are available at: https://github.com/hustvl/MMIL-Transformer\n","authors":["Ruijie Zhang","Qiaozhe Zhang","Yingzhuang Liu","Hao Xin","Yan Liu","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05023v1","updated":"2023-06-08T08:22:27Z","published":"2023-06-08T08:22:27Z","title":"Posterior Collapse in Linear Conditional and Hierarchical Variational\n  Autoencoders","summary":"  The posterior collapse phenomenon in variational autoencoders (VAEs), where\nthe variational posterior distribution closely matches the prior distribution,\ncan hinder the quality of the learned latent variables. As a consequence of\nposterior collapse, the latent variables extracted by the encoder in VAEs\npreserve less information from the input data and thus fail to produce\nmeaningful representations as input to the reconstruction process in the\ndecoder. While this phenomenon has been an actively addressed topic related to\nVAEs performance, the theory for posterior collapse remains underdeveloped,\nespecially beyond the standard VAEs. In this work, we advance the theoretical\nunderstanding of posterior collapse to two important and prevalent yet less\nstudied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically,\nvia a non-trivial theoretical analysis of linear conditional VAEs and\nhierarchical VAEs with two levels of latent, we prove that the cause of\nposterior collapses in these models includes the correlation between the input\nand output of the conditional VAEs and the effect of learnable encoder variance\nin the hierarchical VAEs. We empirically validate our theoretical findings for\nlinear conditional and hierarchical VAEs and demonstrate that these results are\nalso predictive for non-linear cases.\n","authors":["Hien Dang","Tho Tran","Tan Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2306.05023v1.pdf","comment":"50 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.05021v1","updated":"2023-06-08T08:16:38Z","published":"2023-06-08T08:16:38Z","title":"Mixed-TD: Efficient Neural Network Accelerator with Layer-Specific\n  Tensor Decomposition","summary":"  Neural Network designs are quite diverse, from VGG-style to ResNet-style, and\nfrom Convolutional Neural Networks to Transformers. Towards the design of\nefficient accelerators, many works have adopted a dataflow-based, inter-layer\npipelined architecture, with a customised hardware towards each layer,\nachieving ultra high throughput and low latency. The deployment of neural\nnetworks to such dataflow architecture accelerators is usually hindered by the\navailable on-chip memory as it is desirable to preload the weights of neural\nnetworks on-chip to maximise the system performance. To address this, networks\nare usually compressed before the deployment through methods such as pruning,\nquantization and tensor decomposition. In this paper, a framework for mapping\nCNNs onto FPGAs based on a novel tensor decomposition method called Mixed-TD is\nproposed. The proposed method applies layer-specific Singular Value\nDecomposition (SVD) and Canonical Polyadic Decomposition (CPD) in a mixed\nmanner, achieving 1.73x to 10.29x throughput per DSP to state-of-the-art CNNs.\nOur work is open-sourced: https://github.com/Yu-Zhewen/Mixed-TD\n","authors":["Zhewen Yu","Christos-Savvas Bouganis"],"pdf_url":"https://arxiv.org/pdf/2306.05021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05017v1","updated":"2023-06-08T08:11:21Z","published":"2023-06-08T08:11:21Z","title":"Non-Intrusive Load Monitoring (NILM) using Deep Neural Networks: A\n  Review","summary":"  Demand-side management now encompasses more residential loads. To efficiently\napply demand response strategies, it's essential to periodically observe the\ncontribution of various domestic appliances to total energy consumption.\nNon-intrusive load monitoring (NILM), also known as load disaggregation, is a\nmethod for decomposing the total energy consumption profile into individual\nappliance load profiles within the household. It has multiple applications in\ndemand-side management, energy consumption monitoring, and analysis. Various\nmethods, including machine learning and deep learning, have been used to\nimplement and improve NILM algorithms. This paper reviews some recent NILM\nmethods based on deep learning and introduces the most accurate methods for\nresidential loads. It summarizes public databases for NILM evaluation and\ncompares methods using standard performance metrics.\n","authors":["Mohammad Irani Azad","Roozbeh Rajabi","Abouzar Estebsari"],"pdf_url":"https://arxiv.org/pdf/2306.05017v1.pdf","comment":"6 pages, EEEIC 2023 conference"},{"id":"http://arxiv.org/abs/2306.05014v1","updated":"2023-06-08T08:07:54Z","published":"2023-06-08T08:07:54Z","title":"Learning Closed-form Equations for Subgrid-scale Closures from\n  High-fidelity Data: Promises and Challenges","summary":"  There is growing interest in discovering interpretable, closed-form equations\nfor subgrid-scale (SGS) closures/parameterizations of complex processes in\nEarth system. Here, we apply a common equation-discovery technique with\nexpansive libraries to learn closures from filtered direct numerical\nsimulations of 2D forced turbulence and Rayleigh-B\\'enard convection (RBC).\nAcross common filters, we robustly discover closures of the same form for\nmomentum and heat fluxes. These closures depend on nonlinear combinations of\ngradients of filtered variables (velocity, temperature), with constants that\nare independent of the fluid/flow properties and only depend on filter\ntype/size. We show that these closures are the nonlinear gradient model (NGM),\nwhich is derivable analytically using Taylor-series expansions. In fact, we\nsuggest that with common (physics-free) equation-discovery algorithms,\nregardless of the system/physics, discovered closures are always consistent\nwith the Taylor-series. Like previous studies, we find that large-eddy\nsimulations with NGM closures are unstable, despite significant similarities\nbetween the true and NGM-predicted fluxes (pattern correlations $> 0.95$). We\nidentify two shortcomings as reasons for these instabilities: in 2D, NGM\nproduces zero kinetic energy transfer between resolved and subgrid scales,\nlacking both diffusion and backscattering. In RBC, backscattering of potential\nenergy is poorly predicted. Moreover, we show that SGS fluxes diagnosed from\ndata, presumed the \"truth\" for discovery, depend on filtering procedures and\nare not unique. Accordingly, to learn accurate, stable closures from\nhigh-fidelity data in future work, we propose several ideas around using\nphysics-informed libraries, loss functions, and metrics. These findings are\nrelevant beyond turbulence to closure modeling of any multi-scale system.\n","authors":["Karan Jakhar","Yifei Guan","Rambod Mojgani","Ashesh Chattopadhyay","Pedram Hassanzadeh","Laura Zanna"],"pdf_url":"https://arxiv.org/pdf/2306.05014v1.pdf","comment":"40 pages, 4 figures. The codes and data used in this work can be\n  found at https://github.com/jakharkaran/EqsDiscovery_2D-FHIT_RBC and\n  https://doi.org/10.5281/zenodo.7500647, respectively"},{"id":"http://arxiv.org/abs/2306.05012v1","updated":"2023-06-08T08:04:56Z","published":"2023-06-08T08:04:56Z","title":"Sequence-to-Sequence Model with Transformer-based Attention Mechanism\n  and Temporal Pooling for Non-Intrusive Load Monitoring","summary":"  This paper presents a novel Sequence-to-Sequence (Seq2Seq) model based on a\ntransformer-based attention mechanism and temporal pooling for Non-Intrusive\nLoad Monitoring (NILM) of smart buildings. The paper aims to improve the\naccuracy of NILM by using a deep learning-based method. The proposed method\nuses a Seq2Seq model with a transformer-based attention mechanism to capture\nthe long-term dependencies of NILM data. Additionally, temporal pooling is used\nto improve the model's accuracy by capturing both the steady-state and\ntransient behavior of appliances. The paper evaluates the proposed method on a\npublicly available dataset and compares the results with other state-of-the-art\nNILM techniques. The results demonstrate that the proposed method outperforms\nthe existing methods in terms of both accuracy and computational efficiency.\n","authors":["Mohammad Irani Azad","Roozbeh Rajabi","Abouzar Estebsari"],"pdf_url":"https://arxiv.org/pdf/2306.05012v1.pdf","comment":"5 pages, EEEIC 2023 conference"},{"id":"http://arxiv.org/abs/2306.05011v1","updated":"2023-06-08T07:59:08Z","published":"2023-06-08T07:59:08Z","title":"Attention Weighted Mixture of Experts with Contrastive Learning for\n  Personalized Ranking in E-commerce","summary":"  Ranking model plays an essential role in e-commerce search and\nrecommendation. An effective ranking model should give a personalized ranking\nlist for each user according to the user preference. Existing algorithms\nusually extract a user representation vector from the user behavior sequence,\nthen feed the vector into a feed-forward network (FFN) together with other\nfeatures for feature interactions, and finally produce a personalized ranking\nscore. Despite tremendous progress in the past, there is still room for\nimprovement. Firstly, the personalized patterns of feature interactions for\ndifferent users are not explicitly modeled. Secondly, most of existing\nalgorithms have poor personalized ranking results for long-tail users with few\nhistorical behaviors due to the data sparsity. To overcome the two challenges,\nwe propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive\nlearning for personalized ranking. Firstly, AW-MoE leverages the MoE framework\nto capture personalized feature interactions for different users. To model the\nuser preference, the user behavior sequence is simultaneously fed into expert\nnetworks and the gate network. Within the gate network, one gate unit and one\nactivation unit are designed to adaptively learn the fine-grained activation\nvector for experts using an attention mechanism. Secondly, a random masking\nstrategy is applied to the user behavior sequence to simulate long-tail users,\nand an auxiliary contrastive loss is imposed to the output of the gate network\nto improve the model generalization for these users. This is validated by a\nhigher performance gain on the long-tail user test set. Experiment results on a\nJD real production dataset and a public dataset demonstrate the effectiveness\nof AW-MoE, which significantly outperforms state-of-art methods. Notably,\nAW-MoE has been successfully deployed in the JD e-commerce search engine, ...\n","authors":["Juan Gong","Zhenlin Chen","Chaoyi Ma","Zhuojian Xiao","Haonan Wang","Guoyu Tang","Lin Liu","Sulong Xu","Bo Long","Yunjiang Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.05011v1.pdf","comment":"Accepted by ICDE2023"},{"id":"http://arxiv.org/abs/2301.12601v2","updated":"2023-06-08T07:47:46Z","published":"2023-01-30T01:22:31Z","title":"Regret Bounds for Markov Decision Processes with Recursive Optimized\n  Certainty Equivalents","summary":"  The optimized certainty equivalent (OCE) is a family of risk measures that\ncover important examples such as entropic risk, conditional value-at-risk and\nmean-variance models. In this paper, we propose a new episodic risk-sensitive\nreinforcement learning formulation based on tabular Markov decision processes\nwith recursive OCEs. We design an efficient learning algorithm for this problem\nbased on value iteration and upper confidence bound. We derive an upper bound\non the regret of the proposed algorithm, and also establish a minimax lower\nbound. Our bounds show that the regret rate achieved by our proposed algorithm\nhas optimal dependence on the number of episodes and the number of actions.\n","authors":["Wenhao Xu","Xuefeng Gao","Xuedong He"],"pdf_url":"https://arxiv.org/pdf/2301.12601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05001v1","updated":"2023-06-08T07:45:24Z","published":"2023-06-08T07:45:24Z","title":"COURIER: Contrastive User Intention Reconstruction for Large-Scale\n  Pre-Train of Image Features","summary":"  With the development of the multi-media internet, visual characteristics have\nbecome an important factor affecting user interests. Thus, incorporating visual\nfeatures is a promising direction for further performance improvements in\nclick-through rate (CTR) prediction. However, we found that simply injecting\nthe image embeddings trained with established pre-training methods only has\nmarginal improvements. We attribute the failure to two reasons: First, The\npre-training methods are designed for well-defined computer vision tasks\nconcentrating on semantic features, and they cannot learn personalized interest\nin recommendations. Secondly, pre-trained image embeddings only containing\nsemantic information have little information gain, considering we already have\nsemantic features such as categories and item titles as inputs in the CTR\nprediction task. We argue that a pre-training method tailored for\nrecommendation is necessary for further improvements. To this end, we propose a\nrecommendation-aware image pre-training method that can learn visual features\nfrom user click histories. Specifically, we propose a user interest\nreconstruction module to mine visual features related to user interests from\nbehavior histories. We further propose a contrastive training method to avoid\ncollapsing of embedding vectors. We conduct extensive experiments to verify\nthat our method can learn users' visual interests, and our method achieves\n$0.46\\%$ improvement in offline AUC and $0.88\\%$ improvement in Taobao online\nGMV with p-value$<0.01$.\n","authors":["Jia-Qi Yang","Chenglei Dai","OU Dan","Ju Huang","De-Chuan Zhan","Qingwen Liu","Xiaoyi Zeng","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02947v2","updated":"2023-06-08T07:43:36Z","published":"2023-06-05T15:11:59Z","title":"Continual Learning with Pretrained Backbones by Tuning in the Input\n  Space","summary":"  The intrinsic difficulty in adapting deep learning models to non-stationary\nenvironments limits the applicability of neural networks to real-world tasks.\nThis issue is critical in practical supervised learning settings, such as the\nones in which a pre-trained model computes projections toward a latent space\nwhere different task predictors are sequentially learned over time. As a matter\nof fact, incrementally fine-tuning the whole model to better adapt to new tasks\nusually results in catastrophic forgetting, with decreasing performance over\nthe past experiences and losing valuable knowledge from the pre-training stage.\nIn this paper, we propose a novel strategy to make the fine-tuning procedure\nmore effective, by avoiding to update the pre-trained part of the network and\nlearning not only the usual classification head, but also a set of\nnewly-introduced learnable parameters that are responsible for transforming the\ninput data. This process allows the network to effectively leverage the\npre-training knowledge and find a good trade-off between plasticity and\nstability with modest computational efforts, thus especially suitable for\non-the-edge settings. Our experiments on four image classification problems in\na continual learning setting confirm the quality of the proposed approach when\ncompared to several fine-tuning procedures and to popular continual learning\nmethods.\n","authors":["Simone Marullo","Matteo Tiezzi","Marco Gori","Stefano Melacci","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2306.02947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00557v2","updated":"2023-06-08T07:32:18Z","published":"2023-01-02T08:31:56Z","title":"Learning to Maximize Mutual Information for Dynamic Feature Selection","summary":"  Feature selection helps reduce data acquisition costs in ML, but the standard\napproach is to train models with static feature subsets. Here, we consider the\ndynamic feature selection (DFS) problem where a model sequentially queries\nfeatures based on the presently available information. DFS is often addressed\nwith reinforcement learning, but we explore a simpler approach of greedily\nselecting features based on their conditional mutual information. This method\nis theoretically appealing but requires oracle access to the data distribution,\nso we develop a learning approach based on amortized optimization. The proposed\nmethod is shown to recover the greedy policy when trained to optimality, and it\noutperforms numerous existing feature selection methods in our experiments,\nthus validating it as a simple but powerful approach for this problem.\n","authors":["Ian Covert","Wei Qiu","Mingyu Lu","Nayoon Kim","Nathan White","Su-In Lee"],"pdf_url":"https://arxiv.org/pdf/2301.00557v2.pdf","comment":"ICML 2023 camera-ready"},{"id":"http://arxiv.org/abs/2306.04994v1","updated":"2023-06-08T07:29:42Z","published":"2023-06-08T07:29:42Z","title":"Ambulance Demand Prediction via Convolutional Neural Networks","summary":"  Minimizing response times is crucial for emergency medical services to reduce\npatients' waiting times and to increase their survival rates. Many models exist\nto optimize operational tasks such as ambulance allocation and dispatching.\nIncluding accurate demand forecasts in such models can improve operational\ndecision-making. Against this background, we present a novel convolutional\nneural network (CNN) architecture that transforms time series data into\nheatmaps to predict ambulance demand. Applying such predictions requires\nincorporating external features that influence ambulance demands. We contribute\nto the existing literature by providing a flexible, generic CNN architecture,\nallowing for the inclusion of external features with varying dimensions.\nAdditionally, we provide a feature selection and hyperparameter optimization\nframework utilizing Bayesian optimization. We integrate historical ambulance\ndemand and external information such as weather, events, holidays, and time. To\nshow the superiority of the developed CNN architecture over existing\napproaches, we conduct a case study for Seattle's 911 call data and include\nexternal information. We show that the developed CNN architecture outperforms\nexisting state-of-the-art methods and industry practice by more than 9%.\n","authors":["Maximiliane Rautenstrauß","Maximilian Schiffer"],"pdf_url":"https://arxiv.org/pdf/2306.04994v1.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.04985v1","updated":"2023-06-08T07:16:03Z","published":"2023-06-08T07:16:03Z","title":"Beyond Probability Partitions: Calibrating Neural Networks with Semantic\n  Aware Grouping","summary":"  Research has shown that deep networks tend to be overly optimistic about\ntheir predictions, leading to an underestimation of prediction errors. Due to\nthe limited nature of data, existing studies have proposed various methods\nbased on model prediction probabilities to bin the data and evaluate\ncalibration error. We propose a more generalized definition of calibration\nerror called Partitioned Calibration Error (PCE), revealing that the key\ndifference among these calibration error metrics lies in how the data space is\npartitioned. We put forth an intuitive proposition that an accurate model\nshould be calibrated across any partition, suggesting that the input space\npartitioning can extend beyond just the partitioning of prediction\nprobabilities, and include partitions directly related to the input. Through\nsemantic-related partitioning functions, we demonstrate that the relationship\nbetween model accuracy and calibration lies in the granularity of the\npartitioning function. This highlights the importance of partitioning criteria\nfor training a calibrated and accurate model. To validate the aforementioned\nanalysis, we propose a method that involves jointly learning a semantic aware\ngrouping function based on deep model features and logits to partition the data\nspace into subsets. Subsequently, a separate calibration function is learned\nfor each subset. Experimental results demonstrate that our approach achieves\nsignificant performance improvements across multiple datasets and network\narchitectures, thus highlighting the importance of the partitioning function\nfor calibration.\n","authors":["Jia-Qi Yang","De-Chuan Zhan","Le Gan"],"pdf_url":"https://arxiv.org/pdf/2306.04985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04984v1","updated":"2023-06-08T07:15:04Z","published":"2023-06-08T07:15:04Z","title":"G$^2$uardFL: Safeguarding Federated Learning Against Backdoor Attacks\n  through Attributed Client Graph Clustering","summary":"  As a collaborative paradigm, Federated Learning (FL) empowers clients to\nengage in collective model training without exchanging their respective local\ndata. Nevertheless, FL remains vulnerable to backdoor attacks in which an\nattacker compromises malicious clients, and injects poisoned model weights into\nthe aggregation process to yield attacker-chosen predictions for particular\nsamples. Existing countermeasures, mainly based on anomaly detection, may\nerroneously reject legitimate weights while accepting malicious ones, which is\ndue to inadequacies in quantifying client model similarities. Other defense\nmechanisms prove effective exclusively when confronted with a restricted number\nof malicious clients, e.g., less than 10%. To address these vulnerabilities, we\npresent G$^2$uardFL, a protective framework that reframes the detection of\nmalicious clients as an attributed graph clustering problem, thereby\nsafeguarding FL systems. This framework employs a client graph clustering\ntechnique to identify malicious clients and incorporates an adaptive method to\namplify the disparity between the aggregated model and poisoned client models,\nthereby eliminating previously embedded backdoors. A theoretical analysis of\nconvergence is also performed to demonstrate that the global model closely\napproximates the model untouched by any backdoor. Through empirical evaluation\ncompared to cutting-edge defenses and against various backdoor attacks, our\nexperimental results indicate that G$^2$uardFL considerably undermines the\neffectiveness of backdoor attacks while maintaining a negligible impact on the\nbenign sample performance.\n","authors":["Hao Yu","Chuan Ma","Meng Liu","Xinwang Liu","Zhe Liu","Ming Ding"],"pdf_url":"https://arxiv.org/pdf/2306.04984v1.pdf","comment":"20 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.04979v1","updated":"2023-06-08T07:10:35Z","published":"2023-06-08T07:10:35Z","title":"CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive\n  Graph Classification","summary":"  Although graph neural networks (GNNs) have achieved impressive achievements\nin graph classification, they often need abundant task-specific labels, which\ncould be extensively costly to acquire. A credible solution is to explore\nadditional labeled graphs to enhance unsupervised learning on the target\ndomain. However, how to apply GNNs to domain adaptation remains unsolved owing\nto the insufficient exploration of graph topology and the significant domain\ndiscrepancy. In this paper, we propose \\underline{Co}upled\n\\underline{Co}ntrastive Graph Representation Learning (\\method{}), which\nextracts the topological information from coupled learning branches and reduces\nthe domain discrepancy with coupled contrastive learning. \\method{} contains a\ngraph convolutional network branch and a hierarchical graph kernel network\nbranch, which explore graph topology in implicit and explicit manners. Besides,\nwe incorporate coupled branches into a holistic multi-view contrastive learning\nframework, which not only incorporates graph representations learned from\ncomplementary views for enhanced understanding, but also encourages the\nsimilarity between cross-domain example pairs with the same semantics for\ndomain alignment. Extensive experiments on various popular datasets show that\n\\method{} outperforms these competing baselines by 5.7\\% to 21.0\\% generally.\n","authors":["Nan Yin","Li Shen","Mengzhu Wang","Long Lan","Zeyu Ma","Chong Chen","Xian-Sheng Hua","Xiao Luo"],"pdf_url":"https://arxiv.org/pdf/2306.04979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04974v1","updated":"2023-06-08T07:05:36Z","published":"2023-06-08T07:05:36Z","title":"Conservative Prediction via Data-Driven Confidence Minimization","summary":"  Errors of machine learning models are costly, especially in safety-critical\ndomains such as healthcare, where such mistakes can prevent the deployment of\nmachine learning altogether. In these settings, conservative models -- models\nwhich can defer to human judgment when they are likely to make an error -- may\noffer a solution. However, detecting unusual or difficult examples is notably\nchallenging, as it is impossible to anticipate all potential inputs at test\ntime. To address this issue, prior work has proposed to minimize the model's\nconfidence on an auxiliary pseudo-OOD dataset. We theoretically analyze the\neffect of confidence minimization and show that the choice of auxiliary dataset\nis critical. Specifically, if the auxiliary dataset includes samples from the\nOOD region of interest, confidence minimization provably separates ID and OOD\ninputs by predictive confidence. Taking inspiration from this result, we\npresent data-driven confidence minimization (DCM), which minimizes confidence\non an uncertainty dataset containing examples that the model is likely to\nmisclassify at test time. Our experiments show that DCM consistently\noutperforms state-of-the-art OOD detection methods on 8 ID-OOD dataset pairs,\nreducing FPR (at TPR 95%) by 6.3% and 58.1% on CIFAR-10 and CIFAR-100, and\noutperforms existing selective classification approaches on 4 datasets in\nconditions of distribution shift.\n","authors":["Caroline Choi","Fahim Tajwar","Yoonho Lee","Huaxiu Yao","Ananya Kumar","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2306.04974v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2306.04971v1","updated":"2023-06-08T06:59:21Z","published":"2023-06-08T06:59:21Z","title":"A Melting Pot of Evolution and Learning","summary":"  We survey eight recent works by our group, involving the successful blending\nof evolutionary algorithms with machine learning and deep learning: 1. Binary\nand Multinomial Classification through Evolutionary Symbolic Regression, 2.\nClassy Ensemble: A Novel Ensemble Algorithm for Classification, 3. EC-KitY:\nEvolutionary Computation Tool Kit in Python, 4. Evolution of Activation\nFunctions for Deep Learning-Based Image Classification, 5. Adaptive Combination\nof a Genetic Algorithm and Novelty Search for Deep Neuroevolution, 6. An\nEvolutionary, Gradient-Free, Query-Efficient, Black-Box Algorithm for\nGenerating Adversarial Instances in Deep Networks, 7. Foiling Explanations in\nDeep Neural Networks, 8. Patch of Invisibility: Naturalistic Black-Box\nAdversarial Attacks on Object Detectors.\n","authors":["Moshe Sipper","Achiya Elyasaf","Tomer Halperin","Zvika Haramaty","Raz Lapid","Eyal Segal","Itai Tzruia","Snir Vitrack Tamam"],"pdf_url":"https://arxiv.org/pdf/2306.04971v1.pdf","comment":"To Appear in Proceedings of Genetic Programming Theory & Practice XX,\n  2023"},{"id":"http://arxiv.org/abs/2302.10912v2","updated":"2023-06-08T06:58:05Z","published":"2023-02-14T15:35:17Z","title":"Balanced Audiovisual Dataset for Imbalance Analysis","summary":"  The imbalance problem is widespread in the field of machine learning, which\nalso exists in multimodal learning areas caused by the intrinsic discrepancy\nbetween modalities of samples. Recent works have attempted to solve the\nmodality imbalance problem from algorithm perspective, however, they do not\nfully analyze the influence of modality bias in datasets. Concretely, existing\nmultimodal datasets are usually collected under specific tasks, where one\nmodality tends to perform better than other ones in most conditions. In this\nwork, to comprehensively explore the influence of modality bias, we first split\nexisting datasets into different subsets by estimating sample-wise modality\ndiscrepancy. We surprisingly find that: the multimodal models with existing\nimbalance algorithms consistently perform worse than the unimodal one on\nspecific subsets, in accordance with the modality bias. To further explore the\ninfluence of modality bias and analyze the effectiveness of existing imbalance\nalgorithms, we build a balanced audiovisual dataset, with uniformly distributed\nmodality discrepancy over the whole dataset. We then conduct extensive\nexperiments to re-evaluate existing imbalance algorithms and draw some\ninteresting findings: existing algorithms only provide a compromise between\nmodalities and suffer from the large modality discrepancy of samples. We hope\nthat these findings could facilitate future research on the modality imbalance\nproblem.\n","authors":["Wenke Xia","Xu Zhao","Xincheng Pang","Changqing Zhang","Di Hu"],"pdf_url":"https://arxiv.org/pdf/2302.10912v2.pdf","comment":"website:https://gewu-lab.github.io/Balanced-Audiovisual-Dataset/"},{"id":"http://arxiv.org/abs/2306.04964v1","updated":"2023-06-08T06:43:10Z","published":"2023-06-08T06:43:10Z","title":"Leveraging Language Identification to Enhance Code-Mixed Text\n  Classification","summary":"  The usage of more than one language in the same text is referred to as Code\nMixed. It is evident that there is a growing degree of adaption of the use of\ncode-mixed data, especially English with a regional language, on social media\nplatforms. Existing deep-learning models do not take advantage of the implicit\nlanguage information in the code-mixed text. Our study aims to improve\nBERT-based models performance on low-resource Code-Mixed Hindi-English Datasets\nby experimenting with language augmentation approaches. We propose a pipeline\nto improve code-mixed systems that comprise data preprocessing, word-level\nlanguage identification, language augmentation, and model training on\ndownstream tasks like sentiment analysis. For language augmentation in BERT\nmodels, we explore word-level interleaving and post-sentence placement of\nlanguage information. We have examined the performance of vanilla BERT-based\nmodels and their code-mixed HingBERT counterparts on respective benchmark\ndatasets, comparing their results with and without using word-level language\ninformation. The models were evaluated using metrics such as accuracy,\nprecision, recall, and F1 score. Our findings show that the proposed language\naugmentation approaches work well across different BERT models. We demonstrate\nthe importance of augmenting code-mixed text with language information on five\ndifferent code-mixed Hindi-English downstream datasets based on sentiment\nanalysis, hate speech detection, and emotion detection.\n","authors":["Gauri Takawane","Abhishek Phaltankar","Varad Patwardhan","Aryan Patil","Raviraj Joshi","Mukta S. Takalikar"],"pdf_url":"https://arxiv.org/pdf/2306.04964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04962v1","updated":"2023-06-08T06:37:04Z","published":"2023-06-08T06:37:04Z","title":"arXiv4TGC: Large-Scale Datasets for Temporal Graph Clustering","summary":"  Temporal graph clustering (TGC) is a crucial task in temporal graph learning.\nIts focus is on node clustering on temporal graphs, and it offers greater\nflexibility for large-scale graph structures due to the mechanism of temporal\ngraph methods. However, the development of TGC is currently constrained by a\nsignificant problem: the lack of suitable and reliable large-scale temporal\ngraph datasets to evaluate clustering performance. In other words, most\nexisting temporal graph datasets are in small sizes, and even large-scale\ndatasets contain only a limited number of available node labels. It makes\nevaluating models for large-scale temporal graph clustering challenging. To\naddress this challenge, we build arXiv4TGC, a set of novel academic datasets\n(including arXivAI, arXivCS, arXivMath, arXivPhy, and arXivLarge) for\nlarge-scale temporal graph clustering. In particular, the largest dataset,\narXivLarge, contains 1.3 million labeled available nodes and 10 million\ntemporal edges. We further compare the clustering performance with typical\ntemporal graph learning models on both previous classic temporal graph datasets\nand the new datasets proposed in this paper. The clustering performance on\narXiv4TGC can be more apparent for evaluating different models, resulting in\nhigher clustering confidence and more suitable for large-scale temporal graph\nclustering. The arXiv4TGC datasets are publicly available at:\nhttps://github.com/MGitHubL/arXiv4TGC.\n","authors":["Meng Liu","Ke Liang","Yue Liu","Siwei Wang","Sihang Zhou","Xinwang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.04962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04961v1","updated":"2023-06-08T06:35:47Z","published":"2023-06-08T06:35:47Z","title":"Recovering Simultaneously Structured Data via Non-Convex Iteratively\n  Reweighted Least Squares","summary":"  We propose a new algorithm for the problem of recovering data that adheres to\nmultiple, heterogeneous low-dimensional structures from linear observations.\nFocusing on data matrices that are simultaneously row-sparse and low-rank, we\npropose and analyze an iteratively reweighted least squares (IRLS) algorithm\nthat is able to leverage both structures. In particular, it optimizes a\ncombination of non-convex surrogates for row-sparsity and rank, a balancing of\nwhich is built into the algorithm. We prove locally quadratic convergence of\nthe iterates to a simultaneously structured data matrix in a regime of minimal\nsample complexity (up to constants and a logarithmic factor), which is known to\nbe impossible for a combination of convex surrogates. In experiments, we show\nthat the IRLS method exhibits favorable empirical convergence, identifying\nsimultaneously row-sparse and low-rank matrices from fewer measurements than\nstate-of-the-art methods.\n","authors":["Christian Kümmerle","Johannes Maly"],"pdf_url":"https://arxiv.org/pdf/2306.04961v1.pdf","comment":"35 pages, 6 figures"},{"id":"http://arxiv.org/abs/2304.14293v2","updated":"2023-06-08T06:33:23Z","published":"2023-04-27T15:56:34Z","title":"Controlled Text Generation with Natural Language Instructions","summary":"  Large language models generate fluent texts and can follow natural language\ninstructions to solve a wide range of tasks without task-specific training.\nNevertheless, it is notoriously difficult to control their generation to\nsatisfy the various constraints required by different applications. In this\nwork, we present InstructCTG, a controlled text generation framework that\nincorporates different constraints by conditioning on natural language\ndescriptions and demonstrations of the constraints. In particular, we first\nextract the underlying constraints of natural texts through a combination of\noff-the-shelf NLP tools and simple heuristics. We then verbalize the\nconstraints into natural language instructions to form weakly supervised\ntraining data. By prepending natural language descriptions of the constraints\nand a few demonstrations, we fine-tune a pre-trained language model to\nincorporate various types of constraints. Compared to existing search-based or\nscore-based methods, InstructCTG is more flexible to different constraint types\nand has a much smaller impact on the generation quality and speed because it\ndoes not modify the decoding procedure. Additionally, InstructCTG allows the\nmodel to adapt to new constraints without re-training through the use of\nfew-shot task generalization and in-context learning abilities of\ninstruction-tuned language models.\n","authors":["Wangchunshu Zhou","Yuchen Eleanor Jiang","Ethan Wilcox","Ryan Cotterell","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2304.14293v2.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2205.10044v3","updated":"2023-06-08T06:31:40Z","published":"2022-05-20T09:35:26Z","title":"Towards biologically plausible Dreaming and Planning in recurrent\n  spiking networks","summary":"  Humans and animals can learn new skills after practicing for a few hours,\nwhile current reinforcement learning algorithms require a large amount of data\nto achieve good performances. Recent model-based approaches show promising\nresults by reducing the number of necessary interactions with the environment\nto learn a desirable policy. However, these methods require biological\nimplausible ingredients, such as the detailed storage of older experiences, and\nlong periods of offline learning. The optimal way to learn and exploit\nword-models is still an open question. Taking inspiration from biology, we\nsuggest that dreaming might be an efficient expedient to use an inner model. We\npropose a two-module (agent and model) spiking neural network in which\n\"dreaming\" (living new experiences in a model-based simulated environment)\nsignificantly boosts learning. We also explore \"planning\", an online\nalternative to dreaming, that shows comparable performances. Importantly, our\nmodel does not require the detailed storage of experiences, and learns online\nthe world-model and the policy. Moreover, we stress that our network is\ncomposed of spiking neurons, further increasing the biological plausibility and\nimplementability in neuromorphic hardware.\n","authors":["Cristiano Capone","Pier Stanislao Paolucci"],"pdf_url":"https://arxiv.org/pdf/2205.10044v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04288v2","updated":"2023-06-08T06:27:37Z","published":"2023-06-07T09:40:18Z","title":"Revising deep learning methods in parking lot occupancy detection","summary":"  Parking guidance systems have recently become a popular trend as a part of\nthe smart cities' paradigm of development. The crucial part of such systems is\nthe algorithm allowing drivers to search for available parking lots across\nregions of interest. The classic approach to this task is based on the\napplication of neural network classifiers to camera records. However, existing\nsystems demonstrate a lack of generalization ability and appropriate testing\nregarding specific visual conditions. In this study, we extensively evaluate\nstate-of-the-art parking lot occupancy detection algorithms, compare their\nprediction quality with the recently emerged vision transformers, and propose a\nnew pipeline based on EfficientNet architecture. Performed computational\nexperiments have demonstrated the performance increase in the case of our\nmodel, which was evaluated on 5 different datasets.\n","authors":["Anastasia Martynova","Mikhail Kuznetsov","Vadim Porvatov","Vladislav Tishin","Andrey Kuznetsov","Natalia Semenova","Ksenia Kuznetsova"],"pdf_url":"https://arxiv.org/pdf/2306.04288v2.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.04956v1","updated":"2023-06-08T06:06:42Z","published":"2023-06-08T06:06:42Z","title":"Adaptive Fake Audio Detection with Low-Rank Model Squeezing","summary":"  The rapid advancement of spoofing algorithms necessitates the development of\nrobust detection methods capable of accurately identifying emerging fake audio.\nTraditional approaches, such as finetuning on new datasets containing these\nnovel spoofing algorithms, are computationally intensive and pose a risk of\nimpairing the acquired knowledge of known fake audio types. To address these\nchallenges, this paper proposes an innovative approach that mitigates the\nlimitations associated with finetuning. We introduce the concept of training\nlow-rank adaptation matrices tailored specifically to the newly emerging fake\naudio types. During the inference stage, these adaptation matrices are combined\nwith the existing model to generate the final prediction output. Extensive\nexperimentation is conducted to evaluate the efficacy of the proposed method.\nThe results demonstrate that our approach effectively preserves the prediction\naccuracy of the existing model for known fake audio types. Furthermore, our\napproach offers several advantages, including reduced storage memory\nrequirements and lower equal error rates compared to conventional finetuning\nmethods, particularly on specific spoofing algorithms.\n","authors":["Xiaohui Zhang","Jiangyan Yi","Jianhua Tao","Chenlong Wang","Le Xu","Ruibo Fu"],"pdf_url":"https://arxiv.org/pdf/2306.04956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04955v1","updated":"2023-06-08T06:02:39Z","published":"2023-06-08T06:02:39Z","title":"Degraded Polygons Raise Fundamental Questions of Neural Network\n  Perception","summary":"  It is well-known that modern computer vision systems often exhibit behaviors\nmisaligned with those of humans: from adversarial attacks to image corruptions,\ndeep learning vision models suffer in a variety of settings that humans capably\nhandle. In light of these phenomena, here we introduce another, orthogonal\nperspective studying the human-machine vision gap. We revisit the task of\nrecovering images under degradation, first introduced over 30 years ago in the\nRecognition-by-Components theory of human vision. Specifically, we study the\nperformance and behavior of neural networks on the seemingly simple task of\nclassifying regular polygons at varying orders of degradation along their\nperimeters. To this end, we implement the Automated Shape Recoverability Test\nfor rapidly generating large-scale datasets of perimeter-degraded regular\npolygons, modernizing the historically manual creation of image recoverability\nexperiments. We then investigate the capacity of neural networks to recognize\nand recover such degraded shapes when initialized with different priors.\nUltimately, we find that neural networks' behavior on this simple task\nconflicts with human behavior, raising a fundamental question of the robustness\nand learning capabilities of modern computer vision models.\n","authors":["Leonard Tang","Dan Ley"],"pdf_url":"https://arxiv.org/pdf/2306.04955v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17303v4","updated":"2023-06-08T06:00:55Z","published":"2023-05-26T23:23:48Z","title":"Distilling BlackBox to Interpretable models for Efficient Transfer\n  Learning","summary":"  Building generalizable AI models is one of the primary challenges in the\nhealthcare domain. While radiologists rely on generalizable descriptive rules\nof abnormality, Neural Network (NN) models suffer even with a slight shift in\ninput distribution (e.g., scanner type). Fine-tuning a model to transfer\nknowledge from one domain to another requires a significant amount of labeled\ndata in the target domain. In this paper, we develop an interpretable model\nthat can be efficiently fine-tuned to an unseen target domain with minimal\ncomputational cost. We assume the interpretable component of NN to be\napproximately domain-invariant. However, interpretable models typically\nunderperform compared to their Blackbox (BB) variants. We start with a BB in\nthe source domain and distill it into a \\emph{mixture} of shallow interpretable\nmodels using human-understandable concepts. As each interpretable model covers\na subset of data, a mixture of interpretable models achieves comparable\nperformance as BB. Further, we use the pseudo-labeling technique from\nsemi-supervised learning (SSL) to learn the concept classifier in the target\ndomain, followed by fine-tuning the interpretable models in the target domain.\nWe evaluate our model using a real-life large-scale chest-X-ray (CXR)\nclassification dataset. The code is available at:\n\\url{https://github.com/batmanlab/MICCAI-2023-Route-interpret-repeat-CXRs}.\n","authors":["Shantanu Ghosh","Ke Yu","Kayhan Batmanghelich"],"pdf_url":"https://arxiv.org/pdf/2305.17303v4.pdf","comment":"MICCAI, 2023, Early accept"},{"id":"http://arxiv.org/abs/2012.06951v5","updated":"2023-06-08T05:58:43Z","published":"2020-12-13T03:41:52Z","title":"Attentional-Biased Stochastic Gradient Descent","summary":"  In this paper, we present a simple yet effective provable method (named\nABSGD) for addressing the data imbalance or label noise problem in deep\nlearning. Our method is a simple modification to momentum SGD where we assign\nan individual importance weight to each sample in the mini-batch. The\nindividual-level weight of sampled data is systematically proportional to the\nexponential of a scaled loss value of the data, where the scaling factor is\ninterpreted as the regularization parameter in the framework of\ndistributionally robust optimization (DRO). Depending on whether the scaling\nfactor is positive or negative, ABSGD is guaranteed to converge to a stationary\npoint of an information-regularized min-max or min-min DRO problem,\nrespectively. Compared with existing class-level weighting schemes, our method\ncan capture the diversity between individual examples within each class.\nCompared with existing individual-level weighting methods using meta-learning\nthat require three backward propagations for computing mini-batch stochastic\ngradients, our method is more efficient with only one backward propagation at\neach iteration as in standard deep learning methods. ABSGD is flexible enough\nto combine with other robust losses without any additional cost. Our empirical\nstudies on several benchmark datasets demonstrate the effectiveness of the\nproposed method.\\footnote{Code is available\nat:\\url{https://github.com/qiqi-helloworld/ABSGD/}}\n","authors":["Qi Qi","Yi Xu","Rong Jin","Wotao Yin","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2012.06951v5.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2306.04952v1","updated":"2023-06-08T05:56:05Z","published":"2023-06-08T05:56:05Z","title":"Entropy-based Training Methods for Scalable Neural Implicit Sampler","summary":"  Efficiently sampling from un-normalized target distributions is a fundamental\nproblem in scientific computing and machine learning. Traditional approaches\nlike Markov Chain Monte Carlo (MCMC) guarantee asymptotically unbiased samples\nfrom such distributions but suffer from computational inefficiency,\nparticularly when dealing with high-dimensional targets, as they require\nnumerous iterations to generate a batch of samples. In this paper, we propose\nan efficient and scalable neural implicit sampler that overcomes these\nlimitations. Our sampler can generate large batches of samples with low\ncomputational costs by leveraging a neural transformation that directly maps\neasily sampled latent vectors to target samples without the need for iterative\nprocedures. To train the neural implicit sampler, we introduce two novel\nmethods: the KL training method and the Fisher training method. The former\nminimizes the Kullback-Leibler divergence, while the latter minimizes the\nFisher divergence. By employing these training methods, we effectively optimize\nthe neural implicit sampler to capture the desired target distribution. To\ndemonstrate the effectiveness, efficiency, and scalability of our proposed\nsamplers, we evaluate them on three sampling benchmarks with different scales.\nThese benchmarks include sampling from 2D targets, Bayesian inference, and\nsampling from high-dimensional energy-based models (EBMs). Notably, in the\nexperiment involving high-dimensional EBMs, our sampler produces samples that\nare comparable to those generated by MCMC-based methods while being more than\n100 times more efficient, showcasing the efficiency of our neural sampler. We\nbelieve that the theoretical and empirical contributions presented in this work\nwill stimulate further research on developing efficient samplers for various\napplications beyond the ones explored in this study.\n","authors":["Weijian Luo","Boya Zhang","Zhihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.04952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03712v2","updated":"2023-06-08T05:51:40Z","published":"2023-05-05T17:54:22Z","title":"Statistical Inference for Fairness Auditing","summary":"  Before deploying a black-box model in high-stakes problems, it is important\nto evaluate the model's performance on sensitive subpopulations. For example,\nin a recidivism prediction task, we may wish to identify demographic groups for\nwhich our prediction model has unacceptably high false positive rates or\ncertify that no such groups exist. In this paper, we frame this task, often\nreferred to as \"fairness auditing,\" in terms of multiple hypothesis testing. We\nshow how the bootstrap can be used to simultaneously bound performance\ndisparities over a collection of groups with statistical guarantees. Our\nmethods can be used to flag subpopulations affected by model underperformance,\nand certify subpopulations for which the model performs adequately. Crucially,\nour audit is model-agnostic and applicable to nearly any performance metric or\ngroup fairness criterion. Our methods also accommodate extremely rich -- even\ninfinite -- collections of subpopulations. Further, we generalize beyond\nsubpopulations by showing how to assess performance over certain distribution\nshifts. We test the proposed methods on benchmark datasets in predictive\ninference and algorithmic fairness and find that our audits can provide\ninterpretable and trustworthy guarantees.\n","authors":["John J. Cherian","Emmanuel J. Candès"],"pdf_url":"https://arxiv.org/pdf/2305.03712v2.pdf","comment":"44 pages, 8 figures"},{"id":"http://arxiv.org/abs/2208.12401v5","updated":"2023-06-08T05:50:50Z","published":"2022-08-26T02:13:38Z","title":"Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased\n  Full Set Gradient Approximation","summary":"  Recent work on mini-batch consistency (MBC) for set functions has brought\nattention to the need for sequentially processing and aggregating chunks of a\npartitioned set while guaranteeing the same output for all partitions. However,\nexisting constraints on MBC architectures lead to models with limited\nexpressive power. Additionally, prior work has not addressed how to deal with\nlarge sets during training when the full set gradient is required. To address\nthese issues, we propose a Universally MBC (UMBC) class of set functions which\ncan be used in conjunction with arbitrary non-MBC components while still\nsatisfying MBC, enabling a wider range of function classes to be used in MBC\nsettings. Furthermore, we propose an efficient MBC training algorithm which\ngives an unbiased approximation of the full set gradient and has a constant\nmemory overhead for any set size for both train- and test-time. We conduct\nextensive experiments including image completion, text classification,\nunsupervised clustering, and cancer detection on high-resolution images to\nverify the efficiency and efficacy of our scalable set encoding framework. Our\ncode is available at github.com/jeffwillette/umbc\n","authors":["Jeffrey Willette","Seanie Lee","Bruno Andreis","Kenji Kawaguchi","Juho Lee","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2208.12401v5.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2201.01247v3","updated":"2023-06-08T05:44:57Z","published":"2022-01-04T17:05:07Z","title":"Value Functions Factorization with Latent State Information Sharing in\n  Decentralized Multi-Agent Policy Gradients","summary":"  Value function factorization via centralized training and decentralized\nexecution is promising for solving cooperative multi-agent reinforcement tasks.\nOne of the approaches in this area, QMIX, has become state-of-the-art and\nachieved the best performance on the StarCraft II micromanagement benchmark.\nHowever, the monotonic-mixing of per agent estimates in QMIX is known to\nrestrict the joint action Q-values it can represent, as well as the\ninsufficient global state information for single agent value function\nestimation, often resulting in suboptimality. To this end, we present LSF-SAC,\na novel framework that features a variational inference-based\ninformation-sharing mechanism as extra state information to assist individual\nagents in the value function factorization. We demonstrate that such latent\nindividual state information sharing can significantly expand the power of\nvalue function factorization, while fully decentralized execution can still be\nmaintained in LSF-SAC through a soft-actor-critic design. We evaluate LSF-SAC\non the StarCraft II micromanagement challenge and demonstrate that it\noutperforms several state-of-the-art methods in challenging collaborative\ntasks. We further set extensive ablation studies for locating the key factors\naccounting for its performance improvements. We believe that this new insight\ncan lead to new local value estimation methods and variational deep learning\nalgorithms. A demo video and code of implementation can be found at\nhttps://sites.google.com/view/sacmm.\n","authors":["Hanhan Zhou","Tian Lan","Vaneet Aggarwal"],"pdf_url":"https://arxiv.org/pdf/2201.01247v3.pdf","comment":"Accepted to IEEE Transactions on Emerging Topics in Computational\n  Intelligence (TETCI)"},{"id":"http://arxiv.org/abs/2306.04949v1","updated":"2023-06-08T05:44:06Z","published":"2023-06-08T05:44:06Z","title":"Robust Learning with Progressive Data Expansion Against Spurious\n  Correlation","summary":"  While deep learning models have shown remarkable performance in various\ntasks, they are susceptible to learning non-generalizable spurious features\nrather than the core features that are genuinely correlated to the true label.\nIn this paper, beyond existing analyses of linear models, we theoretically\nexamine the learning process of a two-layer nonlinear convolutional neural\nnetwork in the presence of spurious features. Our analysis suggests that\nimbalanced data groups and easily learnable spurious features can lead to the\ndominance of spurious features during the learning process. In light of this,\nwe propose a new training algorithm called PDE that efficiently enhances the\nmodel's robustness for a better worst-group performance. PDE begins with a\ngroup-balanced subset of training data and progressively expands it to\nfacilitate the learning of the core features. Experiments on synthetic and\nreal-world benchmark datasets confirm the superior performance of our method on\nmodels such as ResNets and Transformers. On average, our method achieves a 2.8%\nimprovement in worst-group accuracy compared with the state-of-the-art method,\nwhile enjoying up to 10x faster training efficiency.\n","authors":["Yihe Deng","Yu Yang","Baharan Mirzasoleiman","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2306.04949v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04948v1","updated":"2023-06-08T05:41:42Z","published":"2023-06-08T05:41:42Z","title":"ShuttleSet: A Human-Annotated Stroke-Level Singles Dataset for Badminton\n  Tactical Analysis","summary":"  With the recent progress in sports analytics, deep learning approaches have\ndemonstrated the effectiveness of mining insights into players' tactics for\nimproving performance quality and fan engagement. This is attributed to the\navailability of public ground-truth datasets. While there are a few available\ndatasets for turn-based sports for action detection, these datasets severely\nlack structured source data and stroke-level records since these require\nhigh-cost labeling efforts from domain experts and are hard to detect using\nautomatic techniques. Consequently, the development of artificial intelligence\napproaches is significantly hindered when existing models are applied to more\nchallenging structured turn-based sequences. In this paper, we present\nShuttleSet, the largest publicly-available badminton singles dataset with\nannotated stroke-level records. It contains 104 sets, 3,685 rallies, and 36,492\nstrokes in 44 matches between 2018 and 2021 with 27 top-ranking men's singles\nand women's singles players. ShuttleSet is manually annotated with a\ncomputer-aided labeling tool to increase the labeling efficiency and\neffectiveness of selecting the shot type with a choice of 18 distinct classes,\nthe corresponding hitting locations, and the locations of both players at each\nstroke. In the experiments, we provide multiple benchmarks (i.e., stroke\ninfluence, stroke forecasting, and movement forecasting) with baselines to\nillustrate the practicability of using ShuttleSet for turn-based analytics,\nwhich is expected to stimulate both academic and sports communities. Over the\npast two years, a visualization platform has been deployed to illustrate the\nvariability of analysis cases from ShuttleSet for coaches to delve into\nplayers' tactical preferences with human-interactive interfaces, which was also\nused by national badminton teams during multiple international high-ranking\nmatches.\n","authors":["Wei-Yao Wang","Yung-Chang Huang","Tsi-Ui Ik","Wen-Chih Peng"],"pdf_url":"https://arxiv.org/pdf/2306.04948v1.pdf","comment":"KDD 2023. Project page: https://github.com/wywyWang/CoachAI-Projects"},{"id":"http://arxiv.org/abs/2306.04941v1","updated":"2023-06-08T05:17:03Z","published":"2023-06-08T05:17:03Z","title":"A modified model for topic detection from a corpus and a new metric\n  evaluating the understandability of topics","summary":"  This paper presents a modified neural model for topic detection from a corpus\nand proposes a new metric to evaluate the detected topics. The new model builds\nupon the embedded topic model incorporating some modifications such as document\nclustering. Numerical experiments suggest that the new model performs\nfavourably regardless of the document's length. The new metric, which can be\ncomputed more efficiently than widely-used metrics such as topic coherence,\nprovides variable information regarding the understandability of the detected\ntopics.\n","authors":["Tomoya Kitano","Yuto Miyatake","Daisuke Furihata"],"pdf_url":"https://arxiv.org/pdf/2306.04941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04940v1","updated":"2023-06-08T05:13:34Z","published":"2023-06-08T05:13:34Z","title":"Layer-level activation mechanism","summary":"  In this work, we propose a novel activation mechanism aimed at establishing\nlayer-level activation (LayerAct) functions. These functions are designed to be\nmore noise-robust compared to traditional element-level activation functions by\nreducing the layer-level fluctuation of the activation outputs due to shift in\ninputs. Moreover, the LayerAct functions achieve a zero-like mean activation\noutput without restricting the activation output space. We present an analysis\nand experiments demonstrating that LayerAct functions exhibit superior\nnoise-robustness compared to element-level activation functions, and\nempirically show that these functions have a zero-like mean activation.\nExperimental results on three benchmark image classification tasks show that\nLayerAct functions excel in handling noisy image datasets, outperforming\nelement-level activation functions, while the performance on clean datasets is\nalso superior in most cases.\n","authors":["Yoon Kihyuk","Lim Chiehyeon"],"pdf_url":"https://arxiv.org/pdf/2306.04940v1.pdf","comment":"9 pages, 4 figures, 4 tables except appendix"},{"id":"http://arxiv.org/abs/2110.02398v6","updated":"2023-06-08T04:57:49Z","published":"2021-10-05T23:07:12Z","title":"Approximate Newton policy gradient algorithms","summary":"  Policy gradient algorithms have been widely applied to Markov decision\nprocesses and reinforcement learning problems in recent years. Regularization\nwith various entropy functions is often used to encourage exploration and\nimprove stability. This paper proposes an approximate Newton method for the\npolicy gradient algorithm with entropy regularization. In the case of Shannon\nentropy, the resulting algorithm reproduces the natural policy gradient\nalgorithm. For other entropy functions, this method results in brand-new policy\ngradient algorithms. We prove that all these algorithms enjoy Newton-type\nquadratic convergence and that the corresponding gradient flow converges\nglobally to the optimal solution. We use synthetic and industrial-scale\nexamples to demonstrate that the proposed approximate Newton method typically\nconverges in single-digit iterations, often orders of magnitude faster than\nother state-of-the-art algorithms.\n","authors":["Haoya Li","Samarth Gupta","Hsiangfu Yu","Lexing Ying","Inderjit Dhillon"],"pdf_url":"https://arxiv.org/pdf/2110.02398v6.pdf","comment":"22 pages, 15 figures, v6 accepted by SIAM SISC"}]},"2023-06-09T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2306.04634v2","updated":"2023-06-09T17:58:04Z","published":"2023-06-07T17:58:48Z","title":"On the Reliability of Watermarks for Large Language Models","summary":"  As LLMs become commonplace, machine-generated text has the potential to flood\nthe internet with spam, social media bots, and valueless content. Watermarking\nis a simple and effective strategy for mitigating such harms by enabling the\ndetection and documentation of LLM-generated text. Yet a crucial question\nremains: How reliable is watermarking in realistic settings in the wild? There,\nwatermarked text may be modified to suit a user's needs, or entirely rewritten\nto avoid detection.\n  We study the robustness of watermarked text after it is re-written by humans,\nparaphrased by a non-watermarked LLM, or mixed into a longer hand-written\ndocument. We find that watermarks remain detectable even after human and\nmachine paraphrasing. While these attacks dilute the strength of the watermark,\nparaphrases are statistically likely to leak n-grams or even longer fragments\nof the original text, resulting in high-confidence detections when enough\ntokens are observed. For example, after strong human paraphrasing the watermark\nis detectable after observing 800 tokens on average, when setting a 1e-5 false\npositive rate. We also consider a range of new detection schemes that are\nsensitive to short spans of watermarked text embedded inside a large document,\nand we compare the robustness of watermarking to other kinds of detectors.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Manli Shu","Khalid Saifullah","Kezhi Kong","Kasun Fernando","Aniruddha Saha","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2306.04634v2.pdf","comment":"14 pages in the main body. Code is available at\n  https://github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2306.06094v1","updated":"2023-06-09T17:57:01Z","published":"2023-06-09T17:57:01Z","title":"Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding","summary":"  Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.\n","authors":["Mu Cai","Zeyi Huang","Yuheng Li","Haohan Wang","Yong Jae Lee"],"pdf_url":"https://arxiv.org/pdf/2306.06094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06086v1","updated":"2023-06-09T17:48:58Z","published":"2023-06-09T17:48:58Z","title":"Developing Speech Processing Pipelines for Police Accountability","summary":"  Police body-worn cameras have the potential to improve accountability and\ntransparency in policing. Yet in practice, they result in millions of hours of\nfootage that is never reviewed. We investigate the potential of large\npre-trained speech models for facilitating reviews, focusing on ASR and officer\nspeech detection in footage from traffic stops. Our proposed pipeline includes\ntraining data alignment and filtering, fine-tuning with resource constraints,\nand combining officer speech detection with ASR for a fully automated approach.\nWe find that (1) fine-tuning strongly improves ASR performance on officer\nspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than on\ncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks like\nofficer speech detection and diarization remain challenging. Our work offers\npractical applications for reviewing body camera footage and general guidance\nfor adapting pre-trained speech models to noisy multi-speaker domains.\n","authors":["Anjalie Field","Prateek Verma","Nay San","Jennifer L. Eberhardt","Dan Jurafsky"],"pdf_url":"https://arxiv.org/pdf/2306.06086v1.pdf","comment":"Accepted to INTERSPEECH 2023"},{"id":"http://arxiv.org/abs/2306.06085v1","updated":"2023-06-09T17:48:54Z","published":"2023-06-09T17:48:54Z","title":"Trapping LLM Hallucinations Using Tagged Context Prompts","summary":"  Recent advances in large language models (LLMs), such as ChatGPT, have led to\nhighly sophisticated conversation agents. However, these models suffer from\n\"hallucinations,\" where the model generates false or fabricated information.\nAddressing this challenge is crucial, particularly with AI-driven platforms\nbeing adopted across various sectors. In this paper, we propose a novel method\nto recognize and flag instances when LLMs perform outside their domain\nknowledge, and ensuring users receive accurate information.\n  We find that the use of context combined with embedded tags can successfully\ncombat hallucinations within generative language models. To do this, we\nbaseline hallucination frequency in no-context prompt-response pairs using\ngenerated URLs as easily-tested indicators of fabricated data. We observed a\nsignificant reduction in overall hallucination when context was supplied along\nwith question prompts for tested generative engines. Lastly, we evaluated how\nplacing tags within contexts impacted model responses and were able to\neliminate hallucinations in responses with 98.88% effectiveness.\n","authors":["Philip Feldman","James R. Foulds","Shimei Pan"],"pdf_url":"https://arxiv.org/pdf/2306.06085v1.pdf","comment":"13 pages, 3 Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2306.06070v1","updated":"2023-06-09T17:44:31Z","published":"2023-06-09T17:44:31Z","title":"Mind2Web: Towards a Generalist Agent for the Web","summary":"  We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.\n","authors":["Xiang Deng","Yu Gu","Boyuan Zheng","Shijie Chen","Samuel Stevens","Boshi Wang","Huan Sun","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2306.06070v1.pdf","comment":"website: https://osu-nlp-group.github.io/Mind2Web"},{"id":"http://arxiv.org/abs/2306.06058v1","updated":"2023-06-09T17:32:45Z","published":"2023-06-09T17:32:45Z","title":"Assisting Language Learners: Automated Trans-Lingual Definition\n  Generation via Contrastive Prompt Learning","summary":"  The standard definition generation task requires to automatically produce\nmono-lingual definitions (e.g., English definitions for English words), but\nignores that the generated definitions may also consist of unfamiliar words for\nlanguage learners. In this work, we propose a novel task of Trans-Lingual\nDefinition Generation (TLDG), which aims to generate definitions in another\nlanguage, i.e., the native speaker's language. Initially, we explore the\nunsupervised manner of this task and build up a simple implementation of\nfine-tuning the multi-lingual machine translation model. Then, we develop two\nnovel methods, Prompt Combination and Contrastive Prompt Learning, for further\nenhancing the quality of the generation. Our methods are evaluated against the\nbaseline Pipeline method in both rich- and low-resource settings, and we\nempirically establish its superiority in generating higher-quality\ntrans-lingual definitions.\n","authors":["Hengyuan Zhang","Dawei Li","Yanran Li","Chenming Shang","Chufan Shi","Yong Jiang"],"pdf_url":"https://arxiv.org/pdf/2306.06058v1.pdf","comment":"Accepted by ACL-BEA workshop"},{"id":"http://arxiv.org/abs/2303.06245v3","updated":"2023-06-09T17:18:03Z","published":"2023-03-10T23:34:14Z","title":"AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model","summary":"  As large dialogue models become commonplace in practice, the problems\nsurrounding high compute requirements for training, inference and larger memory\nfootprint still persists. In this work, we present AUTODIAL, a multi-task\ndialogue model that addresses the challenges of deploying dialogue model.\nAUTODIAL utilizes parallel decoders to perform tasks such as dialogue act\nprediction, domain prediction, intent prediction, and dialogue state tracking.\nUsing classification decoders over generative decoders allows AUTODIAL to\nsignificantly reduce memory footprint and achieve faster inference times\ncompared to existing generative approach namely SimpleTOD. We demonstrate that\nAUTODIAL provides 3-6x speedups during inference while having 11x fewer\nparameters on three dialogue tasks compared to SimpleTOD. Our results show that\nextending current dialogue models to have parallel decoders can be a viable\nalternative for deploying them in resource-constrained environments.\n","authors":["Prajjwal Bhargava","Pooyan Amini","Shahin Shayandeh","Chinnadhurai Sankar"],"pdf_url":"https://arxiv.org/pdf/2303.06245v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06031v1","updated":"2023-06-09T16:52:00Z","published":"2023-06-09T16:52:00Z","title":"FinGPT: Open-Source Financial Large Language Models","summary":"  Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}\n","authors":["Hongyang Yang","Xiao-Yang Liu","Christina Dan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.06031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06029v1","updated":"2023-06-09T16:50:02Z","published":"2023-06-09T16:50:02Z","title":"HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence\n  for Digital Medicine","summary":"  Providing high quality explanations for AI predictions based on machine\nlearning is a challenging and complex task. To work well it requires, among\nother factors: selecting a proper level of generality/specificity of the\nexplanation; considering assumptions about the familiarity of the explanation\nbeneficiary with the AI task under consideration; referring to specific\nelements that have contributed to the decision; making use of additional\nknowledge (e.g. expert evidence) which might not be part of the prediction\nprocess; and providing evidence supporting negative hypothesis. Finally, the\nsystem needs to formulate the explanation in a clearly interpretable, and\npossibly convincing, way. Given these considerations, ANTIDOTE fosters an\nintegrated vision of explainable AI, where low-level characteristics of the\ndeep learning process are combined with higher level schemes proper of the\nhuman argumentation capacity. ANTIDOTE will exploit cross-disciplinary\ncompetences in deep learning and argumentation to support a broader and\ninnovative view of explainable AI, where the need for high-quality explanations\nfor clinical cases deliberation is critical. As a first result of the project,\nwe publish the Antidote CasiMedicos dataset to facilitate research on\nexplainable AI in general, and argumentation in the medical domain in\nparticular.\n","authors":["Rodrigo Agerri","Iñigo Alonso","Aitziber Atutxa","Ander Berrondo","Ainara Estarrona","Iker Garcia-Ferrero","Iakes Goenaga","Koldo Gojenola","Maite Oronoz","Igor Perez-Tejedor","German Rigau","Anar Yeginbergenova"],"pdf_url":"https://arxiv.org/pdf/2306.06029v1.pdf","comment":"To appear: In SEPLN 2023: 39th International Conference of the\n  Spanish Society for Natural Language Processing"},{"id":"http://arxiv.org/abs/2306.05997v1","updated":"2023-06-09T16:08:35Z","published":"2023-06-09T16:08:35Z","title":"Automated Labeling of German Chest X-Ray Radiology Reports using Deep\n  Learning","summary":"  Radiologists are in short supply globally, and deep learning models offer a\npromising solution to address this shortage as part of clinical\ndecision-support systems. However, training such models often requires\nexpensive and time-consuming manual labeling of large datasets. Automatic label\nextraction from radiology reports can reduce the time required to obtain\nlabeled datasets, but this task is challenging due to semantically similar\nwords and missing annotated data. In this work, we explore the potential of\nweak supervision of a deep learning-based label prediction model, using a\nrule-based labeler. We propose a deep learning-based CheXpert label prediction\nmodel, pre-trained on reports labeled by a rule-based German CheXpert model and\nfine-tuned on a small dataset of manually labeled reports. Our results\ndemonstrate the effectiveness of our approach, which significantly outperformed\nthe rule-based model on all three tasks. Our findings highlight the benefits of\nemploying deep learning-based models even in scenarios with sparse data and the\nuse of the rule-based labeler as a tool for weak supervision.\n","authors":["Alessandro Wollek","Philip Haitzer","Thomas Sedlmeyr","Sardi Hyska","Johannes Rueckel","Bastian Sabel","Michael Ingrisch","Tobias Lasser"],"pdf_url":"https://arxiv.org/pdf/2306.05997v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01555v4","updated":"2023-06-09T15:59:18Z","published":"2023-05-02T15:55:41Z","title":"How to Unleash the Power of Large Language Models for Few-shot Relation\n  Extraction?","summary":"  Scaling language models have revolutionized widespread NLP tasks, yet little\ncomprehensively explored few-shot relation extraction with large language\nmodels. In this paper, we investigate principal methodologies, in-context\nlearning and data generation, for few-shot relation extraction via GPT-3.5\nthrough exhaustive experiments. To enhance few-shot performance, we further\npropose task-related instructions and schema-constrained data generation. We\nobserve that in-context learning can achieve performance on par with previous\nprompt learning approaches, and data generation with the large language model\ncan boost previous solutions to obtain new state-of-the-art few-shot results on\nfour widely-studied relation extraction datasets. We hope our work can inspire\nfuture research for the capabilities of large language models in few-shot\nrelation extraction. Code is available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.\n","authors":["Xin Xu","Yuqi Zhu","Xiaohan Wang","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.01555v4.pdf","comment":"SustaiNLP Workshop@ACL 2023"},{"id":"http://arxiv.org/abs/2212.09140v2","updated":"2023-06-09T15:42:50Z","published":"2022-12-18T18:10:45Z","title":"Unsupervised Discontinuous Constituency Parsing with Mildly\n  Context-Sensitive Grammars","summary":"  We study grammar induction with mildly context-sensitive grammars for\nunsupervised discontinuous parsing. Using the probabilistic linear context-free\nrewriting system (LCFRS) formalism, our approach fixes the rule structure in\nadvance and focuses on parameter learning with maximum likelihood. To reduce\nthe computational complexity of both parsing and parameter estimation, we\nrestrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two)\nand further discard rules that require O(n^6) time to parse, reducing inference\nto O(n^5). We find that using a large number of nonterminals is beneficial and\nthus make use of tensor decomposition-based rank-space dynamic programming with\nan embedding-based parameterization of rule probabilities to scale up the\nnumber of nonterminals. Experiments on German and Dutch show that our approach\nis able to induce linguistically meaningful trees with continuous and\ndiscontinuous structures\n","authors":["Songlin Yang","Roger P. Levy","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2212.09140v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2306.05969v1","updated":"2023-06-09T15:35:11Z","published":"2023-06-09T15:35:11Z","title":"Language Models Can Learn Exceptions to Syntactic Rules","summary":"  Artificial neural networks can generalize productively to novel contexts. Can\nthey also learn exceptions to those productive rules? We explore this question\nusing the case of restrictions on English passivization (e.g., the fact that\n\"The vacation lasted five days\" is grammatical, but \"*Five days was lasted by\nthe vacation\" is not). We collect human acceptability judgments for passive\nsentences with a range of verbs, and show that the probability distribution\ndefined by GPT-2, a language model, matches the human judgments with high\ncorrelation. We also show that the relative acceptability of a verb in the\nactive vs. passive voice is positively correlated with the relative frequency\nof its occurrence in those voices. These results provide preliminary support\nfor the entrenchment hypothesis, according to which learners track and uses the\ndistributional properties of their input to learn negative exceptions to rules.\nAt the same time, this hypothesis fails to explain the magnitude of\nunpassivizability demonstrated by certain individual verbs, suggesting that\nother cues to exceptionality are available in the linguistic input.\n","authors":["Cara Su-Yi Leong","Tal Linzen"],"pdf_url":"https://arxiv.org/pdf/2306.05969v1.pdf","comment":"Accepted to SCiL 2023"},{"id":"http://arxiv.org/abs/2306.05887v1","updated":"2023-06-09T13:30:27Z","published":"2023-06-09T13:30:27Z","title":"An Efficient Speech Separation Network Based on Recurrent Fusion Dilated\n  Convolution and Channel Attention","summary":"  We present an efficient speech separation neural network, ARFDCN, which\ncombines dilated convolutions, multi-scale fusion (MSF), and channel attention\nto overcome the limited receptive field of convolution-based networks and the\nhigh computational cost of transformer-based networks. The suggested network\narchitecture is encoder-decoder based. By using dilated convolutions with\ngradually increasing dilation value to learn local and global features and\nfusing them at adjacent stages, the model can learn rich feature content.\nMeanwhile, by adding channel attention modules to the network, the model can\nextract channel weights, learn more important features, and thus improve its\nexpressive power and robustness. Experimental results indicate that the model\nachieves a decent balance between performance and computational efficiency,\nmaking it a promising alternative to current mainstream models for practical\napplications.\n","authors":["Junyu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05887v1.pdf","comment":"Accepted by Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.05882v1","updated":"2023-06-09T13:24:27Z","published":"2023-06-09T13:24:27Z","title":"Good, but not always Fair: An Evaluation of Gender Bias for three\n  commercial Machine Translation Systems","summary":"  Machine Translation (MT) continues to make significant strides in quality and\nis increasingly adopted on a larger scale. Consequently, analyses have been\nredirected to more nuanced aspects, intricate phenomena, as well as potential\nrisks that may arise from the widespread use of MT tools. Along this line, this\npaper offers a meticulous assessment of three commercial MT systems - Google\nTranslate, DeepL, and Modern MT - with a specific focus on gender translation\nand bias. For three language pairs (English/Spanish, English/Italian, and\nEnglish/French), we scrutinize the behavior of such systems at several levels\nof granularity and on a variety of naturally occurring gender phenomena in\ntranslation. Our study takes stock of the current state of online MT tools, by\nrevealing significant discrepancies in the gender translation of the three\nsystems, with each system displaying varying degrees of bias despite their\noverall translation quality.\n","authors":["Silvia Alma Piazzolla","Beatrice Savoldi","Luisa Bentivogli"],"pdf_url":"https://arxiv.org/pdf/2306.05882v1.pdf","comment":"Under review at HERMES Journal"},{"id":"http://arxiv.org/abs/2306.05871v1","updated":"2023-06-09T13:03:53Z","published":"2023-06-09T13:03:53Z","title":"Towards a Robust Detection of Language Model Generated Text: Is ChatGPT\n  that Easy to Detect?","summary":"  Recent advances in natural language processing (NLP) have led to the\ndevelopment of large language models (LLMs) such as ChatGPT. This paper\nproposes a methodology for developing and evaluating ChatGPT detectors for\nFrench text, with a focus on investigating their robustness on out-of-domain\ndata and against common attack schemes. The proposed method involves\ntranslating an English dataset into French and training a classifier on the\ntranslated data. Results show that the detectors can effectively detect\nChatGPT-generated text, with a degree of robustness against basic attack\ntechniques in in-domain settings. However, vulnerabilities are evident in\nout-of-domain contexts, highlighting the challenge of detecting adversarial\ntext. The study emphasizes caution when applying in-domain testing results to a\nwider variety of content. We provide our translated datasets and models as\nopen-source resources. https://gitlab.inria.fr/wantoun/robust-chatgpt-detection\n","authors":["Wissam Antoun","Virginie Mouilleron","Benoît Sagot","Djamé Seddah"],"pdf_url":"https://arxiv.org/pdf/2306.05871v1.pdf","comment":"Accepted to TALN 2023"},{"id":"http://arxiv.org/abs/2303.04091v2","updated":"2023-06-09T12:52:24Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v2.pdf","comment":"The first two authors have contributed equally to this work. Accepted\n  as regular paper at CVPR 2023 Workshop and Challenges for New Frontiers in\n  Visual Language Reasoning: Compositionality, Prompts and Causality (NFVLR)"},{"id":"http://arxiv.org/abs/2306.05861v1","updated":"2023-06-09T12:52:01Z","published":"2023-06-09T12:52:01Z","title":"Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive\n  Feature Learning in Speech Enhancement","summary":"  Current speech enhancement (SE) research has largely neglected channel\nattention and spatial attention, and encoder-decoder architecture-based\nnetworks have not adequately considered how to provide efficient inputs to the\nintermediate enhancement layer. To address these issues, this paper proposes a\ntime-frequency (T-F) domain SE network (DPCFCS-Net) that incorporates improved\ndensely connected blocks, dual-path modules, convolution-augmented transformers\n(conformers), channel attention, and spatial attention. Compared with previous\nmodels, our proposed model has a more efficient encoder-decoder and can learn\ncomprehensive features. Experimental results on the VCTK+DEMAND dataset\ndemonstrate that our method outperforms existing techniques in SE performance.\nFurthermore, the improved densely connected block and two dimensions attention\nmodule developed in this work are highly adaptable and easily integrated into\nexisting networks.\n","authors":["Junyu Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05861v1.pdf","comment":"Accepted at Interspeech2023"},{"id":"http://arxiv.org/abs/2206.08657v5","updated":"2023-06-09T12:36:33Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v5.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2306.05836v1","updated":"2023-06-09T12:09:15Z","published":"2023-06-09T12:09:15Z","title":"Can Large Language Models Infer Causation from Correlation?","summary":"  Causal inference is one of the hallmarks of human intelligence. While the\nfield of CausalNLP has attracted much interest in the recent years, existing\ncausal inference datasets in NLP primarily rely on discovering causality from\nempirical knowledge (e.g., commonsense knowledge). In this work, we propose the\nfirst benchmark dataset to test the pure causal inference skills of large\nlanguage models (LLMs). Specifically, we formulate a novel task Corr2Cause,\nwhich takes a set of correlational statements and determines the causal\nrelationship between the variables. We curate a large-scale dataset of more\nthan 400K samples, on which we evaluate seventeen existing LLMs. Through our\nexperiments, we identify a key shortcoming of LLMs in terms of their causal\ninference skills, and show that these models achieve almost close to random\nperformance on the task. This shortcoming is somewhat mitigated when we try to\nre-purpose LLMs for this skill via finetuning, but we find that these models\nstill fail to generalize -- they can only perform causal inference in\nin-distribution settings when variable names and textual expressions used in\nthe queries are similar to those in the training set, but fail in\nout-of-distribution settings generated by perturbing these queries. Corr2Cause\nis a challenging task for LLMs, and would be helpful in guiding future research\non improving LLMs' pure reasoning skills and generalizability. Our data is at\nhttps://huggingface.co/datasets/causalnlp/corr2cause. Our code is at\nhttps://github.com/causalNLP/corr2cause.\n","authors":["Zhijing Jin","Jiarui Liu","Zhiheng Lyu","Spencer Poff","Mrinmaya Sachan","Rada Mihalcea","Mona Diab","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2306.05836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05827v1","updated":"2023-06-09T11:57:57Z","published":"2023-06-09T11:57:57Z","title":"Towards the Exploitation of LLM-based Chatbot for Providing Legal\n  Support to Palestinian Cooperatives","summary":"  With the ever-increasing utilization of natural language processing (NLP), we\nstarted to witness over the past few years a significant transformation in our\ninteraction with legal texts. This technology has advanced the analysis and\nenhanced the understanding of complex legal terminology and contexts. The\ndevelopment of recent large language models (LLMs), particularly ChatGPT, has\nalso introduced a revolutionary contribution to the way that legal texts can be\nprocessed and comprehended. In this paper, we present our work on a\ncooperative-legal question-answering LLM-based chatbot, where we developed a\nset of legal questions about Palestinian cooperatives, associated with their\nregulations and compared the auto-generated answers by the chatbot to their\ncorrespondences that are designed by a legal expert. To evaluate the proposed\nchatbot, we have used 50 queries generated by the legal expert and compared the\nanswers produced by the chart to their relevance judgments. Finding\ndemonstrated that an overall accuracy rate of 82% has been achieved when\nanswering the queries, while exhibiting an F1 score equivalent to 79%.\n","authors":["Rabee Qasem","Banan Tantour","Mohammed Maree"],"pdf_url":"https://arxiv.org/pdf/2306.05827v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05803v1","updated":"2023-06-09T10:40:22Z","published":"2023-06-09T10:40:22Z","title":"Causality between Sentiment and Cryptocurrency Prices","summary":"  This study investigates the relationship between narratives conveyed through\nmicroblogging platforms, namely Twitter, and the value of crypto assets. Our\nstudy provides a unique technique to build narratives about cryptocurrency by\ncombining topic modelling of short texts with sentiment analysis. First, we\nused an unsupervised machine learning algorithm to discover the latent topics\nwithin the massive and noisy textual data from Twitter, and then we revealed\n4-5 cryptocurrency-related narratives, including financial investment,\ntechnological advancement related to crypto, financial and political\nregulations, crypto assets, and media coverage. In a number of situations, we\nnoticed a strong link between our narratives and crypto prices. Our work\nconnects the most recent innovation in economics, Narrative Economics, to a new\narea of study that combines topic modelling and sentiment analysis to relate\nconsumer behaviour to narratives.\n","authors":["Lubdhak Mondal","Udeshya Raj","Abinandhan S","Began Gowsik S","Sarwesh P","Abhijeet Chandra"],"pdf_url":"https://arxiv.org/pdf/2306.05803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05783v1","updated":"2023-06-09T09:52:05Z","published":"2023-06-09T09:52:05Z","title":"Xiezhi: An Ever-Updating Benchmark for Holistic Domain Knowledge\n  Evaluation","summary":"  New Natural Langauge Process~(NLP) benchmarks are urgently needed to align\nwith the rapid development of large language models (LLMs). We present Xiezhi,\nthe most comprehensive evaluation suite designed to assess holistic domain\nknowledge. Xiezhi comprises multiple-choice questions across 516 diverse\ndisciplines ranging from 13 different subjects with 220,000 questions and\naccompanied by Xiezhi-Specialty and Xiezhi-Interdiscipline, both with 15k\nquestions. We conduct evaluation of the 47 cutting-edge LLMs on Xiezhi. Results\nindicate that LLMs exceed average performance of humans in science,\nengineering, agronomy, medicine, and art, but fall short in economics,\njurisprudence, pedagogy, literature, history, and management. We anticipate\nXiezhi will help analyze important strengths and shortcomings of LLMs, and the\nbenchmark is released in https://github.com/MikeGu721/XiezhiBenchmark .\n","authors":["Zhouhong Gu","Xiaoxuan Zhu","Haoning Ye","Lin Zhang","Jianchen Wang","Sihang Jiang","Zhuozhi Xiong","Zihan Li","Qianyu He","Rui Xu","Wenhao Huang","Weiguo Zheng","Hongwei Feng","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2306.05783v1.pdf","comment":"Under review of NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.05779v1","updated":"2023-06-09T09:46:38Z","published":"2023-06-09T09:46:38Z","title":"Transformer-based Time-to-Event Prediction for Chronic Kidney Disease\n  Deterioration","summary":"  Deep-learning techniques, particularly the transformer model, have shown\ngreat potential in enhancing the prediction performance of longitudinal health\nrecords. While previous methods have mainly focused on fixed-time risk\nprediction, time-to-event prediction (also known as survival analysis) is often\nmore appropriate for clinical scenarios. Here, we present a novel deep-learning\narchitecture we named STRAFE, a generalizable survival analysis\ntransformer-based architecture for electronic health records. The performance\nof STRAFE was evaluated using a real-world claim dataset of over 130,000\nindividuals with stage 3 chronic kidney disease (CKD) and was found to\noutperform other time-to-event prediction algorithms in predicting the exact\ntime of deterioration to stage 5. Additionally, STRAFE was found to outperform\nbinary outcome algorithms in predicting fixed-time risk, possibly due to its\nability to train on censored data. We show that STRAFE predictions can improve\nthe positive predictive value of high-risk patients by 3-fold, demonstrating\npossible usage to improve targeting for intervention programs. Finally, we\nsuggest a novel visualization approach to predictions on a per-patient basis.\nIn conclusion, STRAFE is a cutting-edge time-to-event prediction algorithm that\nhas the potential to enhance risk predictions in large claims datasets.\n","authors":["Moshe Zisser","Dvir Aran"],"pdf_url":"https://arxiv.org/pdf/2306.05779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15182v2","updated":"2023-06-09T08:53:14Z","published":"2023-05-24T14:14:08Z","title":"HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text\n  Classification","summary":"  Hierarchical text classification (HTC) is a challenging subtask of\nmulti-label classification as the labels form a complex hierarchical structure.\nExisting dual-encoder methods in HTC achieve weak performance gains with huge\nmemory overheads and their structure encoders heavily rely on domain knowledge.\nUnder such observation, we tend to investigate the feasibility of a\nmemory-friendly model with strong generalization capability that could boost\nthe performance of HTC without prior statistics or label semantics. In this\npaper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance\nthe text representations with only syntactic information of the label\nhierarchy. Specifically, we convert the label hierarchy into an unweighted tree\nstructure, termed coding tree, with the guidance of structural entropy. Then we\ndesign a structure encoder to incorporate hierarchy-aware information in the\ncoding tree into text representations. Besides the text encoder, HiTIN only\ncontains a few multi-layer perceptions and linear transformations, which\ngreatly saves memory. We conduct experiments on three commonly used datasets\nand the results demonstrate that HiTIN could achieve better test performance\nand less memory consumption than state-of-the-art (SOTA) methods.\n","authors":["He Zhu","Chong Zhang","Junjie Huang","Junran Wu","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2305.15182v2.pdf","comment":"Accepted by ACL'23"},{"id":"http://arxiv.org/abs/2008.10522v2","updated":"2023-06-09T08:27:03Z","published":"2020-08-24T15:49:54Z","title":"Machine Semiotics","summary":"  Recognizing a basic difference between the semiotics of humans and machines\npresents a possibility to overcome the shortcomings of current speech assistive\ndevices. For the machine, the meaning of a (human) utterance is defined by its\nown scope of actions. Machines, thus, do not need to understand the\nconventional meaning of an utterance. Rather, they draw conversational\nimplicatures in the sense of (neo-)Gricean pragmatics. For speech assistive\ndevices, the learning of machine-specific meanings of human utterances, i.e.\nthe fossilization of conversational implicatures into conventionalized ones by\ntrial and error through lexicalization appears to be sufficient. Using the\nquite trivial example of a cognitive heating device, we show that - based on\ndynamic semantics - this process can be formalized as the reinforcement\nlearning of utterance-meaning pairs (UMP).\n","authors":["Peter beim Graben","Markus Huber-Liebl","Peter Klimczak","Günther Wirsching"],"pdf_url":"https://arxiv.org/pdf/2008.10522v2.pdf","comment":"48 pages, 4 tables"},{"id":"http://arxiv.org/abs/2306.05741v1","updated":"2023-06-09T08:18:58Z","published":"2023-06-09T08:18:58Z","title":"Challenges and Opportunities for the Design of Smart Speakers","summary":"  Advances in voice technology and voice user interfaces (VUIs) -- such as\nAlexa, Siri, and Google Home -- have opened up the potential for many new types\nof interaction. However, despite the potential of these devices reflected by\nthe growing market and body of VUI research, there is a lingering sense that\nthe technology is still underused. In this paper, we conducted a systematic\nliterature review of 35 papers to identify and synthesize 127 VUI design\nguidelines into five themes. Additionally, we conducted semi-structured\ninterviews with 15 smart speaker users to understand their use and non-use of\nthe technology. From the interviews, we distill four design challenges that\ncontribute the most to non-use. Based on their (non-)use, we identify four\nopportunity spaces for designers to explore such as focusing on information\nsupport while multitasking (cooking, driving, childcare, etc), incorporating\nusers' mental models for smart speakers, and integrating calm design\nprinciples.\n","authors":["Tao Long","Lydia B. Chilton"],"pdf_url":"https://arxiv.org/pdf/2306.05741v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2205.06733v2","updated":"2023-06-09T08:04:40Z","published":"2022-05-13T16:10:13Z","title":"Arithmetic-Based Pretraining -- Improving Numeracy of Pretrained\n  Language Models","summary":"  State-of-the-art pretrained language models tend to perform below their\ncapabilities when applied out-of-the-box on tasks that require understanding\nand working with numbers. Recent work suggests two main reasons for this: (1)\npopular tokenisation algorithms have limited expressiveness for numbers, and\n(2) common pretraining objectives do not target numeracy. Approaches that\naddress these shortcomings usually require architectural changes or pretraining\nfrom scratch. In this paper, we propose a new extended pretraining approach\ncalled Arithmetic-Based Pretraining that jointly addresses both in one extended\npretraining step without requiring architectural changes or pretraining from\nscratch. Arithmetic-Based Pretraining combines contrastive learning to improve\nthe number representation, and a novel extended pretraining objective called\nInferable Number Prediction Task to improve numeracy. Our experiments show the\neffectiveness of Arithmetic-Based Pretraining in three different tasks that\nrequire improved numeracy, i.e., reading comprehension in the DROP dataset,\ninference-on-tables in the InfoTabs dataset, and table-to-text generation in\nthe WikiBio and SciGen datasets.\n","authors":["Dominic Petrak","Nafise Sadat Moosavi","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2205.06733v2.pdf","comment":"Published at StarSEM2023"},{"id":"http://arxiv.org/abs/2306.05715v1","updated":"2023-06-09T07:19:43Z","published":"2023-06-09T07:19:43Z","title":"Exploring the Responses of Large Language Models to Beginner\n  Programmers' Help Requests","summary":"  Background and Context: Over the past year, large language models (LLMs) have\ntaken the world by storm. In computing education, like in other walks of life,\nmany opportunities and threats have emerged as a consequence.\n  Objectives: In this article, we explore such opportunities and threats in a\nspecific area: responding to student programmers' help requests. More\nspecifically, we assess how good LLMs are at identifying issues in problematic\ncode that students request help on.\n  Method: We collected a sample of help requests and code from an online\nprogramming course. We then prompted two different LLMs (OpenAI Codex and\nGPT-3.5) to identify and explain the issues in the students' code and assessed\nthe LLM-generated answers both quantitatively and qualitatively.\n  Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently\nfind at least one actual issue in each student program (GPT-3.5 in 90% of the\ncases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57%\nof the time). False positives are common (40% chance for GPT-3.5). The advice\nthat the LLMs provide on the issues is often sensible. The LLMs perform better\non issues involving program logic rather than on output formatting. Model\nsolutions are frequently provided even when the LLM is prompted not to. LLM\nresponses to prompts in a non-English language are only slightly worse than\nresponses to English prompts.\n  Implications: Our results continue to highlight the utility of LLMs in\nprogramming education. At the same time, the results highlight the\nunreliability of LLMs: LLMs make some of the same mistakes that students do,\nperhaps especially when formatting output as required by automated assessment\nsystems. Our study informs teachers interested in using LLMs as well as future\nefforts to customize LLMs for the needs of programming education.\n","authors":["Arto Hellas","Juho Leinonen","Sami Sarsa","Charles Koutcheme","Lilja Kujanpää","Juha Sorva"],"pdf_url":"https://arxiv.org/pdf/2306.05715v1.pdf","comment":"13 pages, 1 figure. To be published in Proceedings of the 2023 ACM\n  Conference on International Computing Education Research V.1 (ICER '23 V1)"},{"id":"http://arxiv.org/abs/2305.01904v2","updated":"2023-06-09T07:17:14Z","published":"2023-05-03T05:37:30Z","title":"Robust Multi-bit Natural Language Watermarking through Invariant\n  Features","summary":"  Recent years have witnessed a proliferation of valuable original natural\nlanguage contents found in subscription-based media outlets, web novel\nplatforms, and outputs of large language models. However, these contents are\nsusceptible to illegal piracy and potential misuse without proper security\nmeasures. This calls for a secure watermarking system to guarantee copyright\nprotection through leakage tracing or ownership identification. To effectively\ncombat piracy and protect copyrights, a multi-bit watermarking framework should\nbe able to embed adequate bits of information and extract the watermarks in a\nrobust manner despite possible corruption. In this work, we explore ways to\nadvance both payload and robustness by following a well-known proposition from\nimage watermarking and identify features in natural language that are invariant\nto minor corruption. Through a systematic analysis of the possible sources of\nerrors, we further propose a corruption-resistant infill model. Our full method\nimproves upon the previous work on robustness by +16.8% point on average on\nfour datasets, three corruption types, and two corruption ratios. Code\navailable at https://github.com/bangawayoo/nlp-watermarking.\n","authors":["KiYoon Yoo","Wonhyuk Ahn","Jiho Jang","Nojun Kwak"],"pdf_url":"https://arxiv.org/pdf/2305.01904v2.pdf","comment":"ACL 2023 long"},{"id":"http://arxiv.org/abs/2306.05709v1","updated":"2023-06-09T07:04:56Z","published":"2023-06-09T07:04:56Z","title":"Learning Emotional Representations from Imbalanced Speech Data for\n  Speech Emotion Recognition and Emotional Text-to-Speech","summary":"  Effective speech emotional representations play a key role in Speech Emotion\nRecognition (SER) and Emotional Text-To-Speech (TTS) tasks. However, emotional\nspeech samples are more difficult and expensive to acquire compared with\nNeutral style speech, which causes one issue that most related works\nunfortunately neglect: imbalanced datasets. Models might overfit to the\nmajority Neutral class and fail to produce robust and effective emotional\nrepresentations. In this paper, we propose an Emotion Extractor to address this\nissue. We use augmentation approaches to train the model and enable it to\nextract effective and generalizable emotional representations from imbalanced\ndatasets. Our empirical results show that (1) for the SER task, the proposed\nEmotion Extractor surpasses the state-of-the-art baseline on three imbalanced\ndatasets; (2) the produced representations from our Emotion Extractor benefit\nthe TTS model, and enable it to synthesize more expressive speech.\n","authors":["Shijun Wang","Jón Guðnason","Damian Borth"],"pdf_url":"https://arxiv.org/pdf/2306.05709v1.pdf","comment":"Accepted by INTERSPEECH2023"},{"id":"http://arxiv.org/abs/2306.05685v1","updated":"2023-06-09T05:55:52Z","published":"2023-06-09T05:55:52Z","title":"Judging LLM-as-a-judge with MT-Bench and Chatbot Arena","summary":"  Evaluating large language model (LLM) based chat assistants is challenging\ndue to their broad capabilities and the inadequacy of existing benchmarks in\nmeasuring human preferences. To address this, we explore using strong LLMs as\njudges to evaluate these models on more open-ended questions. We examine the\nusage and limitations of LLM-as-a-judge, such as position and verbosity biases\nand limited reasoning ability, and propose solutions to migrate some of them.\nWe then verify the agreement between LLM judges and human preferences by\nintroducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot\nArena, a crowdsourced battle platform. Our results reveal that strong LLM\njudges like GPT-4 can match both controlled and crowdsourced human preferences\nwell, achieving over 80\\% agreement, the same level of agreement between\nhumans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate\nhuman preferences, which are otherwise very expensive to obtain. Additionally,\nwe show our benchmark and traditional benchmarks complement each other by\nevaluating several variants of LLaMA/Vicuna. We will publicly release 80\nMT-bench questions, 3K expert votes, and 30K conversations with human\npreferences from Chatbot Arena.\n","authors":["Lianmin Zheng","Wei-Lin Chiang","Ying Sheng","Siyuan Zhuang","Zhanghao Wu","Yonghao Zhuang","Zi Lin","Zhuohan Li","Dacheng Li","Eric. P Xing","Hao Zhang","Joseph E. Gonzalez","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2306.05685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.02693v2","updated":"2023-06-09T05:16:21Z","published":"2023-06-05T08:35:31Z","title":"CELDA: Leveraging Black-box Language Model as Enhanced Classifier\n  without Labels","summary":"  Utilizing language models (LMs) without internal access is becoming an\nattractive paradigm in the field of NLP as many cutting-edge LMs are released\nthrough APIs and boast a massive scale. The de-facto method in this type of\nblack-box scenario is known as prompting, which has shown progressive\nperformance enhancements in situations where data labels are scarce or\nunavailable. Despite their efficacy, they still fall short in comparison to\nfully supervised counterparts and are generally brittle to slight\nmodifications. In this paper, we propose Clustering-enhanced Linear\nDiscriminative Analysis, a novel approach that improves the text classification\naccuracy with a very weak-supervision signal (i.e., name of the labels). Our\nframework draws a precise decision boundary without accessing weights or\ngradients of the LM model or data labels. The core ideas of CELDA are twofold:\n(1) extracting a refined pseudo-labeled dataset from an unlabeled dataset, and\n(2) training a lightweight and robust model on the top of LM, which learns an\naccurate decision boundary from an extracted noisy dataset. Throughout in-depth\ninvestigations on various datasets, we demonstrated that CELDA reaches new\nstate-of-the-art in weakly-supervised text classification and narrows the gap\nwith a fully-supervised model. Additionally, our proposed methodology can be\napplied universally to any LM and has the potential to scale to larger models,\nmaking it a more viable option for utilizing large LMs.\n","authors":["Hyunsoo Cho","Youna Kim","Sang-goo Lee"],"pdf_url":"https://arxiv.org/pdf/2306.02693v2.pdf","comment":"ACL 2023"},{"id":"http://arxiv.org/abs/2301.11660v3","updated":"2023-06-09T05:06:58Z","published":"2023-01-27T11:27:40Z","title":"Probing Out-of-Distribution Robustness of Language Models with\n  Parameter-Efficient Transfer Learning","summary":"  As the size of the pre-trained language model (PLM) continues to increase,\nnumerous parameter-efficient transfer learning methods have been proposed\nrecently to compensate for the tremendous cost of fine-tuning. Despite the\nimpressive results achieved by large pre-trained language models (PLMs) and\nvarious parameter-efficient transfer learning (PETL) methods on sundry\nbenchmarks, it remains unclear if they can handle inputs that have been\ndistributionally shifted effectively. In this study, we systematically explore\nhow the ability to detect out-of-distribution (OOD) changes as the size of the\nPLM grows or the transfer methods are altered. Specifically, we evaluated\nvarious PETL techniques, including fine-tuning, Adapter, LoRA, and\nprefix-tuning, on three different intention classification tasks, each\nutilizing various language models with different scales.\n","authors":["Hyunsoo Cho","Choonghyun Park","Junyeop Kim","Hyuhng Joon Kim","Kang Min Yoo","Sang-goo Lee"],"pdf_url":"https://arxiv.org/pdf/2301.11660v3.pdf","comment":"*SEM 2023"},{"id":"http://arxiv.org/abs/2306.05672v1","updated":"2023-06-09T05:04:13Z","published":"2023-06-09T05:04:13Z","title":"I run as fast as a rabbit, can you? A Multilingual Simile Dialogue\n  Dataset","summary":"  A simile is a figure of speech that compares two different things (called the\ntenor and the vehicle) via shared properties. The tenor and the vehicle are\nusually connected with comparator words such as \"like\" or \"as\". The simile\nphenomena are unique and complex in a real-life dialogue scene where the tenor\nand the vehicle can be verbal phrases or sentences, mentioned by different\nspeakers, exist in different sentences, or occur in reversed order. However,\nthe current simile research usually focuses on similes in a triplet tuple\n(tenor, property, vehicle) or a single sentence where the tenor and vehicle are\nusually entities or noun phrases, which could not reflect complex simile\nphenomena in real scenarios. In this paper, we propose a novel and high-quality\nmultilingual simile dialogue (MSD) dataset to facilitate the study of complex\nsimile phenomena. The MSD is the largest manually annotated simile data\n($\\sim$20K) and it contains both English and Chinese data. Meanwhile, the MSD\ndata can also be used on dialogue tasks to test the ability of dialogue systems\nwhen using similes. We design 3 simile tasks (recognition, interpretation, and\ngeneration) and 2 dialogue tasks (retrieval and generation) with MSD. For each\ntask, we provide experimental results from strong pre-trained or\nstate-of-the-art models. The experiments demonstrate the challenge of MSD and\nwe have released the data/code on GitHub.\n","authors":["Longxuan Ma","Weinan Zhang","Shuhan Zhou","Churui Sun","Changxin Ke","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2306.05672v1.pdf","comment":"13 Pages, 1 Figure, 12 Tables, ACL 2023 findings"},{"id":"http://arxiv.org/abs/2305.18170v2","updated":"2023-06-09T05:00:30Z","published":"2023-05-29T16:01:40Z","title":"Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning","summary":"  Chain-of-thought (CoT) prompting with large language models has proven\neffective in numerous natural language processing tasks, but designing prompts\nthat generalize well to diverse problem types can be challenging, especially in\nthe context of math word problem (MWP) solving. Additionally, it is common to\nhave a large amount of training data that have a better diversity coverage but\nCoT annotations are not available, which limits the use of supervised learning\ntechniques. To address these issues, we investigate two approaches to leverage\nthe training data in a few-shot prompting scenario: dynamic program prompting\nand program distillation. Our approach is largely inspired by Gao et al.,\n(2022), where they proposed to replace the CoT with the programs as the\nintermediate reasoning step. Such a prompting strategy allows us to accurately\nverify the answer correctness through program execution in MWP solving. Our\ndynamic program prompting involves annotating the training data by sampling\ncorrect programs from a large language model, while program distillation\ninvolves adapting a smaller model to the program-annotated training data. Our\nexperiments on three standard MWP datasets demonstrate the effectiveness of\nthese approaches, yielding significant improvements over previous baselines for\nprompting and fine-tuning. Our results suggest that leveraging a large amount\nof training data can improve the generalization ability of prompts and boost\nthe performance of fine-tuned small models in MWP solving.\n","authors":["Zhanming Jie","Wei Lu"],"pdf_url":"https://arxiv.org/pdf/2305.18170v2.pdf","comment":"ACL 2023 Findings"},{"id":"http://arxiv.org/abs/2306.05659v1","updated":"2023-06-09T03:53:42Z","published":"2023-06-09T03:53:42Z","title":"COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in\n  Language Models","summary":"  Prompt-based learning has been proved to be an effective way in pre-trained\nlanguage models (PLMs), especially in low-resource scenarios like few-shot\nsettings. However, the trustworthiness of PLMs is of paramount significance and\npotential vulnerabilities have been shown in prompt-based templates that could\nmislead the predictions of language models, causing serious security concerns.\nIn this paper, we will shed light on some vulnerabilities of PLMs, by proposing\na prompt-based adversarial attack on manual templates in black box scenarios.\nFirst of all, we design character-level and word-level heuristic approaches to\nbreak manual templates separately. Then we present a greedy algorithm for the\nattack based on the above heuristic destructive approaches. Finally, we\nevaluate our approach with the classification tasks on three variants of BERT\nseries models and eight datasets. And comprehensive experimental results\njustify the effectiveness of our approach in terms of attack success rate and\nattack speed. Further experimental studies indicate that our proposed method\nalso displays good capabilities in scenarios with varying shot counts, template\nlengths and query counts, exhibiting good generalizability.\n","authors":["Zihao Tan","Qingliang Chen","Wenbin Zhu","Yongjian Huang"],"pdf_url":"https://arxiv.org/pdf/2306.05659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.11579v2","updated":"2023-06-09T03:48:42Z","published":"2023-05-19T10:37:56Z","title":"Speech-Text Dialog Pre-training for Spoken Dialog Understanding with\n  Explicit Cross-Modal Alignment","summary":"  Recently, speech-text pre-training methods have shown remarkable success in\nmany speech and natural language processing tasks. However, most previous\npre-trained models are usually tailored for one or two specific tasks, but fail\nto conquer a wide range of speech-text tasks. In addition, existing speech-text\npre-training methods fail to explore the contextual information within a\ndialogue to enrich utterance representations. In this paper, we propose\nSpeech-text dialog Pre-training for spoken dialog understanding with ExpliCiT\ncRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog\npre-training model. Concretely, to consider the temporality of speech modality,\nwe design a novel temporal position prediction task to capture the speech-text\nalignment. This pre-training task aims to predict the start and end time of\neach textual word in the corresponding speech waveform. In addition, to learn\nthe characteristics of spoken dialogs, we generalize a response selection task\nfrom textual dialog pre-training to speech-text dialog pre-training scenarios.\nExperimental results on four different downstream speech-text tasks demonstrate\nthe superiority of SPECTRA in learning speech-text alignment and multi-turn\ndialog context.\n","authors":["Tianshu Yu","Haoyu Gao","Ting-En Lin","Min Yang","Yuchuan Wu","Wentao Ma","Chao Wang","Fei Huang","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2305.11579v2.pdf","comment":"Accepted at ACL 2023 main conference"},{"id":"http://arxiv.org/abs/2306.05652v1","updated":"2023-06-09T03:37:49Z","published":"2023-06-09T03:37:49Z","title":"Privacy Aware Question-Answering System for Online Mental Health Risk\n  Assessment","summary":"  Social media platforms have enabled individuals suffering from mental\nillnesses to share their lived experiences and find the online support\nnecessary to cope. However, many users fail to receive genuine clinical\nsupport, thus exacerbating their symptoms. Screening users based on what they\npost online can aid providers in administering targeted healthcare and minimize\nfalse positives. Pre-trained Language Models (LMs) can assess users' social\nmedia data and classify them in terms of their mental health risk. We propose a\nQuestion-Answering (QA) approach to assess mental health risk using the\nUnified-QA model on two large mental health datasets. To protect user data, we\nextend Unified-QA by anonymizing the model training process using differential\nprivacy. Our results demonstrate the effectiveness of modeling risk assessment\nas a QA task, specifically for mental health use cases. Furthermore, the\nmodel's performance decreases by less than 1% with the inclusion of\ndifferential privacy. The proposed system's performance is indicative of a\npromising research direction that will lead to the development of privacy-aware\ndiagnostic systems.\n","authors":["Prateek Chhikara","Ujjwal Pasupulety","John Marshall","Dhiraj Chaurasia","Shweta Kumari"],"pdf_url":"https://arxiv.org/pdf/2306.05652v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2306.05644v1","updated":"2023-06-09T03:11:42Z","published":"2023-06-09T03:11:42Z","title":"WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised\n  Span Prediction","summary":"  Most existing word alignment methods rely on manual alignment datasets or\nparallel corpora, which limits their usefulness. Here, to mitigate the\ndependence on manual data, we broaden the source of supervision by relaxing the\nrequirement for correct, fully-aligned, and parallel sentences. Specifically,\nwe make noisy, partially aligned, and non-parallel paragraphs. We then use such\na large-scale weakly-supervised dataset for word alignment pre-training via\nspan prediction. Extensive experiments with various settings empirically\ndemonstrate that our approach, which is named WSPAlign, is an effective and\nscalable way to pre-train word aligners without manual data. When fine-tuned on\nstandard benchmarks, WSPAlign has set a new state-of-the-art by improving upon\nthe best-supervised baseline by 3.3~6.1 points in F1 and 1.5~6.1 points in AER.\nFurthermore, WSPAlign also achieves competitive performance compared with the\ncorresponding baselines in few-shot, zero-shot and cross-lingual tests, which\ndemonstrates that WSPAlign is potentially more practical for low-resource\nlanguages than existing methods.\n","authors":["Qiyu Wu","Masaaki Nagata","Yoshimasa Tsuruoka"],"pdf_url":"https://arxiv.org/pdf/2306.05644v1.pdf","comment":"To appear at ACL 2023"},{"id":"http://arxiv.org/abs/2306.05642v1","updated":"2023-06-09T03:02:36Z","published":"2023-06-09T03:02:36Z","title":"Customizing General-Purpose Foundation Models for Medical Report\n  Generation","summary":"  Medical caption prediction which can be regarded as a task of medical report\ngeneration (MRG), requires the automatic generation of coherent and accurate\ncaptions for the given medical images. However, the scarcity of labelled\nmedical image-report pairs presents great challenges in the development of deep\nand large-scale neural networks capable of harnessing the potential artificial\ngeneral intelligence power like large language models (LLMs). In this work, we\npropose customizing off-the-shelf general-purpose large-scale pre-trained\nmodels, i.e., foundation models (FMs), in computer vision and natural language\nprocessing with a specific focus on medical report generation. Specifically,\nfollowing BLIP-2, a state-of-the-art vision-language pre-training approach, we\nintroduce our encoder-decoder-based MRG model. This model utilizes a\nlightweight query Transformer to connect two FMs: the giant vision Transformer\nEVA-ViT-g and a bilingual LLM trained to align with human intentions (referred\nto as ChatGLM-6B). Furthermore, we conduct ablative experiments on the\ntrainable components of the model to identify the crucial factors for effective\ntransfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn\nmedical image representations, followed by parameter-efficient training of\nChatGLM-6B to capture the writing styles of medical reports, is essential for\nachieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and\nthe 2nd, respectively, out of 13 participating teams, based on the BERTScore\nand ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction\nTask competition.\n","authors":["Bang Yang","Asif Raza","Yuexian Zou","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05642v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.05176v2","updated":"2023-06-09T02:56:20Z","published":"2023-06-08T13:17:06Z","title":"RRWKV: Capturing Long-range Dependencies in RWKV","summary":"  Owing to the impressive dot-product attention, the Transformers have been the\ndominant architectures in various natural language processing (NLP) tasks.\nRecently, the Receptance Weighted Key Value (RWKV) architecture follows a\nnon-transformer architecture to eliminate the drawbacks of dot-product\nattention, where memory and computational complexity exhibits quadratic scaling\nwith sequence length. Although RWKV has exploited a linearly tensor-product\nattention mechanism and achieved parallelized computations by deploying the\ntime-sequential mode, it fails to capture long-range dependencies because of\nits limitation on looking back at previous information, compared with full\ninformation obtained by direct interactions in the standard transformer.\nTherefore, the paper devises the Retrospected Receptance Weighted Key Value\n(RRWKV) architecture via incorporating the retrospecting ability into the RWKV\nto effectively absorb information, which maintains memory and computational\nefficiency as well.\n","authors":["Leilei Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05176v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04835v3","updated":"2023-06-09T02:25:29Z","published":"2023-05-08T16:32:18Z","title":"How Do In-Context Examples Affect Compositional Generalization?","summary":"  Compositional generalization--understanding unseen combinations of seen\nprimitives--is an essential reasoning capability in human intelligence. The AI\ncommunity mainly studies this capability by fine-tuning neural networks on lots\nof training samples, while it is still unclear whether and how in-context\nlearning--the prevailing few-shot paradigm based on large language\nmodels--exhibits compositional generalization. In this paper, we present CoFe,\na test suite to investigate in-context compositional generalization. We find\nthat the compositional generalization performance can be easily affected by the\nselection of in-context examples, thus raising the research question what the\nkey factors are to make good in-context examples for compositional\ngeneralization. We study three potential factors: similarity, diversity and\ncomplexity. Our systematic experiments indicate that in-context examples should\nbe structurally similar to the test case, diverse from each other, and\nindividually simple. Furthermore, two strong limitations are observed:\nin-context compositional generalization on fictional words is much weaker than\nthat on commonly used ones; it is still critical that the in-context examples\nshould cover required linguistic structures, even though the backbone model has\nbeen pre-trained on large corpus. We hope our analysis would facilitate the\nunderstanding and utilization of in-context learning paradigm.\n","authors":["Shengnan An","Zeqi Lin","Qiang Fu","Bei Chen","Nanning Zheng","Jian-Guang Lou","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.04835v3.pdf","comment":"ACL 2023 main conference, long paper"},{"id":"http://arxiv.org/abs/2306.01985v2","updated":"2023-06-09T01:49:06Z","published":"2023-06-03T02:47:24Z","title":"COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive\n  Statements","summary":"  Warning: This paper contains content that may be offensive or upsetting.\nUnderstanding the harms and offensiveness of statements requires reasoning\nabout the social and situational context in which statements are made. For\nexample, the utterance \"your English is very good\" may implicitly signal an\ninsult when uttered by a white man to a non-white colleague, but uttered by an\nESL teacher to their student would be interpreted as a genuine compliment. Such\ncontextual factors have been largely ignored by previous approaches to toxic\nlanguage detection. We introduce COBRA frames, the first context-aware\nformalism for explaining the intents, reactions, and harms of offensive or\nbiased statements grounded in their social and situational context. We create\nCOBRACORPUS, a dataset of 33k potentially offensive statements paired with\nmachine-generated contexts and free-text explanations of offensiveness, implied\nbiases, speaker intents, and listener reactions. To study the contextual\ndynamics of offensiveness, we train models to generate COBRA explanations, with\nand without access to the context. We find that explanations by\ncontext-agnostic models are significantly worse than by context-aware ones,\nespecially in situations where the context inverts the statement's\noffensiveness (29% accuracy drop). Our work highlights the importance and\nfeasibility of contextualized NLP by modeling social factors.\n","authors":["Xuhui Zhou","Hao Zhu","Akhila Yerukola","Thomas Davidson","Jena D. Hwang","Swabha Swayamdipta","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2306.01985v2.pdf","comment":"Accepted to Findings of ACL 2023"},{"id":"http://arxiv.org/abs/2306.05617v1","updated":"2023-06-09T01:43:41Z","published":"2023-06-09T01:43:41Z","title":"Low-rank Adaptation Method for Wav2vec2-based Fake Audio Detection","summary":"  Self-supervised speech models are a rapidly developing research topic in fake\naudio detection. Many pre-trained models can serve as feature extractors,\nlearning richer and higher-level speech features. However,when fine-tuning\npre-trained models, there is often a challenge of excessively long training\ntimes and high memory consumption, and complete fine-tuning is also very\nexpensive. To alleviate this problem, we apply low-rank adaptation(LoRA) to the\nwav2vec2 model, freezing the pre-trained model weights and injecting a\ntrainable rank-decomposition matrix into each layer of the transformer\narchitecture, greatly reducing the number of trainable parameters for\ndownstream tasks. Compared with fine-tuning with Adam on the wav2vec2 model\ncontaining 317M training parameters, LoRA achieved similar performance by\nreducing the number of trainable parameters by 198 times.\n","authors":["Chenglong Wang","Jiangyan Yi","Xiaohui Zhang","Jianhua Tao","Le Xu","Ruibo Fu"],"pdf_url":"https://arxiv.org/pdf/2306.05617v1.pdf","comment":"6pages"},{"id":"http://arxiv.org/abs/2305.11255v4","updated":"2023-06-09T01:27:58Z","published":"2023-05-18T18:38:32Z","title":"Reasoning Implicit Sentiment with Chain-of-Thought Prompting","summary":"  While sentiment analysis systems try to determine the sentiment polarities of\ngiven targets based on the key opinion expressions in input texts, in implicit\nsentiment analysis (ISA) the opinion cues come in an implicit and obscure\nmanner. Thus detecting implicit sentiment requires the common-sense and\nmulti-hop reasoning ability to infer the latent intent of opinion. Inspired by\nthe recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop\nReasoning (THOR) CoT framework to mimic the human-like reasoning process for\nISA. We design a three-step prompting principle for THOR to step-by-step induce\nthe implicit aspect, opinion, and finally the sentiment polarity. Our\nTHOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on\nsupervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50%\nF1 on zero-shot setting. Our code is open at\nhttps://github.com/scofield7419/THOR-ISA.\n","authors":["Hao Fei","Bobo Li","Qian Liu","Lidong Bing","Fei Li","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2305.11255v4.pdf","comment":"ACL2023 Short Paper"},{"id":"http://arxiv.org/abs/2306.03984v2","updated":"2023-06-09T01:17:39Z","published":"2023-06-06T19:43:29Z","title":"Toward More Accurate and Generalizable Evaluation Metrics for\n  Task-Oriented Dialogs","summary":"  Measurement of interaction quality is a critical task for the improvement of\nspoken dialog systems. Existing approaches to dialog quality estimation either\nfocus on evaluating the quality of individual turns, or collect dialog-level\nquality measurements from end users immediately following an interaction. In\ncontrast to these approaches, we introduce a new dialog-level annotation\nworkflow called Dialog Quality Annotation (DQA). DQA expert annotators evaluate\nthe quality of dialogs as a whole, and also label dialogs for attributes such\nas goal completion and user sentiment. In this contribution, we show that: (i)\nwhile dialog quality cannot be completely decomposed into dialog-level\nattributes, there is a strong relationship between some objective dialog\nattributes and judgments of dialog quality; (ii) for the task of dialog-level\nquality estimation, a supervised model trained on dialog-level annotations\noutperforms methods based purely on aggregating turn-level features; and (iii)\nthe proposed evaluation model shows better domain generalization ability\ncompared to the baselines. On the basis of these results, we argue that having\nhigh-quality human-annotated data is an important component of evaluating\ninteraction quality for large industrial-scale voice assistant platforms.\n","authors":["Abishek Komma","Nagesh Panyam Chandrasekarasastry","Timothy Leffel","Anuj Goyal","Angeliki Metallinou","Spyros Matsoukas","Aram Galstyan"],"pdf_url":"https://arxiv.org/pdf/2306.03984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05609v1","updated":"2023-06-09T00:54:21Z","published":"2023-06-09T00:54:21Z","title":"Word sense extension","summary":"  Humans often make creative use of words to express novel senses. A\nlong-standing effort in natural language processing has been focusing on word\nsense disambiguation (WSD), but little has been explored about how the sense\ninventory of a word may be extended toward novel meanings. We present a\nparadigm of word sense extension (WSE) that enables words to spawn new senses\ntoward novel context. We develop a framework that simulates novel word sense\nextension by first partitioning a polysemous word type into two pseudo-tokens\nthat mark its different senses, and then inferring whether the meaning of a\npseudo-token can be extended to convey the sense denoted by the token\npartitioned from the same word type. Our framework combines cognitive models of\nchaining with a learning scheme that transforms a language model embedding\nspace to support various types of word sense extension. We evaluate our\nframework against several competitive baselines and show that it is superior in\npredicting plausible novel senses for over 7,500 English words. Furthermore, we\nshow that our WSE framework improves performance over a range of\ntransformer-based WSD models in predicting rare word senses with few or zero\nmentions in the training data.\n","authors":["Lei Yu","Yang Xu"],"pdf_url":"https://arxiv.org/pdf/2306.05609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05605v1","updated":"2023-06-09T00:33:30Z","published":"2023-06-09T00:33:30Z","title":"A Unified Generative Approach to Product Attribute-Value Identification","summary":"  Product attribute-value identification (PAVI) has been studied to link\nproducts on e-commerce sites with their attribute values (e.g., <Material,\nCotton>) using product text as clues. Technical demands from real-world\ne-commerce platforms require PAVI methods to handle unseen values,\nmulti-attribute values, and canonicalized values, which are only partly\naddressed in existing extraction- and classification-based approaches.\nMotivated by this, we explore a generative approach to the PAVI task. We\nfinetune a pre-trained generative model, T5, to decode a set of attribute-value\npairs as a target sequence from the given product text. Since the attribute\nvalue pairs are unordered set elements, how to linearize them will matter; we,\nthus, explore methods of composing an attribute-value pair and ordering the\npairs for the task. Experimental results confirm that our generation-based\napproach outperforms the existing extraction and classification-based methods\non large-scale real-world datasets meant for those methods.\n","authors":["Keiji Shinzato","Naoki Yoshinaga","Yandi Xia","Wei-Te Chen"],"pdf_url":"https://arxiv.org/pdf/2306.05605v1.pdf","comment":"Accepted to the Findings of ACL 2023"}],"Optimization and Control":[{"id":"http://arxiv.org/abs/2306.06101v1","updated":"2023-06-09T17:59:35Z","published":"2023-06-09T17:59:35Z","title":"Prodigy: An Expeditiously Adaptive Parameter-Free Learner","summary":"  We consider the problem of estimating the learning rate in adaptive methods,\nsuch as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to\nprovably estimate the distance to the solution $D$, which is needed to set the\nlearning rate optimally. Our techniques are modifications of the D-Adaptation\nmethod for learning-rate-free learning. Our methods improve upon the\nconvergence rate of D-Adaptation by a factor of $O(\\sqrt{\\log(D/d_0)})$, where\n$d_0$ is the initial estimate of $D$. We test our methods on 12 common\nlogistic-regression benchmark datasets, VGG11 and ResNet-50 training on\nCIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on\nCriteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT\ntransformer training on BookWiki. Our experimental results show that our\napproaches consistently outperform D-Adaptation and reach test accuracy values\nclose to that of hand-tuned Adam.\n","authors":["Konstantin Mishchenko","Aaron Defazio"],"pdf_url":"https://arxiv.org/pdf/2306.06101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06098v1","updated":"2023-06-09T17:58:47Z","published":"2023-06-09T17:58:47Z","title":"Error Feedback Can Accurately Compress Preconditioners","summary":"  Leveraging second-order information at the scale of deep networks is one of\nthe main lines of approach for improving the performance of current optimizers\nfor deep learning. Yet, existing approaches for accurate full-matrix\npreconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate\nCurvature (M-FAC) suffer from massive storage costs when applied even to\nmedium-scale models, as they must store a sliding window of gradients, whose\nmemory requirements are multiplicative in the model dimension. In this paper,\nwe address this issue via an efficient and simple-to-implement error-feedback\ntechnique that can be applied to compress preconditioners by up to two orders\nof magnitude in practice, without loss of convergence. Specifically, our\napproach compresses the gradient information via sparsification or low-rank\ncompression \\emph{before} it is fed into the preconditioner, feeding the\ncompression error back into future iterations. Extensive experiments on deep\nneural networks for vision show that this approach can compress full-matrix\npreconditioners by up to two orders of magnitude without impact on accuracy,\neffectively removing the memory overhead of full-matrix preconditioning for\nimplementations of full-matrix Adagrad (GGT) and natural gradient (M-FAC). Our\ncode is available at https://github.com/IST-DASLab/EFCP.\n","authors":["Ionut-Vlad Modoranu","Aleksei Kalinov","Eldar Kurtic","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2306.06098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06050v1","updated":"2023-06-09T17:20:11Z","published":"2023-06-09T17:20:11Z","title":"Branching via Cutting Plane Selection: Improving Hybrid Branching","summary":"  Cutting planes and branching are two of the most important algorithms for\nsolving mixed-integer linear programs. For both algorithms, disjunctions play\nan important role, being used both as branching candidates and as the\nfoundation for some cutting planes. We relate branching decisions and cutting\nplanes to each other through the underlying disjunctions that they are based\non, with a focus on Gomory mixed-integer cuts and their corresponding split\ndisjunctions. We show that selecting branching decisions based on quality\nmeasures of Gomory mixed-integer cuts leads to relatively small\nbranch-and-bound trees, and that the result improves when using cuts that more\naccurately represent the branching decisions. Finally, we show how the history\nof previously computed Gomory mixed-integer cuts can be used to improve the\nperformance of the state-of-the-art hybrid branching rule of SCIP. Our results\nshow a 4\\% decrease in solve time, and an 8\\% decrease in number of nodes over\naffected instances of MIPLIB 2017.\n","authors":["Mark Turner","Timo Berthold","Mathieu Besançon","Thorsten Koch"],"pdf_url":"https://arxiv.org/pdf/2306.06050v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.10650v2","updated":"2023-06-09T17:12:20Z","published":"2023-05-18T02:09:15Z","title":"Iteration Complexity and Finite-Time Efficiency of Adaptive Sampling\n  Trust-Region Methods for Stochastic Derivative-Free Optimization","summary":"  Adaptive sampling with interpolation-based trust regions or ASTRO-DF is a\nsuccessful algorithm for stochastic derivative-free optimization with an\neasy-to-understand-and-implement concept that guarantees almost sure\nconvergence to a first-order critical point. To reduce its dependence on the\nproblem dimension, we present local models with diagonal Hessians constructed\non interpolation points based on a coordinate basis. We also leverage the\ninterpolation points in a direct search manner whenever possible to boost\nASTRO-DF's performance in a finite time. We prove that the algorithm has a\ncanonical iteration complexity of $\\mathcal{O}(\\epsilon^{-2})$ almost surely,\nwhich is the first guarantee of its kind without placing assumptions on the\nquality of function estimates or model quality or independence between them.\nNumerical experimentation reveals the computational advantage of ASTRO-DF with\ncoordinate direct search due to saving and better steps in the early iterations\nof the search.\n","authors":["Yunsoo Ha","Sara Shashaani"],"pdf_url":"https://arxiv.org/pdf/2305.10650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.04086v2","updated":"2023-06-09T17:11:50Z","published":"2023-05-06T16:11:49Z","title":"Efficient Learning for Selecting Top-m Context-Dependent Designs","summary":"  We consider a simulation optimization problem for a context-dependent\ndecision-making, which aims to determine the top-m designs for all contexts.\nUnder a Bayesian framework, we formulate the optimal dynamic sampling decision\nas a stochastic dynamic programming problem, and develop a sequential sampling\npolicy to efficiently learn the performance of each design under each context.\nThe asymptotically optimal sampling ratios are derived to attain the optimal\nlarge deviations rate of the worst-case of probability of false selection. The\nproposed sampling policy is proved to be consistent and its asymptotic sampling\nratios are asymptotically optimal. Numerical experiments demonstrate that the\nproposed method improves the efficiency for selection of top-m\ncontext-dependent designs.\n","authors":["Gongbo Zhang","Sihua Chen","Kuihua Huang","Yijie Peng"],"pdf_url":"https://arxiv.org/pdf/2305.04086v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06619v3","updated":"2023-06-09T16:53:42Z","published":"2023-01-16T21:56:38Z","title":"Distributionally Robust Learning with Weakly Convex Losses: Convergence\n  Rates and Finite-Sample Guarantees","summary":"  We consider a distributionally robust stochastic optimization problem and\nformulate it as a stochastic two-level composition optimization problem with\nthe use of the mean--semideviation risk measure. In this setting, we consider a\nsingle time-scale algorithm, involving two versions of the inner function value\ntracking: linearized tracking of a continuously differentiable loss function,\nand SPIDER tracking of a weakly convex loss function. We adopt the norm of the\ngradient of the Moreau envelope as our measure of stationarity and show that\nthe sample complexity of $\\mathcal{O}(\\varepsilon^{-3})$ is possible in both\ncases, with only the constant larger in the second case. Finally, we\ndemonstrate the performance of our algorithm with a robust learning example and\na weakly convex, non-smooth regression example.\n","authors":["Landi Zhu","Mert Gürbüzbalaban","Andrzej Ruszczyński"],"pdf_url":"https://arxiv.org/pdf/2301.06619v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06016v1","updated":"2023-06-09T16:33:41Z","published":"2023-06-09T16:33:41Z","title":"Lifting partial smoothing to solve HJB equations and stochastic control\n  problems","summary":"  We study a family of stochastic control problems arising in typical\napplications (such as boundary control and control of delay equations with\ndelay in the control) with the ultimate aim of finding solutions of the\nassociated HJB equations, regular enough to find optimal feedback controls.\nThese problems are difficult to treat since the underlying transition\nsemigroups do not possess good smoothing properties nor the so-called\n\"structure condition\" which typically allows to apply the backward equations\napproach. In the papers [14], [15], and, more recently, [16] we studied such\nproblems developing new partial smoothing techniques which allowed us to obtain\nthe required regularity in the case when the cost functional is independent of\nthe state variable. This is a somehow strong restriction which is not verified\nin most applications. In this paper (which can be considered a continuation of\nthe research of the above papers) we develop a new approach to overcome this\nrestriction. We extend the partial smoothing result to a wider class of\nfunctions which depend on the whole trajectory of the underlying semigroup and\nwe use this as a key tool to improve our regularity result for the HJB\nequation. The fact that such class depends on trajectories requires a\nnontrivial technical work as we have to lift the original transition semigroup\nto a space of trajectories, defining a new \"high-level\" environment where our\nproblems can be solved.\n","authors":["Fausto Gozzi","Federica Masiero"],"pdf_url":"https://arxiv.org/pdf/2306.06016v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2107.04305"},{"id":"http://arxiv.org/abs/2208.11364v2","updated":"2023-06-09T15:57:46Z","published":"2022-08-24T08:23:12Z","title":"A Converse Robust-Safety Theorem for Differential Inclusions","summary":"  This paper establishes the equivalence between robust safety and the\nexistence of a barrier function certificate for differential inclusions. More\nprecisely, for a robustly-safe system, a barrier function is constructed as the\ntime-to-impact function with respect to a specifically-constructed reachable\nset. Using techniques from set-valued and nonsmooth analysis, we show that such\na function, although being possibly discontinuous, certifies robust safety by\nverifying a condition involving the system's solutions. Furthermore, we refine\nthis construction, using integral techniques from the literature, to provide a\nsmooth barrier certificate that certifies robust safety by verifying a\ncondition involving only the barrier function and the system's right-hand side.\nIn comparison with existing converse robust-safety theorems, our result is more\ngeneral as it allows the safety region to be unbounded, the right-hand side to\nbe a general continuous set-valued map, and the solutions to be non-unique.\n","authors":["Mohamed Maghenem","Masoumeh Ghanbarpour"],"pdf_url":"https://arxiv.org/pdf/2208.11364v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.09884v3","updated":"2023-06-09T15:47:55Z","published":"2021-05-20T16:30:11Z","title":"A Stochastic Operator Framework for Optimization and Learning with\n  Sub-Weibull Errors","summary":"  This paper proposes a framework to study the convergence of stochastic\noptimization and learning algorithms. The framework is modeled over the\ndifferent challenges that these algorithms pose, such as (i) the presence of\nrandom additive errors (e.g. due to stochastic gradients), and (ii) random\ncoordinate updates (e.g. due to asynchrony in distributed set-ups). The paper\ncovers both convex and strongly convex problems, and it also analyzes online\nscenarios, involving changes in the data and costs. The paper relies on\ninterpreting stochastic algorithms as the iterated application of stochastic\noperators, thus allowing us to use the powerful tools of operator theory. In\nparticular, we consider operators characterized by additive errors with\nsub-Weibull distribution (which parameterize a broad class of errors by their\ntail probability), and random updates. In this framework we derive convergence\nresults in mean and in high probability, by providing bounds to the distance of\nthe current iteration from a solution of the optimization or learning problem.\nThe contributions are discussed in light of federated learning applications.\n","authors":["Nicola Bastianello","Liam Madden","Ruggero Carli","Emiliano Dall'Anese"],"pdf_url":"https://arxiv.org/pdf/2105.09884v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05937v1","updated":"2023-06-09T14:56:06Z","published":"2023-06-09T14:56:06Z","title":"Robust Data-driven Prescriptiveness Optimization","summary":"  The abundance of data has led to the emergence of a variety of optimization\ntechniques that attempt to leverage available side information to provide more\nanticipative decisions. The wide range of methods and contexts of application\nhave motivated the design of a universal unitless measure of performance known\nas the coefficient of prescriptiveness. This coefficient was designed to\nquantify both the quality of contextual decisions compared to a reference one\nand the prescriptive power of side information. To identify policies that\nmaximize the former in a data-driven context, this paper introduces a\ndistributionally robust contextual optimization model where the coefficient of\nprescriptiveness substitutes for the classical empirical risk minimization\nobjective. We present a bisection algorithm to solve this model, which relies\non solving a series of linear programs when the distributional ambiguity set\nhas an appropriate nested form and polyhedral structure. Studying a contextual\nshortest path problem, we evaluate the robustness of the resulting policies\nagainst alternative methods when the out-of-sample dataset is subject to\nvarying amounts of distribution shift.\n","authors":["Mehran Poursoltani","Erick Delage","Angelos Georghiou"],"pdf_url":"https://arxiv.org/pdf/2306.05937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00163v3","updated":"2023-06-09T14:26:29Z","published":"2023-02-01T00:52:55Z","title":"FLSTRA: Federated Learning in Stratosphere","summary":"  We propose a federated learning (FL) in stratosphere (FLSTRA) system, where a\nhigh altitude platform station (HAPS) facilitates a large number of terrestrial\nclients to collaboratively learn a global model without sharing the training\ndata. FLSTRA overcomes the challenges faced by FL in terrestrial networks, such\nas slow convergence and high communication delay due to limited client\nparticipation and multi-hop communications. HAPS leverages its altitude and\nsize to allow the participation of more clients with line-of-sight (LOS) links\nand the placement of a powerful server. However, handling many clients at once\nintroduces computing and transmission delays. Thus, we aim to obtain a\ndelay-accuracy trade-off for FLSTRA. Specifically, we first develop a joint\nclient selection and resource allocation algorithm for uplink and downlink to\nminimize the FL delay subject to the energy and quality-of-service (QoS)\nconstraints. Second, we propose a communication and computation resource-aware\n(CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upper\nbound for its convergence rate. The formulated problem is non-convex; thus, we\npropose an iterative algorithm to solve it. Simulation results demonstrate the\neffectiveness of the proposed FLSTRA system, compared to terrestrial\nbenchmarks, in terms of FL delay and accuracy.\n","authors":["Amin Farajzadeh","Animesh Yadav","Omid Abbasi","Wael Jaafar","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2302.00163v3.pdf","comment":"Accepted to IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2306.05905v1","updated":"2023-06-09T14:01:26Z","published":"2023-06-09T14:01:26Z","title":"TreeDQN: Learning to minimize Branch-and-Bound tree","summary":"  Combinatorial optimization problems require an exhaustive search to find the\noptimal solution. A convenient approach to solving combinatorial optimization\ntasks in the form of Mixed Integer Linear Programs is Branch-and-Bound.\nBranch-and-Bound solver splits a task into two parts dividing the domain of an\ninteger variable, then it solves them recursively, producing a tree of nested\nsub-tasks. The efficiency of the solver depends on the branchning heuristic\nused to select a variable for splitting. In the present work, we propose a\nreinforcement learning method that can efficiently learn the branching\nheuristic. We view the variable selection task as a tree Markov Decision\nProcess, prove that the Bellman operator adapted for the tree Markov Decision\nProcess is contracting in mean, and propose a modified learning objective for\nthe reinforcement learning agent. Our agent requires less training data and\nproduces smaller trees compared to previous reinforcement learning methods.\n","authors":["Dmitry Sorokin","Alexander Kostin"],"pdf_url":"https://arxiv.org/pdf/2306.05905v1.pdf","comment":"Submitted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2306.05899v1","updated":"2023-06-09T13:49:23Z","published":"2023-06-09T13:49:23Z","title":"An Accelerated Stochastic ADMM for Nonconvex and Nonsmooth Finite-Sum\n  Optimization","summary":"  The nonconvex and nonsmooth finite-sum optimization problem with linear\nconstraint has attracted much attention in the fields of artificial\nintelligence, computer, and mathematics, due to its wide applications in\nmachine learning and the lack of efficient algorithms with convincing\nconvergence theories. A popular approach to solve it is the stochastic\nAlternating Direction Method of Multipliers (ADMM), but most stochastic\nADMM-type methods focus on convex models. In addition, the variance reduction\n(VR) and acceleration techniques are useful tools in the development of\nstochastic methods due to their simplicity and practicability in providing\nacceleration characteristics of various machine learning models. However, it\nremains unclear whether accelerated SVRG-ADMM algorithm (ASVRG-ADMM), which\nextends SVRG-ADMM by incorporating momentum techniques, exhibits a comparable\nacceleration characteristic or convergence rate in the nonconvex setting. To\nfill this gap, we consider a general nonconvex nonsmooth optimization problem\nand study the convergence of ASVRG-ADMM. By utilizing a well-defined potential\nenergy function, we establish its sublinear convergence rate $O(1/T)$, where\n$T$ denotes the iteration number. Furthermore, under the additional\nKurdyka-Lojasiewicz (KL) property which is less stringent than the frequently\nused conditions for showcasing linear convergence rates, such as strong\nconvexity, we show that the ASVRG-ADMM sequence has a finite length and\nconverges to a stationary solution with a linear convergence rate. Several\nexperiments on solving the graph-guided fused lasso problem and regularized\nlogistic regression problem validate that the proposed ASVRG-ADMM performs\nbetter than the state-of-the-art methods.\n","authors":["Yuxuan Zeng","Zhiguo Wang","Jianchao Bai","Xiaojing Shen"],"pdf_url":"https://arxiv.org/pdf/2306.05899v1.pdf","comment":"40 Pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.01986v2","updated":"2023-06-09T13:46:50Z","published":"2023-06-03T02:47:46Z","title":"A Novel Correlation-optimized Deep Learning Method for Wind Speed\n  Forecast","summary":"  The increasing installation rate of wind power poses great challenges to the\nglobal power system. In order to ensure the reliable operation of the power\nsystem, it is necessary to accurately forecast the wind speed and power of the\nwind turbines. At present, deep learning is progressively applied to the wind\nspeed prediction. Nevertheless, the recent deep learning methods still reflect\nthe embarrassment for practical applications due to model interpretability and\nhardware limitation. To this end, a novel deep knowledge-based learning method\nis proposed in this paper. The proposed method hybridizes pre-training method\nand auto-encoder structure to improve data representation and modeling of the\ndeep knowledge-based learning framework. In order to form knowledge and\ncorresponding absorbers, the original data is preprocessed by an optimization\nmodel based on correlation to construct multi-layer networks (knowledge) which\nare absorbed by sequence to sequence (Seq2Seq) models. Specifically, new\ncognition and memory units (CMU) are designed to reinforce traditional deep\nlearning framework. Finally, the effectiveness of the proposed method is\nverified by three wind prediction cases from a wind farm in Liaoning, China.\nExperimental results show that the proposed method increases the stability and\ntraining efficiency compared to the traditional LSTM method and LSTM/GRU-based\nSeq2Seq method for applications of wind speed forecasting.\n","authors":["Yang Yang","Jin Lang","Jian Wu","Yanyan Zhang","Xiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.01986v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.04083v2","updated":"2023-06-09T12:20:45Z","published":"2023-02-08T14:37:34Z","title":"Improving the Model Consistency of Decentralized Federated Learning","summary":"  To mitigate the privacy leakages and communication burdens of Federated\nLearning (FL), decentralized FL (DFL) discards the central server and each\nclient only communicates with its neighbors in a decentralized communication\nnetwork. However, existing DFL suffers from high inconsistency among local\nclients, which results in severe distribution shift and inferior performance\ncompared with centralized FL (CFL), especially on heterogeneous data or sparse\ncommunication topology. To alleviate this issue, we propose two DFL algorithms\nnamed DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically,\nDFedSAM leverages gradient perturbation to generate local flat models via\nSharpness Aware Minimization (SAM), which searches for models with uniformly\nlow loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip\nSteps (MGS) for better model consistency, which accelerates the aggregation of\nlocal flat models and better balances communication complexity and\ngeneralization. Theoretically, we present improved convergence rates $\\small\n\\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{1}{K^{1/2}T^{3/2}(1-\\lambda)^2}\\big)$\nand $\\small\n\\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{\\lambda^Q+1}{K^{1/2}T^{3/2}(1-\\lambda^Q)^2}\\big)$\nin non-convex setting for DFedSAM and DFedSAM-MGS, respectively, where\n$1-\\lambda$ is the spectral gap of gossip matrix and $Q$ is the number of MGS.\nEmpirically, our methods can achieve competitive performance compared with CFL\nmethods and outperform existing DFL methods.\n","authors":["Yifan Shi","Li Shen","Kang Wei","Yan Sun","Bo Yuan","Xueqian Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.04083v2.pdf","comment":"ICML2023"},{"id":"http://arxiv.org/abs/2306.01946v2","updated":"2023-06-09T12:11:23Z","published":"2023-06-02T23:04:57Z","title":"Linearly convergent adjoint free solution of least squares problems by\n  random descent","summary":"  We consider the problem of solving linear least squares problems in a\nframework where only evaluations of the linear map are possible. We derive\nrandomized methods that do not need any other matrix operations than forward\nevaluations, especially no evaluation of the adjoint map is needed. Our method\nis motivated by the simple observation that one can get an unbiased estimate of\nthe application of the adjoint. We show convergence of the method and then\nderive a more efficient method that uses an exact linesearch. This method,\ncalled random descent, resembles known methods in other context and has the\nrandomized coordinate descent method as special case. We provide convergence\nanalysis of the random descent method emphasizing the dependence on the\nunderlying distribution of the random vectors. Furthermore we investigate the\napplicability of the method in the context of ill-posed inverse problems and\nshow that the method can have beneficial properties when the unknown solution\nis rough. We illustrate the theoretical findings in numerical examples. One\nparticular result is that the random descent method actually outperforms\nestablished transposed-free methods (TFQMR and CGS) in examples.\n","authors":["Dirk A. Lorenz","Felix Schneppe","Lionel Tondji"],"pdf_url":"https://arxiv.org/pdf/2306.01946v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14449v2","updated":"2023-06-09T12:06:32Z","published":"2022-12-29T20:25:18Z","title":"Policy Mirror Ascent for Efficient and Independent Learning in Mean\n  Field Games","summary":"  Mean-field games have been used as a theoretical tool to obtain an\napproximate Nash equilibrium for symmetric and anonymous $N$-player games.\nHowever, limiting applicability, existing theoretical results assume variations\nof a \"population generative model\", which allows arbitrary modifications of the\npopulation distribution by the learning algorithm. Moreover, learning\nalgorithms typically work on abstract simulators with population instead of the\n$N$-player game. Instead, we show that $N$ agents running policy mirror ascent\nconverge to the Nash equilibrium of the regularized game within\n$\\widetilde{\\mathcal{O}}(\\varepsilon^{-2})$ samples from a single sample\ntrajectory without a population generative model, up to a standard\n$\\mathcal{O}(\\frac{1}{\\sqrt{N}})$ error due to the mean field. Taking a\ndivergent approach from the literature, instead of working with the\nbest-response map we first show that a policy mirror ascent map can be used to\nconstruct a contractive operator having the Nash equilibrium as its fixed\npoint. We analyze single-path TD learning for $N$-agent games, proving sample\ncomplexity guarantees by only using a sample path from the $N$-agent simulator\nwithout a population generative model. Furthermore, we demonstrate that our\nmethodology allows for independent learning by $N$ agents with finite sample\nguarantees.\n","authors":["Batuhan Yardim","Semih Cayci","Matthieu Geist","Niao He"],"pdf_url":"https://arxiv.org/pdf/2212.14449v2.pdf","comment":"Accepted for publication at ICML 2023"},{"id":"http://arxiv.org/abs/2306.05825v1","updated":"2023-06-09T11:50:01Z","published":"2023-06-09T11:50:01Z","title":"Extremal properties of the first eigenvalue and the fundamental gap of a\n  sub-elliptic operator","summary":"  We consider the problems of extreming the first eigenvalue and the\nfundamental gap of a sub-elliptic operator with Dirichlet boundary condition,\nwhen the potential $V$ is subjected to a $p$-norm constraint. The existence\nresults for weak solutions, compact embedding theorem and spectral theory for\nsub-elliptic equation are given. Moreover, we provide the specific\ncharacteristics of the corresponding optimal potential function.\n","authors":["Hongli Sun","Weijia Wu","Donghui Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13459v2","updated":"2023-06-09T11:00:15Z","published":"2023-05-22T19:59:19Z","title":"The First Proven Performance Guarantees for the Non-Dominated Sorting\n  Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem","summary":"  The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most\nprominent algorithms to solve multi-objective optimization problems. Recently,\nthe first mathematical runtime guarantees have been obtained for this\nalgorithm, however only for synthetic benchmark problems.\n  In this work, we give the first proven performance guarantees for a classic\noptimization problem, the NP-complete bi-objective minimum spanning tree\nproblem. More specifically, we show that the NSGA-II with population size $N\n\\ge 4((n-1) w_{\\max} + 1)$ computes all extremal points of the Pareto front in\nan expected number of $O(m^2 n w_{\\max} \\log(n w_{\\max}))$ iterations, where\n$n$ is the number of vertices, $m$ the number of edges, and $w_{\\max}$ is the\nmaximum edge weight in the problem instance. This result confirms, via\nmathematical means, the good performance of the NSGA-II observed empirically.\nIt also shows that mathematical analyses of this algorithm are not only\npossible for synthetic benchmark problems, but also for more complex\ncombinatorial optimization problems.\n  As a side result, we also obtain a new analysis of the performance of the\nglobal SEMO algorithm on the bi-objective minimum spanning tree problem, which\nimproves the previous best result by a factor of $|F|$, the number of extremal\npoints of the Pareto front, a set that can be as large as $n w_{\\max}$. The\nmain reason for this improvement is our observation that both multi-objective\nevolutionary algorithms find the different extremal points in parallel rather\nthan sequentially, as assumed in the previous proofs.\n","authors":["Sacha Cerf","Benjamin Doerr","Benjamin Hebras","Yakob Kahane","Simon Wietheger"],"pdf_url":"https://arxiv.org/pdf/2305.13459v2.pdf","comment":"Author-generated version of a paper appearing in the proceedings of\n  IJCAI 2023, with appendix"},{"id":"http://arxiv.org/abs/2211.16064v2","updated":"2023-06-09T10:48:55Z","published":"2022-11-29T10:18:45Z","title":"Locating the source of forced oscillations in transmission power grids","summary":"  Forced oscillation event in power grids refers to a state where\nmalfunctioning or abnormally operating equipment causes persisting periodic\ndisturbances in the system. While power grids are designed to damp most of\nperturbations during standard operations, some of them can excite normal modes\nof the system and cause significant energy transfers across the system,\ncreating large oscillations thousands of miles away from the source.\nLocalization of the source of such disturbances remains an outstanding\nchallenge due to a limited knowledge of the system parameters outside of the\nzone of responsibility of system operators. Here, we propose a new method for\nlocating the source of forced oscillations which addresses this challenge by\nperforming a simultaneous dynamic model identification using a principled\nmaximum likelihood approach. We illustrate the validity of the algorithm on a\nvariety of examples where forcing leads to resonance conditions in the system\ndynamics. Our results establish that an accurate knowledge of system parameters\nis not required for a successful inference of the source and frequency of a\nforced oscillation. We anticipate that our method will find a broader\napplication in general dynamical systems that can be well-described by their\nlinearized dynamics over short periods of time.\n","authors":["Robin Delabays","Andrey Y. Lokhov","Melvyn Tyloo","Marc Vuffray"],"pdf_url":"https://arxiv.org/pdf/2211.16064v2.pdf","comment":"Main text: 9 pages, 4 figures. Supplementary material: 10 pages, 9\n  figures"},{"id":"http://arxiv.org/abs/2306.05761v1","updated":"2023-06-09T08:55:26Z","published":"2023-06-09T08:55:26Z","title":"Sums of squares certificates for polynomial moment inequalities","summary":"  This paper introduces and develops the algebraic framework of moment\npolynomials, which are polynomial expressions in commuting variables and their\nformal mixed moments. Their positivity and optimization over probability\nmeasures supported on semialgebraic sets and subject to moment polynomial\nconstraints is investigated. A positive solution to Hilbert's 17th problem for\npseudo-moments is given. On the other hand, moment polynomials positive on\nactual measures are shown to be sums of squares and formal moments of squares\nup to arbitrarily small perturbation of their coefficients. When only measures\nsupported on a bounded semialgebraic set are considered, a stronger algebraic\ncertificate for moment polynomial positivity is derived. This result gives rise\nto a converging hierarchy of semidefinite programs for moment polynomial\noptimization. Finally, as an application, two nonlinear Bell inequalities from\nquantum physics are settled.\n","authors":["Igor Klep","Victor Magron","Jurij Volčič"],"pdf_url":"https://arxiv.org/pdf/2306.05761v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2208.11678v2","updated":"2023-06-09T08:48:47Z","published":"2022-08-23T09:33:46Z","title":"A short simple proof of closedness of convex cones and Farkas' lemma","summary":"  Proving that a finitely generated convex cone is closed is often considered\nthe most difficult part of geometric proofs of Farkas' lemma. We provide a\nshort simple proof of this fact and (for completeness) derive Farkas' lemma\nfrom it using well-known arguments.\n","authors":["Wouter Kager"],"pdf_url":"https://arxiv.org/pdf/2208.11678v2.pdf","comment":"2 pages; v2: note largely rewritten, provided more context, improved\n  presentation, added 5 references"},{"id":"http://arxiv.org/abs/2303.07160v2","updated":"2023-06-09T08:30:56Z","published":"2023-03-13T14:35:55Z","title":"Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond","summary":"  We study convergence lower bounds of without-replacement stochastic gradient\ndescent (SGD) for solving smooth (strongly-)convex finite-sum minimization\nproblems. Unlike most existing results focusing on final iterate lower bounds\nin terms of the number of components $n$ and the number of epochs $K$, we seek\nbounds for arbitrary weighted average iterates that are tight in all factors\nincluding the condition number $\\kappa$. For SGD with Random Reshuffling, we\npresent lower bounds that have tighter $\\kappa$ dependencies than existing\nbounds. Our results are the first to perfectly close the gap between lower and\nupper bounds for weighted average iterates in both strongly-convex and convex\ncases. We also prove weighted average iterate lower bounds for arbitrary\npermutation-based SGD, which apply to all variants that carefully choose the\nbest permutation. Our bounds improve the existing bounds in factors of $n$ and\n$\\kappa$ and thereby match the upper bounds shown for a recently proposed\nalgorithm called GraB.\n","authors":["Jaeyoung Cha","Jaewook Lee","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2303.07160v2.pdf","comment":"58 pages"},{"id":"http://arxiv.org/abs/2306.05732v1","updated":"2023-06-09T07:52:42Z","published":"2023-06-09T07:52:42Z","title":"Computing Algorithm for an Equilibrium of the Generalized Stackelberg\n  Game","summary":"  The $1-N$ generalized Stackelberg game (single-leader multi-follower game) is\nintricately intertwined with the interaction between a leader and followers\n(hierarchical interaction) and the interaction among followers (simultaneous\ninteraction). However, obtaining the optimal strategy of the leader is\ngenerally challenging due to the complex interactions among the leader and\nfollowers. Here, we propose a general methodology to find a generalized\nStackelberg equilibrium of a $1-N$ generalized Stackelberg game. Specifically,\nwe first provide the conditions where a generalized Stackelberg equilibrium\nalways exists using the variational equilibrium concept. Next, to find an\nequilibrium in polynomial time, we transformed the $1-N$ generalized\nStackelberg game into a $1-1$ Stackelberg game whose Stackelberg equilibrium is\nidentical to that of the original. Finally, we propose an effective computation\nprocedure based on the projected implicit gradient descent algorithm to find a\nStackelberg equilibrium of the transformed $1-1$ Stackelberg game. We validate\nthe proposed approaches using the two problems of deriving operating strategies\nfor EV charging stations: (1) the first problem is optimizing the one-time\ncharging price for EV users, in which a platform operator determines the price\nof electricity and EV users determine the optimal amount of charging for their\nsatisfaction; and (2) the second problem is to determine the spatially varying\ncharging price to optimally balance the demand and supply over every charging\nstation.\n","authors":["Jaeyeon Jo","Jihwan Yu","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.05732v1.pdf","comment":"37 pages, 10 figures"},{"id":"http://arxiv.org/abs/2104.12328v5","updated":"2023-06-09T07:40:48Z","published":"2021-04-26T03:21:07Z","title":"Non-uniform Observability for Moving Horizon Estimation and stability\n  with respect to additive perturbation","summary":"  This paper formalises the concepts of weakly and weakly regularly persistent\ninput trajectory as well as their link to the Observability Grammian and the\nexistence and uniqueness of solutions of Moving Horizon Estimation (MHE)\nproblems. Additionally, thanks to a new time-uniform Implicit Function Theorem,\nthese notions are proved to imply the stability of MHE solutions with respect\nto small additive perturbation in the measurements and in the dynamics, both\nuniformly and non-uniformly in time. Finally, examples and counter-examples of\nweakly persistent and weakly regularly persistent input trajectories are given\nin the case of 2D bearing-only navigation.\n","authors":["Emilien Flayac","Iman Shames"],"pdf_url":"https://arxiv.org/pdf/2104.12328v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.11755v3","updated":"2023-06-09T07:06:17Z","published":"2022-07-24T14:34:21Z","title":"Revisiting the central limit theorems for the SGD-type methods","summary":"  We revisited the central limit theorem (CLT) for stochastic gradient descent\n(SGD) type methods, including the vanilla SGD, momentum SGD and Nesterov\naccelerated SGD methods with constant or vanishing damping parameters. By\ntaking advantage of Lyapunov function technique and $L^p$ bound estimates, we\nestablished the CLT under more general conditions on learning rates for broader\nclasses of SGD methods compared with previous results. The CLT for the time\naverage was also investigated, and we found that it held in the linear case,\nwhile it was not generally true in nonlinear situation. Numerical tests were\nalso carried out to verify our theoretical analysis.\n","authors":["Tiejun Li","Tiannan Xiao","Guoguo Yang"],"pdf_url":"https://arxiv.org/pdf/2207.11755v3.pdf","comment":"23 pages, 2 figures"},{"id":"http://arxiv.org/abs/2306.05706v1","updated":"2023-06-09T06:55:15Z","published":"2023-06-09T06:55:15Z","title":"Understanding How Consistency Works in Federated Learning via Stage-wise\n  Relaxed Initialization","summary":"  Federated learning (FL) is a distributed paradigm that coordinates massive\nlocal clients to collaboratively train a global model via stage-wise local\ntraining processes on the heterogeneous dataset. Previous works have implicitly\nstudied that FL suffers from the ``client-drift'' problem, which is caused by\nthe inconsistent optimum across local clients. However, till now it still lacks\nsolid theoretical analysis to explain the impact of this local inconsistency.\nTo alleviate the negative impact of the ``client drift'' and explore its\nsubstance in FL, in this paper, we first design an efficient FL algorithm\n\\textit{FedInit}, which allows employing the personalized relaxed\ninitialization state at the beginning of each local training stage.\nSpecifically, \\textit{FedInit} initializes the local state by moving away from\nthe current global state towards the reverse direction of the latest local\nstate. This relaxed initialization helps to revise the local divergence and\nenhance the local consistency level. Moreover, to further understand how\ninconsistency disrupts performance in FL, we introduce the excess risk analysis\nand study the divergence term to investigate the test error of the proposed\n\\textit{FedInit} method. Our studies show that optimization error is not\nsensitive to this local inconsistency, while it mainly affects the\ngeneralization error bound in \\textit{FedInit}. Extensive experiments are\nconducted to validate this conclusion. Our proposed \\textit{FedInit} could\nachieve state-of-the-art~(SOTA) results compared to several advanced benchmarks\nwithout any additional costs. Meanwhile, stage-wise relaxed initialization\ncould also be incorporated into the current advanced algorithms to achieve\nhigher performance in the FL paradigm.\n","authors":["Yan Sun","Li Shen","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.05706v1.pdf","comment":"32 pages"},{"id":"http://arxiv.org/abs/2206.13090v2","updated":"2023-06-09T06:53:18Z","published":"2022-06-27T07:50:49Z","title":"Variance Reduced Random Relaxed Projection Method for Constrained\n  Finite-sum Minimization Problems","summary":"  For many applications in signal processing and machine learning, we are\ntasked with minimizing a large sum of convex functions subject to a large\nnumber of convex constraints. In this paper, we devise a new random projection\nmethod (RPM) to efficiently solve this problem. Compared with existing RPMs,\nour proposed algorithm features two useful algorithmic ideas. First, at each\niteration, instead of projecting onto the subset defined by one of the\nconstraints, our algorithm only requires projecting onto a half-space\napproximation of the subset, which significantly reduces the computational cost\nas it admits a closed-form formula. Second, to exploit the structure that the\nobjective is a sum, variance reduction is incorporated into our algorithm to\nfurther improve the performance. As theoretical contributions, under an error\nbound condition and other standard assumptions, we prove that the proposed RPM\nconverges to an optimal solution and that both optimality and feasibility gaps\nvanish at a sublinear rate. We also provide sufficient conditions for the error\nbound condition to hold. Experiments on a beamforming problem and a robust\nclassification problem are also presented to demonstrate the superiority of our\nRPM over existing ones.\n","authors":["Zhichun Yang","Fu-quan Xia","Kai Tu","Man-Chung Yue"],"pdf_url":"https://arxiv.org/pdf/2206.13090v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12978v4","updated":"2023-06-09T06:34:33Z","published":"2022-12-26T00:28:07Z","title":"Doubly Smoothed GDA for Constrained Nonconvex-Nonconcave Minimax\n  Optimization","summary":"  Nonconvex-nonconcave minimax optimization has received intense attention over\nthe last decade due to its broad applications in machine learning.\nUnfortunately, most existing algorithms cannot be guaranteed to converge\nglobally and even suffer from limit cycles. To address this issue, we propose a\nnovel single-loop algorithm called doubly smoothed gradient descent ascent\nmethod (DSGDA), which naturally balances the primal and dual updates. The\nproposed DSGDA can get rid of limit cycles in various challenging\nnonconvex-nonconcave examples in the literature, including Forsaken,\nBilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further\nshow that under an one-sided Kurdyka-\\L{}ojasiewicz condition with exponent\n$\\theta\\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a\ngame-stationary point with an iteration complexity of\n$\\mathcal{O}(\\epsilon^{-2\\max\\{2\\theta,1\\}})$ (resp.\n$\\mathcal{O}(\\epsilon^{-4})$). These match the best results for single-loop\nalgorithms that solve nonconvex-concave or convex-nonconcave minimax problems,\nor problems satisfying the rather restrictive one-sided Polyak-\\L{}ojasiewicz\ncondition. Our work demonstrates, for the first time, the possibility of having\na simple and unified single-loop algorithm for solving nonconvex-nonconcave,\nnonconvex-concave, and convex-nonconcave minimax problems.\n","authors":["Taoli Zheng","Linglingzhi Zhu","Anthony Man-Cho So","Jose Blanchet","Jiajin Li"],"pdf_url":"https://arxiv.org/pdf/2212.12978v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06197v2","updated":"2023-06-09T06:30:03Z","published":"2022-11-11T13:37:31Z","title":"A convergence study of SGD-type methods for stochastic optimization","summary":"  In this paper, we first reinvestigate the convergence of vanilla SGD method\nin the sense of $L^2$ under more general learning rates conditions and a more\ngeneral convex assumption, which relieves the conditions on learning rates and\ndo not need the problem to be strongly convex. Then, by taking advantage of the\nLyapunov function technique, we present the convergence of the momentum SGD and\nNesterov accelerated SGD methods for the convex and non-convex problem under\n$L$-smooth assumption that extends the bounded gradient limitation to a certain\nextent. The convergence of time averaged SGD was also analyzed.\n","authors":["Tiannan Xiao","Guoguo Yang"],"pdf_url":"https://arxiv.org/pdf/2211.06197v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2302.04972v2","updated":"2023-06-09T04:49:55Z","published":"2023-02-09T23:22:48Z","title":"Differentially Private Optimization for Smooth Nonconvex ERM","summary":"  We develop simple differentially private optimization algorithms that move\nalong directions of (expected) descent to find an approximate second-order\nsolution for nonconvex ERM. We use line search, mini-batching, and a two-phase\nstrategy to improve the speed and practicality of the algorithm. Numerical\nexperiments demonstrate the effectiveness of these approaches.\n","authors":["Changyu Gao","Stephen J. Wright"],"pdf_url":"https://arxiv.org/pdf/2302.04972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05662v1","updated":"2023-06-09T04:08:26Z","published":"2023-06-09T04:08:26Z","title":"Consensus ALADIN: A Framework for Distributed Optimization and Its\n  Application in Federated Learning","summary":"  This paper investigates algorithms for solving distributed consensus\noptimization problems that are non-convex. Since Typical ALADIN (Typical\nAugmented Lagrangian based Alternating Direction Inexact Newton Method,\nT-ALADIN for short) [1] is a well-performed algorithm treating distributed\noptimization problems that are non-convex, directly adopting T-ALADIN to those\nof consensus is a natural approach. However, T-ALADIN typically results in high\ncommunication and computation overhead, which makes such an approach far from\nefficient. In this paper, we propose a new variant of the ALADIN family, coined\nconsensus ALADIN (C-ALADIN for short). C-ALADIN inherits all the good\nproperties of T-ALADIN, such as the local linear or super-linear convergence\nrate and the local convergence guarantees for non-convex optimization problems;\nbesides, C-ALADIN offers unique improvements in terms of communication\nefficiency and computational efficiency. Moreover, C-ALADIN involves a reduced\nversion, in comparison with Consensus ADMM (Alternating Direction Method of\nMultipliers) [3], showing significant convergence performance, even without the\nhelp of second-order information. We also propose a practical version of\nC-ALADIN, named FedALADIN, that seamlessly serves the emerging federated\nlearning applications, which expands the reach of our proposed C-ALADIN. We\nprovide numerical experiments to demonstrate the effectiveness of C-ALADIN. The\nresults show that C-ALADIN has significant improvements in convergence\nperformance.\n","authors":["Xu Du","Jingzhe Wang"],"pdf_url":"https://arxiv.org/pdf/2306.05662v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05655v1","updated":"2023-06-09T03:51:45Z","published":"2023-06-09T03:51:45Z","title":"Communication-Efficient Zeroth-Order Distributed Online Optimization:\n  Algorithm, Theory, and Applications","summary":"  This paper focuses on a multi-agent zeroth-order online optimization problem\nin a federated learning setting for target tracking. The agents only sense\ntheir current distances to their targets and aim to maintain a minimum safe\ndistance from each other to prevent collisions. The coordination among the\nagents and dissemination of collision-prevention information is managed by a\ncentral server using the federated learning paradigm. The proposed formulation\nleads to an instance of distributed online nonconvex optimization problem that\nis solved via a group of communication-constrained agents. To deal with the\ncommunication limitations of the agents, an error feedback-based compression\nscheme is utilized for agent-to-server communication. The proposed algorithm is\nanalyzed theoretically for the general class of distributed online nonconvex\noptimization problems. We provide non-asymptotic convergence rates that show\nthe dominant term is independent of the characteristics of the compression\nscheme. Our theoretical results feature a new approach that employs\nsignificantly more relaxed assumptions in comparison to standard literature.\nThe performance of the proposed solution is further analyzed numerically in\nterms of tracking errors and collisions between agents in two relevant\napplications.\n","authors":["Ege C. Kaya","M. Berk Sahin","Abolfazl Hashemi"],"pdf_url":"https://arxiv.org/pdf/2306.05655v1.pdf","comment":"21 pages, 5 figures, and this paper has been accepted by IEEE Access"},{"id":"http://arxiv.org/abs/2306.05649v1","updated":"2023-06-09T03:35:33Z","published":"2023-06-09T03:35:33Z","title":"Specifying and Solving Robust Empirical Risk Minimization Problems Using\n  CVXPY","summary":"  We consider robust empirical risk minimization (ERM), where model parameters\nare chosen to minimize the worst-case empirical loss when each data point\nvaries over a given convex uncertainty set. In some simple cases, such problems\ncan be expressed in an analytical form. In general the problem can be made\ntractable via dualization, which turns a min-max problem into a min-min\nproblem. Dualization requires expertise and is tedious and error-prone. We\ndemonstrate how CVXPY can be used to automate this dualization procedure in a\nuser-friendly manner. Our framework allows practitioners to specify and solve\nrobust ERM problems with a general class of convex losses, capturing many\nstandard regression and classification problems. Users can easily specify any\ncomplex uncertainty set that is representable via disciplined convex\nprogramming (DCP) constraints.\n","authors":["Eric Luxenberg","Dhruv Malik","Yuanzhi Li","Aarti Singh","Stephen Boyd"],"pdf_url":"https://arxiv.org/pdf/2306.05649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05537v3","updated":"2023-06-09T03:33:00Z","published":"2023-01-13T13:35:43Z","title":"Almost Surely $\\sqrt{T}$ Regret Bound for Adaptive LQR","summary":"  The Linear-Quadratic Regulation (LQR) problem with unknown system parameters\nhas been widely studied, but it has remained unclear whether $\\tilde{\n\\mathcal{O}}(\\sqrt{T})$ regret, which is the best known dependence on time, can\nbe achieved almost surely. In this paper, we propose an adaptive LQR controller\nwith almost surely $\\tilde{ \\mathcal{O}}(\\sqrt{T})$ regret upper bound. The\ncontroller features a circuit-breaking mechanism, which circumvents potential\nsafety breach and guarantees the convergence of the system parameter estimate,\nbut is shown to be triggered only finitely often and hence has negligible\neffect on the asymptotic performance of the controller. The proposed controller\nis also validated via simulation on Tennessee Eastman Process~(TEP), a commonly\nused industrial process example.\n","authors":["Yiwen Lu","Yilin Mo"],"pdf_url":"https://arxiv.org/pdf/2301.05537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2009.07514v3","updated":"2023-06-09T03:07:57Z","published":"2020-09-16T07:25:50Z","title":"A Unified Approach to Synchronization Problems over Subgroups of the\n  Orthogonal Group","summary":"  The problem of synchronization over a group $\\mathcal{G}$ aims to estimate a\ncollection of group elements $G^*_1, \\dots, G^*_n \\in \\mathcal{G}$ based on\nnoisy observations of a subset of all pairwise ratios of the form $G^*_i\n{G^*_j}^{-1}$. Such a problem has gained much attention recently and finds many\napplications across a wide range of scientific and engineering areas. In this\npaper, we consider the class of synchronization problems in which the group is\na closed subgroup of the orthogonal group. This class covers many group\nsynchronization problems that arise in practice. Our contribution is fivefold.\nFirst, we propose a unified approach for solving this class of group\nsynchronization problems, which consists of a suitable initialization step and\nan iterative refinement step based on the generalized power method, and show\nthat it enjoys a strong theoretical guarantee on the estimation error under\ncertain assumptions on the group, measurement graph, noise, and initialization.\nSecond, we formulate two geometric conditions that are required by our approach\nand show that they hold for various practically relevant subgroups of the\northogonal group. The conditions are closely related to the error-bound\ngeometry of the subgroup -- an important notion in optimization. Third, we\nverify the assumptions on the measurement graph and noise for standard random\ngraph and random matrix models. Fourth, based on the classic notion of metric\nentropy, we develop and analyze a novel spectral-type estimator. Finally, we\nshow via extensive numerical experiments that our proposed non-convex approach\noutperforms existing approaches in terms of computational speed, scalability,\nand/or estimation error.\n","authors":["Huikang Liu","Man-Chung Yue","Anthony Man-Cho So"],"pdf_url":"https://arxiv.org/pdf/2009.07514v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05627v1","updated":"2023-06-09T02:21:43Z","published":"2023-06-09T02:21:43Z","title":"A Macro-Micro Approach to Reconstructing Vehicle Trajectories on\n  Multi-Lane Freeways with Lane Changing","summary":"  Vehicle trajectories can offer the most precise and detailed depiction of\ntraffic flow and serve as a critical component in traffic management and\ncontrol applications. Various technologies have been applied to reconstruct\nvehicle trajectories from sparse fixed and mobile detection data. However,\nexisting methods predominantly concentrate on single-lane scenarios and neglect\nlane-changing (LC) behaviors that occur across multiple lanes, which limit\ntheir applicability in practical traffic systems. To address this research gap,\nwe propose a macro-micro approach for reconstructing complete vehicle\ntrajectories on multi-lane freeways, wherein the macro traffic state\ninformation and micro driving models are integrated to overcome the\nrestrictions imposed by lane boundary. Particularly, the macroscopic velocity\ncontour maps are established for each lane to regulate the movement of vehicle\nplatoons, meanwhile the velocity difference between adjacent lanes provide\nvaluable criteria for guiding LC behaviors. Simultaneously, the car-following\nmodels are extended from micro perspective to supply lane-based candidate\ntrajectories and define the plausible range for LC positions. Later, a\ntwo-stage trajectory fusion algorithm is proposed to jointly infer both the\ncar-following and LC behaviors, in which the optimal LC positions is identified\nand candidate trajectories are adjusted according to their weights. The\nproposed framework was evaluated using NGSIM dataset, and the results indicated\na remarkable enhancement in both the accuracy and smoothness of reconstructed\ntrajectories, with performance indicators reduced by over 30% compared to two\nrepresentative reconstruction methods. Furthermore, the reconstruction process\neffectively reproduced LC behaviors across contiguous lanes, adding to the\nframework's comprehensiveness and realism.\n","authors":["Xuejian Chen","Guoyang Qin","Toru Seo","Ye Tian","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2306.05627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13182v2","updated":"2023-06-09T01:43:39Z","published":"2022-12-26T15:04:57Z","title":"Regularized Nonsmooth Newton Algorithms for Best Approximation","summary":"  We consider the problem of finding the best approximation point from a\npolyhedral set, and its applications, in particular to solving large-scale\nlinear programs. The classical projection problem has many various and many\napplications. We study a regularized nonsmooth Newton type solution method\nwhere the Jacobian is singular; and we compare the computational performance to\nthat of the classical projection method of Halperin-Lions-Wittmann-Bauschke\n(HLWB).\n  We observe empirically that the regularized nonsmooth method significantly\noutperforms the HLWB method. However, the HLWB has a convergence guarantee\nwhile the nonsmooth method is not monotonic and does not guarantee convergence\ndue in part to singularity of the generalized Jacobian.\n  Our application to solving large-scale linear programs uses a parametrized\nprojection problem. This leads to a \\emph{stepping stone external path\nfollowing} algorithm. Other applications are finding triangles from branch and\nbound methods, and generalized constrained linear least squares. We include\nscaling methods that improve the efficiency and robustness.\n","authors":["Yair Censor","Walaa M. Moursi","Tyler Weames","Henry Wolkowicz"],"pdf_url":"https://arxiv.org/pdf/2212.13182v2.pdf","comment":"38 pages, 7 tables, 8 figures"},{"id":"http://arxiv.org/abs/2306.05615v1","updated":"2023-06-09T01:38:09Z","published":"2023-06-09T01:38:09Z","title":"Mixed-Integer Programming for a Class of Robust Submodular Maximization\n  Problems","summary":"  We consider robust submodular maximization problems (RSMs), where given a set\nof $m$ monotone submodular objective functions, the robustness is with respect\nto the worst-case (scaled) objective function. The model we consider\ngeneralizes two variants of robust submodular maximization problems in the\nliterature, depending on the choice of the scaling vector. On one hand, by\nusing unit scaling, we obtain a usual robust submodular maximization problem.\nOn the other hand, by letting the scaling vector be the optimal objective\nfunction of each individual (NP-hard) submodular maximization problem, we\nobtain a second variant. While the robust version of the objective is no longer\nsubmodular, we reformulate the problem by exploiting the submodularity of each\nfunction. We conduct a polyhedral study of the resulting formulation and\nprovide conditions under which the submodular inequalities are facet-defining\nfor a key mixed-integer set. We investigate several strategies for\nincorporating these inequalities within a delayed cut generation framework to\nsolve the problem exactly. For the second variant, we provide an algorithm to\nobtain a feasible solution along with its optimality gap. We apply the proposed\nmethods to a sensor placement optimization problem in water distribution\nnetworks using real-world datasets to demonstrate the effectiveness of the\nmethods.\n","authors":["Hsin-Yi Huang","Hao-Hsiang Wu","Simge Kucukyavuz"],"pdf_url":"https://arxiv.org/pdf/2306.05615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.04094v4","updated":"2023-06-09T00:37:46Z","published":"2021-07-08T20:24:16Z","title":"Robust Control Barrier Functions under High Relative Degree and Input\n  Constraints for Satellite Trajectories","summary":"  This paper presents methodologies for constructing Control Barrier Functions\n(CBFs) for nonlinear, control-affine systems, in the presence of input\nconstraints and bounded disturbances. More specifically, given a constraint\nfunction with high-relative-degree with respect to the system dynamics, the\npaper considers three methodologies, two for relative-degree 2 and one for\nhigher relative-degrees, for creating CBFs whose zero sublevel sets are subsets\nof the constraint function's zero sublevel set. Three special forms of Robust\nCBFs (RCBFs) are developed as functions of the input constraints, system\ndynamics, and disturbance bounds, such that the resultant RCBF condition on the\ncontrol input is always feasible for states in the RCBF zero sublevel set. The\nRCBF condition is then enforced in a switched fashion, which allows the system\nto operate safely without enforcing the RCBF condition when far from the safe\nset boundary and allows tuning of how closely trajectories approach the safe\nset boundary. The proposed methods are verified in simulations demonstrating\nthe developed RCBFs in an asteroid flyby scenario for a satellite with\nlow-thrust actuators, and in asteroid proximity operations for a satellite with\nhigh-thrust actuators.\n","authors":["Joseph Breeden","Dimitra Panagou"],"pdf_url":"https://arxiv.org/pdf/2107.04094v4.pdf","comment":"21 pages, extended version contains additional simulations and\n  proofs. Accepted to Automatica"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.06101v1","updated":"2023-06-09T17:59:35Z","published":"2023-06-09T17:59:35Z","title":"Prodigy: An Expeditiously Adaptive Parameter-Free Learner","summary":"  We consider the problem of estimating the learning rate in adaptive methods,\nsuch as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to\nprovably estimate the distance to the solution $D$, which is needed to set the\nlearning rate optimally. Our techniques are modifications of the D-Adaptation\nmethod for learning-rate-free learning. Our methods improve upon the\nconvergence rate of D-Adaptation by a factor of $O(\\sqrt{\\log(D/d_0)})$, where\n$d_0$ is the initial estimate of $D$. We test our methods on 12 common\nlogistic-regression benchmark datasets, VGG11 and ResNet-50 training on\nCIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on\nCriteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT\ntransformer training on BookWiki. Our experimental results show that our\napproaches consistently outperform D-Adaptation and reach test accuracy values\nclose to that of hand-tuned Adam.\n","authors":["Konstantin Mishchenko","Aaron Defazio"],"pdf_url":"https://arxiv.org/pdf/2306.06101v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06099v1","updated":"2023-06-09T17:59:16Z","published":"2023-06-09T17:59:16Z","title":"NuCLR: Nuclear Co-Learned Representations","summary":"  We introduce Nuclear Co-Learned Representations (NuCLR), a deep learning\nmodel that predicts various nuclear observables, including binding and decay\nenergies, and nuclear charge radii. The model is trained using a multi-task\napproach with shared representations and obtains state-of-the-art performance,\nachieving levels of precision that are crucial for understanding fundamental\nphenomena in nuclear (astro)physics. We also report an intriguing finding that\nthe learned representation of NuCLR exhibits the prominent emergence of crucial\naspects of the nuclear shell model, namely the shell structure, including the\nwell-known magic numbers, and the Pauli Exclusion Principle. This suggests that\nthe model is capable of capturing the underlying physical principles and that\nour approach has the potential to offer valuable insights into nuclear theory.\n","authors":["Ouail Kitouni","Niklas Nolte","Sokratis Trifinopoulos","Subhash Kantamneni","Mike Williams"],"pdf_url":"https://arxiv.org/pdf/2306.06099v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2306.06098v1","updated":"2023-06-09T17:58:47Z","published":"2023-06-09T17:58:47Z","title":"Error Feedback Can Accurately Compress Preconditioners","summary":"  Leveraging second-order information at the scale of deep networks is one of\nthe main lines of approach for improving the performance of current optimizers\nfor deep learning. Yet, existing approaches for accurate full-matrix\npreconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate\nCurvature (M-FAC) suffer from massive storage costs when applied even to\nmedium-scale models, as they must store a sliding window of gradients, whose\nmemory requirements are multiplicative in the model dimension. In this paper,\nwe address this issue via an efficient and simple-to-implement error-feedback\ntechnique that can be applied to compress preconditioners by up to two orders\nof magnitude in practice, without loss of convergence. Specifically, our\napproach compresses the gradient information via sparsification or low-rank\ncompression \\emph{before} it is fed into the preconditioner, feeding the\ncompression error back into future iterations. Extensive experiments on deep\nneural networks for vision show that this approach can compress full-matrix\npreconditioners by up to two orders of magnitude without impact on accuracy,\neffectively removing the memory overhead of full-matrix preconditioning for\nimplementations of full-matrix Adagrad (GGT) and natural gradient (M-FAC). Our\ncode is available at https://github.com/IST-DASLab/EFCP.\n","authors":["Ionut-Vlad Modoranu","Aleksei Kalinov","Eldar Kurtic","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2306.06098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04634v2","updated":"2023-06-09T17:58:04Z","published":"2023-06-07T17:58:48Z","title":"On the Reliability of Watermarks for Large Language Models","summary":"  As LLMs become commonplace, machine-generated text has the potential to flood\nthe internet with spam, social media bots, and valueless content. Watermarking\nis a simple and effective strategy for mitigating such harms by enabling the\ndetection and documentation of LLM-generated text. Yet a crucial question\nremains: How reliable is watermarking in realistic settings in the wild? There,\nwatermarked text may be modified to suit a user's needs, or entirely rewritten\nto avoid detection.\n  We study the robustness of watermarked text after it is re-written by humans,\nparaphrased by a non-watermarked LLM, or mixed into a longer hand-written\ndocument. We find that watermarks remain detectable even after human and\nmachine paraphrasing. While these attacks dilute the strength of the watermark,\nparaphrases are statistically likely to leak n-grams or even longer fragments\nof the original text, resulting in high-confidence detections when enough\ntokens are observed. For example, after strong human paraphrasing the watermark\nis detectable after observing 800 tokens on average, when setting a 1e-5 false\npositive rate. We also consider a range of new detection schemes that are\nsensitive to short spans of watermarked text embedded inside a large document,\nand we compare the robustness of watermarking to other kinds of detectors.\n","authors":["John Kirchenbauer","Jonas Geiping","Yuxin Wen","Manli Shu","Khalid Saifullah","Kezhi Kong","Kasun Fernando","Aniruddha Saha","Micah Goldblum","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2306.04634v2.pdf","comment":"14 pages in the main body. Code is available at\n  https://github.com/jwkirchenbauer/lm-watermarking"},{"id":"http://arxiv.org/abs/2306.06094v1","updated":"2023-06-09T17:57:01Z","published":"2023-06-09T17:57:01Z","title":"Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding","summary":"  Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.\n","authors":["Mu Cai","Zeyi Huang","Yuheng Li","Haohan Wang","Yong Jae Lee"],"pdf_url":"https://arxiv.org/pdf/2306.06094v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06088v1","updated":"2023-06-09T17:50:53Z","published":"2023-06-09T17:50:53Z","title":"SENS: Sketch-based Implicit Neural Shape Modeling","summary":"  We present SENS, a novel method for generating and editing 3D models from\nhand-drawn sketches, including those of an abstract nature. Our method allows\nusers to quickly and easily sketch a shape, and then maps the sketch into the\nlatent space of a part-aware neural implicit shape architecture. SENS analyzes\nthe sketch and encodes its parts into ViT patch encoding, then feeds them into\na transformer decoder that converts them to shape embeddings, suitable for\nediting 3D neural implicit shapes. SENS not only provides intuitive\nsketch-based generation and editing, but also excels in capturing the intent of\nthe user's sketch to generate a variety of novel and expressive 3D shapes, even\nfrom abstract sketches. We demonstrate the effectiveness of our model compared\nto the state-of-the-art using objective metric evaluation criteria and a\ndecisive user study, both indicating strong performance on sketches with a\nmedium level of abstraction. Furthermore, we showcase its intuitive\nsketch-based shape editing capabilities.\n","authors":["Alexandre Binninger","Amir Hertz","Olga Sorkine-Hornung","Daniel Cohen-Or","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2306.06088v1.pdf","comment":"18 pages, 18 figures"},{"id":"http://arxiv.org/abs/2306.06087v1","updated":"2023-06-09T17:49:56Z","published":"2023-06-09T17:49:56Z","title":"Learning Not to Spoof","summary":"  As intelligent trading agents based on reinforcement learning (RL) gain\nprevalence, it becomes more important to ensure that RL agents obey laws,\nregulations, and human behavioral expectations. There is substantial literature\nconcerning the aversion of obvious catastrophes like crashing a helicopter or\nbankrupting a trading account, but little around the avoidance of subtle\nnon-normative behavior for which there are examples, but no programmable\ndefinition. Such behavior may violate legal or regulatory, rather than physical\nor monetary, constraints.\n  In this article, I consider a series of experiments in which an intelligent\nstock trading agent maximizes profit but may also inadvertently learn to spoof\nthe market in which it participates. I first inject a hand-coded spoofing agent\nto a multi-agent market simulation and learn to recognize spoofing activity\nsequences. Then I replace the hand-coded spoofing trader with a simple\nprofit-maximizing RL agent and observe that it independently discovers spoofing\nas the optimal strategy. Finally, I introduce a method to incorporate the\nrecognizer as normative guide, shaping the agent's perceived rewards and\naltering its selected actions. The agent remains profitable while avoiding\nspoofing behaviors that would result in even higher profit. After presenting\nthe empirical results, I conclude with some recommendations. The method should\ngeneralize to the reduction of any unwanted behavior for which a recognizer can\nbe learned.\n","authors":["David Byrd"],"pdf_url":"https://arxiv.org/pdf/2306.06087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06063v1","updated":"2023-06-09T17:38:22Z","published":"2023-06-09T17:38:22Z","title":"Virtual Node Tuning for Few-shot Node Classification","summary":"  Few-shot Node Classification (FSNC) is a challenge in graph representation\nlearning where only a few labeled nodes per class are available for training.\nTo tackle this issue, meta-learning has been proposed to transfer structural\nknowledge from base classes with abundant labels to target novel classes.\nHowever, existing solutions become ineffective or inapplicable when base\nclasses have no or limited labeled nodes. To address this challenge, we propose\nan innovative method dubbed Virtual Node Tuning (VNT). Our approach utilizes a\npretrained graph transformer as the encoder and injects virtual nodes as soft\nprompts in the embedding space, which can be optimized with few-shot labels in\nnovel classes to modulate node embeddings for each specific FSNC task. A unique\nfeature of VNT is that, by incorporating a Graph-based Pseudo Prompt Evolution\n(GPPE) module, VNT-GPPE can handle scenarios with sparse labels in base\nclasses. Experimental results on four datasets demonstrate the superiority of\nthe proposed approach in addressing FSNC with unlabeled or sparsely labeled\nbase classes, outperforming existing state-of-the-art methods and even fully\nsupervised baselines.\n","authors":["Zhen Tan","Ruocheng Guo","Kaize Ding","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2306.06063v1.pdf","comment":"Accepted to KDD 2023"},{"id":"http://arxiv.org/abs/2306.06048v1","updated":"2023-06-09T17:16:50Z","published":"2023-06-09T17:16:50Z","title":"How Does Fine-Tuning Impact Out-of-Distribution Detection for\n  Vision-Language Models?","summary":"  Recent large vision-language models such as CLIP have shown remarkable\nout-of-distribution (OOD) detection and generalization performance. However,\ntheir zero-shot in-distribution (ID) accuracy is often limited for downstream\ndatasets. Recent CLIP-based fine-tuning methods such as prompt learning have\ndemonstrated significant improvements in ID classification and OOD\ngeneralization where OOD labels are available. Nonetheless, it remains unclear\nwhether the model is reliable to semantic shifts without OOD labels. In this\npaper, we aim to bridge the gap and present a comprehensive study to understand\nhow fine-tuning impact OOD detection for few-shot downstream tasks. By framing\nOOD detection as multi-modal concept matching, we establish a connection\nbetween fine-tuning methods and various OOD scores. Our results suggest that a\nproper choice of OOD scores is essential for CLIP-based fine-tuning. In\nparticular, the maximum concept matching (MCM) score provides a promising\nsolution consistently. We also show that prompt learning demonstrates the\nstate-of-the-art OOD detection performance over the zero-shot counterpart.\n","authors":["Yifei Ming","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2306.06048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17357v2","updated":"2023-06-09T17:11:26Z","published":"2022-10-31T14:37:41Z","title":"L-GreCo: Layerwise-Adaptive Gradient Compression for Efficient and\n  Accurate Deep Learning","summary":"  Data-parallel distributed training of deep neural networks (DNN) has gained\nvery widespread adoption, but can still experience communication bottlenecks.\nTo address this issue, entire families of compression mechanisms have been\ndeveloped, including quantization, sparsification, and low-rank approximation,\nsome of which are seeing significant practical adoption. Despite this progress,\nalmost all known compression schemes apply compression uniformly across DNN\nlayers, although layers are heterogeneous in terms of parameter count and their\nimpact on model accuracy. In this work, we provide a general framework for\nadapting the degree of compression across the model's layers dynamically during\ntraining, improving the overall compression, while leading to substantial\nspeedups, without sacrificing accuracy. Our framework, called L-GreCo, is based\non an adaptive algorithm, which automatically picks the optimal compression\nparameters for model layers guaranteeing the best compression ratio while\nsatisfying an error constraint. Extensive experiments over image classification\nand language modeling tasks shows that L-GreCo is effective across all existing\nfamilies of compression methods, and achieves up to 2.5$\\times$ training\nspeedup and up to 5$\\times$ compression improvement over efficient\nimplementations of existing approaches, while recovering full accuracy.\nMoreover, L-GreCo is complementary to existing adaptive algorithms, improving\ntheir compression ratio by 50% and practical throughput by 66%.\n","authors":["Mohammadreza Alimohammadi","Ilia Markov","Elias Frantar","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2210.17357v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06041v1","updated":"2023-06-09T17:07:04Z","published":"2023-06-09T17:07:04Z","title":"A Dynamical Graph Prior for Relational Inference","summary":"  Relational inference aims to identify interactions between parts of a\ndynamical system from the observed dynamics. Current state-of-the-art methods\nfit a graph neural network (GNN) on a learnable graph to the dynamics. They use\none-step message-passing GNNs -- intuitively the right choice since\nnon-locality of multi-step or spectral GNNs may confuse direct and indirect\ninteractions. But the \\textit{effective} interaction graph depends on the\nsampling rate and it is rarely localized to direct neighbors, leading to local\nminima for the one-step model. In this work, we propose a \\textit{dynamical\ngraph prior} (DYGR) for relational inference. The reason we call it a prior is\nthat, contrary to established practice, it constructively uses error\namplification in high-degree non-local polynomial filters to generate good\ngradients for graph learning. To deal with non-uniqueness, DYGR simultaneously\nfits a ``shallow'' one-step model with shared graph topology. Experiments show\nthat DYGR reconstructs graphs far more accurately than earlier methods, with\nremarkable robustness to under-sampling. Since appropriate sampling rates for\nunknown dynamical systems are not known a priori, this robustness makes DYGR\nsuitable for real applications in scientific machine learning.\n","authors":["Liming Pan","Cheng Shi","Ivan Dokmanić"],"pdf_url":"https://arxiv.org/pdf/2306.06041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06040v1","updated":"2023-06-09T17:05:53Z","published":"2023-06-09T17:05:53Z","title":"Reconstructing Human Expressiveness in Piano Performances with a\n  Transformer Network","summary":"  Capturing intricate and subtle variations in human expressiveness in music\nperformance using computational approaches is challenging. In this paper, we\npropose a novel approach for reconstructing human expressiveness in piano\nperformance with a multi-layer bi-directional Transformer encoder. To address\nthe needs for large amounts of accurately captured and score-aligned\nperformance data in training neural networks, we use transcribed scores\nobtained from an existing transcription model to train our model. We integrate\npianist identities to control the sampling process and explore the ability of\nour system to model variations in expressiveness for different pianists. The\nsystem is evaluated through statistical analysis of generated expressive\nperformances and a listening test. Overall, the results suggest that our method\nachieves state-of-the-art in generating human-like piano performances from\ntranscribed scores, while fully and consistently reconstructing human\nexpressiveness poses further challenges.\n","authors":["Jingjing Tang","Geraint Wiggins","George Fazekas"],"pdf_url":"https://arxiv.org/pdf/2306.06040v1.pdf","comment":"12 pages, 5 figures, submitted to CMMR 2023"},{"id":"http://arxiv.org/abs/2302.01851v3","updated":"2023-06-09T17:05:09Z","published":"2023-02-03T16:53:32Z","title":"Unsupervised hierarchical clustering using the learning dynamics of RBMs","summary":"  Datasets in the real world are often complex and to some degree hierarchical,\nwith groups and sub-groups of data sharing common characteristics at different\nlevels of abstraction. Understanding and uncovering the hidden structure of\nthese datasets is an important task that has many practical applications. To\naddress this challenge, we present a new and general method for building\nrelational data trees by exploiting the learning dynamics of the Restricted\nBoltzmann Machine (RBM). Our method is based on the mean-field approach,\nderived from the Plefka expansion, and developed in the context of disordered\nsystems. It is designed to be easily interpretable. We tested our method in an\nartificially created hierarchical dataset and on three different real-world\ndatasets (images of digits, mutations in the human genome, and a homologous\nfamily of proteins). The method is able to automatically identify the\nhierarchical structure of the data. This could be useful in the study of\nhomologous protein sequences, where the relationships between proteins are\ncritical for understanding their function and evolution.\n","authors":["Aurélien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2302.01851v3.pdf","comment":"Version accepted in Physical Review E"},{"id":"http://arxiv.org/abs/2211.15355v2","updated":"2023-06-09T17:03:15Z","published":"2022-11-28T14:34:39Z","title":"Causal Deep Reinforcement Learning Using Observational Data","summary":"  Deep reinforcement learning (DRL) requires the collection of interventional\ndata, which is sometimes expensive and even unethical in the real world, such\nas in the autonomous driving and the medical field. Offline reinforcement\nlearning promises to alleviate this issue by exploiting the vast amount of\nobservational data available in the real world. However, observational data may\nmislead the learning agent to undesirable outcomes if the behavior policy that\ngenerates the data depends on unobserved random variables (i.e., confounders).\nIn this paper, we propose two deconfounding methods in DRL to address this\nproblem. The methods first calculate the importance degree of different samples\nbased on the causal inference technique, and then adjust the impact of\ndifferent samples on the loss function by reweighting or resampling the offline\ndataset to ensure its unbiasedness. These deconfounding methods can be flexibly\ncombined with existing model-free DRL algorithms such as soft actor-critic and\ndeep Q-learning, provided that a weak condition can be satisfied by the loss\nfunctions of these algorithms. We prove the effectiveness of our deconfounding\nmethods and validate them experimentally.\n","authors":["Wenxuan Zhu","Chao Yu","Qiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.15355v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06034v1","updated":"2023-06-09T16:55:49Z","published":"2023-06-09T16:55:49Z","title":"RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows","summary":"  Physics-informed neural networks (PINNs) provide a framework to build\nsurrogate models for dynamical systems governed by differential equations.\nDuring the learning process, PINNs incorporate a physics-based regularization\nterm within the loss function to enhance generalization performance. Since\nsimulating dynamics controlled by partial differential equations (PDEs) can be\ncomputationally expensive, PINNs have gained popularity in learning parametric\nsurrogates for fluid flow problems governed by Navier-Stokes equations. In this\nwork, we introduce RANS-PINN, a modified PINN framework, to predict flow fields\n(i.e., velocity and pressure) in high Reynolds number turbulent flow regime. To\naccount for the additional complexity introduced by turbulence, RANS-PINN\nemploys a 2-equation eddy viscosity model based on a Reynolds-averaged\nNavier-Stokes (RANS) formulation. Furthermore, we adopt a novel training\napproach that ensures effective initialization and balance among the various\ncomponents of the loss function. The effectiveness of RANS-PINN framework is\nthen demonstrated using a parametric PINN.\n","authors":["Shinjan Ghosh","Amit Chakraborty","Georgia Olympia Brikis","Biswadip Dey"],"pdf_url":"https://arxiv.org/pdf/2306.06034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06031v1","updated":"2023-06-09T16:52:00Z","published":"2023-06-09T16:52:00Z","title":"FinGPT: Open-Source Financial Large Language Models","summary":"  Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}\n","authors":["Hongyang Yang","Xiao-Yang Liu","Christina Dan Wang"],"pdf_url":"https://arxiv.org/pdf/2306.06031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05359v2","updated":"2023-06-09T16:44:52Z","published":"2022-05-11T09:11:02Z","title":"Exploring Local Explanations of Nonlinear Models Using Animated Linear\n  Projections","summary":"  The increased predictive power of machine learning models comes at the cost\nof increased complexity and loss of interpretability, particularly in\ncomparison to parametric statistical models. This trade-off has led to the\nemergence of eXplainable AI (XAI) which provides methods, such as local\nexplanations (LEs) and local variable attributions (LVAs), to shed light on how\na model use predictors to arrive at a prediction. These provide a point\nestimate of the linear variable importance in the vicinity of a single\nobservation. However, LVAs tend not to effectively handle association between\npredictors. To understand how the interaction between predictors affects the\nvariable importance estimate, we can convert LVAs into linear projections and\nuse the radial tour. This is also useful for learning how a model has made a\nmistake, or the effect of outliers, or the clustering of observations. The\napproach is illustrated with examples from categorical (penguin species,\nchocolate types) and quantitative (soccer/football salaries, house prices)\nresponse models. The methods are implemented in the R package cheem, available\non CRAN.\n","authors":["Nicholas Spyrison","Dianne Cook","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2205.05359v2.pdf","comment":"26 pages, 10 figures, 0 tables"},{"id":"http://arxiv.org/abs/2306.06024v1","updated":"2023-06-09T16:42:52Z","published":"2023-06-09T16:42:52Z","title":"Self-Interpretable Time Series Prediction with Counterfactual\n  Explanations","summary":"  Interpretable time series prediction is crucial for safety-critical areas\nsuch as healthcare and autonomous driving. Most existing methods focus on\ninterpreting predictions by assigning important scores to segments of time\nseries. In this paper, we take a different and more challenging route and aim\nat developing a self-interpretable model, dubbed Counterfactual Time Series\n(CounTS), which generates counterfactual and actionable explanations for time\nseries predictions. Specifically, we formalize the problem of time series\ncounterfactual explanations, establish associated evaluation protocols, and\npropose a variational Bayesian deep learning model equipped with counterfactual\ninference capability of time series abduction, action, and prediction. Compared\nwith state-of-the-art baselines, our self-interpretable model can generate\nbetter counterfactual explanations while maintaining comparable prediction\naccuracy.\n","authors":["Jingquan Yan","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2306.06024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11181v2","updated":"2023-06-09T16:33:08Z","published":"2023-01-26T15:45:39Z","title":"Deep Laplacian-based Options for Temporally-Extended Exploration","summary":"  Selecting exploratory actions that generate a rich stream of experience for\nbetter learning is a fundamental challenge in reinforcement learning (RL). An\napproach to tackle this problem consists in selecting actions according to\nspecific policies for an extended period of time, also known as options. A\nrecent line of work to derive such exploratory options builds upon the\neigenfunctions of the graph Laplacian. Importantly, until now these methods\nhave been mostly limited to tabular domains where (1) the graph Laplacian\nmatrix was either given or could be fully estimated, (2) performing\neigendecomposition on this matrix was computationally tractable, and (3) value\nfunctions could be learned exactly. Additionally, these methods required a\nseparate option discovery phase. These assumptions are fundamentally not\nscalable. In this paper we address these limitations and show how recent\nresults for directly approximating the eigenfunctions of the Laplacian can be\nleveraged to truly scale up options-based exploration. To do so, we introduce a\nfully online deep RL algorithm for discovering Laplacian-based options and\nevaluate our approach on a variety of pixel-based tasks. We compare to several\nstate-of-the-art exploration methods and show that our approach is effective,\ngeneral, and especially promising in non-stationary settings.\n","authors":["Martin Klissarov","Marlos C. Machado"],"pdf_url":"https://arxiv.org/pdf/2301.11181v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.04820v2","updated":"2023-06-09T16:20:37Z","published":"2022-02-10T03:51:25Z","title":"L0Learn: A Scalable Package for Sparse Learning using L0 Regularization","summary":"  We present L0Learn: an open-source package for sparse linear regression and\nclassification using $\\ell_0$ regularization. L0Learn implements scalable,\napproximate algorithms, based on coordinate descent and local combinatorial\noptimization. The package is built using C++ and has user-friendly R and Python\ninterfaces. L0Learn can address problems with millions of features, achieving\ncompetitive run times and statistical performance with state-of-the-art sparse\nlearning packages. L0Learn is available on both CRAN and GitHub\n(https://cran.r-project.org/package=L0Learn and\nhttps://github.com/hazimehh/L0Learn).\n","authors":["Hussein Hazimeh","Rahul Mazumder","Tim Nonet"],"pdf_url":"https://arxiv.org/pdf/2202.04820v2.pdf","comment":"Accepted to JMLR (MLOSS)"},{"id":"http://arxiv.org/abs/2306.05998v1","updated":"2023-06-09T16:10:26Z","published":"2023-06-09T16:10:26Z","title":"Distributed Consensus Algorithm for Decision-Making in Multi-agent\n  Multi-armed Bandit","summary":"  We study a structured multi-agent multi-armed bandit (MAMAB) problem in a\ndynamic environment. A graph reflects the information-sharing structure among\nagents, and the arms' reward distributions are piecewise-stationary with\nseveral unknown change points. The agents face the identical\npiecewise-stationary MAB problem. The goal is to develop a decision-making\npolicy for the agents that minimizes the regret, which is the expected total\nloss of not playing the optimal arm at each time step. Our proposed solution,\nRestarted Bayesian Online Change Point Detection in Cooperative Upper\nConfidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agent\nUCB algorithm as its core enhanced with a Bayesian change point detector. We\nalso develop a simple restart decision cooperation that improves\ndecision-making. Theoretically, we establish that the expected group regret of\nRBO-Coop-UCB is upper bounded by $\\mathcal{O}(KNM\\log T + K\\sqrt{MT\\log T})$,\nwhere K is the number of agents, M is the number of arms, and T is the number\nof time steps. Numerical experiments on synthetic and real-world datasets\ndemonstrate that our proposed method outperforms the state-of-the-art\nalgorithms.\n","authors":["Xiaotong Cheng","Setareh Maghsudi"],"pdf_url":"https://arxiv.org/pdf/2306.05998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01255v2","updated":"2023-06-09T16:05:12Z","published":"2023-02-02T17:39:10Z","title":"adSformers: Personalization from Short-Term Sequences and Diversity of\n  Representations in Etsy Ads","summary":"  In this article, we present a general approach to personalizing ads through\nencoding and learning from variable-length sequences of recent user actions and\ndiverse representations. To this end we introduce a three-component module\ncalled the adSformer diversifiable personalization module (ADPM) that learns a\ndynamic user representation. We illustrate the module's effectiveness and\nflexibility by personalizing the Click-Through Rate (CTR) and Post-Click\nConversion Rate (PCCVR) models used in sponsored search. The first component of\nthe ADPM, the adSformer encoder, includes a novel adSformer block which learns\nthe most salient sequence signals. ADPM's second component enriches the learned\nsignal through visual, multimodal, and other pretrained representations.\nLastly, the third ADPM \"learned on the fly\" component further diversifies the\nsignal encoded in the dynamic user representation. The ADPM-personalized CTR\nand PCCVR models, henceforth referred to as adSformer CTR and adSformer PCCVR,\noutperform the CTR and PCCVR production baselines by $+2.66\\%$ and $+2.42\\%$,\nrespectively, in offline Area Under the Receiver Operating Characteristic Curve\n(ROC-AUC). Following the robust online gains in A/B tests, Etsy Ads deployed\nthe ADPM-personalized sponsored search system to $100\\%$ of traffic as of\nFebruary 2023.\n","authors":["Alaa Awad","Denisa Roberts","Eden Dolev","Andrea Heyman","Zahra Ebrahimzadeh","Zoe Weil","Marcin Mejran","Vaibhav Malpani","Mahir Yavuz"],"pdf_url":"https://arxiv.org/pdf/2302.01255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05991v1","updated":"2023-06-09T15:59:39Z","published":"2023-06-09T15:59:39Z","title":"Approximate information state based convergence analysis of recurrent\n  Q-learning","summary":"  In spite of the large literature on reinforcement learning (RL) algorithms\nfor partially observable Markov decision processes (POMDPs), a complete\ntheoretical understanding is still lacking. In a partially observable setting,\nthe history of data available to the agent increases over time so most\npractical algorithms either truncate the history to a finite window or compress\nit using a recurrent neural network leading to an agent state that is\nnon-Markovian. In this paper, it is shown that in spite of the lack of the\nMarkov property, recurrent Q-learning (RQL) converges in the tabular setting.\nMoreover, it is shown that the quality of the converged limit depends on the\nquality of the representation which is quantified in terms of what is known as\nan approximate information state (AIS). Based on this characterization of the\napproximation error, a variant of RQL with AIS losses is presented. This\nvariant performs better than a strong baseline for RQL that does not use AIS\nlosses. It is demonstrated that there is a strong correlation between the\nperformance of RQL over time and the loss associated with the AIS\nrepresentation.\n","authors":["Erfan Seyedsalehi","Nima Akbarzadeh","Amit Sinha","Aditya Mahajan"],"pdf_url":"https://arxiv.org/pdf/2306.05991v1.pdf","comment":"25 pages, 6 figures"},{"id":"http://arxiv.org/abs/2306.05989v1","updated":"2023-06-09T15:59:27Z","published":"2023-06-09T15:59:27Z","title":"Quartile-Based Seasonality Decomposition for Time Series Forecasting and\n  Anomaly Detection","summary":"  The timely detection of anomalies is essential in the telecom domain as it\nfacilitates the identification and characterization of irregular patterns,\nabnormal behaviors, and network anomalies, contributing to enhanced service\nquality and operational efficiency. Precisely forecasting and eliminating\npredictable time series patterns constitutes a vital component of time series\nanomaly detection. While the state-of-the-art methods aim to maximize\nforecasting accuracy, the computational performance takes a hit. In a system\ncomposed of a large number of time series variables, e.g., cell Key Performance\nIndicators (KPIs), the time and space complexity of the forecasting employed is\nof crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a\nlive forecasting method proposed in this paper to make an optimal trade-off\nbetween computational complexity and forecasting accuracy. This paper compares\nthe performance of QBSD to the state-of-the-art forecasting methods and their\napplicability to practical anomaly detection. To demonstrate the efficacy of\nthe proposed solution, experimental evaluation was conducted using publicly\navailable datasets as well as a telecom KPI dataset.\n","authors":["Ebenezer RHP Isaac","Bulbul Singh"],"pdf_url":"https://arxiv.org/pdf/2306.05989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.01555v4","updated":"2023-06-09T15:59:18Z","published":"2023-05-02T15:55:41Z","title":"How to Unleash the Power of Large Language Models for Few-shot Relation\n  Extraction?","summary":"  Scaling language models have revolutionized widespread NLP tasks, yet little\ncomprehensively explored few-shot relation extraction with large language\nmodels. In this paper, we investigate principal methodologies, in-context\nlearning and data generation, for few-shot relation extraction via GPT-3.5\nthrough exhaustive experiments. To enhance few-shot performance, we further\npropose task-related instructions and schema-constrained data generation. We\nobserve that in-context learning can achieve performance on par with previous\nprompt learning approaches, and data generation with the large language model\ncan boost previous solutions to obtain new state-of-the-art few-shot results on\nfour widely-studied relation extraction datasets. We hope our work can inspire\nfuture research for the capabilities of large language models in few-shot\nrelation extraction. Code is available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/llm.\n","authors":["Xin Xu","Yuqi Zhu","Xiaohan Wang","Ningyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.01555v4.pdf","comment":"SustaiNLP Workshop@ACL 2023"},{"id":"http://arxiv.org/abs/2306.05987v1","updated":"2023-06-09T15:56:06Z","published":"2023-06-09T15:56:06Z","title":"Agent market orders representation through a contrastive learning\n  approach","summary":"  Due to the access to the labeled orders on the CAC40 data from Euronext, we\nare able to analyse agents' behaviours in the market based on their placed\norders. In this study, we construct a self-supervised learning model using\ntriplet loss to effectively learn the representation of agent market orders. By\nacquiring this learned representation, various downstream tasks become\nfeasible. In this work, we utilise the K-means clustering algorithm on the\nlearned representation vectors of agent orders to identify distinct behaviour\ntypes within each cluster.\n","authors":["Ruihua Ruan","Emmanuel Bacry","Jean-François Muzy"],"pdf_url":"https://arxiv.org/pdf/2306.05987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.03860v2","updated":"2023-06-09T15:55:11Z","published":"2022-11-07T20:59:14Z","title":"Automatic Change-Point Detection in Time Series via Deep Learning","summary":"  Detecting change-points in data is challenging because of the range of\npossible types of change and types of behaviour of data when there is no\nchange. Statistically efficient methods for detecting a change will depend on\nboth of these features, and it can be difficult for a practitioner to develop\nan appropriate detection method for their application of interest. We show how\nto automatically generate new offline detection methods based on training a\nneural network. Our approach is motivated by many existing tests for the\npresence of a change-point being representable by a simple neural network, and\nthus a neural network trained with sufficient data should have performance at\nleast as good as these methods. We present theory that quantifies the error\nrate for such an approach, and how it depends on the amount of training data.\nEmpirical results show that, even with limited training data, its performance\nis competitive with the standard CUSUM-based classifier for detecting a change\nin mean when the noise is independent and Gaussian, and can substantially\noutperform it in the presence of auto-correlated or heavy-tailed noise. Our\nmethod also shows strong results in detecting and localising changes in\nactivity based on accelerometer data.\n","authors":["Jie Li","Paul Fearnhead","Piotr Fryzlewicz","Tengyao Wang"],"pdf_url":"https://arxiv.org/pdf/2211.03860v2.pdf","comment":"33 pages, 15 figures and 3 tables"},{"id":"http://arxiv.org/abs/2110.15444v3","updated":"2023-06-09T15:53:54Z","published":"2021-10-28T21:45:53Z","title":"10 Security and Privacy Problems in Large Foundation Models","summary":"  Foundation models--such as GPT, CLIP, and DINO--have achieved revolutionary\nprogress in the past several years and are commonly believed to be a promising\napproach for general-purpose AI. In particular, self-supervised learning is\nadopted to pre-train a foundation model using a large amount of unlabeled data.\nA pre-trained foundation model is like an ``operating system'' of the AI\necosystem. Specifically, a foundation model can be used as a feature extractor\nfor many downstream tasks with little or no labeled training data. Existing\nstudies on foundation models mainly focused on pre-training a better foundation\nmodel to improve its performance on downstream tasks in non-adversarial\nsettings, leaving its security and privacy in adversarial settings largely\nunexplored. A security or privacy issue of a pre-trained foundation model leads\nto a single point of failure for the AI ecosystem. In this book chapter, we\ndiscuss 10 basic security and privacy problems for the pre-trained foundation\nmodels, including six confidentiality problems, three integrity problems, and\none availability problem. For each problem, we discuss potential opportunities\nand challenges. We hope our book chapter will inspire future research on the\nsecurity and privacy of foundation models.\n","authors":["Jinyuan Jia","Hongbin Liu","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2110.15444v3.pdf","comment":"A book chapter"},{"id":"http://arxiv.org/abs/2206.01298v3","updated":"2023-06-09T15:43:27Z","published":"2022-06-02T20:46:26Z","title":"A memory-efficient neural ODE framework based on high-level adjoint\n  differentiation","summary":"  Neural ordinary differential equations (neural ODEs) have emerged as a novel\nnetwork architecture that bridges dynamical systems and deep learning. However,\nthe gradient obtained with the continuous adjoint method in the vanilla neural\nODE is not reverse-accurate. Other approaches suffer either from an excessive\nmemory requirement due to deep computational graphs or from limited choices for\nthe time integration scheme, hampering their application to large-scale complex\ndynamical systems. To achieve accurate gradients without compromising memory\nefficiency and flexibility, we present a new neural ODE framework, PNODE, based\non high-level discrete adjoint algorithmic differentiation. By leveraging\ndiscrete adjoint time integrators and advanced checkpointing strategies\ntailored for these integrators, PNODE can provide a balance between memory and\ncomputational costs, while computing the gradients consistently and accurately.\nWe provide an open-source implementation based on PyTorch and PETSc, one of the\nmost commonly used portable, scalable scientific computing libraries. We\ndemonstrate the performance through extensive numerical experiments on image\nclassification and continuous normalizing flow problems. We show that PNODE\nachieves the highest memory efficiency when compared with other\nreverse-accurate methods. On the image classification problems, PNODE is up to\ntwo times faster than the vanilla neural ODE and up to 2.3 times faster than\nthe best existing reverse-accurate method. We also show that PNODE enables the\nuse of the implicit time integration methods that are needed for stiff\ndynamical systems.\n","authors":["Hong Zhang","Wenjun Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.01298v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05965v1","updated":"2023-06-09T15:33:30Z","published":"2023-06-09T15:33:30Z","title":"Automating Model Comparison in Factor Graphs","summary":"  Bayesian state and parameter estimation have been automated effectively in\nthe literature, however, this has not yet been the case for model comparison,\nwhich therefore still requires error-prone and time-consuming manual\nderivations. As a result, model comparison is often overlooked and ignored,\ndespite its importance. This paper efficiently automates Bayesian model\naveraging, selection, and combination by message passing on a Forney-style\nfactor graph with a custom mixture node. Parameter and state inference, and\nmodel comparison can then be executed simultaneously using message passing with\nscale factors. This approach shortens the model design cycle and allows for the\nstraightforward extension to hierarchical and temporal model priors to\naccommodate for modeling complicated time-varying processes.\n","authors":["Bart van Erp","Wouter W. L. Nuijten","Thijs van de Laar","Bert de Vries"],"pdf_url":"https://arxiv.org/pdf/2306.05965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05963v1","updated":"2023-06-09T15:29:54Z","published":"2023-06-09T15:29:54Z","title":"Adaptive Contextual Perception: How to Generalize to New Backgrounds and\n  Ambiguous Objects","summary":"  Biological vision systems make adaptive use of context to recognize objects\nin new settings with novel contexts as well as occluded or blurry objects in\nfamiliar settings. In this paper, we investigate how vision models adaptively\nuse context for out-of-distribution (OOD) generalization and leverage our\nanalysis results to improve model OOD generalization. First, we formulate two\ndistinct OOD settings where the contexts are either irrelevant\n(Background-Invariance) or beneficial (Object-Disambiguation), reflecting the\ndiverse contextual challenges faced in biological vision. We then analyze model\nperformance in these two different OOD settings and demonstrate that models\nthat excel in one setting tend to struggle in the other. Notably, prior works\non learning causal features improve on one setting but hurt in the other. This\nunderscores the importance of generalizing across both OOD settings, as this\nability is crucial for both human cognition and robust AI systems. Next, to\nbetter understand the model properties contributing to OOD generalization, we\nuse representational geometry analysis and our own probing methods to examine a\npopulation of models, and we discover that those with more factorized\nrepresentations and appropriate feature weighting are more successful in\nhandling Background-Invariance and Object-Disambiguation tests. We further\nvalidate these findings through causal intervention on representation\nfactorization and feature weighting to demonstrate their causal effect on\nperformance. Lastly, we propose new augmentation methods to enhance model\ngeneralization. These methods outperform strong baselines, yielding\nimprovements in both in-distribution and OOD tests. In conclusion, to replicate\nthe generalization abilities of biological vision, computer vision models must\nhave factorized object vs. background representations and appropriately weight\nboth kinds of features.\n","authors":["Zhuofan Ying","Peter Hase","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2306.05963v1.pdf","comment":"21 pages, 12 figures. Our code is available at\n  https://github.com/zfying/AdaptiveContext"},{"id":"http://arxiv.org/abs/2306.05957v1","updated":"2023-06-09T15:17:13Z","published":"2023-06-09T15:17:13Z","title":"DDLP: Unsupervised Object-Centric Video Prediction with Deep Dynamic\n  Latent Particles","summary":"  We propose a new object-centric video prediction algorithm based on the deep\nlatent particle (DLP) representation. In comparison to existing slot- or\npatch-based representations, DLPs model the scene using a set of keypoints with\nlearned parameters for properties such as position and size, and are both\nefficient and interpretable. Our method, deep dynamic latent particles (DDLP),\nyields state-of-the-art object-centric video prediction results on several\nchallenging datasets. The interpretable nature of DDLP allows us to perform\n``what-if'' generation -- predict the consequence of changing properties of\nobjects in the initial frames, and DLP's compact structure enables efficient\ndiffusion-based unconditional video generation. Videos, code and pre-trained\nmodels are available: https://taldatech.github.io/ddlp-web\n","authors":["Tal Daniel","Aviv Tamar"],"pdf_url":"https://arxiv.org/pdf/2306.05957v1.pdf","comment":"Project site: https://taldatech.github.io/ddlp-web"},{"id":"http://arxiv.org/abs/2203.14572v2","updated":"2023-06-09T15:15:14Z","published":"2022-03-28T08:26:14Z","title":"Distributed Task Management in Fog Computing: A Socially Concave Bandit\n  Game","summary":"  Fog computing leverages the task offloading capabilities at the network's\nedge to improve efficiency and enable swift responses to application demands.\nHowever, the design of task allocation strategies in a fog computing network is\nstill challenging because of the heterogeneity of fog nodes and uncertainties\nin system dynamics. We formulate the distributed task allocation problem as a\nsocial-concave game with bandit feedback and show that the game has a unique\nNash equilibrium, which is implementable using no-regret learning strategies\n(regret with sublinear growth). We then develop two no-regret online\ndecision-making strategies. One strategy, namely bandit gradient ascent with\nmomentum, is an online convex optimization algorithm with bandit feedback. The\nother strategy, Lipschitz bandit with initialization, is an EXP3 multi-armed\nbandit algorithm. We establish regret bounds for both strategies and analyze\ntheir convergence characteristics. Moreover, we compare the proposed strategies\nwith an allocation strategy named learning with linear rewards. Theoretical-\nand numerical analysis shows the superior performance of the proposed\nstrategies for efficient task allocation compared to the state-of-the-art\nmethods.\n","authors":["Xiaotong Cheng","Setareh Maghsudi"],"pdf_url":"https://arxiv.org/pdf/2203.14572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05955v1","updated":"2023-06-09T15:11:49Z","published":"2023-06-09T15:11:49Z","title":"Path Neural Networks: Expressive and Accurate Graph Neural Networks","summary":"  Graph neural networks (GNNs) have recently become the standard approach for\nlearning with graph-structured data. Prior work has shed light into their\npotential, but also their limitations. Unfortunately, it was shown that\nstandard GNNs are limited in their expressive power. These models are no more\npowerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms of\ndistinguishing non-isomorphic graphs. In this paper, we propose Path Neural\nNetworks (PathNNs), a model that updates node representations by aggregating\npaths emanating from nodes. We derive three different variants of the PathNN\nmodel that aggregate single shortest paths, all shortest paths and all simple\npaths of length up to K. We prove that two of these variants are strictly more\npowerful than the 1-WL algorithm, and we experimentally validate our\ntheoretical results. We find that PathNNs can distinguish pairs of\nnon-isomorphic graphs that are indistinguishable by 1-WL, while our most\nexpressive PathNN variant can even distinguish between 3-WL indistinguishable\ngraphs. The different PathNN variants are also evaluated on graph\nclassification and graph regression datasets, where in most cases, they\noutperform the baseline methods.\n","authors":["Gaspard Michel","Giannis Nikolentzos","Johannes Lutzeyer","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2306.05955v1.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.05952v1","updated":"2023-06-09T15:09:16Z","published":"2023-06-09T15:09:16Z","title":"Overcoming Adversarial Attacks for Human-in-the-Loop Applications","summary":"  Including human analysis has the potential to positively affect the\nrobustness of Deep Neural Networks and is relatively unexplored in the\nAdversarial Machine Learning literature. Neural network visual explanation maps\nhave been shown to be prone to adversarial attacks. Further research is needed\nin order to select robust visualizations of explanations for the image analyst\nto evaluate a given model. These factors greatly impact Human-In-The-Loop\n(HITL) evaluation tools due to their reliance on adversarial images, including\nexplanation maps and measurements of robustness. We believe models of human\nvisual attention may improve interpretability and robustness of human-machine\nimagery analysis systems. Our challenge remains, how can HITL evaluation be\nrobust in this adversarial landscape?\n","authors":["Ryan McCoppin","Marla Kennedy","Platon Lukyanenko","Sean Kennedy"],"pdf_url":"https://arxiv.org/pdf/2306.05952v1.pdf","comment":"New Frontiers in Adversarial Machine Learning, ICML 2022"},{"id":"http://arxiv.org/abs/2208.07365v2","updated":"2023-06-09T15:06:02Z","published":"2022-08-15T17:59:31Z","title":"Unsupervised Video Domain Adaptation for Action Recognition: A\n  Disentanglement Perspective","summary":"  Unsupervised video domain adaptation is a practical yet challenging task. In\nthis work, for the first time, we tackle it from a disentanglement view. Our\nkey idea is to handle the spatial and temporal domain divergence separately\nthrough disentanglement. Specifically, we consider the generation of\ncross-domain videos from two sets of latent factors, one encoding the static\ninformation and another encoding the dynamic information. A Transfer Sequential\nVAE (TranSVAE) framework is then developed to model such generation. To better\nserve for adaptation, we propose several objectives to constrain the latent\nfactors. With these constraints, the spatial divergence can be readily removed\nby disentangling the static domain-specific information out, and the temporal\ndivergence is further reduced from both frame- and video-levels through\nadversarial learning. Extensive experiments on the UCF-HMDB, Jester, and\nEpic-Kitchens datasets verify the effectiveness and superiority of TranSVAE\ncompared with several state-of-the-art methods. The code with reproducible\nresults is publicly accessible.\n","authors":["Pengfei Wei","Lingdong Kong","Xinghua Qu","Yi Ren","Zhiqiang Xu","Jing Jiang","Xiang Yin"],"pdf_url":"https://arxiv.org/pdf/2208.07365v2.pdf","comment":"18 pages, 9 figures, 7 tables. Code at\n  https://github.com/ldkong1205/TranSVAE"},{"id":"http://arxiv.org/abs/2306.05951v1","updated":"2023-06-09T15:05:40Z","published":"2023-06-09T15:05:40Z","title":"Prediction of Transportation Index for Urban Patterns in Small and\n  Medium-sized Indian Cities using Hybrid RidgeGAN Model","summary":"  The rapid urbanization trend in most developing countries including India is\ncreating a plethora of civic concerns such as loss of green space, degradation\nof environmental health, clean water availability, air pollution, traffic\ncongestion leading to delays in vehicular transportation, etc. Transportation\nand network modeling through transportation indices have been widely used to\nunderstand transportation problems in the recent past. This necessitates\npredicting transportation indices to facilitate sustainable urban planning and\ntraffic management. Recent advancements in deep learning research, in\nparticular, Generative Adversarial Networks (GANs), and their modifications in\nspatial data analysis such as CityGAN, Conditional GAN, and MetroGAN have\nenabled urban planners to simulate hyper-realistic urban patterns. These\nsynthetic urban universes mimic global urban patterns and evaluating their\nlandscape structures through spatial pattern analysis can aid in comprehending\nlandscape dynamics, thereby enhancing sustainable urban planning. This research\naddresses several challenges in predicting the urban transportation index for\nsmall and medium-sized Indian cities. A hybrid framework based on Kernel Ridge\nRegression (KRR) and CityGAN is introduced to predict transportation index\nusing spatial indicators of human settlement patterns. This paper establishes a\nrelationship between the transportation index and human settlement indicators\nand models it using KRR for the selected 503 Indian cities. The proposed hybrid\npipeline, we call it RidgeGAN model, can evaluate the sustainability of urban\nsprawl associated with infrastructure development and transportation systems in\nsprawling cities. Experimental results show that the two-step pipeline approach\noutperforms existing benchmarks based on spatial and statistical measures.\n","authors":["Rahisha Thottolil","Uttam Kumar","Tanujit Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2306.05951v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14306v4","updated":"2023-06-09T15:03:06Z","published":"2022-10-25T20:01:15Z","title":"Reading Between the Lines: Modeling User Behavior and Costs in\n  AI-Assisted Programming","summary":"  Code-recommendation systems, such as Copilot and CodeWhisperer, have the\npotential to improve programmer productivity by suggesting and auto-completing\ncode. However, to fully realize their potential, we must understand how\nprogrammers interact with these systems and identify ways to improve that\ninteraction. To make progress, we studied GitHub Copilot, a code-recommendation\nsystem used by millions of programmers daily. We developed CUPS, a taxonomy of\ncommon programmer activities when interacting with Copilot. Our study of 21\nprogrammers, who completed coding tasks and retrospectively labeled their\nsessions with CUPS, showed that CUPS can help us understand how programmers\ninteract with code-recommendation systems, revealing inefficiencies and time\ncosts. Our insights reveal how programmers interact with Copilot and motivate\nnew interface designs and metrics.\n","authors":["Hussein Mozannar","Gagan Bansal","Adam Fourney","Eric Horvitz"],"pdf_url":"https://arxiv.org/pdf/2210.14306v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05937v1","updated":"2023-06-09T14:56:06Z","published":"2023-06-09T14:56:06Z","title":"Robust Data-driven Prescriptiveness Optimization","summary":"  The abundance of data has led to the emergence of a variety of optimization\ntechniques that attempt to leverage available side information to provide more\nanticipative decisions. The wide range of methods and contexts of application\nhave motivated the design of a universal unitless measure of performance known\nas the coefficient of prescriptiveness. This coefficient was designed to\nquantify both the quality of contextual decisions compared to a reference one\nand the prescriptive power of side information. To identify policies that\nmaximize the former in a data-driven context, this paper introduces a\ndistributionally robust contextual optimization model where the coefficient of\nprescriptiveness substitutes for the classical empirical risk minimization\nobjective. We present a bisection algorithm to solve this model, which relies\non solving a series of linear programs when the distributional ambiguity set\nhas an appropriate nested form and polyhedral structure. Studying a contextual\nshortest path problem, we evaluate the robustness of the resulting policies\nagainst alternative methods when the out-of-sample dataset is subject to\nvarying amounts of distribution shift.\n","authors":["Mehran Poursoltani","Erick Delage","Angelos Georghiou"],"pdf_url":"https://arxiv.org/pdf/2306.05937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10911v3","updated":"2023-06-09T14:49:41Z","published":"2023-02-14T07:52:21Z","title":"Revisiting Weighted Aggregation in Federated Learning with Neural\n  Networks","summary":"  In federated learning (FL), weighted aggregation of local models is conducted\nto generate a global model, and the aggregation weights are normalized (the sum\nof weights is 1) and proportional to the local data sizes. In this paper, we\nrevisit the weighted aggregation process and gain new insights into the\ntraining dynamics of FL. First, we find that the sum of weights can be smaller\nthan 1, causing global weight shrinking effect (analogous to weight decay) and\nimproving generalization. We explore how the optimal shrinking factor is\naffected by clients' data heterogeneity and local epochs. Second, we dive into\nthe relative aggregation weights among clients to depict the clients'\nimportance. We develop client coherence to study the learning dynamics and find\na critical point that exists. Before entering the critical point, more coherent\nclients play more essential roles in generalization. Based on the above\ninsights, we propose an effective method for Federated Learning with Learnable\nAggregation Weights, named as FedLAW. Extensive experiments verify that our\nmethod can improve the generalization of the global model by a large margin on\ndifferent datasets and models.\n","authors":["Zexi Li","Tao Lin","Xinyi Shang","Chao Wu"],"pdf_url":"https://arxiv.org/pdf/2302.10911v3.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2203.13617v2","updated":"2023-06-09T14:45:18Z","published":"2022-03-25T12:35:44Z","title":"EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion\n  Recognition","summary":"  Speech emotion recognition (SER) is an important research topic in\nhuman-computer interaction. Existing works mainly rely on human expertise to\ndesign models. Despite their success, different datasets often require distinct\nstructures and hyperparameters. Searching for an optimal model for each dataset\nis time-consuming and labor-intensive. To address this problem, we propose a\ntwo-stream neural architecture search (NAS) based framework, called\n\\enquote{EmotionNAS}. Specifically, we take two-stream features (i.e.,\nhandcrafted and deep features) as the inputs, followed by NAS to search for the\noptimal structure for each stream. Furthermore, we incorporate complementary\ninformation in different streams through an efficient information supplement\nmodule. Experimental results demonstrate that our method outperforms existing\nmanually-designed and NAS-based models, setting the new state-of-the-art\nrecord.\n","authors":["Haiyang Sun","Zheng Lian","Bin Liu","Ying Li","Licai Sun","Cong Cai","Jianhua Tao","Meng Wang","Yuan Cheng"],"pdf_url":"https://arxiv.org/pdf/2203.13617v2.pdf","comment":"Accepted to Interspeech 2023"},{"id":"http://arxiv.org/abs/2302.00163v3","updated":"2023-06-09T14:26:29Z","published":"2023-02-01T00:52:55Z","title":"FLSTRA: Federated Learning in Stratosphere","summary":"  We propose a federated learning (FL) in stratosphere (FLSTRA) system, where a\nhigh altitude platform station (HAPS) facilitates a large number of terrestrial\nclients to collaboratively learn a global model without sharing the training\ndata. FLSTRA overcomes the challenges faced by FL in terrestrial networks, such\nas slow convergence and high communication delay due to limited client\nparticipation and multi-hop communications. HAPS leverages its altitude and\nsize to allow the participation of more clients with line-of-sight (LOS) links\nand the placement of a powerful server. However, handling many clients at once\nintroduces computing and transmission delays. Thus, we aim to obtain a\ndelay-accuracy trade-off for FLSTRA. Specifically, we first develop a joint\nclient selection and resource allocation algorithm for uplink and downlink to\nminimize the FL delay subject to the energy and quality-of-service (QoS)\nconstraints. Second, we propose a communication and computation resource-aware\n(CCRA-FL) algorithm to achieve the target FL accuracy while deriving an upper\nbound for its convergence rate. The formulated problem is non-convex; thus, we\npropose an iterative algorithm to solve it. Simulation results demonstrate the\neffectiveness of the proposed FLSTRA system, compared to terrestrial\nbenchmarks, in terms of FL delay and accuracy.\n","authors":["Amin Farajzadeh","Animesh Yadav","Omid Abbasi","Wael Jaafar","Halim Yanikomeroglu"],"pdf_url":"https://arxiv.org/pdf/2302.00163v3.pdf","comment":"Accepted to IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2206.13378v2","updated":"2023-06-09T14:22:16Z","published":"2022-06-27T15:37:54Z","title":"Guillotine Regularization: Why removing layers is needed to improve\n  generalization in Self-Supervised Learning","summary":"  One unexpected technique that emerged in recent years consists in training a\nDeep Network (DN) with a Self-Supervised Learning (SSL) method, and using this\nnetwork on downstream tasks but with its last few projector layers entirely\nremoved. This trick of throwing away the projector is actually critical for SSL\nmethods to display competitive performances on ImageNet for which more than 30\npercentage points can be gained that way. This is a little vexing, as one would\nhope that the network layer at which invariance is explicitly enforced by the\nSSL criterion during training (the last projector layer) should be the one to\nuse for best generalization performance downstream. But it seems not to be, and\nthis study sheds some light on why. This trick, which we name Guillotine\nRegularization (GR), is in fact a generically applicable method that has been\nused to improve generalization performance in transfer learning scenarios. In\nthis work, we identify the underlying reasons behind its success and show that\nthe optimal layer to use might change significantly depending on the training\nsetup, the data or the downstream task. Lastly, we give some insights on how to\nreduce the need for a projector in SSL by aligning the pretext SSL task and the\ndownstream task.\n","authors":["Florian Bordes","Randall Balestriero","Quentin Garrido","Adrien Bardes","Pascal Vincent"],"pdf_url":"https://arxiv.org/pdf/2206.13378v2.pdf","comment":"Accepted at TMLR 2023"},{"id":"http://arxiv.org/abs/2306.05915v1","updated":"2023-06-09T14:11:07Z","published":"2023-06-09T14:11:07Z","title":"Speaker Embeddings as Individuality Proxy for Voice Stress Detection","summary":"  Since the mental states of the speaker modulate speech, stress introduced by\ncognitive or physical loads could be detected in the voice. The existing voice\nstress detection benchmark has shown that the audio embeddings extracted from\nthe Hybrid BYOL-S self-supervised model perform well. However, the benchmark\nonly evaluates performance separately on each dataset, but does not evaluate\nperformance across the different types of stress and different languages.\nMoreover, previous studies found strong individual differences in stress\nsusceptibility. This paper presents the design and development of voice stress\ndetection, trained on more than 100 speakers from 9 language groups and five\ndifferent types of stress. We address individual variabilities in voice stress\nanalysis by adding speaker embeddings to the hybrid BYOL-S features. The\nproposed method significantly improves voice stress detection performance with\nan input audio length of only 3-5 seconds.\n","authors":["Zihan Wu","Neil Scheidwasser-Clow","Karl El Hajal","Milos Cernak"],"pdf_url":"https://arxiv.org/pdf/2306.05915v1.pdf","comment":"5 pages, 2 figures. Accepted at Interspeech 2023"},{"id":"http://arxiv.org/abs/2306.05907v1","updated":"2023-06-09T14:02:53Z","published":"2023-06-09T14:02:53Z","title":"2DeteCT -- A large 2D expandable, trainable, experimental Computed\n  Tomography dataset for machine learning","summary":"  Recent research in computational imaging largely focuses on developing\nmachine learning (ML) techniques for image reconstruction, which requires\nlarge-scale training datasets consisting of measurement data and ground-truth\nimages. However, suitable experimental datasets for X-ray Computed Tomography\n(CT) are scarce, and methods are often developed and evaluated only on\nsimulated data. We fill this gap by providing the community with a versatile,\nopen 2D fan-beam CT dataset suitable for developing ML techniques for a range\nof image reconstruction tasks. To acquire it, we designed a sophisticated,\nsemi-automatic scan procedure that utilizes a highly-flexible laboratory X-ray\nCT setup. A diverse mix of samples with high natural variability in shape and\ndensity was scanned slice-by-slice (5000 slices in total) with high angular and\nspatial resolution and three different beam characteristics: A high-fidelity, a\nlow-dose and a beam-hardening-inflicted mode. In addition, 750\nout-of-distribution slices were scanned with sample and beam variations to\naccommodate robustness and segmentation tasks. We provide raw projection data,\nreference reconstructions and segmentations based on an open-source data\nprocessing pipeline.\n","authors":["Maximilian B. Kiss","Sophia B. Coban","K. Joost Batenburg","Tristan van Leeuwen","Felix Lucka"],"pdf_url":"https://arxiv.org/pdf/2306.05907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05905v1","updated":"2023-06-09T14:01:26Z","published":"2023-06-09T14:01:26Z","title":"TreeDQN: Learning to minimize Branch-and-Bound tree","summary":"  Combinatorial optimization problems require an exhaustive search to find the\noptimal solution. A convenient approach to solving combinatorial optimization\ntasks in the form of Mixed Integer Linear Programs is Branch-and-Bound.\nBranch-and-Bound solver splits a task into two parts dividing the domain of an\ninteger variable, then it solves them recursively, producing a tree of nested\nsub-tasks. The efficiency of the solver depends on the branchning heuristic\nused to select a variable for splitting. In the present work, we propose a\nreinforcement learning method that can efficiently learn the branching\nheuristic. We view the variable selection task as a tree Markov Decision\nProcess, prove that the Bellman operator adapted for the tree Markov Decision\nProcess is contracting in mean, and propose a modified learning objective for\nthe reinforcement learning agent. Our agent requires less training data and\nproduces smaller trees compared to previous reinforcement learning methods.\n","authors":["Dmitry Sorokin","Alexander Kostin"],"pdf_url":"https://arxiv.org/pdf/2306.05905v1.pdf","comment":"Submitted to NeurIPS 2023"},{"id":"http://arxiv.org/abs/2204.08335v2","updated":"2023-06-09T13:51:13Z","published":"2022-04-18T14:27:31Z","title":"Active Learning with Weak Supervision for Gaussian Processes","summary":"  Annotating data for supervised learning can be costly. When the annotation\nbudget is limited, active learning can be used to select and annotate those\nobservations that are likely to give the most gain in model performance. We\npropose an active learning algorithm that, in addition to selecting which\nobservation to annotate, selects the precision of the annotation that is\nacquired. Assuming that annotations with low precision are cheaper to obtain,\nthis allows the model to explore a larger part of the input space, with the\nsame annotation budget. We build our acquisition function on the previously\nproposed BALD objective for Gaussian Processes, and empirically demonstrate the\ngains of being able to adjust the annotation precision in the active learning\nloop.\n","authors":["Amanda Olmin","Jakob Lindqvist","Lennart Svensson","Fredrik Lindsten"],"pdf_url":"https://arxiv.org/pdf/2204.08335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01986v2","updated":"2023-06-09T13:46:50Z","published":"2023-06-03T02:47:46Z","title":"A Novel Correlation-optimized Deep Learning Method for Wind Speed\n  Forecast","summary":"  The increasing installation rate of wind power poses great challenges to the\nglobal power system. In order to ensure the reliable operation of the power\nsystem, it is necessary to accurately forecast the wind speed and power of the\nwind turbines. At present, deep learning is progressively applied to the wind\nspeed prediction. Nevertheless, the recent deep learning methods still reflect\nthe embarrassment for practical applications due to model interpretability and\nhardware limitation. To this end, a novel deep knowledge-based learning method\nis proposed in this paper. The proposed method hybridizes pre-training method\nand auto-encoder structure to improve data representation and modeling of the\ndeep knowledge-based learning framework. In order to form knowledge and\ncorresponding absorbers, the original data is preprocessed by an optimization\nmodel based on correlation to construct multi-layer networks (knowledge) which\nare absorbed by sequence to sequence (Seq2Seq) models. Specifically, new\ncognition and memory units (CMU) are designed to reinforce traditional deep\nlearning framework. Finally, the effectiveness of the proposed method is\nverified by three wind prediction cases from a wind farm in Liaoning, China.\nExperimental results show that the proposed method increases the stability and\ntraining efficiency compared to the traditional LSTM method and LSTM/GRU-based\nSeq2Seq method for applications of wind speed forecasting.\n","authors":["Yang Yang","Jin Lang","Jian Wu","Yanyan Zhang","Xiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.01986v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05889v1","updated":"2023-06-09T13:35:04Z","published":"2023-06-09T13:35:04Z","title":"C(NN)FD -- a deep learning framework for turbomachinery CFD analysis","summary":"  Deep Learning methods have seen a wide range of successful applications\nacross different industries. Up until now, applications to physical simulations\nsuch as CFD (Computational Fluid Dynamics), have been limited to simple\ntest-cases of minor industrial relevance. This paper demonstrates the\ndevelopment of a novel deep learning framework for real-time predictions of the\nimpact of manufacturing and build variations on the overall performance of\naxial compressors in gas turbines, with a focus on tip clearance variations.\nThe associated scatter in efficiency can significantly increase the $CO_2$\nemissions, thus being of great industrial and environmental relevance. The\nproposed \\textit{C(NN)FD} architecture achieves in real-time accuracy\ncomparable to the CFD benchmark. Predicting the flow field and using it to\ncalculate the corresponding overall performance renders the methodology\ngeneralisable, while filtering only relevant parts of the CFD solution makes\nthe methodology scalable to industrial applications.\n","authors":["Giuseppe Bruni","Sepehr Maleki","Senthil K. Krishnababu"],"pdf_url":"https://arxiv.org/pdf/2306.05889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01642v2","updated":"2023-06-09T13:32:29Z","published":"2023-01-04T14:36:44Z","title":"CI-GNN: A Granger Causality-Inspired Graph Neural Network for\n  Interpretable Brain Network-Based Psychiatric Diagnosis","summary":"  There is a recent trend to leverage the power of graph neural networks (GNNs)\nfor brain-network based psychiatric diagnosis, which,in turn, also motivates an\nurgent need for psychiatrists to fully understand the decision behavior of the\nused GNNs. However, most of the existing GNN explainers are either post-hoc in\nwhich another interpretive model needs to be created to explain a well-trained\nGNN, or do not consider the causal relationship between the extracted\nexplanation and the decision, such that the explanation itself contains\nspurious correlations and suffers from weak faithfulness. In this work, we\npropose a granger causality-inspired graph neural network (CI-GNN), a built-in\ninterpretable model that is able to identify the most influential subgraph\n(i.e., functional connectivity within brain regions) that is causally related\nto the decision (e.g., major depressive disorder patients or healthy controls),\nwithout the training of an auxillary interpretive network. CI-GNN learns\ndisentangled subgraph-level representations {\\alpha} and \\b{eta} that encode,\nrespectively, the causal and noncausal aspects of original graph under a graph\nvariational autoencoder framework, regularized by a conditional mutual\ninformation (CMI) constraint. We theoretically justify the validity of the CMI\nregulation in capturing the causal relationship. We also empirically evaluate\nthe performance of CI-GNN against three baseline GNNs and four state-of-the-art\nGNN explainers on synthetic data and three large-scale brain disease datasets.\nWe observe that CI-GNN achieves the best performance in a wide range of metrics\nand provides more reliable and concise explanations which have clinical\nevidence.\n","authors":["Kaizhong Zheng","Shujian Yu","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2301.01642v2.pdf","comment":"45 pages, 13 figures"},{"id":"http://arxiv.org/abs/2205.15239v2","updated":"2023-06-09T13:30:44Z","published":"2022-05-30T16:53:16Z","title":"Conformal Credal Self-Supervised Learning","summary":"  In semi-supervised learning, the paradigm of self-training refers to the idea\nof learning from pseudo-labels suggested by the learner itself. Across various\ndomains, corresponding methods have proven effective and achieve\nstate-of-the-art performance. However, pseudo-labels typically stem from ad-hoc\nheuristics, relying on the quality of the predictions though without\nguaranteeing their validity. One such method, so-called credal self-supervised\nlearning, maintains pseudo-supervision in the form of sets of (instead of\nsingle) probability distributions over labels, thereby allowing for a flexible\nyet uncertainty-aware labeling. Again, however, there is no justification\nbeyond empirical effectiveness. To address this deficiency, we make use of\nconformal prediction, an approach that comes with guarantees on the validity of\nset-valued predictions. As a result, the construction of credal sets of labels\nis supported by a rigorous theoretical foundation, leading to better calibrated\nand less error-prone supervision for unlabeled data. Along with this, we\npresent effective algorithms for learning from credal self-supervision. An\nempirical study demonstrates excellent calibration properties of the\npseudo-supervision, as well as the competitiveness of our method on several\nbenchmark datasets.\n","authors":["Julian Lienen","Caglar Demir","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2205.15239v2.pdf","comment":"26 pages, 5 figures, 10 tables, to be published at the 12th Symposium\n  on Conformal and Probabilistic Prediction with Applications (COPA 2023)"},{"id":"http://arxiv.org/abs/2302.06280v3","updated":"2023-06-09T13:27:31Z","published":"2023-02-13T11:35:59Z","title":"Causal Strategic Classification: A Tale of Two Shifts","summary":"  When users can benefit from certain predictive outcomes, they may be prone to\nact to achieve those outcome, e.g., by strategically modifying their features.\nThe goal in strategic classification is therefore to train predictive models\nthat are robust to such behavior. However, the conventional framework assumes\nthat changing features does not change actual outcomes, which depicts users as\n\"gaming\" the system. Here we remove this assumption, and study learning in a\ncausal strategic setting where true outcomes do change. Focusing on accuracy as\nour primary objective, we show how strategic behavior and causal effects\nunderlie two complementing forms of distribution shift. We characterize these\nshifts, and propose a learning algorithm that balances between these two forces\nand over time, and permits end-to-end training. Experiments on synthetic and\nsemi-synthetic data demonstrate the utility of our approach.\n","authors":["Guy Horowitz","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2302.06280v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05880v1","updated":"2023-06-09T13:20:04Z","published":"2023-06-09T13:20:04Z","title":"Time Series Continuous Modeling for Imputation and Forecasting with\n  Implicit Neural Representations","summary":"  Although widely explored, time series modeling continues to encounter\nsignificant challenges when confronted with real-world data. We propose a novel\nmodeling approach leveraging Implicit Neural Representations (INR). This\napproach enables us to effectively capture the continuous aspect of time series\nand provides a natural solution to recurring modeling issues such as handling\nmissing data, dealing with irregular sampling, or unaligned observations from\nmultiple sensors. By introducing conditional modulation of INR parameters and\nleveraging meta-learning techniques, we address the issue of generalization to\nboth unseen samples and time window shifts. Through extensive experimentation,\nour model demonstrates state-of-the-art performance in forecasting and\nimputation tasks, while exhibiting flexibility in handling a wide range of\nchallenging scenarios that competing models cannot.\n","authors":["Etienne Le Naour","Louis Serrano","Léon Migus","Yuan Yin","patrick gallinari","Ghislain Agoua","Nicolas Baskiotis","Vincent Guigue"],"pdf_url":"https://arxiv.org/pdf/2306.05880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05879v1","updated":"2023-06-09T13:18:50Z","published":"2023-06-09T13:18:50Z","title":"Is Normalization Indispensable for Multi-domain Federated Learning?","summary":"  Federated learning (FL) enhances data privacy with collaborative in-situ\ntraining on decentralized clients. Nevertheless, FL encounters challenges due\nto non-independent and identically distributed (non-i.i.d) data, leading to\npotential performance degradation and hindered convergence. While prior studies\npredominantly addressed the issue of skewed label distribution, our research\naddresses a crucial yet frequently overlooked problem known as multi-domain FL.\nIn this scenario, clients' data originate from diverse domains with distinct\nfeature distributions, as opposed to label distributions. To address the\nmulti-domain problem in FL, we propose a novel method called Federated learning\nWithout normalizations (FedWon). FedWon draws inspiration from the observation\nthat batch normalization (BN) faces challenges in effectively modeling the\nstatistics of multiple domains, while alternative normalization techniques\npossess their own limitations. In order to address these issues, FedWon\neliminates all normalizations in FL and reparameterizes convolution layers with\nscaled weight standardization. Through comprehensive experimentation on four\ndatasets and four models, our results demonstrate that FedWon surpasses both\nFedAvg and the current state-of-the-art method (FedBN) across all experimental\nsetups, achieving notable improvements of over 10% in certain domains.\nFurthermore, FedWon is versatile for both cross-silo and cross-device FL,\nexhibiting strong performance even with a batch size as small as 1, thereby\ncatering to resource-constrained devices. Additionally, FedWon effectively\ntackles the challenge of skewed label distribution.\n","authors":["Weiming Zhuang","Lingjuan Lyu"],"pdf_url":"https://arxiv.org/pdf/2306.05879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05873v1","updated":"2023-06-09T13:11:05Z","published":"2023-06-09T13:11:05Z","title":"Detecting Adversarial Directions in Deep Reinforcement Learning to Make\n  Robust Decisions","summary":"  Learning in MDPs with highly complex state representations is currently\npossible due to multiple advancements in reinforcement learning algorithm\ndesign. However, this incline in complexity, and furthermore the increase in\nthe dimensions of the observation came at the cost of volatility that can be\ntaken advantage of via adversarial attacks (i.e. moving along worst-case\ndirections in the observation space). To solve this policy instability problem\nwe propose a novel method to detect the presence of these non-robust directions\nvia local quadratic approximation of the deep neural policy loss. Our method\nprovides a theoretical basis for the fundamental cut-off between safe\nobservations and adversarial observations. Furthermore, our technique is\ncomputationally efficient, and does not depend on the methods used to produce\nthe worst-case directions. We conduct extensive experiments in the Arcade\nLearning Environment with several different adversarial attack techniques. Most\nsignificantly, we demonstrate the effectiveness of our approach even in the\nsetting where non-robust directions are explicitly optimized to circumvent our\nproposed method.\n","authors":["Ezgi Korkmaz","Jonah Brown-Cohen"],"pdf_url":"https://arxiv.org/pdf/2306.05873v1.pdf","comment":"Published in ICML 2023"},{"id":"http://arxiv.org/abs/2305.17535v3","updated":"2023-06-09T13:09:16Z","published":"2023-05-27T17:35:01Z","title":"PFNs4BO: In-Context Learning for Bayesian Optimization","summary":"  In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible\nsurrogate for Bayesian Optimization (BO). PFNs are neural processes that are\ntrained to approximate the posterior predictive distribution (PPD) through\nin-context learning on any prior distribution that can be efficiently sampled\nfrom. We describe how this flexibility can be exploited for surrogate modeling\nin BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and\na Bayesian Neural Network (BNN). In addition, we show how to incorporate\nfurther information into the prior, such as allowing hints about the position\nof optima (user priors), ignoring irrelevant dimensions, and performing\nnon-myopic BO by learning the acquisition function. The flexibility underlying\nthese extensions opens up vast possibilities for using PFNs for BO. We\ndemonstrate the usefulness of PFNs for BO in a large-scale evaluation on\nartificial GP samples and three different hyperparameter optimization testbeds:\nHPO-B, Bayesmark, and PD1. We publish code alongside trained models at\nhttps://github.com/automl/PFNs4BO.\n","authors":["Samuel Müller","Matthias Feurer","Noah Hollmann","Frank Hutter"],"pdf_url":"https://arxiv.org/pdf/2305.17535v3.pdf","comment":"Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2306.05865v1","updated":"2023-06-09T12:58:47Z","published":"2023-06-09T12:58:47Z","title":"Faster Discrete Convex Function Minimization with Predictions: The\n  M-Convex Case","summary":"  Recent years have seen a growing interest in accelerating optimization\nalgorithms with machine-learned predictions. Sakaue and Oki (NeurIPS 2022) have\ndeveloped a general framework that warm-starts the L-convex function\nminimization method with predictions, revealing the idea's usefulness for\nvarious discrete optimization problems. In this paper, we present a framework\nfor using predictions to accelerate M-convex function minimization, thus\ncomplementing previous research and extending the range of discrete\noptimization algorithms that can benefit from predictions. Our framework is\nparticularly effective for an important subclass called laminar convex\nminimization, which appears in many operations research applications. Our\nmethods can improve time complexity bounds upon the best worst-case results by\nusing predictions and even have potential to go beyond a lower-bound result.\n","authors":["Taihei Oki","Shinsaku Sakaue"],"pdf_url":"https://arxiv.org/pdf/2306.05865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05862v1","updated":"2023-06-09T12:53:24Z","published":"2023-06-09T12:53:24Z","title":"Federated Learning You May Communicate Less Often!","summary":"  We investigate the generalization error of statistical learning models in a\nFederated Learning (FL) setting. Specifically, we study the evolution of the\ngeneralization error with the number of communication rounds between the\nclients and the parameter server, i.e., the effect on the generalization error\nof how often the local models as computed by the clients are aggregated at the\nparameter server. We establish PAC-Bayes and rate-distortion theoretic bounds\non the generalization error that account explicitly for the effect of the\nnumber of rounds, say $ R \\in \\mathbb{N}$, in addition to the number of\nparticipating devices $K$ and individual datasets size $n$. The bounds, which\napply in their generality for a large class of loss functions and learning\nalgorithms, appear to be the first of their kind for the FL setting.\nFurthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and\nwe derive (more) explicit bounds on the generalization error in this case. In\nparticular, we show that the generalization error of FSVM increases with $R$,\nsuggesting that more frequent communication with the parameter server\ndiminishes the generalization power of such learning algorithms. Combined with\nthat the empirical risk generally decreases for larger values of $R$, this\nindicates that $R$ might be a parameter to optimize in order to minimize the\npopulation risk of FL algorithms. Moreover, specialized to the case $R=1$\n(sometimes referred to as \"one-shot\" FL or distributed learning) our bounds\nsuggest that the generalization error of the FL setting decreases faster than\nthat of centralized learning by a factor of $\\mathcal{O}(\\sqrt{\\log(K)/K})$,\nthereby generalizing recent findings in this direction to arbitrary loss\nfunctions and algorithms. The results of this paper are also validated on some\nexperiments.\n","authors":["Milad Sefidgaran","Romain Chor","Abdellatif Zaidi","Yijun Wan"],"pdf_url":"https://arxiv.org/pdf/2306.05862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04091v2","updated":"2023-06-09T12:52:24Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v2.pdf","comment":"The first two authors have contributed equally to this work. Accepted\n  as regular paper at CVPR 2023 Workshop and Challenges for New Frontiers in\n  Visual Language Reasoning: Compositionality, Prompts and Causality (NFVLR)"},{"id":"http://arxiv.org/abs/2306.05859v1","updated":"2023-06-09T12:45:41Z","published":"2023-06-09T12:45:41Z","title":"Robust Reinforcement Learning via Adversarial Kernel Approximation","summary":"  Robust Markov Decision Processes (RMDPs) provide a framework for sequential\ndecision-making that is robust to perturbations on the transition kernel.\nHowever, robust reinforcement learning (RL) approaches in RMDPs do not scale\nwell to realistic online settings with high-dimensional domains. By\ncharacterizing the adversarial kernel in RMDPs, we propose a novel approach for\nonline robust RL that approximates the adversarial kernel and uses a standard\n(non-robust) RL algorithm to learn a robust policy. Notably, our approach can\nbe applied on top of any underlying RL algorithm, enabling easy scaling to\nhigh-dimensional domains. Experiments in classic control tasks, MinAtar and\nDeepMind Control Suite demonstrate the effectiveness and the applicability of\nour method.\n","authors":["Kaixin Wang","Uri Gadot","Navdeep Kumar","Kfir Levy","Shie Mannor"],"pdf_url":"https://arxiv.org/pdf/2306.05859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05857v1","updated":"2023-06-09T12:39:41Z","published":"2023-06-09T12:39:41Z","title":"How Sparse Can We Prune A Deep Network: A Geometric Viewpoint","summary":"  Overparameterization constitutes one of the most significant hallmarks of\ndeep neural networks. Though it can offer the advantage of outstanding\ngeneralization performance, it meanwhile imposes substantial storage burden,\nthus necessitating the study of network pruning. A natural and fundamental\nquestion is: How sparse can we prune a deep network (with almost no hurt on the\nperformance)? To address this problem, in this work we take a first principles\napproach, specifically, by merely enforcing the sparsity constraint on the\noriginal loss function, we're able to characterize the sharp phase transition\npoint of pruning ratio, which corresponds to the boundary between the feasible\nand the infeasible, from the perspective of high-dimensional geometry. It turns\nout that the phase transition point of pruning ratio equals the squared\nGaussian width of some convex body resulting from the $l_1$-regularized loss\nfunction, normalized by the original dimension of parameters. As a byproduct,\nwe provide a novel network pruning algorithm which is essentially a global\none-shot pruning one. Furthermore, we provide efficient countermeasures to\naddress the challenges in computing the involved Gaussian width, including the\nspectrum estimation of a large-scale Hessian matrix and dealing with the\nnon-definite positiveness of a Hessian matrix. It is demonstrated that the\npredicted pruning ratio threshold coincides very well with the actual value\nobtained from the experiments and our proposed pruning algorithm can achieve\ncompetitive or even better performance than the existing pruning algorithms.\nAll codes are available at:\nhttps://github.com/QiaozheZhang/Global-One-shot-Pruning\n","authors":["Qiaozhe Zhang","Ruijie Zhang","Jun Sun","Yingzhuang Liu"],"pdf_url":"https://arxiv.org/pdf/2306.05857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08657v5","updated":"2023-06-09T12:36:33Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v5.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2302.04083v2","updated":"2023-06-09T12:20:45Z","published":"2023-02-08T14:37:34Z","title":"Improving the Model Consistency of Decentralized Federated Learning","summary":"  To mitigate the privacy leakages and communication burdens of Federated\nLearning (FL), decentralized FL (DFL) discards the central server and each\nclient only communicates with its neighbors in a decentralized communication\nnetwork. However, existing DFL suffers from high inconsistency among local\nclients, which results in severe distribution shift and inferior performance\ncompared with centralized FL (CFL), especially on heterogeneous data or sparse\ncommunication topology. To alleviate this issue, we propose two DFL algorithms\nnamed DFedSAM and DFedSAM-MGS to improve the performance of DFL. Specifically,\nDFedSAM leverages gradient perturbation to generate local flat models via\nSharpness Aware Minimization (SAM), which searches for models with uniformly\nlow loss values. DFedSAM-MGS further boosts DFedSAM by adopting Multiple Gossip\nSteps (MGS) for better model consistency, which accelerates the aggregation of\nlocal flat models and better balances communication complexity and\ngeneralization. Theoretically, we present improved convergence rates $\\small\n\\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{1}{K^{1/2}T^{3/2}(1-\\lambda)^2}\\big)$\nand $\\small\n\\mathcal{O}\\big(\\frac{1}{\\sqrt{KT}}+\\frac{1}{T}+\\frac{\\lambda^Q+1}{K^{1/2}T^{3/2}(1-\\lambda^Q)^2}\\big)$\nin non-convex setting for DFedSAM and DFedSAM-MGS, respectively, where\n$1-\\lambda$ is the spectral gap of gossip matrix and $Q$ is the number of MGS.\nEmpirically, our methods can achieve competitive performance compared with CFL\nmethods and outperform existing DFL methods.\n","authors":["Yifan Shi","Li Shen","Kang Wei","Yan Sun","Bo Yuan","Xueqian Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.04083v2.pdf","comment":"ICML2023"},{"id":"http://arxiv.org/abs/2306.05844v1","updated":"2023-06-09T12:18:14Z","published":"2023-06-09T12:18:14Z","title":"How Object Information Improves Skeleton-based Human Action Recognition\n  in Assembly Tasks","summary":"  As the use of collaborative robots (cobots) in industrial manufacturing\ncontinues to grow, human action recognition for effective human-robot\ncollaboration becomes increasingly important. This ability is crucial for\ncobots to act autonomously and assist in assembly tasks. Recently,\nskeleton-based approaches are often used as they tend to generalize better to\ndifferent people and environments. However, when processing skeletons alone,\ninformation about the objects a human interacts with is lost. Therefore, we\npresent a novel approach of integrating object information into skeleton-based\naction recognition. We enhance two state-of-the-art methods by treating object\ncenters as further skeleton joints. Our experiments on the assembly dataset\nIKEA ASM show that our approach improves the performance of these\nstate-of-the-art methods to a large extent when combining skeleton joints with\nobjects predicted by a state-of-the-art instance segmentation model. Our\nresearch sheds light on the benefits of combining skeleton joints with object\ninformation for human action recognition in assembly tasks. We analyze the\neffect of the object detector on the combination for action classification and\ndiscuss the important factors that must be taken into account.\n","authors":["Dustin Aganian","Mona Köhler","Sebastian Baake","Markus Eisenbach","Horst-Michael Gross"],"pdf_url":"https://arxiv.org/pdf/2306.05844v1.pdf","comment":"IEEE International Joint Conference on Neural Networks (IJCNN) 2023"},{"id":"http://arxiv.org/abs/2306.05843v1","updated":"2023-06-09T12:17:18Z","published":"2023-06-09T12:17:18Z","title":"Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via\n  Bayesian Quadrature","summary":"  Real-world optimisation problems often feature complex combinations of (1)\ndiverse constraints, (2) discrete and mixed spaces, and are (3) highly\nparallelisable. (4) There are also cases where the objective function cannot be\nqueried if unknown constraints are not satisfied, e.g. in drug discovery,\nsafety on animal experiments (unknown constraints) must be established before\nhuman clinical trials (querying objective function) may proceed. However, most\nexisting works target each of the above three problems in isolation and do not\nconsider (4) unknown constraints with query rejection. For problems with\ndiverse constraints and/or unconventional input spaces, it is difficult to\napply these techniques as they are often mutually incompatible. We propose\ncSOBER, a domain-agnostic prudent parallel active sampler for Bayesian\noptimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility\nunder unknown constraints as a type of integration error that we can estimate.\nWe propose a theoretically-driven approach that propagates such error as a\ntolerance in the quadrature precision that automatically balances exploitation\nand exploration with the expected rejection rate. Moreover, our method flexibly\naccommodates diverse constraints and/or discrete and mixed spaces via adaptive\ntolerance, including conventional zero-risk cases. We show that cSOBER\noutperforms competitive baselines on diverse real-world blackbox-constrained\nproblems, including safety-constrained drug discovery, and\nhuman-relationship-aware team optimisation over graph-structured space.\n","authors":["Masaki Adachi","Satoshi Hayakawa","Xingchen Wan","Martin Jørgensen","Harald Oberhauser","Michael A. Osborne"],"pdf_url":"https://arxiv.org/pdf/2306.05843v1.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.05838v1","updated":"2023-06-09T12:12:07Z","published":"2023-06-09T12:12:07Z","title":"Expectation-Complete Graph Representations with Homomorphisms","summary":"  We investigate novel random graph embeddings that can be computed in expected\npolynomial time and that are able to distinguish all non-isomorphic graphs in\nexpectation. Previous graph embeddings have limited expressiveness and either\ncannot distinguish all graphs or cannot be computed efficiently for every\ngraph. To be able to approximate arbitrary functions on graphs, we are\ninterested in efficient alternatives that become arbitrarily expressive with\nincreasing resources. Our approach is based on Lov\\'asz' characterisation of\ngraph isomorphism through an infinite dimensional vector of homomorphism\ncounts. Our empirical evaluation shows competitive results on several benchmark\ngraph learning tasks.\n","authors":["Pascal Welke","Maximilian Thiessen","Fabian Jogl","Thomas Gärtner"],"pdf_url":"https://arxiv.org/pdf/2306.05838v1.pdf","comment":"accepted for publication at ICML 2023"},{"id":"http://arxiv.org/abs/2306.05836v1","updated":"2023-06-09T12:09:15Z","published":"2023-06-09T12:09:15Z","title":"Can Large Language Models Infer Causation from Correlation?","summary":"  Causal inference is one of the hallmarks of human intelligence. While the\nfield of CausalNLP has attracted much interest in the recent years, existing\ncausal inference datasets in NLP primarily rely on discovering causality from\nempirical knowledge (e.g., commonsense knowledge). In this work, we propose the\nfirst benchmark dataset to test the pure causal inference skills of large\nlanguage models (LLMs). Specifically, we formulate a novel task Corr2Cause,\nwhich takes a set of correlational statements and determines the causal\nrelationship between the variables. We curate a large-scale dataset of more\nthan 400K samples, on which we evaluate seventeen existing LLMs. Through our\nexperiments, we identify a key shortcoming of LLMs in terms of their causal\ninference skills, and show that these models achieve almost close to random\nperformance on the task. This shortcoming is somewhat mitigated when we try to\nre-purpose LLMs for this skill via finetuning, but we find that these models\nstill fail to generalize -- they can only perform causal inference in\nin-distribution settings when variable names and textual expressions used in\nthe queries are similar to those in the training set, but fail in\nout-of-distribution settings generated by perturbing these queries. Corr2Cause\nis a challenging task for LLMs, and would be helpful in guiding future research\non improving LLMs' pure reasoning skills and generalizability. Our data is at\nhttps://huggingface.co/datasets/causalnlp/corr2cause. Our code is at\nhttps://github.com/causalNLP/corr2cause.\n","authors":["Zhijing Jin","Jiarui Liu","Zhiheng Lyu","Spencer Poff","Mrinmaya Sachan","Rada Mihalcea","Mona Diab","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2306.05836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14449v2","updated":"2023-06-09T12:06:32Z","published":"2022-12-29T20:25:18Z","title":"Policy Mirror Ascent for Efficient and Independent Learning in Mean\n  Field Games","summary":"  Mean-field games have been used as a theoretical tool to obtain an\napproximate Nash equilibrium for symmetric and anonymous $N$-player games.\nHowever, limiting applicability, existing theoretical results assume variations\nof a \"population generative model\", which allows arbitrary modifications of the\npopulation distribution by the learning algorithm. Moreover, learning\nalgorithms typically work on abstract simulators with population instead of the\n$N$-player game. Instead, we show that $N$ agents running policy mirror ascent\nconverge to the Nash equilibrium of the regularized game within\n$\\widetilde{\\mathcal{O}}(\\varepsilon^{-2})$ samples from a single sample\ntrajectory without a population generative model, up to a standard\n$\\mathcal{O}(\\frac{1}{\\sqrt{N}})$ error due to the mean field. Taking a\ndivergent approach from the literature, instead of working with the\nbest-response map we first show that a policy mirror ascent map can be used to\nconstruct a contractive operator having the Nash equilibrium as its fixed\npoint. We analyze single-path TD learning for $N$-agent games, proving sample\ncomplexity guarantees by only using a sample path from the $N$-agent simulator\nwithout a population generative model. Furthermore, we demonstrate that our\nmethodology allows for independent learning by $N$ agents with finite sample\nguarantees.\n","authors":["Batuhan Yardim","Semih Cayci","Matthieu Geist","Niao He"],"pdf_url":"https://arxiv.org/pdf/2212.14449v2.pdf","comment":"Accepted for publication at ICML 2023"},{"id":"http://arxiv.org/abs/2207.04396v4","updated":"2023-06-09T11:52:42Z","published":"2022-07-10T06:42:02Z","title":"Graph Generative Model for Benchmarking Graph Neural Networks","summary":"  As the field of Graph Neural Networks (GNN) continues to grow, it experiences\na corresponding increase in the need for large, real-world datasets to train\nand test new GNN models on challenging, realistic problems. Unfortunately, such\ngraph datasets are often generated from online, highly privacy-restricted\necosystems, which makes research and development on these datasets hard, if not\nimpossible. This greatly reduces the amount of benchmark graphs available to\nresearchers, causing the field to rely only on a handful of publicly-available\ndatasets. To address this problem, we introduce a novel graph generative model,\nComputation Graph Transformer (CGT) that learns and reproduces the distribution\nof real-world graphs in a privacy-controlled way. More specifically, CGT (1)\ngenerates effective benchmark graphs on which GNNs show similar task\nperformance as on the source graphs, (2) scales to process large-scale graphs,\n(3) incorporates off-the-shelf privacy modules to guarantee end-user privacy of\nthe generated graph. Extensive experiments across a vast body of graph\ngenerative models show that only our model can successfully generate\nprivacy-controlled, synthetic substitutes of large-scale real-world graphs that\ncan be effectively used to benchmark GNN models.\n","authors":["Minji Yoon","Yue Wu","John Palowitch","Bryan Perozzi","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.04396v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04810v2","updated":"2023-06-09T11:40:26Z","published":"2023-06-07T22:14:33Z","title":"Correlative Information Maximization: A Biologically Plausible Approach\n  to Supervised Deep Neural Networks without Weight Symmetry","summary":"  The backpropagation algorithm has experienced remarkable success in training\nlarge-scale artificial neural networks, however, its biological-plausibility is\ndisputed, and it remains an open question whether the brain employs supervised\nlearning mechanisms akin to it. Here, we propose correlative information\nmaximization between layer activations as an alternative normative approach to\ndescribe the signal propagation in biological neural networks in both forward\nand backward directions. This new framework addresses many concerns about the\nbiological-plausibility of conventional artificial neural networks and the\nbackpropagation algorithm. The coordinate descent-based optimization of the\ncorresponding objective, combined with the mean square error loss function for\nfitting labeled supervision data, gives rise to a neural network structure that\nemulates a more biologically realistic network of multi-compartment pyramidal\nneurons with dendritic processing and lateral inhibitory neurons. Furthermore,\nour approach provides a natural resolution to the weight symmetry problem\nbetween forward and backward signal propagation paths, a significant critique\nagainst the plausibility of the conventional backpropagation algorithm. This is\nachieved by leveraging two alternative, yet equivalent forms of the correlative\nmutual information objective. These alternatives intrinsically lead to forward\nand backward prediction networks without weight symmetry issues, providing a\ncompelling solution to this long-standing challenge.\n","authors":["Bariscan Bozkurt","Cengiz Pehlevan","Alper T Erdogan"],"pdf_url":"https://arxiv.org/pdf/2306.04810v2.pdf","comment":"Preprint, 31 pages"},{"id":"http://arxiv.org/abs/2306.05275v2","updated":"2023-06-09T11:32:04Z","published":"2023-06-08T15:21:47Z","title":"Federated Linear Contextual Bandits with User-level Differential Privacy","summary":"  This paper studies federated linear contextual bandits under the notion of\nuser-level differential privacy (DP). We first introduce a unified federated\nbandits framework that can accommodate various definitions of DP in the\nsequential decision-making setting. We then formally introduce user-level\ncentral DP (CDP) and local DP (LDP) in the federated bandits framework, and\ninvestigate the fundamental trade-offs between the learning regrets and the\ncorresponding DP guarantees in a federated linear contextual bandits model. For\nCDP, we propose a federated algorithm termed as $\\texttt{ROBIN}$ and show that\nit is near-optimal in terms of the number of clients $M$ and the privacy budget\n$\\varepsilon$ by deriving nearly-matching upper and lower regret bounds when\nuser-level DP is satisfied. For LDP, we obtain several lower bounds, indicating\nthat learning under user-level $(\\varepsilon,\\delta)$-LDP must suffer a regret\nblow-up factor at least $\\min\\{1/\\varepsilon,M\\}$ or\n$\\min\\{1/\\sqrt{\\varepsilon},\\sqrt{M}\\}$ under different conditions.\n","authors":["Ruiquan Huang","Huanyu Zhang","Luca Melis","Milan Shen","Meisam Hajzinia","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05275v2.pdf","comment":"Accepted by ICML 2023"},{"id":"http://arxiv.org/abs/2306.05815v1","updated":"2023-06-09T11:27:35Z","published":"2023-06-09T11:27:35Z","title":"Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast\n  Algorithms","summary":"  The goal of this paper is to revisit Kernel Principal Component Analysis\n(KPCA) through dualization of a difference of convex functions. This allows to\nnaturally extend KPCA to multiple objective functions and leads to efficient\ngradient-based algorithms avoiding the expensive SVD of the Gram matrix.\nParticularly, we consider objective functions that can be written as Moreau\nenvelopes, demonstrating how to promote robustness and sparsity within the same\nframework. The proposed method is evaluated on synthetic and real-world\nbenchmarks, showing significant speedup in KPCA training time as well as\nhighlighting the benefits in terms of robustness and sparsity.\n","authors":["Francesco Tonin","Alex Lambert","Panagiotis Patrinos","Johan A. K. Suykens"],"pdf_url":"https://arxiv.org/pdf/2306.05815v1.pdf","comment":"15 pages, ICML 2023"},{"id":"http://arxiv.org/abs/2212.02191v2","updated":"2023-06-09T11:13:54Z","published":"2022-12-05T11:56:35Z","title":"On the effectiveness of partial variance reduction in federated learning\n  with heterogeneous data","summary":"  Data heterogeneity across clients is a key challenge in federated learning.\nPrior works address this by either aligning client and server models or using\ncontrol variates to correct client model drift. Although these methods achieve\nfast convergence in convex or simple non-convex problems, the performance in\nover-parameterized models such as deep neural networks is lacking. In this\npaper, we first revisit the widely used FedAvg algorithm in a deep neural\nnetwork to understand how data heterogeneity influences the gradient updates\nacross the neural network layers. We observe that while the feature extraction\nlayers are learned efficiently by FedAvg, the substantial diversity of the\nfinal classification layers across clients impedes the performance. Motivated\nby this, we propose to correct model drift by variance reduction only on the\nfinal layers. We demonstrate that this significantly outperforms existing\nbenchmarks at a similar or lower communication cost. We furthermore provide\nproof for the convergence rate of our algorithm.\n","authors":["Bo Li","Mikkel N. Schmidt","Tommy S. Alstrøm","Sebastian U. Stich"],"pdf_url":"https://arxiv.org/pdf/2212.02191v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2306.05813v1","updated":"2023-06-09T11:12:55Z","published":"2023-06-09T11:12:55Z","title":"Incorporating Prior Knowledge in Deep Learning Models via Pathway\n  Activity Autoencoders","summary":"  Motivation: Despite advances in the computational analysis of high-throughput\nmolecular profiling assays (e.g. transcriptomics), a dichotomy exists between\nmethods that are simple and interpretable, and ones that are complex but with\nlower degree of interpretability. Furthermore, very few methods deal with\ntrying to translate interpretability in biologically relevant terms, such as\nknown pathway cascades. Biological pathways reflecting signalling events or\nmetabolic conversions are Small improvements or modifications of existing\nalgorithms will generally not be suitable, unless novel biological results have\nbeen predicted and verified. Determining which pathways are implicated in\ndisease and incorporating such pathway data as prior knowledge may enhance\npredictive modelling and personalised strategies for diagnosis, treatment and\nprevention of disease.\n  Results: We propose a novel prior-knowledge-based deep auto-encoding\nframework, PAAE, together with its accompanying generative variant, PAVAE, for\nRNA-seq data in cancer. Through comprehensive comparisons among various\nlearning models, we show that, despite having access to a smaller set of\nfeatures, our PAAE and PAVAE models achieve better out-of-set reconstruction\nresults compared to common methodologies. Furthermore, we compare our model\nwith equivalent baselines on a classification task and show that they achieve\nbetter results than models which have access to the full input gene set.\nAnother result is that using vanilla variational frameworks might negatively\nimpact both reconstruction outputs as well as classification performance.\nFinally, our work directly contributes by providing comprehensive\ninterpretability analyses on our models on top of improving prognostication for\ntranslational medicine.\n","authors":["Pedro Henrique da Costa Avelar","Min Wu","Sophia Tsoka"],"pdf_url":"https://arxiv.org/pdf/2306.05813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05812v1","updated":"2023-06-09T11:05:09Z","published":"2023-06-09T11:05:09Z","title":"HRTF upsampling with a generative adversarial network using a gnomonic\n  equiangular projection","summary":"  An individualised head-related transfer function (HRTF) is essential for\ncreating realistic virtual reality (VR) and augmented reality (AR)\nenvironments. However, acoustically measuring high-quality HRTFs requires\nexpensive equipment and an acoustic lab setting. To overcome these limitations\nand to make this measurement more efficient HRTF upsampling has been exploited\nin the past where a high-resolution HRTF is created from a low-resolution one.\nThis paper demonstrates how generative adversarial networks (GANs) can be\napplied to HRTF upsampling. We propose a novel approach that transforms the\nHRTF data for convenient use with a convolutional super-resolution generative\nadversarial network (SRGAN). This new approach is benchmarked against two\nbaselines: barycentric upsampling and a HRTF selection approach. Experimental\nresults show that the proposed method outperforms both baselines in terms of\nlog-spectral distortion (LSD) and localisation performance using perceptual\nmodels when the input HRTF is sparse.\n","authors":["Aidan O. T. Hogg","Mads Jenkins","He Liu","Isaac Squires","Samuel J. Cooper","Lorenzo Picinali"],"pdf_url":"https://arxiv.org/pdf/2306.05812v1.pdf","comment":"13 pages, 9 figures, Preprint (Submitted to Transactions on Audio,\n  Speech and Language Processing on the 24 Feb 2023)"},{"id":"http://arxiv.org/abs/2306.05810v1","updated":"2023-06-09T10:52:39Z","published":"2023-06-09T10:52:39Z","title":"Explaining Reinforcement Learning with Shapley Values","summary":"  For reinforcement learning systems to be widely adopted, their users must\nunderstand and trust them. We present a theoretical analysis of explaining\nreinforcement learning using Shapley values, following a principled approach\nfrom game theory for identifying the contribution of individual players to the\noutcome of a cooperative game. We call this general framework Shapley Values\nfor Explaining Reinforcement Learning (SVERL). Our analysis exposes the\nlimitations of earlier uses of Shapley values in reinforcement learning. We\nthen develop an approach that uses Shapley values to explain agent performance.\nIn a variety of domains, SVERL produces meaningful explanations that match and\nsupplement human intuition.\n","authors":["Daniel Beechey","Thomas M. S. Smith","Özgür Şimşek"],"pdf_url":"https://arxiv.org/pdf/2306.05810v1.pdf","comment":"12 pages, 9 figures. Accepted at ICML 2023"},{"id":"http://arxiv.org/abs/2305.08637v3","updated":"2023-06-09T10:48:45Z","published":"2023-05-15T13:31:09Z","title":"Double-Weighting for Covariate Shift Adaptation","summary":"  Supervised learning is often affected by a covariate shift in which the\nmarginal distributions of instances (covariates $x$) of training and testing\nsamples $\\mathrm{p}_\\text{tr}(x)$ and $\\mathrm{p}_\\text{te}(x)$ are different\nbut the label conditionals coincide. Existing approaches address such covariate\nshift by either using the ratio\n$\\mathrm{p}_\\text{te}(x)/\\mathrm{p}_\\text{tr}(x)$ to weight training samples\n(reweighted methods) or using the ratio\n$\\mathrm{p}_\\text{tr}(x)/\\mathrm{p}_\\text{te}(x)$ to weight testing samples\n(robust methods). However, the performance of such approaches can be poor under\nsupport mismatch or when the above ratios take large values. We propose a\nminimax risk classification (MRC) approach for covariate shift adaptation that\navoids such limitations by weighting both training and testing samples. In\naddition, we develop effective techniques that obtain both sets of weights and\ngeneralize the conventional kernel mean matching method. We provide novel\ngeneralization bounds for our method that show a significant increase in the\neffective sample size compared with reweighted methods. The proposed method\nalso achieves enhanced classification performance in both synthetic and\nempirical experiments.\n","authors":["José I. Segovia-Martín","Santiago Mazuelas","Anqi Liu"],"pdf_url":"https://arxiv.org/pdf/2305.08637v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05808v1","updated":"2023-06-09T10:47:06Z","published":"2023-06-09T10:47:06Z","title":"RankFormer: Listwise Learning-to-Rank Using Listwide Labels","summary":"  Web applications where users are presented with a limited selection of items\nhave long employed ranking models to put the most relevant results first. Any\nfeedback received from users is typically assumed to reflect a relative\njudgement on the utility of items, e.g. a user clicking on an item only implies\nit is better than items not clicked in the same ranked list. Hence, the\nobjectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.\n  Yet, by only viewing feedback as relative, we neglect the user's absolute\nfeedback on the list's overall quality, e.g. when no items in the selection are\nclicked. We thus reconsider the standard LTR paradigm and argue the benefits of\nlearning from this listwide signal. To this end, we propose the RankFormer as\nan architecture that, with a Transformer at its core, can jointly optimize a\nnovel listwide assessment objective and a traditional listwise LTR objective.\n  We simulate implicit feedback on public datasets and observe that the\nRankFormer succeeds in benefitting from listwide signals. Additionally, we\nconduct experiments in e-commerce on Amazon Search data and find the RankFormer\nto be superior to all baselines offline. An online experiment shows that\nknowledge distillation can be used to find immediate practical use for the\nRankFormer.\n","authors":["Maarten Buyl","Paul Missault","Pierre-Antoine Sondag"],"pdf_url":"https://arxiv.org/pdf/2306.05808v1.pdf","comment":"Accepted at KDD 2023"},{"id":"http://arxiv.org/abs/2306.05805v1","updated":"2023-06-09T10:42:32Z","published":"2023-06-09T10:42:32Z","title":"DynaBench: A benchmark dataset for learning dynamical systems from\n  low-resolution data","summary":"  Previous work on learning physical systems from data has focused on\nhigh-resolution grid-structured measurements. However, real-world knowledge of\nsuch systems (e.g. weather data) relies on sparsely scattered measuring\nstations. In this paper, we introduce a novel simulated benchmark dataset,\nDynaBench, for learning dynamical systems directly from sparsely scattered data\nwithout prior knowledge of the equations. The dataset focuses on predicting the\nevolution of a dynamical system from low-resolution, unstructured measurements.\nWe simulate six different partial differential equations covering a variety of\nphysical systems commonly used in the literature and evaluate several machine\nlearning models, including traditional graph neural networks and point cloud\nprocessing models, with the task of predicting the evolution of the system. The\nproposed benchmark dataset is expected to advance the state of art as an\nout-of-the-box easy-to-use tool for evaluating models in a setting where only\nunstructured low-resolution observations are available. The benchmark is\navailable at https://anonymous.4open.science/r/code-2022-dynabench/.\n","authors":["Andrzej Dulny","Andreas Hotho","Anna Krause"],"pdf_url":"https://arxiv.org/pdf/2306.05805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05803v1","updated":"2023-06-09T10:40:22Z","published":"2023-06-09T10:40:22Z","title":"Causality between Sentiment and Cryptocurrency Prices","summary":"  This study investigates the relationship between narratives conveyed through\nmicroblogging platforms, namely Twitter, and the value of crypto assets. Our\nstudy provides a unique technique to build narratives about cryptocurrency by\ncombining topic modelling of short texts with sentiment analysis. First, we\nused an unsupervised machine learning algorithm to discover the latent topics\nwithin the massive and noisy textual data from Twitter, and then we revealed\n4-5 cryptocurrency-related narratives, including financial investment,\ntechnological advancement related to crypto, financial and political\nregulations, crypto assets, and media coverage. In a number of situations, we\nnoticed a strong link between our narratives and crypto prices. Our work\nconnects the most recent innovation in economics, Narrative Economics, to a new\narea of study that combines topic modelling and sentiment analysis to relate\nconsumer behaviour to narratives.\n","authors":["Lubdhak Mondal","Udeshya Raj","Abinandhan S","Began Gowsik S","Sarwesh P","Abhijeet Chandra"],"pdf_url":"https://arxiv.org/pdf/2306.05803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01075v3","updated":"2023-06-09T10:23:28Z","published":"2023-02-02T13:05:27Z","title":"MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein\n  Gradient Flows","summary":"  The conventional understanding of adversarial training in generative\nadversarial networks (GANs) is that the discriminator is trained to estimate a\ndivergence, and the generator learns to minimize this divergence. We argue that\ndespite the fact that many variants of GANs were developed following this\nparadigm, the current theoretical understanding of GANs and their practical\nalgorithms are inconsistent. In this paper, we leverage Wasserstein gradient\nflows which characterize the evolution of particles in the sample space, to\ngain theoretical insights and algorithmic inspiration of GANs. We introduce a\nunified generative modeling framework - MonoFlow: the particle evolution is\nrescaled via a monotonically increasing mapping of the log density ratio. Under\nour framework, adversarial training can be viewed as a procedure first\nobtaining MonoFlow's vector field via training the discriminator and the\ngenerator learns to draw the particle flow defined by the corresponding vector\nfield. We also reveal the fundamental difference between variational divergence\nminimization and adversarial training. This analysis helps us to identify what\ntypes of generator loss functions can lead to the successful training of GANs\nand suggest that GANs may have more loss designs beyond the literature (e.g.,\nnon-saturated loss), as long as they realize MonoFlow. Consistent empirical\nstudies are included to validate the effectiveness of our framework.\n","authors":["Mingxuan Yi","Zhanxing Zhu","Song Liu"],"pdf_url":"https://arxiv.org/pdf/2302.01075v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.07896v2","updated":"2023-06-09T10:00:05Z","published":"2023-04-16T21:29:54Z","title":"Out-of-Variable Generalization for Discriminative Models","summary":"  The ability of an agent to do well in new environments is a critical aspect\nof intelligence. In machine learning, this ability is known as\n$\\textit{strong}$ or $\\textit{out-of-distribution}$ generalization. However,\nmerely considering differences in data distributions is inadequate for fully\ncapturing differences between learning environments. In the present paper, we\ninvestigate $\\textit{out-of-variable}$ generalization, which pertains to an\nagent's generalization capabilities concerning environments with variables that\nwere never jointly observed before. This skill closely reflects the process of\nanimate learning: we, too, explore Nature by probing, observing, and measuring\n$\\textit{subsets}$ of variables at any given time. Mathematically,\n$\\textit{out-of-variable}$ generalization requires the efficient re-use of past\nmarginal information, i.e., information over subsets of previously observed\nvariables. We study this problem, focusing on prediction tasks across\nenvironments that contain overlapping, yet distinct, sets of causes. We show\nthat after fitting a classifier, the residual distribution in one environment\nreveals the partial derivative of the true generating function with respect to\nthe unobserved causal parent in that environment. We leverage this information\nand propose a method that exhibits non-trivial out-of-variable generalization\nperformance when facing an overlapping, yet distinct, set of causal predictors.\n","authors":["Siyuan Guo","Jonas Wildberger","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2304.07896v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10613v2","updated":"2023-06-09T09:59:27Z","published":"2023-04-20T19:19:55Z","title":"Debiasing Conditional Stochastic Optimization","summary":"  In this paper, we study the conditional stochastic optimization (CSO) problem\nwhich covers a variety of applications including portfolio selection,\nreinforcement learning, robust learning, causal inference, etc. The\nsample-averaged gradient of the CSO objective is biased due to its nested\nstructure, and therefore requires a high sample complexity to reach\nconvergence. We introduce a general stochastic extrapolation technique that\neffectively reduces the bias. We show that for nonconvex smooth objectives,\ncombining this extrapolation with variance reduction techniques can achieve a\nsignificantly better sample complexity than existing bounds. Additionally, we\ndevelop new algorithms for the finite-sum variant of the CSO problem that also\nsignificantly improve upon existing results. Finally, we believe that our\ndebiasing technique has the potential to be a useful tool for addressing\nsimilar challenges in other stochastic optimization problems.\n","authors":["Lie He","Shiva Prasad Kasiviswanathan"],"pdf_url":"https://arxiv.org/pdf/2304.10613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05786v1","updated":"2023-06-09T09:57:18Z","published":"2023-06-09T09:57:18Z","title":"Two-level histograms for dealing with outliers and heavy tail\n  distributions","summary":"  Histograms are among the most popular methods used in exploratory analysis to\nsummarize univariate distributions. In particular, irregular histograms are\ngood non-parametric density estimators that require very few parameters: the\nnumber of bins with their lengths and frequencies. Many approaches have been\nproposed in the literature to infer these parameters, either assuming\nhypotheses about the underlying data distributions or exploiting a model\nselection approach. In this paper, we focus on the G-Enum histogram method,\nwhich exploits the Minimum Description Length (MDL) principle to build\nhistograms without any user parameter and achieves state-of-the art performance\nw.r.t accuracy; parsimony and computation time. We investigate on the limits of\nthis method in the case of outliers or heavy-tailed distributions. We suggest a\ntwo-level heuristic to deal with such cases. The first level exploits a\nlogarithmic transformation of the data to split the data set into a list of\ndata subsets with a controlled range of values. The second level builds a\nsub-histogram for each data subset and aggregates them to obtain a complete\nhistogram. Extensive experiments show the benefits of the approach.\n","authors":["Marc Boullé"],"pdf_url":"https://arxiv.org/pdf/2306.05786v1.pdf","comment":"30 pages, 47 figures"},{"id":"http://arxiv.org/abs/2306.05785v1","updated":"2023-06-09T09:57:17Z","published":"2023-06-09T09:57:17Z","title":"End-to-End Neural Network Compression via $\\frac{\\ell_1}{\\ell_2}$\n  Regularized Latency Surrogates","summary":"  Neural network (NN) compression via techniques such as pruning, quantization\nrequires setting compression hyperparameters (e.g., number of channels to be\npruned, bitwidths for quantization) for each layer either manually or via\nneural architecture search (NAS) which can be computationally expensive. We\naddress this problem by providing an end-to-end technique that optimizes for\nmodel's Floating Point Operations (FLOPs) or for on-device latency via a novel\n$\\frac{\\ell_1}{\\ell_2}$ latency surrogate. Our algorithm is versatile and can\nbe used with many popular compression methods including pruning, low-rank\nfactorization, and quantization. Crucially, it is fast and runs in almost the\nsame amount of time as single model training; which is a significant training\nspeed-up over standard NAS methods. For BERT compression on GLUE fine-tuning\ntasks, we achieve $50\\%$ reduction in FLOPs with only $1\\%$ drop in\nperformance. For compressing MobileNetV3 on ImageNet-1K, we achieve $15\\%$\nreduction in FLOPs, and $11\\%$ reduction in on-device latency without drop in\naccuracy, while still requiring $3\\times$ less training compute than SOTA\ncompression techniques. Finally, for transfer learning on smaller datasets, our\ntechnique identifies $1.2\\times$-$1.4\\times$ cheaper architectures than\nstandard MobileNetV3, EfficientNet suite of architectures at almost the same\ntraining cost and accuracy.\n","authors":["Anshul Nasery","Hardik Shah","Arun Sai Suggala","Prateek Jain"],"pdf_url":"https://arxiv.org/pdf/2306.05785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05784v1","updated":"2023-06-09T09:55:20Z","published":"2023-06-09T09:55:20Z","title":"Quantitative Ink Analysis: Estimating the Number of Inks in Documents\n  through Hyperspectral Imaging","summary":"  In the field of document forensics, ink analysis plays a crucial role in\ndetermining the authenticity of legal and historic documents and detecting\nforgery. Visual examination alone is insufficient for distinguishing visually\nsimilar inks, necessitating the use of advanced scientific techniques. This\npaper proposes an ink analysis technique based on hyperspectral imaging, which\nenables the examination of documents in hundreds of narrowly spaced spectral\nbands, revealing hidden details. The main objective of this study is to\nidentify the number of distinct inks used in a document. Three clustering\nalgorithms, namely k-means, Agglomerative, and c-means, are employed to\nestimate the number of inks present. The methodology involves data extraction,\nink pixel segmentation, and ink number determination. The results demonstrate\nthe effectiveness of the proposed technique in identifying ink clusters and\ndistinguishing between different inks. The analysis of a hyperspectral cube\ndataset reveals variations in spectral reflectance across different bands and\ndistinct spectral responses among the 12 lines, indicating the presence of\nmultiple inks. The clustering algorithms successfully identify ink clusters,\nwith k-means clustering showing superior classification performance. These\nfindings contribute to the development of reliable methodologies for ink\nanalysis using hyperspectral imaging, enhancing the\n","authors":["Aneeqa Abrar","Hamza Iqbal"],"pdf_url":"https://arxiv.org/pdf/2306.05784v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05781v1","updated":"2023-06-09T09:49:16Z","published":"2023-06-09T09:49:16Z","title":"Adaptivity Complexity for Causal Graph Discovery","summary":"  Causal discovery from interventional data is an important problem, where the\ntask is to design an interventional strategy that learns the hidden ground\ntruth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of\nperformed interventions. Most prior interventional strategies broadly fall into\ntwo categories: non-adaptive and adaptive. Non-adaptive strategies decide on a\nsingle fixed set of interventions to be performed while adaptive strategies can\ndecide on which nodes to intervene on sequentially based on past interventions.\nWhile adaptive algorithms may use exponentially fewer interventions than their\nnon-adaptive counterparts, there are practical concerns that constrain the\namount of adaptivity allowed. Motivated by this trade-off, we study the problem\nof $r$-adaptivity, where the algorithm designer recovers the causal graph under\na total of $r$ sequential rounds whilst trying to minimize the total number of\ninterventions. For this problem, we provide a $r$-adaptive algorithm that\nachieves $O(\\min\\{r,\\log n\\} \\cdot n^{1/\\min\\{r,\\log n\\}})$ approximation with\nrespect to the verification number, a well-known lower bound for adaptive\nalgorithms. Furthermore, for every $r$, we show that our approximation is\ntight. Our definition of $r$-adaptivity interpolates nicely between the\nnon-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our\napproximation simplifies to $O(n)$ and $O(\\log n)$ respectively, matching the\nbest-known approximation guarantees for both extremes. Our results also extend\nnaturally to the bounded size interventions.\n","authors":["Davin Choo","Kirankumar Shiragur"],"pdf_url":"https://arxiv.org/pdf/2306.05781v1.pdf","comment":"Accepted into UAI 2023"},{"id":"http://arxiv.org/abs/2306.05779v1","updated":"2023-06-09T09:46:38Z","published":"2023-06-09T09:46:38Z","title":"Transformer-based Time-to-Event Prediction for Chronic Kidney Disease\n  Deterioration","summary":"  Deep-learning techniques, particularly the transformer model, have shown\ngreat potential in enhancing the prediction performance of longitudinal health\nrecords. While previous methods have mainly focused on fixed-time risk\nprediction, time-to-event prediction (also known as survival analysis) is often\nmore appropriate for clinical scenarios. Here, we present a novel deep-learning\narchitecture we named STRAFE, a generalizable survival analysis\ntransformer-based architecture for electronic health records. The performance\nof STRAFE was evaluated using a real-world claim dataset of over 130,000\nindividuals with stage 3 chronic kidney disease (CKD) and was found to\noutperform other time-to-event prediction algorithms in predicting the exact\ntime of deterioration to stage 5. Additionally, STRAFE was found to outperform\nbinary outcome algorithms in predicting fixed-time risk, possibly due to its\nability to train on censored data. We show that STRAFE predictions can improve\nthe positive predictive value of high-risk patients by 3-fold, demonstrating\npossible usage to improve targeting for intervention programs. Finally, we\nsuggest a novel visualization approach to predictions on a per-patient basis.\nIn conclusion, STRAFE is a cutting-edge time-to-event prediction algorithm that\nhas the potential to enhance risk predictions in large claims datasets.\n","authors":["Moshe Zisser","Dvir Aran"],"pdf_url":"https://arxiv.org/pdf/2306.05779v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05776v1","updated":"2023-06-09T09:42:21Z","published":"2023-06-09T09:42:21Z","title":"Weight Re-Mapping for Variational Quantum Algorithms","summary":"  Inspired by the remarkable success of artificial neural networks across a\nbroad spectrum of AI tasks, variational quantum circuits (VQCs) have recently\nseen an upsurge in quantum machine learning applications. The promising\noutcomes shown by VQCs, such as improved generalization and reduced parameter\ntraining requirements, are attributed to the robust algorithmic capabilities of\nquantum computing. However, the current gradient-based training approaches for\nVQCs do not adequately accommodate the fact that trainable parameters (or\nweights) are typically used as angles in rotational gates. To address this, we\nextend the concept of weight re-mapping for VQCs, as introduced by K\\\"olle et\nal. (2023). This approach unambiguously maps the weights to an interval of\nlength $2\\pi$, mirroring data rescaling techniques in conventional machine\nlearning that have proven to be highly beneficial in numerous scenarios. In our\nstudy, we employ seven distinct weight re-mapping functions to assess their\nimpact on eight classification datasets, using variational classifiers as a\nrepresentative example. Our results indicate that weight re-mapping can enhance\nthe convergence speed of the VQC. We assess the efficacy of various re-mapping\nfunctions across all datasets and measure their influence on the VQC's average\nperformance. Our findings indicate that weight re-mapping not only consistently\naccelerates the convergence of VQCs, regardless of the specific re-mapping\nfunction employed, but also significantly increases accuracy in certain cases.\n","authors":["Michael Kölle","Alessandro Giovagnoli","Jonas Stein","Maximilian Balthasar Mansky","Julian Hager","Tobias Rohe","Robert Müller","Claudia Linnhoff-Popien"],"pdf_url":"https://arxiv.org/pdf/2306.05776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05775v1","updated":"2023-06-09T09:33:34Z","published":"2023-06-09T09:33:34Z","title":"Weight Freezing: A Regularization Approach for Fully Connected Layers\n  with an Application in EEG Classification","summary":"  In the realm of EEG decoding, enhancing the performance of artificial neural\nnetworks (ANNs) carries significant potential. This study introduces a novel\napproach, termed \"weight freezing\", that is anchored on the principles of ANN\nregularization and neuroscience prior knowledge. The concept of weight freezing\nrevolves around the idea of reducing certain neurons' influence on the\ndecision-making process for a specific EEG task by freezing specific weights in\nthe fully connected layer during the backpropagation process. This is\nactualized through the use of a mask matrix and a threshold to determine the\nproportion of weights to be frozen during backpropagation. Moreover, by setting\nthe masked weights to zero, weight freezing can not only realize sparse\nconnections in networks with a fully connected layer as the classifier but also\nfunction as an efficacious regularization method for fully connected layers.\nThrough experiments involving three distinct ANN architectures and three widely\nrecognized EEG datasets, we validate the potency of weight freezing. Our method\nsignificantly surpasses previous peak performances in classification accuracy\nacross all examined datasets. Supplementary control experiments offer insights\ninto performance differences pre and post weight freezing implementation and\nscrutinize the influence of the threshold in the weight freezing process. Our\nstudy underscores the superior efficacy of weight freezing compared to\ntraditional fully connected networks for EEG feature classification tasks. With\nits proven effectiveness, this innovative approach holds substantial promise\nfor contributing to future strides in EEG decoding research.\n","authors":["Zhengqing Miao","Meirong Zhao"],"pdf_url":"https://arxiv.org/pdf/2306.05775v1.pdf","comment":"16 pages, 5 figures"},{"id":"http://arxiv.org/abs/2305.07829v2","updated":"2023-06-09T09:27:33Z","published":"2023-05-13T03:20:33Z","title":"No-Reference Point Cloud Quality Assessment via Weighted Patch Quality\n  Prediction","summary":"  With the rapid development of 3D vision applications based on point clouds,\npoint cloud quality assessment(PCQA) is becoming an important research topic.\nHowever, the prior PCQA methods ignore the effect of local quality variance\nacross different areas of the point cloud. To take an advantage of the quality\ndistribution imbalance, we propose a no-reference point cloud quality\nassessment (NR-PCQA) method with local area correlation analysis capability,\ndenoted as COPP-Net. More specifically, we split a point cloud into patches,\ngenerate texture and structure features for each patch, and fuse them into\npatch features to predict patch quality. Then, we gather the features of all\nthe patches of a point cloud for correlation analysis, to obtain the\ncorrelation weights. Finally, the predicted qualities and correlation weights\nfor all the patches are used to derive the final quality score. Experimental\nresults show that our method outperforms the state-of-the-art benchmark NR-PCQA\nmethods. The source code for the proposed COPP-Net can be found at\nhttps://github.com/philox12358/COPP-Net.\n","authors":["Jun Cheng","Honglei Su","Jari Korhonen"],"pdf_url":"https://arxiv.org/pdf/2305.07829v2.pdf","comment":"6 pages, 5 figures, Accepted by International Conference on Software\n  Engineering and Knowledge Engineering(SEKE2023)"},{"id":"http://arxiv.org/abs/2305.06348v4","updated":"2023-06-09T09:20:17Z","published":"2023-05-10T17:54:21Z","title":"Supervised learning with probabilistic morphisms and kernel mean\n  embeddings","summary":"  In this paper I propose a concept of a correct loss function in a generative\nmodel of supervised learning for an input space $\\mathcal{X}$ and a label space\n$\\mathcal{Y}$, both of which are measurable spaces. A correct loss function in\na generative model of supervised learning must accurately measure the\ndiscrepancy between elements of a hypothesis space $\\mathcal{H}$ of possible\npredictors and the supervisor operator, even when the supervisor operator does\nnot belong to $\\mathcal{H}$. To define correct loss functions, I propose a\ncharacterization of a regular conditional probability measure\n$\\mu_{\\mathcal{Y}|\\mathcal{X}}$ for a probability measure $\\mu$ on $\\mathcal{X}\n\\times \\mathcal{Y}$ relative to the projection $\\Pi_{\\mathcal{X}}:\n\\mathcal{X}\\times\\mathcal{Y}\\to \\mathcal{X}$ as a solution of a linear operator\nequation. If $\\mathcal{Y}$ is a separable metrizable topological space with the\nBorel $\\sigma$-algebra $ \\mathcal{B} (\\mathcal{Y})$, I propose an additional\ncharacterization of a regular conditional probability measure\n$\\mu_{\\mathcal{Y}|\\mathcal{X}}$ as a minimizer of mean square error on the\nspace of Markov kernels, referred to as probabilistic morphisms, from\n$\\mathcal{X}$ to $\\mathcal{Y}$. This characterization utilizes kernel mean\nembeddings. Building upon these results and employing inner measure to quantify\nthe generalizability of a learning algorithm, I extend a result due to\nCucker-Smale, which addresses the learnability of a regression model, to the\nsetting of a conditional probability estimation problem. Additionally, I\npresent a variant of Vapnik's regularization method for solving stochastic\nill-posed problems, incorporating inner measure, and showcase its applications.\n","authors":["Hông Vân Lê"],"pdf_url":"https://arxiv.org/pdf/2305.06348v4.pdf","comment":"V4: 50 p., minor corrections and presentation improvement, in\n  particular in Lemma 6.8, Corollary 6.13, Example 6.14"},{"id":"http://arxiv.org/abs/2306.05769v1","updated":"2023-06-09T09:17:51Z","published":"2023-06-09T09:17:51Z","title":"Self-Paced Absolute Learning Progress as a Regularized Approach to\n  Curriculum Learning","summary":"  The usability of Reinforcement Learning is restricted by the large\ncomputation times it requires. Curriculum Reinforcement Learning speeds up\nlearning by defining a helpful order in which an agent encounters tasks, i.e.\nfrom simple to hard. Curricula based on Absolute Learning Progress (ALP) have\nproven successful in different environments, but waste computation on repeating\nalready learned behaviour in new tasks. We solve this problem by introducing a\nnew regularization method based on Self-Paced (Deep) Learning, called\nSelf-Paced Absolute Learning Progress (SPALP). We evaluate our method in three\ndifferent environments. Our method achieves performance comparable to original\nALP in all cases, and reaches it quicker than ALP in two of them. We illustrate\npossibilities to further improve the efficiency and performance of SPALP.\n","authors":["Tobias Niehues","Ulla Scheler","Pascal Klink"],"pdf_url":"https://arxiv.org/pdf/2306.05769v1.pdf","comment":"11 pages, 8 figures. The paper was a result from an Integrated\n  Project at TU Darmstadt for which we received course credit (9 ECTS) and is\n  not meant to be published elsewhere"},{"id":"http://arxiv.org/abs/2305.04501v2","updated":"2023-06-09T08:57:49Z","published":"2023-05-08T06:52:02Z","title":"SEGA: Structural Entropy Guided Anchor View for Graph Contrastive\n  Learning","summary":"  In contrastive learning, the choice of ``view'' controls the information that\nthe representation captures and influences the performance of the model.\nHowever, leading graph contrastive learning methods generally produce views via\nrandom corruption or learning, which could lead to the loss of essential\ninformation and alteration of semantic information. An anchor view that\nmaintains the essential information of input graphs for contrastive learning\nhas been hardly investigated. In this paper, based on the theory of graph\ninformation bottleneck, we deduce the definition of this anchor view; put\ndifferently, \\textit{the anchor view with essential information of input graph\nis supposed to have the minimal structural uncertainty}. Furthermore, guided by\nstructural entropy, we implement the anchor view, termed \\textbf{SEGA}, for\ngraph contrastive learning. We extensively validate the proposed anchor view on\nvarious benchmarks regarding graph classification under unsupervised,\nsemi-supervised, and transfer learning and achieve significant performance\nboosts compared to the state-of-the-art methods.\n","authors":["Junran Wu","Xueyuan Chen","Bowen Shi","Shangzhe Li","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2305.04501v2.pdf","comment":"ICML'23"},{"id":"http://arxiv.org/abs/2306.05764v1","updated":"2023-06-09T08:57:14Z","published":"2023-06-09T08:57:14Z","title":"Fair yet Asymptotically Equal Collaborative Learning","summary":"  In collaborative learning with streaming data, nodes (e.g., organizations)\njointly and continuously learn a machine learning (ML) model by sharing the\nlatest model updates computed from their latest streaming data. For the more\nresourceful nodes to be willing to share their model updates, they need to be\nfairly incentivized. This paper explores an incentive design that guarantees\nfairness so that nodes receive rewards commensurate to their contributions. Our\napproach leverages an explore-then-exploit formulation to estimate the nodes'\ncontributions (i.e., exploration) for realizing our theoretically guaranteed\nfair incentives (i.e., exploitation). However, we observe a \"rich get richer\"\nphenomenon arising from the existing approaches to guarantee fairness and it\ndiscourages the participation of the less resourceful nodes. To remedy this, we\nadditionally preserve asymptotic equality, i.e., less resourceful nodes achieve\nequal performance eventually to the more resourceful/\"rich\" nodes. We\nempirically demonstrate in two settings with real-world streaming data:\nfederated online incremental learning and federated reinforcement learning,\nthat our proposed approach outperforms existing baselines in fairness and\nlearning performance while remaining competitive in preserving equality.\n","authors":["Xiaoqiang Lin","Xinyi Xu","See-Kiong Ng","Chuan-Sheng Foo","Bryan Kian Hsiang Low"],"pdf_url":"https://arxiv.org/pdf/2306.05764v1.pdf","comment":"Accepted to 40th International Conference on Machine Learning (ICML\n  2023), 37 pages"},{"id":"http://arxiv.org/abs/2210.02871v3","updated":"2023-06-09T08:57:07Z","published":"2022-09-30T02:25:12Z","title":"Self-Distillation for Further Pre-training of Transformers","summary":"  Pre-training a large transformer model on a massive amount of unlabeled data\nand fine-tuning it on labeled datasets for diverse downstream tasks has proven\nto be a successful strategy, for a variety of vision and natural language\nprocessing tasks. However, direct fine-tuning of the pre-trained model may be\nsuboptimal if there exist large discrepancies across data domains for\npre-training and fine-tuning. To tackle this issue, several previous studies\nhave proposed further pre-training strategies, where we continue to pre-train\nthe model on the target unlabeled dataset before fine-tuning. However, all of\nthem solely focus on language models and we empirically find that a Vision\nTransformer is vulnerable to overfitting as we continue to pretrain the model\non target unlabeled data. In order to tackle this limitation, we propose\nself-distillation as a regularization for a further pre-training stage.\nSpecifically, we first further pre-train the initial pre-trained model on the\ntarget unlabeled data and then consider it as a teacher for self-distillation.\nThen we take the same initial pre-trained model as a student and enforce its\nhidden representations to be close to those of the teacher while optimizing the\nstudent with a masked auto-encoding objective. We empirically validate the\nefficacy of self-distillation on a variety of benchmark datasets for image and\ntext classification tasks. Experimentally, we show that our proposed method\noutperforms all the relevant baselines. Theoretically, we analyze the proposed\nmethod with a simplified model to understand how self-distillation for further\npre-training can potentially help improve the performance of the downstream\ntasks.\n","authors":["Seanie Lee","Minki Kang","Juho Lee","Sung Ju Hwang","Kenji Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2210.02871v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2306.05760v1","updated":"2023-06-09T08:54:20Z","published":"2023-06-09T08:54:20Z","title":"Efficient GNN Explanation via Learning Removal-based Attribution","summary":"  As Graph Neural Networks (GNNs) have been widely used in real-world\napplications, model explanations are required not only by users but also by\nlegal regulations. However, simultaneously achieving high fidelity and low\ncomputational costs in generating explanations has been a challenge for current\nmethods. In this work, we propose a framework of GNN explanation named LeArn\nRemoval-based Attribution (LARA) to address this problem. Specifically, we\nintroduce removal-based attribution and demonstrate its substantiated link to\ninterpretability fidelity theoretically and experimentally. The explainer in\nLARA learns to generate removal-based attribution which enables providing\nexplanations with high fidelity. A strategy of subgraph sampling is designed in\nLARA to improve the scalability of the training process. In the deployment,\nLARA can efficiently generate the explanation through a feed-forward pass. We\nbenchmark our approach with other state-of-the-art GNN explanation methods on\nsix datasets. Results highlight the effectiveness of our framework regarding\nboth efficiency and fidelity. In particular, LARA is 3.5 times faster and\nachieves higher fidelity than the state-of-the-art method on the large dataset\nogbn-arxiv (more than 160K nodes and 1M edges), showing its great potential in\nreal-world applications. Our source code is available at\nhttps://anonymous.4open.science/r/LARA-10D8/README.md.\n","authors":["Yao Rong","Guanchu Wang","Qizhang Feng","Ninghao Liu","Zirui Liu","Enkelejda Kasneci","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2306.05760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08162v2","updated":"2023-06-09T08:53:56Z","published":"2022-12-15T21:50:54Z","title":"Huber-energy measure quantization","summary":"  We describe a measure quantization procedure i.e., an algorithm which finds\nthe best approximation of a target probability law (and more generally signed\nfinite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the\nquantization parameter). The procedure is implemented by minimizing the\nstatistical distance between the original measure and its quantized version;\nthe distance is built from a negative definite kernel and, if necessary, can be\ncomputed on the fly and feed to a stochastic optimization algorithm (such as\nSGD, Adam, ...). We investigate theoretically the fundamental questions of\nexistence of the optimal measure quantizer and identify what are the required\nkernel properties that guarantee suitable behavior. We propose two best linear\nunbiased (BLUE) estimators for the squared statistical distance and use them in\nan unbiased procedure, called HEMQ, to find the optimal quantization. We test\nHEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space\ncubature, Italian wine cultivars and the MNIST image database. The results\nindicate that the HEMQ algorithm is robust and versatile and, for the class of\nHuber-energy kernels, matches the expected intuitive behavior.\n","authors":["Gabriel Turinici"],"pdf_url":"https://arxiv.org/pdf/2212.08162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08173v3","updated":"2023-06-09T08:40:45Z","published":"2023-01-19T17:04:59Z","title":"Time-Warping Invariant Quantum Recurrent Neural Networks via\n  Quantum-Classical Adaptive Gating","summary":"  Adaptive gating plays a key role in temporal data processing via classical\nrecurrent neural networks (RNN), as it facilitates retention of past\ninformation necessary to predict the future, providing a mechanism that\npreserves invariance to time warping transformations. This paper builds on\nquantum recurrent neural networks (QRNNs), a dynamic model with quantum memory,\nto introduce a novel class of temporal data processing quantum models that\npreserve invariance to time-warping transformations of the (classical)\ninput-output sequences. The model, referred to as time warping-invariant QRNN\n(TWI-QRNN), augments a QRNN with a quantum-classical adaptive gating mechanism\nthat chooses whether to apply a parameterized unitary transformation at each\ntime step as a function of the past samples of the input sequence via a\nclassical recurrent model. The TWI-QRNN model class is derived from first\nprinciples, and its capacity to successfully implement time-warping\ntransformations is experimentally demonstrated on examples with classical or\nquantum dynamics.\n","authors":["Ivana Nikoloska","Osvaldo Simeone","Leonardo Banchi","Petar Veličković"],"pdf_url":"https://arxiv.org/pdf/2301.08173v3.pdf","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2206.03569v4","updated":"2023-06-09T08:38:39Z","published":"2022-06-07T20:39:51Z","title":"Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement\n  Learning with Latent Low-Rank Structure","summary":"  The practicality of reinforcement learning algorithms has been limited due to\npoor scaling with respect to the problem size, as the sample complexity of\nlearning an $\\epsilon$-optimal policy is $\\tilde{\\Omega}\\left(|S||A|H^3 /\n\\epsilon^2\\right)$ over worst case instances of an MDP with state space $S$,\naction space $A$, and horizon $H$. We consider a class of MDPs for which the\nassociated optimal $Q^*$ function is low rank, where the latent features are\nunknown. While one would hope to achieve linear sample complexity in $|S|$ and\n$|A|$ due to the low rank structure, we show that without imposing further\nassumptions beyond low rank of $Q^*$, if one is constrained to estimate the $Q$\nfunction using only observations from a subset of entries, there is a worst\ncase instance in which one must incur a sample complexity exponential in the\nhorizon $H$ to learn a near optimal policy. We subsequently show that under\nstronger low rank structural assumptions, given access to a generative model,\nLow Rank Monte Carlo Policy Iteration (LR-MCPI) and Low Rank Empirical Value\nIteration (LR-EVI) achieve the desired sample complexity of\n$\\tilde{O}\\left((|S|+|A|)\\mathrm{poly}(d,H)/\\epsilon^2\\right)$ for a rank $d$\nsetting, which is minimax optimal with respect to the scaling of $|S|, |A|$,\nand $\\epsilon$. In contrast to literature on linear and low-rank MDPs, we do\nnot require a known feature mapping, our algorithm is computationally simple,\nand our results hold for long time horizons. Our results provide insights on\nthe minimal low-rank structural assumptions required on the MDP with respect to\nthe transition kernel versus the optimal action-value function.\n","authors":["Tyler Sam","Yudong Chen","Christina Lee Yu"],"pdf_url":"https://arxiv.org/pdf/2206.03569v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.07160v2","updated":"2023-06-09T08:30:56Z","published":"2023-03-13T14:35:55Z","title":"Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond","summary":"  We study convergence lower bounds of without-replacement stochastic gradient\ndescent (SGD) for solving smooth (strongly-)convex finite-sum minimization\nproblems. Unlike most existing results focusing on final iterate lower bounds\nin terms of the number of components $n$ and the number of epochs $K$, we seek\nbounds for arbitrary weighted average iterates that are tight in all factors\nincluding the condition number $\\kappa$. For SGD with Random Reshuffling, we\npresent lower bounds that have tighter $\\kappa$ dependencies than existing\nbounds. Our results are the first to perfectly close the gap between lower and\nupper bounds for weighted average iterates in both strongly-convex and convex\ncases. We also prove weighted average iterate lower bounds for arbitrary\npermutation-based SGD, which apply to all variants that carefully choose the\nbest permutation. Our bounds improve the existing bounds in factors of $n$ and\n$\\kappa$ and thereby match the upper bounds shown for a recently proposed\nalgorithm called GraB.\n","authors":["Jaeyoung Cha","Jaewook Lee","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2303.07160v2.pdf","comment":"58 pages"},{"id":"http://arxiv.org/abs/2306.05751v1","updated":"2023-06-09T08:30:51Z","published":"2023-06-09T08:30:51Z","title":"Advancing Counterfactual Inference through Quantile Regression","summary":"  The capacity to address counterfactual \"what if\" inquiries is crucial for\nunderstanding and making use of causal influences. Traditional counterfactual\ninference usually assumes a structural causal model is available. However, in\npractice, such a causal model is often unknown and may not be identifiable.\nThis paper aims to perform reliable counterfactual inference based on the\n(learned) qualitative causal structure and observational data, without a given\ncausal model or even directly estimating conditional distributions. We re-cast\ncounterfactual reasoning as an extended quantile regression problem using\nneural networks. The approach is statistically more efficient than existing\nones, and further makes it possible to develop the generalization ability of\nthe estimated counterfactual outcome to unseen data and provide an upper bound\non the generalization error. Experiment results on multiple datasets strongly\nsupport our theoretical claims.\n","authors":["Shaoan Xie","Biwei Huang","Bin Gu","Tongliang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05344v2","updated":"2023-06-09T08:27:55Z","published":"2023-06-08T16:46:11Z","title":"A Crystal-Specific Pre-Training Framework for Crystal Material Property\n  Prediction","summary":"  Crystal property prediction is a crucial aspect of developing novel\nmaterials. However, there are two technical challenges to be addressed for\nspeeding up the investigation of crystals. First, labeling crystal properties\nis intrinsically difficult due to the high cost and time involved in physical\nsimulations or lab experiments. Second, crystals adhere to a specific quantum\nchemical principle known as periodic invariance, which is often not captured by\nexisting machine learning methods. To overcome these challenges, we propose the\ncrystal-specific pre-training framework for learning crystal representations\nwith self-supervision. The framework designs a mutex mask strategy for\nenhancing representation learning so as to alleviate the limited labels\navailable for crystal property prediction. Moreover, we take into account the\nspecific periodic invariance in crystal structures by developing a periodic\ninvariance multi-graph module and periodic attribute learning within our\nframework. This framework has been tested on eight different tasks. The\nexperimental results on these tasks show that the framework achieves promising\nprediction performance and is able to outperform recent strong baselines.\n","authors":["Haomin Yu","Yanru Song","Jilin Hu","Chenjuan Guo","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2306.05344v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03042v2","updated":"2023-06-09T08:26:57Z","published":"2023-06-05T17:06:23Z","title":"SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with\n  Missing Values for Environmental Monitoring","summary":"  Environmental monitoring is crucial to our understanding of climate change,\nbiodiversity loss and pollution. The availability of large-scale\nspatio-temporal data from sources such as sensors and satellites allows us to\ndevelop sophisticated models for forecasting and understanding key drivers.\nHowever, the data collected from sensors often contain missing values due to\nfaulty equipment or maintenance issues. The missing values rarely occur\nsimultaneously leading to data that are multivariate misaligned sparse time\nseries. We propose two models that are capable of performing multivariate\nspatio-temporal forecasting while handling missing data naturally without the\nneed for imputation. The first model is a transformer-based model, which we\nname SERT (Spatio-temporal Encoder Representations from Transformers). The\nsecond is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial\nNeural Network) which is capable of providing interpretable results. We conduct\nextensive experiments on two different datasets for multivariate\nspatio-temporal forecasting and show that our models have competitive or\nsuperior performance to those at the state-of-the-art.\n","authors":["Amin Shoari Nejad","Rocío Alaiz-Rodríguez","Gerard D. McCarthy","Brian Kelleher","Anthony Grey","Andrew Parnell"],"pdf_url":"https://arxiv.org/pdf/2306.03042v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.05747v1","updated":"2023-06-09T08:24:56Z","published":"2023-06-09T08:24:56Z","title":"An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling\n  Problems Based on Constraint Programming","summary":"  Constraint Programming (CP) is a declarative programming paradigm that allows\nfor modeling and solving combinatorial optimization problems, such as the\nJob-Shop Scheduling Problem (JSSP). While CP solvers manage to find optimal or\nnear-optimal solutions for small instances, they do not scale well to large\nones, i.e., they require long computation times or yield low-quality solutions.\nTherefore, real-world scheduling applications often resort to fast,\nhandcrafted, priority-based dispatching heuristics to find a good initial\nsolution and then refine it using optimization methods.\n  This paper proposes a novel end-to-end approach to solving scheduling\nproblems by means of CP and Reinforcement Learning (RL). In contrast to\nprevious RL methods, tailored for a given problem by including procedural\nsimulation algorithms, complex feature engineering, or handcrafted reward\nfunctions, our neural-network architecture and training algorithm merely\nrequire a generic CP encoding of some scheduling problem along with a set of\nsmall instances. Our approach leverages existing CP solvers to train an agent\nlearning a Priority Dispatching Rule (PDR) that generalizes well to large\ninstances, even from separate datasets. We evaluate our method on seven JSSP\ndatasets from the literature, showing its ability to find higher-quality\nsolutions for very large instances than obtained by static PDRs and by a CP\nsolver within the same time limit.\n","authors":["Pierre Tassel","Martin Gebser","Konstantin Schekotihin"],"pdf_url":"https://arxiv.org/pdf/2306.05747v1.pdf","comment":"To be published at ICAPS 2023"},{"id":"http://arxiv.org/abs/2306.05745v1","updated":"2023-06-09T08:22:41Z","published":"2023-06-09T08:22:41Z","title":"Two Independent Teachers are Better Role Model","summary":"  Recent deep learning models have attracted substantial attention in infant\nbrain analysis. These models have performed state-of-the-art performance, such\nas semi-supervised techniques (e.g., Temporal Ensembling, mean teacher).\nHowever, these models depend on an encoder-decoder structure with stacked local\noperators to gather long-range information, and the local operators limit the\nefficiency and effectiveness. Besides, the $MRI$ data contain different tissue\nproperties ($TPs$) such as $T1$ and $T2$. One major limitation of these models\nis that they use both data as inputs to the segment process, i.e., the models\nare trained on the dataset once, and it requires much computational and memory\nrequirements during inference. In this work, we address the above limitations\nby designing a new deep-learning model, called 3D-DenseUNet, which works as\nadaptable global aggregation blocks in down-sampling to solve the issue of\nspatial information loss. The self-attention module connects the down-sampling\nblocks to up-sampling blocks, and integrates the feature maps in three\ndimensions of spatial and channel, effectively improving the representation\npotential and discriminating ability of the model. Additionally, we propose a\nnew method called Two Independent Teachers ($2IT$), that summarizes the model\nweights instead of label predictions. Each teacher model is trained on\ndifferent types of brain data, $T1$ and $T2$, respectively. Then, a fuse model\nis added to improve test accuracy and enable training with fewer parameters and\nlabels compared to the Temporal Ensembling method without modifying the network\narchitecture. Empirical results demonstrate the effectiveness of the proposed\nmethod.\n","authors":["Afifa Khaled","Ahmed A. Mubarak","Kun He"],"pdf_url":"https://arxiv.org/pdf/2306.05745v1.pdf","comment":"This manuscript contains 14 pages, 7 figures. We have submitted the\n  manuscript to Journal of IEEE Transactions on Medical Imaging (TMI) in June\n  2023"},{"id":"http://arxiv.org/abs/2306.05739v1","updated":"2023-06-09T08:13:06Z","published":"2023-06-09T08:13:06Z","title":"Leaping through tree space: continuous phylogenetic inference for rooted\n  and unrooted trees","summary":"  Phylogenetics is now fundamental in life sciences, providing insights into\nthe earliest branches of life and the origins and spread of epidemics. However,\nfinding suitable phylogenies from the vast space of possible trees remains\nchallenging. To address this problem, for the first time, we perform both tree\nexploration and inference in a continuous space where the computation of\ngradients is possible. This continuous relaxation allows for major leaps across\ntree space in both rooted and unrooted trees, and is less susceptible to\nconvergence to local minima. Our approach outperforms the current best methods\nfor inference on unrooted trees and, in simulation, accurately infers the tree\nand root in ultrametric cases. The approach is effective in cases of empirical\ndata with negligible amounts of data, which we demonstrate on the phylogeny of\njawed vertebrates. Indeed, only a few genes with an ultrametric signal were\ngenerally sufficient for resolving the major lineages of vertebrate. With\ncubic-time complexity and efficient optimisation via automatic differentiation,\nour method presents an effective way forwards for exploring the most difficult,\ndata-deficient phylogenetic questions.\n","authors":["Matthew J Penn","Neil Scheidwasser","Joseph Penn","Christl A Donnelly","David A Duchêne","Samir Bhatt"],"pdf_url":"https://arxiv.org/pdf/2306.05739v1.pdf","comment":"13 pages, 4 figures, 14 supplementary pages, 2 supplementary figures"},{"id":"http://arxiv.org/abs/2305.15871v2","updated":"2023-06-09T08:01:00Z","published":"2023-05-25T09:06:26Z","title":"Learning Robust Statistics for Simulation-based Inference under Model\n  Misspecification","summary":"  Simulation-based inference (SBI) methods such as approximate Bayesian\ncomputation (ABC), synthetic likelihood, and neural posterior estimation (NPE)\nrely on simulating statistics to infer parameters of intractable likelihood\nmodels. However, such methods are known to yield untrustworthy and misleading\ninference outcomes under model misspecification, thus hindering their\nwidespread applicability. In this work, we propose the first general approach\nto handle model misspecification that works across different classes of SBI\nmethods. Leveraging the fact that the choice of statistics determines the\ndegree of misspecification in SBI, we introduce a regularized loss function\nthat penalises those statistics that increase the mismatch between the data and\nthe model. Taking NPE and ABC as use cases, we demonstrate the superior\nperformance of our method on high-dimensional time-series models that are\nartificially misspecified. We also apply our method to real data from the field\nof radio propagation where the model is known to be misspecified. We show\nempirically that the method yields robust inference in misspecified scenarios,\nwhilst still being accurate when the model is well-specified.\n","authors":["Daolang Huang","Ayush Bharti","Amauri Souza","Luigi Acerbi","Samuel Kaski"],"pdf_url":"https://arxiv.org/pdf/2305.15871v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15817v2","updated":"2023-06-09T07:58:13Z","published":"2023-05-25T08:00:34Z","title":"Sharpness-Aware Minimization Revisited: Weighted Sharpness as a\n  Regularization Term","summary":"  Deep Neural Networks (DNNs) generalization is known to be closely related to\nthe flatness of minima, leading to the development of Sharpness-Aware\nMinimization (SAM) for seeking flatter minima and better generalization. In\nthis paper, we revisit the loss of SAM and propose a more general method,\ncalled WSAM, by incorporating sharpness as a regularization term. We prove its\ngeneralization bound through the combination of PAC and Bayes-PAC techniques,\nand evaluate its performance on various public datasets. The results\ndemonstrate that WSAM achieves improved generalization, or is at least highly\ncompetitive, compared to the vanilla optimizer, SAM and its variants. The code\nis available at\nhttps://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.\n","authors":["Yun Yue","Jiadi Jiang","Zhiling Ye","Ning Gao","Yongchao Liu","Ke Zhang"],"pdf_url":"https://arxiv.org/pdf/2305.15817v2.pdf","comment":"10 pages. Accepted as a conference paper at KDD '23"},{"id":"http://arxiv.org/abs/2306.05734v1","updated":"2023-06-09T07:55:46Z","published":"2023-06-09T07:55:46Z","title":"DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework","summary":"  Hyperparameter optimization, also known as hyperparameter tuning, is a widely\nrecognized technique for improving model performance. Regrettably, when\ntraining private ML models, many practitioners often overlook the privacy risks\nassociated with hyperparameter optimization, which could potentially expose\nsensitive information about the underlying dataset. Currently, the sole\nexisting approach to allow privacy-preserving hyperparameter optimization is to\nuniformly and randomly select hyperparameters for a number of runs,\nsubsequently reporting the best-performing hyperparameter. In contrast, in\nnon-private settings, practitioners commonly utilize \"adaptive\" hyperparameter\noptimization methods such as Gaussian process-based optimization, which select\nthe next candidate based on information gathered from previous outputs. This\nsubstantial contrast between private and non-private hyperparameter\noptimization underscores a critical concern. In our paper, we introduce\nDP-HyPO, a pioneering framework for \"adaptive\" private hyperparameter\noptimization, aiming to bridge the gap between private and non-private\nhyperparameter optimization. To accomplish this, we provide a comprehensive\ndifferential privacy analysis of our framework. Furthermore, we empirically\ndemonstrate the effectiveness of DP-HyPO on a diverse set of real-world and\nsynthetic datasets.\n","authors":["Hua Wang","Sheng Gao","Huanyu Zhang","Weijie J. Su","Milan Shen"],"pdf_url":"https://arxiv.org/pdf/2306.05734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16217v2","updated":"2023-06-09T07:48:49Z","published":"2023-05-25T16:24:11Z","title":"Beyond Reward: Offline Preference-guided Policy Optimization","summary":"  This study focuses on the topic of offline preference-based reinforcement\nlearning (PbRL), a variant of conventional reinforcement learning that\ndispenses with the need for online interaction or specification of reward\nfunctions. Instead, the agent is provided with fixed offline trajectories and\nhuman preferences between pairs of trajectories to extract the dynamics and\ntask information, respectively. Since the dynamics and task information are\northogonal, a naive approach would involve using preference-based reward\nlearning followed by an off-the-shelf offline RL algorithm. However, this\nrequires the separate learning of a scalar reward function, which is assumed to\nbe an information bottleneck of the learning process. To address this issue, we\npropose the offline preference-guided policy optimization (OPPO) paradigm,\nwhich models offline trajectories and preferences in a one-step process,\neliminating the need for separately learning a reward function. OPPO achieves\nthis by introducing an offline hindsight information matching objective for\noptimizing a contextual policy and a preference modeling objective for finding\nthe optimal context. OPPO further integrates a well-performing decision policy\nby optimizing the two objectives iteratively. Our empirical results demonstrate\nthat OPPO effectively models offline preferences and outperforms prior\ncompeting baselines, including offline RL algorithms performed over either true\nor pseudo reward function specifications. Our code is available on the project\nwebsite: https://sites.google.com/view/oppo-icml-2023 .\n","authors":["Yachen Kang","Diyuan Shi","Jinxin Liu","Li He","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2305.16217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05727v1","updated":"2023-06-09T07:48:36Z","published":"2023-06-09T07:48:36Z","title":"The Role of Diverse Replay for Generalisation in Reinforcement Learning","summary":"  In reinforcement learning (RL), key components of many algorithms are the\nexploration strategy and replay buffer. These strategies regulate what\nenvironment data is collected and trained on and have been extensively studied\nin the RL literature. In this paper, we investigate the impact of these\ncomponents in the context of generalisation in multi-task RL. We investigate\nthe hypothesis that collecting and training on more diverse data from the\ntraining environment will improve zero-shot generalisation to new\nenvironments/tasks. We motivate mathematically and show empirically that\ngeneralisation to states that are \"reachable\" during training is improved by\nincreasing the diversity of transitions in the replay buffer. Furthermore, we\nshow empirically that this same strategy also shows improvement for\ngeneralisation to similar but \"unreachable\" states and could be due to improved\ngeneralisation of latent representations.\n","authors":["Max Weltevrede","Matthijs T. J. Spaan","Wendelin Böhmer"],"pdf_url":"https://arxiv.org/pdf/2306.05727v1.pdf","comment":"14 pages, 8 figures"},{"id":"http://arxiv.org/abs/2306.05726v1","updated":"2023-06-09T07:46:24Z","published":"2023-06-09T07:46:24Z","title":"In-Sample Policy Iteration for Offline Reinforcement Learning","summary":"  Offline reinforcement learning (RL) seeks to derive an effective control\npolicy from previously collected data. To circumvent errors due to inadequate\ndata coverage, behavior-regularized methods optimize the control policy while\nconcurrently minimizing deviation from the data collection policy.\nNevertheless, these methods often exhibit subpar practical performance,\nparticularly when the offline dataset is collected by sub-optimal policies. In\nthis paper, we propose a novel algorithm employing in-sample policy iteration\nthat substantially enhances behavior-regularized methods in offline RL. The\ncore insight is that by continuously refining the policy used for behavior\nregularization, in-sample policy iteration gradually improves itself while\nimplicitly avoids querying out-of-sample actions to avert catastrophic learning\nfailures. Our theoretical analysis verifies its ability to learn the in-sample\noptimal policy, exclusively utilizing actions well-covered by the dataset.\nMoreover, we propose competitive policy improvement, a technique applying two\ncompetitive policies, both of which are trained by iteratively improving over\nthe best competitor. We show that this simple yet potent technique\nsignificantly enhances learning efficiency when function approximation is\napplied. Lastly, experimental results on the D4RL benchmark indicate that our\nalgorithm outperforms previous state-of-the-art methods in most tasks.\n","authors":["Xiaohan Hu","Yi Ma","Chenjun Xiao","Yan Zheng","Zhaopeng Meng"],"pdf_url":"https://arxiv.org/pdf/2306.05726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05724v1","updated":"2023-06-09T07:43:46Z","published":"2023-06-09T07:43:46Z","title":"Explaining Predictive Uncertainty with Information Theoretic Shapley\n  Values","summary":"  Researchers in explainable artificial intelligence have developed numerous\nmethods for helping users understand the predictions of complex supervised\nlearning models. By contrast, explaining the $\\textit{uncertainty}$ of model\noutputs has received relatively little attention. We adapt the popular Shapley\nvalue framework to explain various types of predictive uncertainty, quantifying\neach feature's contribution to the conditional entropy of individual model\noutputs. We consider games with modified characteristic functions and find deep\nconnections between the resulting Shapley values and fundamental quantities\nfrom information theory and conditional independence testing. We outline\ninference procedures for finite sample error rate control with provable\nguarantees, and implement an efficient algorithm that performs well in a range\nof experiments on real and simulated data. Our method has applications to\ncovariate shift detection, active learning, feature selection, and active\nfeature-value acquisition.\n","authors":["David S. Watson","Joshua O'Hara","Niek Tax","Richard Mudd","Ido Guy"],"pdf_url":"https://arxiv.org/pdf/2306.05724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05722v1","updated":"2023-06-09T07:38:38Z","published":"2023-06-09T07:38:38Z","title":"Estimation of Ridge Using Nonlinear Transformation on Density Function","summary":"  Ridges play a vital role in accurately approximating the underlying structure\nof manifolds. In this paper, we explore the ridge's variation by applying a\nconcave nonlinear transformation to the density function. Through the\nderivation of the Hessian matrix, we observe that nonlinear transformations\nyield a rank-one modification of the Hessian matrix. Leveraging the variational\nproperties of eigenvalue problems, we establish a partial order inclusion\nrelationship among the corresponding ridges. We intuitively discover that the\ntransformation can lead to improved estimation of the tangent space via\nrank-one modification of the Hessian matrix. To validate our theories, we\nconduct extensive numerical experiments on synthetic and real-world datasets\nthat demonstrate the superiority of the ridges obtained from our transformed\napproach in approximating the underlying truth manifold compared to other\nmanifold fitting algorithms.\n","authors":["Zheng Zhai","Hengchao Chen","Zhigang Yao"],"pdf_url":"https://arxiv.org/pdf/2306.05722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05720v1","updated":"2023-06-09T07:34:34Z","published":"2023-06-09T07:34:34Z","title":"Beyond Surface Statistics: Scene Representations in a Latent Diffusion\n  Model","summary":"  Latent diffusion models (LDMs) exhibit an impressive ability to produce\nrealistic images, yet the inner workings of these models remain mysterious.\nEven when trained purely on images without explicit depth information, they\ntypically output coherent pictures of 3D scenes. In this work, we investigate a\nbasic interpretability question: does an LDM create and use an internal\nrepresentation of simple scene geometry? Using linear probes, we find evidence\nthat the internal activations of the LDM encode linear representations of both\n3D depth data and a salient-object / background distinction. These\nrepresentations appear surprisingly early in the denoising process$-$well\nbefore a human can easily make sense of the noisy images. Intervention\nexperiments further indicate these representations play a causal role in image\nsynthesis, and may be used for simple high-level editing of an LDM's output.\n","authors":["Yida Chen","Fernanda Viégas","Martin Wattenberg"],"pdf_url":"https://arxiv.org/pdf/2306.05720v1.pdf","comment":"17 pages, 13 figures"},{"id":"http://arxiv.org/abs/2305.02776v2","updated":"2023-06-09T07:33:29Z","published":"2023-05-04T12:21:34Z","title":"Efficient Personalized Federated Learning via Sparse Model-Adaptation","summary":"  Federated Learning (FL) aims to train machine learning models for multiple\nclients without sharing their own private data. Due to the heterogeneity of\nclients' local data distribution, recent studies explore the personalized FL\nthat learns and deploys distinct local models with the help of auxiliary global\nmodels. However, the clients can be heterogeneous in terms of not only local\ndata distribution, but also their computation and communication resources. The\ncapacity and efficiency of personalized models are restricted by the\nlowest-resource clients, leading to sub-optimal performance and limited\npracticality of personalized FL. To overcome these challenges, we propose a\nnovel approach named pFedGate for efficient personalized FL by adaptively and\nefficiently learning sparse local models. With a lightweight trainable gating\nlayer, pFedGate enables clients to reach their full potential in model capacity\nby generating different sparse models accounting for both the heterogeneous\ndata distributions and resource constraints. Meanwhile, the computation and\ncommunication efficiency are both improved thanks to the adaptability between\nthe model sparsity and clients' resources. Further, we theoretically show that\nthe proposed pFedGate has superior complexity with guaranteed convergence and\ngeneralization error. Extensive experiments show that pFedGate achieves\nsuperior global accuracy, individual accuracy and efficiency simultaneously\nover state-of-the-art methods. We also demonstrate that pFedGate performs\nbetter than competitors in the novel clients participation and partial clients\nparticipation scenarios, and can learn meaningful sparse local models adapted\nto different data distributions.\n","authors":["Daoyuan Chen","Liuyi Yao","Dawei Gao","Bolin Ding","Yaliang Li"],"pdf_url":"https://arxiv.org/pdf/2305.02776v2.pdf","comment":"Accepted to ICML 2023"},{"id":"http://arxiv.org/abs/2209.10866v4","updated":"2023-06-09T07:07:51Z","published":"2022-09-22T09:04:10Z","title":"A One-shot Framework for Distributed Clustered Learning in Heterogeneous\n  Environments","summary":"  The paper proposes a family of communication efficient methods for\ndistributed learning in heterogeneous environments in which users obtain data\nfrom one of $K$ different distributions. In the proposed setup, the grouping of\nusers (based on the data distributions they sample), as well as the underlying\nstatistical properties of the distributions, are apriori unknown. A family of\nOne-shot Distributed Clustered Learning methods (ODCL-$\\mathcal{C}$) is\nproposed, parametrized by the set of admissible clustering algorithms\n$\\mathcal{C}$, with the objective of learning the true model at each user. The\nadmissible clustering methods include $K$-means (KM) and convex clustering\n(CC), giving rise to various one-shot methods within the proposed family, such\nas ODCL-KM and ODCL-CC. The proposed one-shot approach, based on local\ncomputations at the users and a clustering based aggregation step at the server\nis shown to provide strong learning guarantees. In particular, for strongly\nconvex problems it is shown that, as long as the number of data points per user\nis above a threshold, the proposed approach achieves order-optimal mean-squared\nerror (MSE) rates in terms of the sample size. An explicit characterization of\nthe threshold is provided in terms of problem parameters. The trade-offs with\nrespect to selecting various clustering methods (ODCL-CC, ODCL-KM) are\ndiscussed and significant improvements over state-of-the-art are demonstrated.\nNumerical experiments illustrate the findings and corroborate the performance\nof the proposed methods.\n","authors":["Aleksandar Armacki","Dragana Bajovic","Dusan Jakovetic","Soummya Kar"],"pdf_url":"https://arxiv.org/pdf/2209.10866v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05708v1","updated":"2023-06-09T07:02:43Z","published":"2023-06-09T07:02:43Z","title":"Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion","summary":"  Denoising Diffusion Probabilistic Models have shown extraordinary ability on\nvarious generative tasks. However, their slow inference speed renders them\nimpractical in speech synthesis. This paper proposes a linear diffusion model\n(LinDiff) based on an ordinary differential equation to simultaneously reach\nfast inference and high sample quality. Firstly, we employ linear interpolation\nbetween the target and noise to design a diffusion sequence for training, while\npreviously the diffusion path that links the noise and target is a curved\nsegment. When decreasing the number of sampling steps (i.e., the number of line\nsegments used to fit the path), the ease of fitting straight lines compared to\ncurves allows us to generate higher quality samples from a random noise with\nfewer iterations. Secondly, to reduce computational complexity and achieve\neffective global modeling of noisy speech, LinDiff employs a patch-based\nprocessing approach that partitions the input signal into small patches. The\npatch-wise token leverages Transformer architecture for effective modeling of\nglobal information. Adversarial training is used to further improve the sample\nquality with decreased sampling steps. We test proposed method with speech\nsynthesis conditioned on acoustic feature (Mel-spectrograms). Experimental\nresults verify that our model can synthesize high-quality speech even with only\none diffusion step. Both subjective and objective evaluations demonstrate that\nour model can synthesize speech of a quality comparable to that of\nautoregressive models with faster synthesis speed (3 diffusion steps).\n","authors":["Haogeng Liu","Tao Wang","Jie Cao","Ran He","Jianhua Tao"],"pdf_url":"https://arxiv.org/pdf/2306.05708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05706v1","updated":"2023-06-09T06:55:15Z","published":"2023-06-09T06:55:15Z","title":"Understanding How Consistency Works in Federated Learning via Stage-wise\n  Relaxed Initialization","summary":"  Federated learning (FL) is a distributed paradigm that coordinates massive\nlocal clients to collaboratively train a global model via stage-wise local\ntraining processes on the heterogeneous dataset. Previous works have implicitly\nstudied that FL suffers from the ``client-drift'' problem, which is caused by\nthe inconsistent optimum across local clients. However, till now it still lacks\nsolid theoretical analysis to explain the impact of this local inconsistency.\nTo alleviate the negative impact of the ``client drift'' and explore its\nsubstance in FL, in this paper, we first design an efficient FL algorithm\n\\textit{FedInit}, which allows employing the personalized relaxed\ninitialization state at the beginning of each local training stage.\nSpecifically, \\textit{FedInit} initializes the local state by moving away from\nthe current global state towards the reverse direction of the latest local\nstate. This relaxed initialization helps to revise the local divergence and\nenhance the local consistency level. Moreover, to further understand how\ninconsistency disrupts performance in FL, we introduce the excess risk analysis\nand study the divergence term to investigate the test error of the proposed\n\\textit{FedInit} method. Our studies show that optimization error is not\nsensitive to this local inconsistency, while it mainly affects the\ngeneralization error bound in \\textit{FedInit}. Extensive experiments are\nconducted to validate this conclusion. Our proposed \\textit{FedInit} could\nachieve state-of-the-art~(SOTA) results compared to several advanced benchmarks\nwithout any additional costs. Meanwhile, stage-wise relaxed initialization\ncould also be incorporated into the current advanced algorithms to achieve\nhigher performance in the FL paradigm.\n","authors":["Yan Sun","Li Shen","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2306.05706v1.pdf","comment":"32 pages"},{"id":"http://arxiv.org/abs/2303.14822v2","updated":"2023-06-09T06:50:57Z","published":"2023-03-26T21:12:36Z","title":"MGTBench: Benchmarking Machine-Generated Text Detection","summary":"  Nowadays large language models (LLMs) have shown revolutionary power in a\nvariety of natural language processing (NLP) tasks such as text classification,\nsentiment analysis, language translation, and question-answering. In this way,\ndetecting machine-generated texts (MGTs) is becoming increasingly important as\nLLMs become more advanced and prevalent. These models can generate human-like\nlanguage that can be difficult to distinguish from text written by a human,\nwhich raises concerns about authenticity, accountability, and potential bias.\nHowever, existing detection methods against MGTs are evaluated under different\nmodel architectures, datasets, and experimental settings, resulting in a lack\nof a comprehensive evaluation framework across different methodologies\n  In this paper, we fill this gap by proposing the first benchmark framework\nfor MGT detection, named MGTBench. Extensive evaluations on public datasets\nwith curated answers generated by ChatGPT (the most representative and powerful\nLLMs thus far) show that most of the current detection methods perform less\nsatisfactorily against MGTs. An exceptional case is ChatGPT Detector, which is\ntrained with ChatGPT-generated texts and shows great performance in detecting\nMGTs. Nonetheless, we note that only a small fraction of adversarial-crafted\nperturbations on MGTs can evade the ChatGPT Detector, thus highlighting the\nneed for more robust MGT detection methods. We envision that MGTBench will\nserve as a benchmark tool to accelerate future investigations involving the\nevaluation of state-of-the-art MGT detection methods on their respective\ndatasets and the development of more advanced MGT detection methods. Our source\ncode and datasets are available at https://github.com/xinleihe/MGTBench.\n","authors":["Xinlei He","Xinyue Shen","Zeyuan Chen","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.14822v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05700v1","updated":"2023-06-09T06:39:37Z","published":"2023-06-09T06:39:37Z","title":"Finite-Time Analysis of Minimax Q-Learning for Two-Player Zero-Sum\n  Markov Games: Switching System Approach","summary":"  The objective of this paper is to investigate the finite-time analysis of a\nQ-learning algorithm applied to two-player zero-sum Markov games. Specifically,\nwe establish a finite-time analysis of both the minimax Q-learning algorithm\nand the corresponding value iteration method. To enhance the analysis of both\nvalue iteration and Q-learning, we employ the switching system model of minimax\nQ-learning and the associated value iteration. This approach provides further\ninsights into minimax Q-learning and facilitates a more straightforward and\ninsightful convergence analysis. We anticipate that the introduction of these\nadditional insights has the potential to uncover novel connections and foster\ncollaboration between concepts in the fields of control theory and\nreinforcement learning communities.\n","authors":["Donghwan Lee"],"pdf_url":"https://arxiv.org/pdf/2306.05700v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2205.05455"},{"id":"http://arxiv.org/abs/2306.05698v1","updated":"2023-06-09T06:35:14Z","published":"2023-06-09T06:35:14Z","title":"JABBERWOCK: A Tool for WebAssembly Dataset Generation and Its\n  Application to Malicious Website Detection","summary":"  Machine learning is often used for malicious website detection, but an\napproach incorporating WebAssembly as a feature has not been explored due to a\nlimited number of samples, to the best of our knowledge. In this paper, we\npropose JABBERWOCK (JAvascript-Based Binary EncodeR by WebAssembly Optimization\npaCKer), a tool to generate WebAssembly datasets in a pseudo fashion via\nJavaScript. Loosely speaking, JABBERWOCK automatically gathers JavaScript code\nin the real world, convert them into WebAssembly, and then outputs vectors of\nthe WebAssembly as samples for malicious website detection. We also conduct\nexperimental evaluations of JABBERWOCK in terms of the processing time for\ndataset generation, comparison of the generated samples with actual WebAssembly\nsamples gathered from the Internet, and an application for malicious website\ndetection. Regarding the processing time, we show that JABBERWOCK can construct\na dataset in 4.5 seconds per sample for any number of samples. Next, comparing\n10,000 samples output by JABBERWOCK with 168 gathered WebAssembly samples, we\nbelieve that the generated samples by JABBERWOCK are similar to those in the\nreal world. We then show that JABBERWOCK can provide malicious website\ndetection with 99\\% F1-score because JABBERWOCK makes a gap between benign and\nmalicious samples as the reason for the above high score. We also confirm that\nJABBERWOCK can be combined with an existing malicious website detection tool to\nimprove F1-scores. JABBERWOCK is publicly available via GitHub\n(https://github.com/c-chocolate/Jabberwock).\n","authors":["Chika Komiya","Naoto Yanai","Kyosuke Yamashita","Shingo Okamura"],"pdf_url":"https://arxiv.org/pdf/2306.05698v1.pdf","comment":"Accepted in DCDS 2023 (co-located in DSN 2023)"},{"id":"http://arxiv.org/abs/2212.12978v4","updated":"2023-06-09T06:34:33Z","published":"2022-12-26T00:28:07Z","title":"Doubly Smoothed GDA for Constrained Nonconvex-Nonconcave Minimax\n  Optimization","summary":"  Nonconvex-nonconcave minimax optimization has received intense attention over\nthe last decade due to its broad applications in machine learning.\nUnfortunately, most existing algorithms cannot be guaranteed to converge\nglobally and even suffer from limit cycles. To address this issue, we propose a\nnovel single-loop algorithm called doubly smoothed gradient descent ascent\nmethod (DSGDA), which naturally balances the primal and dual updates. The\nproposed DSGDA can get rid of limit cycles in various challenging\nnonconvex-nonconcave examples in the literature, including Forsaken,\nBilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further\nshow that under an one-sided Kurdyka-\\L{}ojasiewicz condition with exponent\n$\\theta\\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a\ngame-stationary point with an iteration complexity of\n$\\mathcal{O}(\\epsilon^{-2\\max\\{2\\theta,1\\}})$ (resp.\n$\\mathcal{O}(\\epsilon^{-4})$). These match the best results for single-loop\nalgorithms that solve nonconvex-concave or convex-nonconcave minimax problems,\nor problems satisfying the rather restrictive one-sided Polyak-\\L{}ojasiewicz\ncondition. Our work demonstrates, for the first time, the possibility of having\na simple and unified single-loop algorithm for solving nonconvex-nonconcave,\nnonconvex-concave, and convex-nonconcave minimax problems.\n","authors":["Taoli Zheng","Linglingzhi Zhu","Anthony Man-Cho So","Jose Blanchet","Jiajin Li"],"pdf_url":"https://arxiv.org/pdf/2212.12978v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05697v1","updated":"2023-06-09T06:34:16Z","published":"2023-06-09T06:34:16Z","title":"Group Equivariant Fourier Neural Operators for Partial Differential\n  Equations","summary":"  We consider solving partial differential equations (PDEs) with Fourier neural\noperators (FNOs), which operate in the frequency domain. Since the laws of\nphysics do not depend on the coordinate system used to describe them, it is\ndesirable to encode such symmetries in the neural operator architecture for\nbetter performance and easier learning. While encoding symmetries in the\nphysical domain using group theory has been studied extensively, how to capture\nsymmetries in the frequency domain is under-explored. In this work, we extend\ngroup convolutions to the frequency domain and design Fourier layers that are\nequivariant to rotations, translations, and reflections by leveraging the\nequivariance property of the Fourier transform. The resulting $G$-FNO\narchitecture generalizes well across input resolutions and performs well in\nsettings with varying levels of symmetry. Our code is publicly available as\npart of the AIRS library (https://github.com/divelab/AIRS).\n","authors":["Jacob Helwig","Xuan Zhang","Cong Fu","Jerry Kurtin","Stephan Wojtowytsch","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2306.05697v1.pdf","comment":"Proceedings of the 40th International Conference on Machine Learning\n  https://icml.cc/virtual/2023/poster/23875"},{"id":"http://arxiv.org/abs/2306.05694v1","updated":"2023-06-09T06:30:25Z","published":"2023-06-09T06:30:25Z","title":"Explainable Representation Learning of Small Quantum States","summary":"  Unsupervised machine learning models build an internal representation of\ntheir training data without the need for explicit human guidance or feature\nengineering. This learned representation provides insights into which features\nof the data are relevant for the task at hand. In the context of quantum\nphysics, training models to describe quantum states without human intervention\noffers a promising approach to gaining insight into how machines represent\ncomplex quantum states. The ability to interpret the learned representation may\noffer a new perspective on non-trivial features of quantum systems and their\nefficient representation. We train a generative model on two-qubit density\nmatrices generated by a parameterized quantum circuit. In a series of\ncomputational experiments, we investigate the learned representation of the\nmodel and its internal understanding of the data. We observe that the model\nlearns an interpretable representation which relates the quantum states to\ntheir underlying entanglement characteristics. In particular, our results\ndemonstrate that the latent representation of the model is directly correlated\nwith the entanglement measure concurrence. The insights from this study\nrepresent proof of concept towards interpretable machine learning of quantum\nstates. Our approach offers insight into how machines learn to represent\nsmall-scale quantum systems autonomously.\n","authors":["Felix Frohnert","Evert van Nieuwenburg"],"pdf_url":"https://arxiv.org/pdf/2306.05694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07894v2","updated":"2023-06-09T06:28:52Z","published":"2023-05-13T11:23:00Z","title":"Voxel-wise classification for porosity investigation of additive\n  manufactured parts with 3D unsupervised and (deeply) supervised neural\n  networks","summary":"  Additive Manufacturing (AM) has emerged as a manufacturing process that\nallows the direct production of samples from digital models. To ensure that\nquality standards are met in all manufactured samples of a batch, X-ray\ncomputed tomography (X-CT) is often used combined with automated anomaly\ndetection. For the latter, deep learning (DL) anomaly detection techniques are\nincreasingly, as they can be trained to be robust to the material being\nanalysed and resilient towards poor image quality. Unfortunately, most recent\nand popular DL models have been developed for 2D image processing, thereby\ndisregarding valuable volumetric information.\n  This study revisits recent supervised (UNet, UNet++, UNet 3+, MSS-UNet) and\nunsupervised (VAE, ceVAE, gmVAE, vqVAE) DL models for porosity analysis of AM\nsamples from X-CT images and extends them to accept 3D input data with a\n3D-patch pipeline for lower computational requirements, improved efficiency and\ngeneralisability. The supervised models were trained using the Focal Tversky\nloss to address class imbalance that arises from the low porosity in the\ntraining datasets. The output of the unsupervised models is post-processed to\nreduce misclassifications caused by their inability to adequately represent the\nobject surface. The findings were cross-validated in a 5-fold fashion and\ninclude: a performance benchmark of the DL models, an evaluation of the\npost-processing algorithm, an evaluation of the effect of training supervised\nmodels with the output of unsupervised models. In a final performance benchmark\non a test set with poor image quality, the best performing supervised model was\nUNet++ with an average precision of 0.751 $\\pm$ 0.030, while the best\nunsupervised model was the post-processed ceVAE with 0.830 $\\pm$ 0.003. The\nVAE/ceVAE models demonstrated superior capabilities, particularly when\nleveraging post-processing techniques.\n","authors":["Domenico Iuso","Soumick Chatterjee","Sven Cornelissen","Dries Verhees","Jan De Beenhouwer","Jan Sijbers"],"pdf_url":"https://arxiv.org/pdf/2305.07894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05272v2","updated":"2023-06-09T06:16:30Z","published":"2023-06-08T15:20:27Z","title":"Image Clustering via the Principle of Rate Reduction in the Age of\n  Pretrained Models","summary":"  The advent of large pre-trained models has brought about a paradigm shift in\nboth visual representation learning and natural language processing. However,\nclustering unlabeled images, as a fundamental and classic machine learning\nproblem, still lacks effective solution, particularly for large-scale datasets.\nIn this paper, we propose a novel image clustering pipeline that leverages the\npowerful feature representation of large pre-trained models such as CLIP and\ncluster images effectively and efficiently at scale. We show that the\npre-trained features are significantly more structured by further optimizing\nthe rate reduction objective. The resulting features may significantly improve\nthe clustering accuracy, e.g., from 57\\% to 66\\% on ImageNet-1k. Furthermore,\nby leveraging CLIP's image-text binding, we show how the new clustering method\nleads to a simple yet effective self-labeling algorithm that successfully works\non unlabeled large datasets such as MS-COCO and LAION-Aesthetics. We will\nrelease the code in https://github.com/LeslieTrue/CPP.\n","authors":["Tianzhe Chu","Shengbang Tong","Tianjiao Ding","Xili Dai","Benjamin David Haeffele","René Vidal","Yi Ma"],"pdf_url":"https://arxiv.org/pdf/2306.05272v2.pdf","comment":"21 pages, 13 figures"},{"id":"http://arxiv.org/abs/2306.05682v1","updated":"2023-06-09T05:51:40Z","published":"2023-06-09T05:51:40Z","title":"Lightweight Monocular Depth Estimation via Token-Sharing Transformer","summary":"  Depth estimation is an important task in various robotics systems and\napplications. In mobile robotics systems, monocular depth estimation is\ndesirable since a single RGB camera can be deployable at a low cost and compact\nsize. Due to its significant and growing needs, many lightweight monocular\ndepth estimation networks have been proposed for mobile robotics systems. While\nmost lightweight monocular depth estimation methods have been developed using\nconvolution neural networks, the Transformer has been gradually utilized in\nmonocular depth estimation recently. However, massive parameters and large\ncomputational costs in the Transformer disturb the deployment to embedded\ndevices. In this paper, we present a Token-Sharing Transformer (TST), an\narchitecture using the Transformer for monocular depth estimation, optimized\nespecially in embedded devices. The proposed TST utilizes global token sharing,\nwhich enables the model to obtain an accurate depth prediction with high\nthroughput in embedded devices. Experimental results show that TST outperforms\nthe existing lightweight monocular depth estimation methods. On the NYU Depth\nv2 dataset, TST can deliver depth maps up to 63.4 FPS in NVIDIA Jetson nano and\n142.6 FPS in NVIDIA Jetson TX2, with lower errors than the existing methods.\nFurthermore, TST achieves real-time depth estimation of high-resolution images\non Jetson TX2 with competitive results.\n","authors":["Dong-Jae Lee","Jae Young Lee","Hyounguk Shon","Eojindl Yi","Yeong-Hun Park","Sung-Sik Cho","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2306.05682v1.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2306.05680v1","updated":"2023-06-09T05:43:06Z","published":"2023-06-09T05:43:06Z","title":"Emotion Detection from EEG using Transfer Learning","summary":"  The detection of emotions using an Electroencephalogram (EEG) is a crucial\narea in brain-computer interfaces and has valuable applications in fields such\nas rehabilitation and medicine. In this study, we employed transfer learning to\novercome the challenge of limited data availability in EEG-based emotion\ndetection. The base model used in this study was Resnet50. Additionally, we\nemployed a novel feature combination in EEG-based emotion detection. The input\nto the model was in the form of an image matrix, which comprised Mean Phase\nCoherence (MPC) and Magnitude Squared Coherence (MSC) in the upper-triangular\nand lower-triangular matrices, respectively. We further improved the technique\nby incorporating features obtained from the Differential Entropy (DE) into the\ndiagonal, which previously held little to no useful information for classifying\nemotions. The dataset used in this study, SEED EEG (62 channel EEG), comprises\nthree classes (Positive, Neutral, and Negative). We calculated both\nsubject-independent and subject-dependent accuracy. The subject-dependent\naccuracy was obtained using a 10-fold cross-validation method and was 93.1%,\nwhile the subject-independent classification was performed by employing the\nleave-one-subject-out (LOSO) strategy. The accuracy obtained in\nsubject-independent classification was 71.6%. Both of these accuracies are at\nleast twice better than the chance accuracy of classifying 3 classes. The study\nfound the use of MSC and MPC in EEG-based emotion detection promising for\nemotion classification. The future scope of this work includes the use of data\naugmentation techniques, enhanced classifiers, and better features for emotion\nclassification.\n","authors":["Sidharth Sidharth","Ashish Abraham Samuel","Ranjana H","Jerrin Thomas Panachakel","Sana Parveen K"],"pdf_url":"https://arxiv.org/pdf/2306.05680v1.pdf","comment":"Preprint of the manuscript accepted for presentation in 45th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society. DOI will be updated soon"},{"id":"http://arxiv.org/abs/2305.19452v2","updated":"2023-06-09T05:17:43Z","published":"2023-05-30T23:23:25Z","title":"Bigger, Better, Faster: Human-level Atari with human-level efficiency","summary":"  We introduce a value-based RL agent, which we call BBF, that achieves\nsuper-human performance in the Atari 100K benchmark. BBF relies on scaling the\nneural networks used for value estimation, as well as a number of other design\nchoices that enable this scaling in a sample-efficient manner. We conduct\nextensive analyses of these design choices and provide insights for future\nwork. We end with a discussion about updating the goalposts for\nsample-efficient RL research on the ALE. We make our code and data publicly\navailable at\nhttps://github.com/google-research/google-research/tree/master/bigger_better_faster.\n","authors":["Max Schwarzer","Johan Obando-Ceron","Aaron Courville","Marc Bellemare","Rishabh Agarwal","Pablo Samuel Castro"],"pdf_url":"https://arxiv.org/pdf/2305.19452v2.pdf","comment":"ICML 2023 Camera Ready"},{"id":"http://arxiv.org/abs/2306.05674v1","updated":"2023-06-09T05:15:53Z","published":"2023-06-09T05:15:53Z","title":"Efficient Uncertainty Quantification and Reduction for\n  Over-Parameterized Neural Networks","summary":"  Uncertainty quantification (UQ) is important for reliability assessment and\nenhancement of machine learning models. In deep learning, uncertainties arise\nnot only from data, but also from the training procedure that often injects\nsubstantial noises and biases. These hinder the attainment of statistical\nguarantees and, moreover, impose computational challenges on UQ due to the need\nfor repeated network retraining. Building upon the recent neural tangent kernel\ntheory, we create statistically guaranteed schemes to principally\n\\emph{quantify}, and \\emph{remove}, the procedural uncertainty of\nover-parameterized neural networks with very low computation effort. In\nparticular, our approach, based on what we call a procedural-noise-correcting\n(PNC) predictor, removes the procedural uncertainty by using only \\emph{one}\nauxiliary network that is trained on a suitably labeled data set, instead of\nmany retrained networks employed in deep ensembles. Moreover, by combining our\nPNC predictor with suitable light-computation resampling methods, we build\nseveral approaches to construct asymptotically exact-coverage confidence\nintervals using as low as four trained networks without additional overheads.\n","authors":["Ziyi Huang","Henry Lam","Haofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2306.05674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.08627v3","updated":"2023-06-09T05:14:58Z","published":"2021-10-16T17:52:32Z","title":"Achieving the Pareto Frontier of Regret Minimization and Best Arm\n  Identification in Multi-Armed Bandits","summary":"  We study the Pareto frontier of two archetypal objectives in multi-armed\nbandits, namely, regret minimization (RM) and best arm identification (BAI)\nwith a fixed horizon. It is folklore that the balance between exploitation and\nexploration is crucial for both RM and BAI, but exploration is more critical in\nachieving the optimal performance for the latter objective. To this end, we\ndesign and analyze the BoBW-lil'UCB$(\\gamma)$ algorithm. Complementarily, by\nestablishing lower bounds on the regret achievable by any algorithm with a\ngiven BAI failure probability, we show that (i) no algorithm can simultaneously\nperform optimally for both the RM and BAI objectives, and (ii)\nBoBW-lil'UCB$(\\gamma)$ achieves order-wise optimal performance for RM or BAI\nunder different values of $\\gamma$. Our work elucidates the trade-off more\nprecisely by showing how the constants in previous works depend on certain\nhardness parameters. Finally, we show that BoBW-lil'UCB outperforms a close\ncompetitor UCB$_\\alpha$ (Degenne et al., 2019) in terms of the time complexity\nand the regret on diverse datasets such as MovieLens and Published Kinase\nInhibitor Set.\n","authors":["Zixin Zhong","Wang Chi Cheung","Vincent Y. F. Tan"],"pdf_url":"https://arxiv.org/pdf/2110.08627v3.pdf","comment":"43 pages, 10 figures"},{"id":"http://arxiv.org/abs/2306.05670v1","updated":"2023-06-09T04:59:24Z","published":"2023-06-09T04:59:24Z","title":"One-Shot Machine Unlearning with Mnemonic Code","summary":"  Deep learning has achieved significant improvements in accuracy and has been\napplied to various fields. With the spread of deep learning, a new problem has\nalso emerged; deep learning models can sometimes have undesirable information\nfrom an ethical standpoint. This problem must be resolved if deep learning is\nto make sensitive decisions such as hiring and prison sentencing. Machine\nunlearning (MU) is the research area that responds to such demands. MU aims at\nforgetting about undesirable training data from a trained deep learning model.\nA naive MU approach is to re-train the whole model with the training data from\nwhich the undesirable data has been removed. However, re-training the whole\nmodel can take a huge amount of time and consumes significant computer\nresources. To make MU even more practical, a simple-yet-effective MU method is\nrequired. In this paper, we propose a one-shot MU method, which does not need\nadditional training. To design one-shot MU, we add noise to the model\nparameters that are sensitive to undesirable information. In our proposed\nmethod, we use the Fisher information matrix (FIM) to estimate the sensitive\nmodel parameters. Training data were usually used to evaluate the FIM in\nexisting methods. In contrast, we avoid the need to retain the training data\nfor calculating the FIM by using class-specific synthetic signals called\nmnemonic code. Extensive experiments using artificial and natural datasets\ndemonstrate that our method outperforms the existing methods.\n","authors":["Tomoya Yamashita","Masanori Yamada","Takashi Shibata"],"pdf_url":"https://arxiv.org/pdf/2306.05670v1.pdf","comment":"14 pages, welcome coments"},{"id":"http://arxiv.org/abs/2210.00471v5","updated":"2023-06-09T04:55:02Z","published":"2022-10-02T09:42:47Z","title":"OCD: Learning to Overfit with Conditional Diffusion Models","summary":"  We present a dynamic model in which the weights are conditioned on an input\nsample x and are learned to match those that would be obtained by finetuning a\nbase model on x and its label y. This mapping between an input sample and\nnetwork weights is approximated by a denoising diffusion model. The diffusion\nmodel we employ focuses on modifying a single layer of the base model and is\nconditioned on the input, activations, and output of this layer. Since the\ndiffusion model is stochastic in nature, multiple initializations generate\ndifferent networks, forming an ensemble, which leads to further improvements.\nOur experiments demonstrate the wide applicability of the method for image\nclassification, 3D reconstruction, tabular data, speech separation, and natural\nlanguage processing. Our code is available at\nhttps://github.com/ShaharLutatiPersonal/OCD\n","authors":["Shahar Lutati","Lior Wolf"],"pdf_url":"https://arxiv.org/pdf/2210.00471v5.pdf","comment":"Accepted to ICML 2023 (Oral & Poster)"},{"id":"http://arxiv.org/abs/2302.04972v2","updated":"2023-06-09T04:49:55Z","published":"2023-02-09T23:22:48Z","title":"Differentially Private Optimization for Smooth Nonconvex ERM","summary":"  We develop simple differentially private optimization algorithms that move\nalong directions of (expected) descent to find an approximate second-order\nsolution for nonconvex ERM. We use line search, mini-batching, and a two-phase\nstrategy to improve the speed and practicality of the algorithm. Numerical\nexperiments demonstrate the effectiveness of these approaches.\n","authors":["Changyu Gao","Stephen J. Wright"],"pdf_url":"https://arxiv.org/pdf/2302.04972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11956v3","updated":"2023-06-09T04:46:39Z","published":"2023-01-27T19:15:31Z","title":"On the Connection Between MPNN and Graph Transformer","summary":"  Graph Transformer (GT) recently has emerged as a new paradigm of graph\nlearning algorithms, outperforming the previously popular Message Passing\nNeural Network (MPNN) on multiple benchmarks. Previous work (Kim et al., 2022)\nshows that with proper position embedding, GT can approximate MPNN arbitrarily\nwell, implying that GT is at least as powerful as MPNN. In this paper, we study\nthe inverse connection and show that MPNN with virtual node (VN), a commonly\nused heuristic with little theoretical understanding, is powerful enough to\narbitrarily approximate the self-attention layer of GT.\n  In particular, we first show that if we consider one type of linear\ntransformer, the so-called Performer/Linear Transformer (Choromanski et al.,\n2020; Katharopoulos et al., 2020), then MPNN + VN with only O(1) depth and O(1)\nwidth can approximate a self-attention layer in Performer/Linear Transformer.\nNext, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN\nwith O(n^d) width and O(1) depth can approximate the self-attention layer\narbitrarily well, where d is the input feature dimension. Lastly, under some\nassumptions, we provide an explicit construction of MPNN + VN with O(1) width\nand O(n) depth approximating the self-attention layer in GT arbitrarily well.\nOn the empirical side, we demonstrate that 1) MPNN + VN is a surprisingly\nstrong baseline, outperforming GT on the recently proposed Long Range Graph\nBenchmark (LRGB) dataset, 2) our MPNN + VN improves over early implementation\non a wide range of OGB datasets and 3) MPNN + VN outperforms Linear Transformer\nand MPNN on the climate modeling task.\n","authors":["Chen Cai","Truong Son Hy","Rose Yu","Yusu Wang"],"pdf_url":"https://arxiv.org/pdf/2301.11956v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05666v1","updated":"2023-06-09T04:40:38Z","published":"2023-06-09T04:40:38Z","title":"QuestEnvSim: Environment-Aware Simulated Motion Tracking from Sparse\n  Sensors","summary":"  Replicating a user's pose from only wearable sensors is important for many\nAR/VR applications. Most existing methods for motion tracking avoid environment\ninteraction apart from foot-floor contact due to their complex dynamics and\nhard constraints. However, in daily life people regularly interact with their\nenvironment, e.g. by sitting on a couch or leaning on a desk. Using\nReinforcement Learning, we show that headset and controller pose, if combined\nwith physics simulation and environment observations can generate realistic\nfull-body poses even in highly constrained environments. The physics simulation\nautomatically enforces the various constraints necessary for realistic poses,\ninstead of manually specifying them as in many kinematic approaches. These hard\nconstraints allow us to achieve high-quality interaction motions without\ntypical artifacts such as penetration or contact sliding. We discuss three\nfeatures, the environment representation, the contact reward and scene\nrandomization, crucial to the performance of the method. We demonstrate the\ngenerality of the approach through various examples, such as sitting on chairs,\na couch and boxes, stepping over boxes, rocking a chair and turning an office\nchair. We believe these are some of the highest-quality results achieved for\nmotion tracking from sparse sensor with scene interaction.\n","authors":["Sunmin Lee","Sebastian Starke","Yuting Ye","Jungdam Won","Alexander Winkler"],"pdf_url":"https://arxiv.org/pdf/2306.05666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04824v2","updated":"2023-06-09T04:06:36Z","published":"2023-06-07T23:07:55Z","title":"Sparse Linear Centroid-Encoder: A Convex Method for Feature Selection","summary":"  We present a novel feature selection technique, Sparse Linear\nCentroid-Encoder (SLCE). The algorithm uses a linear transformation to\nreconstruct a point as its class centroid and, at the same time, uses the\n$\\ell_1$-norm penalty to filter out unnecessary features from the input data.\nThe original formulation of the optimization problem is nonconvex, but we\npropose a two-step approach, where each step is convex. In the first step, we\nsolve the linear Centroid-Encoder, a convex optimization problem over a matrix\n$A$. In the second step, we only search for a sparse solution over a diagonal\nmatrix $B$ while keeping $A$ fixed. Unlike other linear methods, e.g., Sparse\nSupport Vector Machines and Lasso, Sparse Linear Centroid-Encoder uses a single\nmodel for multi-class data. We present an in-depth empirical analysis of the\nproposed model and show that it promotes sparsity on various data sets,\nincluding high-dimensional biological data. Our experimental results show that\nSLCE has a performance advantage over some state-of-the-art neural\nnetwork-based feature selection techniques.\n","authors":["Tomojit Ghosh","Michael Kirby","Karim Karimov"],"pdf_url":"https://arxiv.org/pdf/2306.04824v2.pdf","comment":"A novel linear feature selection technique using convex optimization.\n  Total 13 pages including references, 7 figures. The article is under review"},{"id":"http://arxiv.org/abs/2306.04795v2","updated":"2023-06-09T03:56:10Z","published":"2023-06-07T21:37:21Z","title":"Feature Selection using Sparse Adaptive Bottleneck Centroid-Encoder","summary":"  We introduce a novel nonlinear model, Sparse Adaptive Bottleneck\nCentroid-Encoder (SABCE), for determining the features that discriminate\nbetween two or more classes. The algorithm aims to extract discriminatory\nfeatures in groups while reconstructing the class centroids in the ambient\nspace and simultaneously use additional penalty terms in the bottleneck layer\nto decrease within-class scatter and increase the separation of different class\ncentroids. The model has a sparsity-promoting layer (SPL) with a one-to-one\nconnection to the input layer. Along with the primary objective, we minimize\nthe $l_{2,1}$-norm of the sparse layer, which filters out unnecessary features\nfrom input data. During training, we update class centroids by taking the\nHadamard product of the centroids and weights of the sparse layer, thus\nignoring the irrelevant features from the target. Therefore the proposed method\nlearns to reconstruct the critical components of class centroids rather than\nthe whole centroids. The algorithm is applied to various real-world data sets,\nincluding high-dimensional biological, image, speech, and accelerometer sensor\ndata. We compared our method to different state-of-the-art feature selection\ntechniques, including supervised Concrete Autoencoders (SCAE), Feature\nSelection Networks (FsNet), Stochastic Gates (STG), and LassoNet. We\nempirically showed that SABCE features often produced better classification\naccuracy than other methods on the sequester test sets, setting new\nstate-of-the-art results.\n","authors":["Tomojit Ghosh","Michael Kirby"],"pdf_url":"https://arxiv.org/pdf/2306.04795v2.pdf","comment":"A novel nonlinear feature selection technique with new state of the\n  art result. 22 pages (including references), 13 figures. The article is in\n  review"},{"id":"http://arxiv.org/abs/2306.05655v1","updated":"2023-06-09T03:51:45Z","published":"2023-06-09T03:51:45Z","title":"Communication-Efficient Zeroth-Order Distributed Online Optimization:\n  Algorithm, Theory, and Applications","summary":"  This paper focuses on a multi-agent zeroth-order online optimization problem\nin a federated learning setting for target tracking. The agents only sense\ntheir current distances to their targets and aim to maintain a minimum safe\ndistance from each other to prevent collisions. The coordination among the\nagents and dissemination of collision-prevention information is managed by a\ncentral server using the federated learning paradigm. The proposed formulation\nleads to an instance of distributed online nonconvex optimization problem that\nis solved via a group of communication-constrained agents. To deal with the\ncommunication limitations of the agents, an error feedback-based compression\nscheme is utilized for agent-to-server communication. The proposed algorithm is\nanalyzed theoretically for the general class of distributed online nonconvex\noptimization problems. We provide non-asymptotic convergence rates that show\nthe dominant term is independent of the characteristics of the compression\nscheme. Our theoretical results feature a new approach that employs\nsignificantly more relaxed assumptions in comparison to standard literature.\nThe performance of the proposed solution is further analyzed numerically in\nterms of tracking errors and collisions between agents in two relevant\napplications.\n","authors":["Ege C. Kaya","M. Berk Sahin","Abolfazl Hashemi"],"pdf_url":"https://arxiv.org/pdf/2306.05655v1.pdf","comment":"21 pages, 5 figures, and this paper has been accepted by IEEE Access"},{"id":"http://arxiv.org/abs/2306.05651v1","updated":"2023-06-09T03:37:27Z","published":"2023-06-09T03:37:27Z","title":"Differentially Private Sharpness-Aware Training","summary":"  Training deep learning models with differential privacy (DP) results in a\ndegradation of performance. The training dynamics of models with DP show a\nsignificant difference from standard training, whereas understanding the\ngeometric properties of private learning remains largely unexplored. In this\npaper, we investigate sharpness, a key factor in achieving better\ngeneralization, in private learning. We show that flat minima can help reduce\nthe negative effects of per-example gradient clipping and the addition of\nGaussian noise. We then verify the effectiveness of Sharpness-Aware\nMinimization (SAM) for seeking flat minima in private learning. However, we\nalso discover that SAM is detrimental to the privacy budget and computational\ntime due to its two-step optimization. Thus, we propose a new sharpness-aware\ntraining method that mitigates the privacy-optimization trade-off. Our\nexperimental results demonstrate that the proposed method improves the\nperformance of deep learning models with DP from both scratch and fine-tuning.\nCode is available at https://github.com/jinseongP/DPSAT.\n","authors":["Jinseong Park","Hoki Kim","Yujin Choi","Jaewook Lee"],"pdf_url":"https://arxiv.org/pdf/2306.05651v1.pdf","comment":"ICML 2023"},{"id":"http://arxiv.org/abs/2306.05649v1","updated":"2023-06-09T03:35:33Z","published":"2023-06-09T03:35:33Z","title":"Specifying and Solving Robust Empirical Risk Minimization Problems Using\n  CVXPY","summary":"  We consider robust empirical risk minimization (ERM), where model parameters\nare chosen to minimize the worst-case empirical loss when each data point\nvaries over a given convex uncertainty set. In some simple cases, such problems\ncan be expressed in an analytical form. In general the problem can be made\ntractable via dualization, which turns a min-max problem into a min-min\nproblem. Dualization requires expertise and is tedious and error-prone. We\ndemonstrate how CVXPY can be used to automate this dualization procedure in a\nuser-friendly manner. Our framework allows practitioners to specify and solve\nrobust ERM problems with a general class of convex losses, capturing many\nstandard regression and classification problems. Users can easily specify any\ncomplex uncertainty set that is representable via disciplined convex\nprogramming (DCP) constraints.\n","authors":["Eric Luxenberg","Dhruv Malik","Yuanzhi Li","Aarti Singh","Stephen Boyd"],"pdf_url":"https://arxiv.org/pdf/2306.05649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.05537v3","updated":"2023-06-09T03:33:00Z","published":"2023-01-13T13:35:43Z","title":"Almost Surely $\\sqrt{T}$ Regret Bound for Adaptive LQR","summary":"  The Linear-Quadratic Regulation (LQR) problem with unknown system parameters\nhas been widely studied, but it has remained unclear whether $\\tilde{\n\\mathcal{O}}(\\sqrt{T})$ regret, which is the best known dependence on time, can\nbe achieved almost surely. In this paper, we propose an adaptive LQR controller\nwith almost surely $\\tilde{ \\mathcal{O}}(\\sqrt{T})$ regret upper bound. The\ncontroller features a circuit-breaking mechanism, which circumvents potential\nsafety breach and guarantees the convergence of the system parameter estimate,\nbut is shown to be triggered only finitely often and hence has negligible\neffect on the asymptotic performance of the controller. The proposed controller\nis also validated via simulation on Tennessee Eastman Process~(TEP), a commonly\nused industrial process example.\n","authors":["Yiwen Lu","Yilin Mo"],"pdf_url":"https://arxiv.org/pdf/2301.05537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.03419v2","updated":"2023-06-09T03:29:05Z","published":"2021-12-06T23:28:38Z","title":"Using Image Transformations to Learn Network Structure","summary":"  Many learning tasks require observing a sequence of images and making a\ndecision. In a transportation problem of designing and planning for shipping\nboxes between nodes, we show how to treat the network of nodes and the flows\nbetween them as images. These images have useful structural information that\ncan be statistically summarized. Using image compression techniques, we reduce\nan image down to a set of numbers that contain interpretable geographic\ninformation that we call geographic signatures. Using geographic signatures, we\nlearn network structure that can be utilized to recommend future network\nconnectivity. We develop a Bayesian reinforcement algorithm that takes\nadvantage of statistically summarized network information as priors and\nuser-decisions to reinforce an agent's probabilistic decision. Additionally, we\nshow how reinforcement learning can be used with compression directly without\ninterpretation in simple tasks.\n","authors":["Brayan Ortiz","Amitabh Sinha"],"pdf_url":"https://arxiv.org/pdf/2112.03419v2.pdf","comment":"11 pages, 6 figures, 5 tables, In Submission with Springer Nature,\n  Computer Science Journal"},{"id":"http://arxiv.org/abs/2212.08230v4","updated":"2023-06-09T03:22:52Z","published":"2022-12-16T01:38:35Z","title":"An Energy-aware and Fault-tolerant Deep Reinforcement Learning based\n  approach for Multi-agent Patrolling Problems","summary":"  Autonomous vehicles are suited for continuous area patrolling problems.\nHowever, finding an optimal patrolling strategy can be challenging for many\nreasons. Firstly, patrolling environments are often complex and can include\nunknown environmental factors, such as wind or landscape. Secondly, autonomous\nvehicles can have failures or hardware constraints, such as limited battery\nlife. Importantly, patrolling large areas often requires multiple agents that\nneed to collectively coordinate their actions. In this work, we consider these\nlimitations and propose an approach based on model-free, deep multi-agent\nreinforcement learning. In this approach, the agents are trained to patrol an\nenvironment with various unknown dynamics and factors. They can automatically\nrecharge themselves to support continuous collective patrolling. A distributed\nhomogeneous multi-agent architecture is proposed, where all patrolling agents\nexecute identical policies locally based on their local observations and shared\nlocation information. This architecture provides a patrolling system that can\ntolerate agent failures and allow supplementary agents to be added to replace\nfailed agents or to increase the overall patrol performance. The solution is\nvalidated through simulation experiments from multiple perspectives, including\nthe overall patrol performance, the efficiency of battery recharging\nstrategies, the overall fault tolerance, and the ability to cooperate with\nsupplementary agents.\n","authors":["Chenhao Tong","Aaron Harwood","Maria A. Rodriguez","Richard O. Sinnott"],"pdf_url":"https://arxiv.org/pdf/2212.08230v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2009.07514v3","updated":"2023-06-09T03:07:57Z","published":"2020-09-16T07:25:50Z","title":"A Unified Approach to Synchronization Problems over Subgroups of the\n  Orthogonal Group","summary":"  The problem of synchronization over a group $\\mathcal{G}$ aims to estimate a\ncollection of group elements $G^*_1, \\dots, G^*_n \\in \\mathcal{G}$ based on\nnoisy observations of a subset of all pairwise ratios of the form $G^*_i\n{G^*_j}^{-1}$. Such a problem has gained much attention recently and finds many\napplications across a wide range of scientific and engineering areas. In this\npaper, we consider the class of synchronization problems in which the group is\na closed subgroup of the orthogonal group. This class covers many group\nsynchronization problems that arise in practice. Our contribution is fivefold.\nFirst, we propose a unified approach for solving this class of group\nsynchronization problems, which consists of a suitable initialization step and\nan iterative refinement step based on the generalized power method, and show\nthat it enjoys a strong theoretical guarantee on the estimation error under\ncertain assumptions on the group, measurement graph, noise, and initialization.\nSecond, we formulate two geometric conditions that are required by our approach\nand show that they hold for various practically relevant subgroups of the\northogonal group. The conditions are closely related to the error-bound\ngeometry of the subgroup -- an important notion in optimization. Third, we\nverify the assumptions on the measurement graph and noise for standard random\ngraph and random matrix models. Fourth, based on the classic notion of metric\nentropy, we develop and analyze a novel spectral-type estimator. Finally, we\nshow via extensive numerical experiments that our proposed non-convex approach\noutperforms existing approaches in terms of computational speed, scalability,\nand/or estimation error.\n","authors":["Huikang Liu","Man-Chung Yue","Anthony Man-Cho So"],"pdf_url":"https://arxiv.org/pdf/2009.07514v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05641v1","updated":"2023-06-09T03:00:34Z","published":"2023-06-09T03:00:34Z","title":"Revisiting Permutation Symmetry for Merging Models between Different\n  Datasets","summary":"  Model merging is a new approach to creating a new model by combining the\nweights of different trained models. Previous studies report that model merging\nworks well for models trained on a single dataset with different random seeds,\nwhile model merging between different datasets is difficult. Merging knowledge\nfrom different datasets has practical significance, but it has not been well\ninvestigated. In this paper, we investigate the properties of merging models\nbetween different datasets. Through theoretical and empirical analyses, we find\nthat the accuracy of the merged model decreases more significantly as the\ndatasets diverge more and that the different loss landscapes for each dataset\nmake model merging between different datasets difficult. We also show that\nmerged models require datasets for merging in order to achieve a high accuracy.\nFurthermore, we show that condensed datasets created by dataset condensation\ncan be used as substitutes for the original datasets when merging models. We\nconduct experiments for model merging between different datasets. When merging\nbetween MNIST and Fashion- MNIST models, the accuracy significantly improves by\n28% using the dataset and 25% using the condensed dataset compared with not\nusing the dataset.\n","authors":["Masanori Yamada","Tomoya Yamashita","Shin'ya Yamaguchi","Daiki Chijiwa"],"pdf_url":"https://arxiv.org/pdf/2306.05641v1.pdf","comment":"18 pages; comments are welcome"},{"id":"http://arxiv.org/abs/2306.05637v1","updated":"2023-06-09T02:47:21Z","published":"2023-06-09T02:47:21Z","title":"On the Importance of Feature Decorrelation for Unsupervised\n  Representation Learning in Reinforcement Learning","summary":"  Recently, unsupervised representation learning (URL) has improved the sample\nefficiency of Reinforcement Learning (RL) by pretraining a model from a large\nunlabeled dataset. The underlying principle of these methods is to learn\ntemporally predictive representations by predicting future states in the latent\nspace. However, an important challenge of this approach is the representational\ncollapse, where the subspace of the latent representations collapses into a\nlow-dimensional manifold. To address this issue, we propose a novel URL\nframework that causally predicts future states while increasing the dimension\nof the latent manifold by decorrelating the features in the latent space.\nThrough extensive empirical studies, we demonstrate that our framework\neffectively learns predictive representations without collapse, which\nsignificantly improves the sample efficiency of state-of-the-art URL methods on\nthe Atari 100k benchmark. The code is available at\nhttps://github.com/dojeon-ai/SimTPR.\n","authors":["Hojoon Lee","Koanho Lee","Dongyoon Hwang","Hyunho Lee","Byungkun Lee","Jaegul Choo"],"pdf_url":"https://arxiv.org/pdf/2306.05637v1.pdf","comment":"Accepted to ICML 2023"},{"id":"http://arxiv.org/abs/2306.04641v2","updated":"2023-06-09T02:46:34Z","published":"2023-05-25T08:24:22Z","title":"Generalizable Low-Resource Activity Recognition with Diverse and\n  Discriminative Representation Learning","summary":"  Human activity recognition (HAR) is a time series classification task that\nfocuses on identifying the motion patterns from human sensor readings. Adequate\ndata is essential but a major bottleneck for training a generalizable HAR\nmodel, which assists customization and optimization of online web applications.\nHowever, it is costly in time and economy to collect large-scale labeled data\nin reality, i.e., the low-resource challenge. Meanwhile, data collected from\ndifferent persons have distribution shifts due to different living habits, body\nshapes, age groups, etc. The low-resource and distribution shift challenges are\ndetrimental to HAR when applying the trained model to new unseen subjects. In\nthis paper, we propose a novel approach called Diverse and Discriminative\nrepresentation Learning (DDLearn) for generalizable low-resource HAR. DDLearn\nsimultaneously considers diversity and discrimination learning. With the\nconstructed self-supervised learning task, DDLearn enlarges the data diversity\nand explores the latent activity properties. Then, we propose a diversity\npreservation module to preserve the diversity of learned features by enlarging\nthe distribution divergence between the original and augmented domains.\nMeanwhile, DDLearn also enhances semantic discrimination by learning\ndiscriminative representations with supervised contrastive learning. Extensive\nexperiments on three public HAR datasets demonstrate that our method\nsignificantly outperforms state-of-art methods by an average accuracy\nimprovement of 9.5% under the low-resource distribution shift scenarios, while\nbeing a generic, explainable, and flexible framework. Code is available at:\nhttps://github.com/microsoft/robustlearn.\n","authors":["Xin Qin","Jindong Wang","Shuo Ma","Wang Lu","Yongchun Zhu","Xing Xie","Yiqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2306.04641v2.pdf","comment":"Accepted by SIGKDD 2023 Research track; 12 pages; Code is available\n  at: https://github.com/microsoft/robustlearn"}]}}